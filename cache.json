{"2024-11-08T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2411.05787v1","updated":"2024-11-08T18:57:07Z","published":"2024-11-08T18:57:07Z","title":"Recycled Attention: Efficient inference for long-context language models","summary":"  Generating long sequences of tokens given a long-context input imposes a\nheavy computational burden for large language models (LLMs). One of the\ncomputational bottleneck comes from computing attention over a long sequence of\ninput at each generation step. In this paper, we propose Recycled Attention, an\ninference-time method which alternates between full context attention and\nattention over a subset of input tokens. When performing partial attention, we\nrecycle the attention pattern of a previous token that has performed full\nattention and attend only to the top K most attended tokens, reducing the cost\nof data movement and attention computation. Compared to previously proposed\ninference-time acceleration method which attends only to local context or\ntokens with high accumulative attention scores, our approach flexibly chooses\ntokens that are relevant to the current decoding step. We evaluate our methods\non RULER, a suite of tasks designed to comprehensively evaluate long-context\nabilities, and long-context language modeling tasks. Applying our method to\noff-the-shelf LLMs achieves comparable speedup to baselines which only consider\nlocal context while improving the performance by 2x. We further explore two\nideas to improve performance-efficiency trade-offs: (1) dynamically decide when\nto perform recycled or full attention step based on the query similarities and\n(2) continued pre-training the model with Recycled Attention.\n","authors":["Fangyuan Xu","Tanya Goyal","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2411.05787v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08627v2","updated":"2024-11-08T18:56:42Z","published":"2024-04-12T17:41:05Z","title":"Is ChatGPT Transforming Academics' Writing Style?","summary":"  Based on one million arXiv papers submitted from May 2018 to January 2024, we\nassess the textual density of ChatGPT's writing style in their abstracts\nthrough a statistical analysis of word frequency changes. Our model is\ncalibrated and validated on a mixture of real abstracts and ChatGPT-modified\nabstracts (simulated data) after a careful noise analysis. The words used for\nestimation are not fixed but adaptive, including those with decreasing\nfrequency. We find that large language models (LLMs), represented by ChatGPT,\nare having an increasing impact on arXiv abstracts, especially in the field of\ncomputer science, where the fraction of LLM-style abstracts is estimated to be\napproximately 35%, if we take the responses of GPT-3.5 to one simple prompt,\n\"revise the following sentences\", as a baseline. We conclude with an analysis\nof both positive and negative aspects of the penetration of LLMs into\nacademics' writing style.\n","authors":["Mingmeng Geng","Roberto Trotta"],"pdf_url":"https://arxiv.org/pdf/2404.08627v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2403.09539v3","updated":"2024-11-08T18:56:41Z","published":"2024-03-14T16:27:49Z","title":"Logits of API-Protected LLMs Leak Proprietary Information","summary":"  Large language model (LLM) providers often hide the architectural details and\nparameters of their proprietary models by restricting public access to a\nlimited API. In this work we show that, with only a conservative assumption\nabout the model architecture, it is possible to learn a surprisingly large\namount of non-public information about an API-protected LLM from a relatively\nsmall number of API queries (e.g., costing under $1000 USD for OpenAI's\ngpt-3.5-turbo). Our findings are centered on one key observation: most modern\nLLMs suffer from a softmax bottleneck, which restricts the model outputs to a\nlinear subspace of the full output space. We exploit this fact to unlock\nseveral capabilities, including (but not limited to) obtaining cheap\nfull-vocabulary outputs, auditing for specific types of model updates,\nidentifying the source LLM given a single full LLM output, and even efficiently\ndiscovering the LLM's hidden size. Our empirical investigations show the\neffectiveness of our methods, which allow us to estimate the embedding size of\nOpenAI's gpt-3.5-turbo to be about 4096. Lastly, we discuss ways that LLM\nproviders can guard against these attacks, as well as how these capabilities\ncan be viewed as a feature (rather than a bug) by allowing for greater\ntransparency and accountability.\n","authors":["Matthew Finlayson","Xiang Ren","Swabha Swayamdipta"],"pdf_url":"https://arxiv.org/pdf/2403.09539v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05783v1","updated":"2024-11-08T18:50:37Z","published":"2024-11-08T18:50:37Z","title":"ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles","summary":"  Deaf and hard-of-hearing (DHH) students face significant barriers in\naccessing science, technology, engineering, and mathematics (STEM) education,\nnotably due to the scarcity of STEM resources in signed languages. To help\naddress this, we introduce ASL STEM Wiki: a parallel corpus of 254 Wikipedia\narticles on STEM topics in English, interpreted into over 300 hours of American\nSign Language (ASL). ASL STEM Wiki is the first continuous signing dataset\nfocused on STEM, facilitating the development of AI resources for STEM\neducation in ASL. We identify several use cases of ASL STEM Wiki with\nhuman-centered applications. For example, because this dataset highlights the\nfrequent use of fingerspelling for technical concepts, which inhibits DHH\nstudents' ability to learn, we develop models to identify fingerspelled words\n-- which can later be used to query for appropriate ASL signs to suggest to\ninterpreters.\n","authors":["Kayo Yin","Chinmay Singh","Fyodor O. Minakov","Vanessa Milan","Hal Daum√© III","Cyril Zhang","Alex X. Lu","Danielle Bragg"],"pdf_url":"https://arxiv.org/pdf/2411.05783v1.pdf","comment":"Accepted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05781v1","updated":"2024-11-08T18:48:57Z","published":"2024-11-08T18:48:57Z","title":"Using Language Models to Disambiguate Lexical Choices in Translation","summary":"  In translation, a concept represented by a single word in a source language\ncan have multiple variations in a target language. The task of lexical\nselection requires using context to identify which variation is most\nappropriate for a source text. We work with native speakers of nine languages\nto create DTAiLS, a dataset of 1,377 sentence pairs that exhibit cross-lingual\nconcept variation when translating from English. We evaluate recent LLMs and\nneural machine translation systems on DTAiLS, with the best-performing model,\nGPT-4, achieving from 67 to 85% accuracy across languages. Finally, we use\nlanguage models to generate English rules describing target-language concept\nvariations. Providing weaker models with high-quality lexical rules improves\naccuracy substantially, in some cases reaching or outperforming GPT-4.\n","authors":["Josh Barua","Sanjay Subramanian","Kayo Yin","Alane Suhr"],"pdf_url":"https://arxiv.org/pdf/2411.05781v1.pdf","comment":"Accepted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05778v1","updated":"2024-11-08T18:45:06Z","published":"2024-11-08T18:45:06Z","title":"LLMs as Method Actors: A Model for Prompt Engineering and Architecture","summary":"  We introduce \"Method Actors\" as a mental model for guiding LLM prompt\nengineering and prompt architecture. Under this mental model, LLMs should be\nthought of as actors; prompts as scripts and cues; and LLM responses as\nperformances. We apply this mental model to the task of improving LLM\nperformance at playing Connections, a New York Times word puzzle game that\nprior research identified as a challenging benchmark for evaluating LLM\nreasoning. Our experiments with GPT-4o show that a \"Method Actors\" approach can\nsignificantly improve LLM performance over both a vanilla and \"Chain of\nThoughts\" approach. A vanilla approach solves 27% of Connections puzzles in our\ndataset and a \"Chain of Thoughts\" approach solves 41% of puzzles, whereas our\nstrongest \"Method Actor\" approach solves 86% of puzzles. We also test OpenAI's\nnewest model designed specifically for complex reasoning tasks, o1-preview.\nWhen asked to solve a puzzle all at once, o1-preview solves 79% of Connections\npuzzles in our dataset, and when allowed to build puzzle solutions one guess at\na time over multiple API calls, o1-preview solves 100% of the puzzles.\nIncorporating a \"Method Actor\" prompt architecture increases the percentage of\npuzzles that o1-preview solves perfectly from 76% to 87%.\n","authors":["Colin Doyle"],"pdf_url":"https://arxiv.org/pdf/2411.05778v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05777v1","updated":"2024-11-08T18:43:15Z","published":"2024-11-08T18:43:15Z","title":"Quantitative Assessment of Intersectional Empathetic Bias and\n  Understanding","summary":"  A growing amount of literature critiques the current operationalizations of\nempathy based on loose definitions of the construct. Such definitions\nnegatively affect dataset quality, model robustness, and evaluation\nreliability. We propose an empathy evaluation framework that operationalizes\nempathy close to its psychological origins. The framework measures the variance\nin responses of LLMs to prompts using existing metrics for empathy and\nemotional valence. The variance is introduced through the controlled generation\nof the prompts by varying social biases affecting context understanding, thus\nimpacting empathetic understanding. The control over generation ensures high\ntheoretical validity of the constructs in the prompt dataset. Also, it makes\nhigh-quality translation, especially into languages that currently have\nlittle-to-no way of evaluating empathy or bias, such as the Slavonic family,\nmore manageable. Using chosen LLMs and various prompt types, we demonstrate the\nempathy evaluation with the framework, including multiple-choice answers and\nfree generation. The variance in our initial evaluation sample is small and we\nwere unable to measure convincing differences between the empathetic\nunderstanding in contexts given by different social groups. However, the\nresults are promising because the models showed significant alterations their\nreasoning chains needed to capture the relatively subtle changes in the\nprompts. This provides the basis for future research into the construction of\nthe evaluation sample and statistical methods for measuring the results.\n","authors":["Vojtech Formanek","Ondrej Sotolar"],"pdf_url":"https://arxiv.org/pdf/2411.05777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05775v1","updated":"2024-11-08T18:36:33Z","published":"2024-11-08T18:36:33Z","title":"Fact or Fiction? Can LLMs be Reliable Annotators for Political Truths?","summary":"  Political misinformation poses significant challenges to democratic\nprocesses, shaping public opinion and trust in media. Manual fact-checking\nmethods face issues of scalability and annotator bias, while machine learning\nmodels require large, costly labelled datasets. This study investigates the use\nof state-of-the-art large language models (LLMs) as reliable annotators for\ndetecting political factuality in news articles. Using open-source LLMs, we\ncreate a politically diverse dataset, labelled for bias through LLM-generated\nannotations. These annotations are validated by human experts and further\nevaluated by LLM-based judges to assess the accuracy and reliability of the\nannotations. Our approach offers a scalable and robust alternative to\ntraditional fact-checking, enhancing transparency and public trust in media.\n","authors":["Veronica Chatrath","Marcelo Lotif","Shaina Raza"],"pdf_url":"https://arxiv.org/pdf/2411.05775v1.pdf","comment":"Accepted at Socially Responsible Language Modelling Research (SoLaR)\n  Workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05764v1","updated":"2024-11-08T18:26:17Z","published":"2024-11-08T18:26:17Z","title":"FinDVer: Explainable Claim Verification over Long and Hybrid-Content\n  Financial Documents","summary":"  We introduce FinDVer, a comprehensive benchmark specifically designed to\nevaluate the explainable claim verification capabilities of LLMs in the context\nof understanding and analyzing long, hybrid-content financial documents.\nFinDVer contains 2,400 expert-annotated examples, divided into three subsets:\ninformation extraction, numerical reasoning, and knowledge-intensive reasoning,\neach addressing common scenarios encountered in real-world financial contexts.\nWe assess a broad spectrum of LLMs under long-context and RAG settings. Our\nresults show that even the current best-performing system, GPT-4o, still lags\nbehind human experts. We further provide in-depth analysis on long-context and\nRAG setting, Chain-of-Thought reasoning, and model reasoning errors, offering\ninsights to drive future advancements. We believe that FinDVer can serve as a\nvaluable benchmark for evaluating LLMs in claim verification over complex,\nexpert-domain documents.\n","authors":["Yilun Zhao","Yitao Long","Yuru Jiang","Chengye Wang","Weiyuan Chen","Hongjun Liu","Yiming Zhang","Xiangru Tang","Chen Zhao","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2411.05764v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05762v1","updated":"2024-11-08T18:25:06Z","published":"2024-11-08T18:25:06Z","title":"Multi-hop Evidence Pursuit Meets the Web: Team Papelo at FEVER 2024","summary":"  Separating disinformation from fact on the web has long challenged both the\nsearch and the reasoning powers of humans. We show that the reasoning power of\nlarge language models (LLMs) and the retrieval power of modern search engines\ncan be combined to automate this process and explainably verify claims. We\nintegrate LLMs and search under a multi-hop evidence pursuit strategy. This\nstrategy generates an initial question based on an input claim using a sequence\nto sequence model, searches and formulates an answer to the question, and\niteratively generates follow-up questions to pursue the evidence that is\nmissing using an LLM. We demonstrate our system on the FEVER 2024 (AVeriTeC)\nshared task. Compared to a strategy of generating all the questions at once,\nour method obtains .045 higher label accuracy and .155 higher AVeriTeC score\n(evaluating the adequacy of the evidence). Through ablations, we show the\nimportance of various design choices, such as the question generation method,\nmedium-sized context, reasoning with one document at a time, adding metadata,\nparaphrasing, reducing the problem to two classes, and reconsidering the final\nverdict. Our submitted system achieves .510 AVeriTeC score on the dev set and\n.477 AVeriTeC score on the test set.\n","authors":["Christopher Malon"],"pdf_url":"https://arxiv.org/pdf/2411.05762v1.pdf","comment":"To appear in the Seventh FEVER Workshop at EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05755v1","updated":"2024-11-08T18:16:58Z","published":"2024-11-08T18:16:58Z","title":"End-to-End Navigation with Vision Language Models: Transforming Spatial\n  Reasoning into Question-Answering","summary":"  We present VLMnav, an embodied framework to transform a Vision-Language Model\n(VLM) into an end-to-end navigation policy. In contrast to prior work, we do\nnot rely on a separation between perception, planning, and control; instead, we\nuse a VLM to directly select actions in one step. Surprisingly, we find that a\nVLM can be used as an end-to-end policy zero-shot, i.e., without any\nfine-tuning or exposure to navigation data. This makes our approach open-ended\nand generalizable to any downstream navigation task. We run an extensive study\nto evaluate the performance of our approach in comparison to baseline prompting\nmethods. In addition, we perform a design analysis to understand the most\nimpactful design decisions. Visual examples and code for our project can be\nfound at https://jirl-upenn.github.io/VLMnav/\n","authors":["Dylan Goetting","Himanshu Gaurav Singh","Antonio Loquercio"],"pdf_url":"https://arxiv.org/pdf/2411.05755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05752v1","updated":"2024-11-08T18:10:46Z","published":"2024-11-08T18:10:46Z","title":"FisherMask: Enhancing Neural Network Labeling Efficiency in Image\n  Classification Using Fisher Information","summary":"  Deep learning (DL) models are popular across various domains due to their\nremarkable performance and efficiency. However, their effectiveness relies\nheavily on large amounts of labeled data, which are often time-consuming and\nlabor-intensive to generate manually. To overcome this challenge, it is\nessential to develop strategies that reduce reliance on extensive labeled data\nwhile preserving model performance. In this paper, we propose FisherMask, a\nFisher information-based active learning (AL) approach that identifies key\nnetwork parameters by masking them based on their Fisher information values.\nFisherMask enhances batch AL by using Fisher information to select the most\ncritical parameters, allowing the identification of the most impactful samples\nduring AL training. Moreover, Fisher information possesses favorable\nstatistical properties, offering valuable insights into model behavior and\nproviding a better understanding of the performance characteristics within the\nAL pipeline. Our extensive experiments demonstrate that FisherMask\nsignificantly outperforms state-of-the-art methods on diverse datasets,\nincluding CIFAR-10 and FashionMNIST, especially under imbalanced settings.\nThese improvements lead to substantial gains in labeling efficiency. Hence\nserving as an effective tool to measure the sensitivity of model parameters to\ndata samples. Our code is available on\n\\url{https://github.com/sgchr273/FisherMask}.\n","authors":["Shreen Gul","Mohamed Elmahallawy","Sanjay Madria","Ardhendu Tripathy"],"pdf_url":"https://arxiv.org/pdf/2411.05752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05735v1","updated":"2024-11-08T17:50:24Z","published":"2024-11-08T17:50:24Z","title":"Aioli: A Unified Optimization Framework for Language Model Data Mixing","summary":"  Language model performance depends on identifying the optimal mixture of data\ngroups to train on (e.g., law, code, math). Prior work has proposed a diverse\nset of methods to efficiently learn mixture proportions, ranging from fitting\nregression models over training runs to dynamically updating proportions\nthroughout training. Surprisingly, we find that no existing method consistently\noutperforms a simple stratified sampling baseline in terms of average test\nperplexity per group. In this paper, we study the cause of this inconsistency\nby unifying existing methods into a standard optimization framework. We show\nthat all methods set proportions to minimize total loss, subject to a\nmethod-specific mixing law -- an assumption on how loss is a function of\nmixture proportions. We find that existing parameterizations of mixing laws can\nexpress the true loss-proportion relationship empirically, but the methods\nthemselves often set the mixing law parameters inaccurately, resulting in poor\nand inconsistent performance. Finally, we leverage the insights from our\nframework to derive a new online method named Aioli, which directly estimates\nthe mixing law parameters throughout training and uses them to dynamically\nadjust proportions. Empirically, Aioli outperforms stratified sampling on 6 out\nof 6 datasets by an average of 0.28 test perplexity points, whereas existing\nmethods fail to consistently beat stratified sampling, doing up to 6.9 points\nworse. Moreover, in a practical setting where proportions are learned on\nshorter runs due to computational constraints, Aioli can dynamically adjust\nthese proportions over the full training run, consistently improving\nperformance over existing methods by up to 12.01 test perplexity points.\n","authors":["Mayee F. Chen","Michael Y. Hu","Nicholas Lourie","Kyunghyun Cho","Christopher R√©"],"pdf_url":"https://arxiv.org/pdf/2411.05735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01914v2","updated":"2024-11-08T17:33:31Z","published":"2024-06-04T02:51:26Z","title":"HPE-CogVLM: Advancing Vision Language Models with a Head Pose Grounding\n  Task","summary":"  Head pose estimation (HPE) requires a sophisticated understanding of 3D\nspatial relationships to generate precise yaw, pitch, and roll angles. Previous\nHPE models, primarily CNN-based, rely on cropped close-up human head images as\ninputs and often lack robustness in real-world scenario. Vision Language Models\n(VLMs) can analyze entire images while focusing on specific objects through\ntheir attention mechanisms. In this paper, we propose a novel framework to\nimprove the HPE accuracy by leveraging the object detection grounding\ncapability of a VLM, referred to as CogVLM. We empirically find that directly\nLoRA fine-tuning of this VLM for the HPE task fails to achieve desirable HPE\naccuracy, while some model merging methods can improve accuracy but frequently\nproduce blended invalid response formats, struggling to handle both object\ndetection and HPE tasks simultaneously. To integrate HPE capability into CogVLM\neffectively, we develop a novel LoRA layer-based model merging method. This\nmerging approach applies a high cosine similarity threshold and a\nwinner-takes-all layer selection strategy, aligning attention to the HPE task\nwhile preserving original object detection knowledge. It successfully resolves\nissues with blended invalid response formats and improves accuracy. Results\nshow that our HPE-CogVLM achieves a 31.5\\% reduction in Mean Absolute Error\nover the current state-of-the-art CNN model, 6DRepNet, in cross-dataset\nevaluation. Furthermore, HPE-CogVLM outperforms both directly LoRA fine-tuned\nand task arithmetic-based merged VLMs across all HPE metrics.\n","authors":["Yu Tian","Tianqi Shao","Tsukasa Demizu","Xuyang Wu","Hsin-Tai Wu"],"pdf_url":"https://arxiv.org/pdf/2406.01914v2.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2411.05706v1","updated":"2024-11-08T17:07:01Z","published":"2024-11-08T17:07:01Z","title":"Image2Text2Image: A Novel Framework for Label-Free Evaluation of\n  Image-to-Text Generation with Text-to-Image Diffusion Models","summary":"  Evaluating the quality of automatically generated image descriptions is a\ncomplex task that requires metrics capturing various dimensions, such as\ngrammaticality, coverage, accuracy, and truthfulness. Although human evaluation\nprovides valuable insights, its cost and time-consuming nature pose\nlimitations. Existing automated metrics like BLEU, ROUGE, METEOR, and CIDEr\nattempt to fill this gap, but they often exhibit weak correlations with human\njudgment. To address this challenge, we propose a novel evaluation framework\ncalled Image2Text2Image, which leverages diffusion models, such as Stable\nDiffusion or DALL-E, for text-to-image generation. In the Image2Text2Image\nframework, an input image is first processed by a selected image captioning\nmodel, chosen for evaluation, to generate a textual description. Using this\ngenerated description, a diffusion model then creates a new image. By comparing\nfeatures extracted from the original and generated images, we measure their\nsimilarity using a designated similarity metric. A high similarity score\nsuggests that the model has produced a faithful textual description, while a\nlow score highlights discrepancies, revealing potential weaknesses in the\nmodel's performance. Notably, our framework does not rely on human-annotated\nreference captions, making it a valuable tool for assessing image captioning\nmodels. Extensive experiments and human evaluations validate the efficacy of\nour proposed Image2Text2Image evaluation framework. The code and dataset will\nbe published to support further research in the community.\n","authors":["Jia-Hong Huang","Hongyi Zhu","Yixian Shen","Stevan Rudinac","Evangelos Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2411.05706v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2408.01723"},{"id":"http://arxiv.org/abs/2406.02791v2","updated":"2024-11-08T16:50:24Z","published":"2024-06-04T21:29:56Z","title":"Language Models can Infer Action Semantics for Symbolic Planners from\n  Environment Feedback","summary":"  Symbolic planners can discover a sequence of actions from initial to goal\nstates given expert-defined, domain-specific logical action semantics. Large\nLanguage Models (LLMs) can directly generate such sequences, but limitations in\nreasoning and state-tracking often result in plans that are insufficient or\nunexecutable. We propose Predicting Semantics of Actions with Language Models\n(PSALM), which automatically learns action semantics by leveraging the\nstrengths of both symbolic planners and LLMs. PSALM repeatedly proposes and\nexecutes plans, using the LLM to partially generate plans and to infer\ndomain-specific action semantics based on execution outcomes. PSALM maintains a\nbelief over possible action semantics that is iteratively updated until a goal\nstate is reached. Experiments on 7 environments show that when learning just\nfrom one goal, PSALM boosts plan success rate from 36.4% (on Claude-3.5) to\n100%, and explores the environment more efficiently than prior work to infer\nground truth domain action semantics.\n","authors":["Wang Zhu","Ishika Singh","Robin Jia","Jesse Thomason"],"pdf_url":"https://arxiv.org/pdf/2406.02791v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.05977v3","updated":"2024-11-08T16:42:41Z","published":"2024-09-09T18:21:28Z","title":"Mathematical Formalized Problem Solving and Theorem Proving in Different\n  Fields in Lean 4","summary":"  Formalizing mathematical proofs using computerized verification languages\nlike Lean 4 has the potential to significantly impact the field of mathematics,\nit offers prominent capabilities for advancing mathematical reasoning. However,\nexisting efforts are largely limited to creating formalized versions of proofs\nfrom extensive online mathematical corpora, struggling to keep pace with the\nrapidly evolving nature of mathematics. To bridge the gap between traditional\nand computerized proof techniques, this paper explores the use of Large\nLanguage Models (LLMs) to generate formal proof steps and complete formalized\nproofs. By converting natural language (NL) mathematical proofs into formalized\nversions, this work introduces the basic structure and tactics of the Lean 4\nlanguage. The goal is to determine how AI can be leveraged to assist the\nmathematical formalization process and improve its performance. Several\nexamples are provided that demonstrate solving problems using both traditional\nand Lean 4-based approaches. Ultimately, this paper presents an explanation of\nthe foundations of Lean 4 and comparative analyses of the mathematical\nformalization process using traditional and AI-augmented techniques. The\nfindings indicate that AI- powered tools have significant potential to\naccelerate and enhance the formalization of mathematical proofs, paving the way\nfor more efficient and reliable theorem-proving for AI for Math in the future.\n","authors":["Xichen Tang"],"pdf_url":"https://arxiv.org/pdf/2409.05977v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05691v1","updated":"2024-11-08T16:42:33Z","published":"2024-11-08T16:42:33Z","title":"Asterisk*: Keep it Simple","summary":"  This paper describes Asterisk, a compact GPT-based model for generating text\nembeddings. The model uses a minimalist architecture with two layers, two\nattention heads, and 256 embedding dimensions. By applying knowledge\ndistillation from larger pretrained models, we explore the trade-offs between\nmodel size and performance while minimizing computational and memory\nrequirements. The model is primarily evaluated and optimized for classification\ntasks, with experimental results showing its moderate performance in zero-shot\nclassification across various downstream applications. With additional\nconfiguration, the model performance can approach or even surpass that of\nlarger architectures on specific classification tasks.\n","authors":["Andrew Semenov"],"pdf_url":"https://arxiv.org/pdf/2411.05691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00177v2","updated":"2024-11-08T16:42:18Z","published":"2024-10-31T19:48:12Z","title":"LLM4Mat-Bench: Benchmarking Large Language Models for Materials Property\n  Prediction","summary":"  Large language models (LLMs) are increasingly being used in materials\nscience. However, little attention has been given to benchmarking and\nstandardized evaluation for LLM-based materials property prediction, which\nhinders progress. We present LLM4Mat-Bench, the largest benchmark to date for\nevaluating the performance of LLMs in predicting the properties of crystalline\nmaterials. LLM4Mat-Bench contains about 1.9M crystal structures in total,\ncollected from 10 publicly available materials data sources, and 45 distinct\nproperties. LLM4Mat-Bench features different input modalities: crystal\ncomposition, CIF, and crystal text description, with 4.7M, 615.5M, and 3.1B\ntokens in total for each modality, respectively. We use LLM4Mat-Bench to\nfine-tune models with different sizes, including LLM-Prop and MatBERT, and\nprovide zero-shot and few-shot prompts to evaluate the property prediction\ncapabilities of LLM-chat-like models, including Llama, Gemma, and Mistral. The\nresults highlight the challenges of general-purpose LLMs in materials science\nand the need for task-specific predictive models and task-specific\ninstruction-tuned LLMs in materials property prediction.\n","authors":["Andre Niyongabo Rubungo","Kangming Li","Jason Hattrick-Simpers","Adji Bousso Dieng"],"pdf_url":"https://arxiv.org/pdf/2411.00177v2.pdf","comment":"Accepted at NeurIPS 2024-AI4Mat Workshop. The Benchmark and code can\n  be found at: https://github.com/vertaix/LLM4Mat-Bench"},{"id":"http://arxiv.org/abs/2408.05646v2","updated":"2024-11-08T16:29:33Z","published":"2024-08-10T22:47:12Z","title":"Eigen Attention: Attention in Low-Rank Space for KV Cache Compression","summary":"  Large language models (LLMs) represent a groundbreaking advancement in the\ndomain of natural language processing due to their impressive reasoning\nabilities. Recently, there has been considerable interest in increasing the\ncontext lengths for these models to enhance their applicability to complex\ntasks. However, at long context lengths and large batch sizes, the key-value\n(KV) cache, which stores the attention keys and values, emerges as the new\nbottleneck in memory usage during inference. To address this, we propose Eigen\nAttention, which performs the attention operation in a low-rank space, thereby\nreducing the KV cache memory overhead. Our proposed approach is orthogonal to\nexisting KV cache compression techniques and can be used synergistically with\nthem. Through extensive experiments over OPT, MPT, and Llama model families, we\ndemonstrate that Eigen Attention results in up to 40% reduction in KV cache\nsizes and up to 60% reduction in attention operation latency with minimal drop\nin performance. Code is available at\nhttps://github.com/UtkarshSaxena1/EigenAttn.\n","authors":["Utkarsh Saxena","Gobinda Saha","Sakshi Choudhary","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2408.05646v2.pdf","comment":"12 page, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.02525v4","updated":"2024-11-08T16:26:22Z","published":"2024-10-03T14:33:34Z","title":"Contextual Document Embeddings","summary":"  Dense document embeddings are central to neural retrieval. The dominant\nparadigm is to train and construct embeddings by running encoders directly on\nindividual documents. In this work, we argue that these embeddings, while\neffective, are implicitly out-of-context for targeted use cases of retrieval,\nand that a contextualized document embedding should take into account both the\ndocument and neighboring documents in context - analogous to contextualized\nword embeddings. We propose two complementary methods for contextualized\ndocument embeddings: first, an alternative contrastive learning objective that\nexplicitly incorporates the document neighbors into the intra-batch contextual\nloss; second, a new contextual architecture that explicitly encodes neighbor\ndocument information into the encoded representation. Results show that both\nmethods achieve better performance than biencoders in several settings, with\ndifferences especially pronounced out-of-domain. We achieve state-of-the-art\nresults on the MTEB benchmark with no hard negative mining, score distillation,\ndataset-specific instructions, intra-GPU example-sharing, or extremely large\nbatch sizes. Our method can be applied to improve performance on any\ncontrastive learning dataset and any biencoder.\n","authors":["John X. Morris","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2410.02525v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05665v1","updated":"2024-11-08T16:07:47Z","published":"2024-11-08T16:07:47Z","title":"Unmasking the Limits of Large Language Models: A Systematic Evaluation\n  of Masked Text Processing Ability through MskQA and MskCal","summary":"  This paper sheds light on the limitations of Large Language Models (LLMs) by\nrigorously evaluating their ability to process masked text. We introduce two\nnovel tasks: MskQA, measuring reasoning on masked question-answering datasets\nlike RealtimeQA, and MskCal, assessing numerical reasoning on masked arithmetic\nproblems.Testing GPT-4o and 4o-mini reveals that while LLMs exhibit some\nresilience to masked text, their performance is highly contingent on masking\nrates and semantic cues. Specifically, \"solid masking,\" where semantic clues\nare entirely absent, leads to a significant performance drop compared to\n\"partial lifting,\" where some semantic information is retained, indicating\nLLMs' reliance on surface-level patterns. Interestingly, GPT-4o consistently\noutperforms 4o-mini, particularly in MskCal, demonstrating a greater ability to\nhandle numerical reasoning with masked text. This underscores the crucial role\nof semantic cues in the reasoning process of LLMs. Our study illuminates the\ninterplay between background knowledge and reasoning ability in masked text\nprocessing, paving the way for a deeper understanding of LLM capabilities and\nlimitations, and highlighting the need for more robust evaluation methods to\naccurately assess their true comprehension abilities.\n","authors":["Fuka Matsuzaki","Haru-Tada Sato"],"pdf_url":"https://arxiv.org/pdf/2411.05665v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2411.04920v2","updated":"2024-11-08T16:06:09Z","published":"2024-11-07T17:57:03Z","title":"GPTKB: Building Very Large Knowledge Bases from Language Models","summary":"  General-domain knowledge bases (KB), in particular the \"big three\" --\nWikidata, Yago and DBpedia -- are the backbone of many intelligent\napplications. While these three have seen steady development, comprehensive KB\nconstruction at large has seen few fresh attempts. In this work, we propose to\nbuild a large general-domain KB entirely from a large language model (LLM). We\ndemonstrate the feasibility of large-scale KB construction from LLMs, while\nhighlighting specific challenges arising around entity recognition, entity and\nproperty canonicalization, and taxonomy construction. As a prototype, we use\nGPT-4o-mini to construct GPTKB, which contains 105 million triples for more\nthan 2.9 million entities, at a cost 100x less than previous KBC projects. Our\nwork is a landmark for two fields: For NLP, for the first time, it provides\n\\textit{constructive} insights into the knowledge (or beliefs) of LLMs. For the\nSemantic Web, it shows novel ways forward for the long-standing challenge of\ngeneral-domain KB construction. GPTKB is accessible at http://gptkb.org.\n","authors":["Yujia Hu","Shrestha Ghosh","Tuan-Phong Nguyen","Simon Razniewski"],"pdf_url":"https://arxiv.org/pdf/2411.04920v2.pdf","comment":"11 pages, 4 tables"},{"id":"http://arxiv.org/abs/2406.14553v2","updated":"2024-11-08T15:50:51Z","published":"2024-06-20T17:58:34Z","title":"xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned\n  MT Evaluation Metrics","summary":"  State-of-the-art trainable machine translation evaluation metrics like xCOMET\nachieve high correlation with human judgment but rely on large encoders (up to\n10.7B parameters), making them computationally expensive and inaccessible to\nresearchers with limited resources. To address this issue, we investigate\nwhether the knowledge stored in these large encoders can be compressed while\nmaintaining quality. We employ distillation, quantization, and pruning\ntechniques to create efficient xCOMET alternatives and introduce a novel data\ncollection pipeline for efficient black-box distillation. Our experiments show\nthat, using quantization, xCOMET can be compressed up to three times with no\nquality degradation. Additionally, through distillation, we create an\n278M-sized xCOMET-lite metric, which has only 2.6% of xCOMET-XXL parameters,\nbut retains 92.1% of its quality. Besides, it surpasses strong small-scale\nmetrics like COMET-22 and BLEURT-20 on the WMT22 metrics challenge dataset by\n6.4%, despite using 50% fewer parameters. All code, dataset, and models are\navailable online at https://github.com/NL2G/xCOMET-lite.\n","authors":["Daniil Larionov","Mikhail Seleznyov","Vasiliy Viskov","Alexander Panchenko","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2406.14553v2.pdf","comment":"EMNLP 2024 (Main Conference) Camera-Ready Version"},{"id":"http://arxiv.org/abs/2411.05641v1","updated":"2024-11-08T15:35:43Z","published":"2024-11-08T15:35:43Z","title":"Evaluating Large Language Model Capability in Vietnamese Fact-Checking\n  Data Generation","summary":"  Large Language Models (LLMs), with gradually improving reading comprehension\nand reasoning capabilities, are being applied to a range of complex language\ntasks, including the automatic generation of language data for various\npurposes. However, research on applying LLMs for automatic data generation in\nlow-resource languages like Vietnamese is still underdeveloped and lacks\ncomprehensive evaluation. In this paper, we explore the use of LLMs for\nautomatic data generation for the Vietnamese fact-checking task, which faces\nsignificant data limitations. Specifically, we focus on fact-checking data\nwhere claims are synthesized from multiple evidence sentences to assess the\ninformation synthesis capabilities of LLMs. We develop an automatic data\nconstruction process using simple prompt techniques on LLMs and explore several\nmethods to improve the quality of the generated data. To evaluate the quality\nof the data generated by LLMs, we conduct both manual quality assessments and\nperformance evaluations using language models. Experimental results and manual\nevaluations illustrate that while the quality of the generated data has\nsignificantly improved through fine-tuning techniques, LLMs still cannot match\nthe data quality produced by humans.\n","authors":["Long Truong To","Hung Tuan Le","Dat Van-Thanh Nguyen","Manh Trong Nguyen","Tri Thien Nguyen","Tin Van Huynh","Kiet Van Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.05641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05639v1","updated":"2024-11-08T15:34:08Z","published":"2024-11-08T15:34:08Z","title":"Assessing Open-Source Large Language Models on Argumentation Mining\n  Subtasks","summary":"  We explore the capability of four open-sourcelarge language models (LLMs) in\nargumentation mining (AM). We conduct experiments on three different corpora;\npersuasive essays(PE), argumentative microtexts (AMT) Part 1 and Part 2, based\non two argumentation mining sub-tasks: (i) argumentative discourse units\nclassifications (ADUC), and (ii) argumentative relation classification (ARC).\nThis work aims to assess the argumentation capability of open-source LLMs,\nincluding Mistral 7B, Mixtral8x7B, LlamA2 7B and LlamA3 8B in both, zero-shot\nand few-shot scenarios. Our analysis contributes to further assessing\ncomputational argumentation with open-source LLMs in future research efforts.\n","authors":["Mohammad Yeghaneh Abkenar","Weixing Wang","Hendrik Graupner","Manfred Stede"],"pdf_url":"https://arxiv.org/pdf/2411.05639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05638v1","updated":"2024-11-08T15:32:20Z","published":"2024-11-08T15:32:20Z","title":"Impact of Fake News on Social Media Towards Public Users of Different\n  Age Groups","summary":"  This study examines how fake news affects social media users across a range\nof age groups and how machine learning (ML) and artificial intelligence (AI)\ncan help reduce the spread of false information. The paper evaluates various\nmachine learning models for their efficacy in identifying and categorizing fake\nnews and examines current trends in the spread of fake news, including deepfake\ntechnology. The study assesses four models using a Kaggle dataset: Random\nForest, Support Vector Machine (SVM), Neural Networks, and Logistic Regression.\nThe results show that SVM and neural networks perform better than other models,\nwith accuracies of 93.29% and 93.69%, respectively. The study also emphasises\nhow people in the elder age group diminished capacity for critical analysis of\nnews content makes them more susceptible to disinformation. Natural language\nprocessing (NLP) and deep learning approaches have the potential to improve the\naccuracy of false news detection. Biases in AI and ML models and difficulties\nin identifying information generated by AI continue to be major problems in\nspite of the developments. The study recommends that datasets be expanded to\nencompass a wider range of languages and that detection algorithms be\ncontinuously improved to keep up with the latest advancements in disinformation\ntactics. In order to combat fake news and promote an informed and resilient\nsociety, this study emphasizes the value of cooperative efforts between AI\nresearchers, social media platforms, and governments.\n","authors":["Kahlil bin Abdul Hakim","Sathishkumar Veerappampalayam Easwaramoorthy"],"pdf_url":"https://arxiv.org/pdf/2411.05638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12964v2","updated":"2024-11-08T14:58:29Z","published":"2024-03-19T17:59:39Z","title":"Enhancing Vision-Language Few-Shot Adaptation with Negative Learning","summary":"  Large-scale pre-trained Vision-Language Models (VLMs) have exhibited\nimpressive zero-shot performance and transferability, allowing them to adapt to\ndownstream tasks in a data-efficient manner. However, when only a few labeled\nsamples are available, adapting VLMs to distinguish subtle differences between\nsimilar classes in specific downstream tasks remains challenging. In this work,\nwe propose a Simple yet effective Negative Learning approach, SimNL, to more\nefficiently exploit the task-specific knowledge from few-shot labeled samples.\nUnlike previous methods that focus on identifying a set of representative\npositive features defining \"what is a {CLASS}\", SimNL discovers a complementary\nset of negative features that define \"what is not a {CLASS}\", providing\nadditional insights that supplement the positive features to enhance\ntask-specific recognition capability. Further, we identify that current\nadaptation approaches are particularly vulnerable to potential noise in the\nfew-shot sample set. To mitigate this issue, we introduce a plug-and-play\nfew-shot instance reweighting technique to suppress noisy outliers and amplify\nclean samples for more stable adaptation. Our extensive experimental results\nacross 15 datasets validate that the proposed SimNL outperforms existing\nstate-of-the-art methods on both few-shot learning and domain generalization\ntasks while achieving competitive computational efficiency. Code is available\nat https://github.com/zhangce01/SimNL.\n","authors":["Ce Zhang","Simon Stepputtis","Katia Sycara","Yaqi Xie"],"pdf_url":"https://arxiv.org/pdf/2403.12964v2.pdf","comment":"Accepted by WACV 2025. Code is available at\n  https://github.com/zhangce01/SimNL"},{"id":"http://arxiv.org/abs/2411.04699v2","updated":"2024-11-08T14:29:03Z","published":"2024-11-07T13:33:34Z","title":"BhasaAnuvaad: A Speech Translation Dataset for 13 Indian Languages","summary":"  Automatic Speech Translation (AST) datasets for Indian languages remain\ncritically scarce, with public resources covering fewer than 10 of the 22\nofficial languages. This scarcity has resulted in AST systems for Indian\nlanguages lagging far behind those available for high-resource languages like\nEnglish. In this paper, we first evaluate the performance of widely-used AST\nsystems on Indian languages, identifying notable performance gaps and\nchallenges. Our findings show that while these systems perform adequately on\nread speech, they struggle significantly with spontaneous speech, including\ndisfluencies like pauses and hesitations. Additionally, there is a striking\nabsence of systems capable of accurately translating colloquial and informal\nlanguage, a key aspect of everyday communication. To this end, we introduce\nBhasaAnuvaad, the largest publicly available dataset for AST involving 13 out\nof 22 scheduled Indian languages and English spanning over 44,400 hours and 17M\ntext segments. BhasaAnuvaad contains data for English speech to Indic text, as\nwell as Indic speech to English text. This dataset comprises three key\ncategories: (1) Curated datasets from existing resources, (2) Large-scale web\nmining, and (3) Synthetic data generation. By offering this diverse and\nexpansive dataset, we aim to bridge the resource gap and promote advancements\nin AST for Indian languages.\n","authors":["Sparsh Jain","Ashwin Sankar","Devilal Choudhary","Dhairya Suman","Nikhil Narasimhan","Mohammed Safi Ur Rahman Khan","Anoop Kunchukuttan","Mitesh M Khapra","Raj Dabre"],"pdf_url":"https://arxiv.org/pdf/2411.04699v2.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2411.05593v1","updated":"2024-11-08T14:26:56Z","published":"2024-11-08T14:26:56Z","title":"Evaluating and Adapting Large Language Models to Represent Folktales in\n  Low-Resource Languages","summary":"  Folktales are a rich resource of knowledge about the society and culture of a\ncivilisation. Digital folklore research aims to use automated techniques to\nbetter understand these folktales, and it relies on abstract representations of\nthe textual data. Although a number of large language models (LLMs) claim to be\nable to represent low-resource langauges such as Irish and Gaelic, we present\ntwo classification tasks to explore how useful these representations are, and\nthree adaptations to improve the performance of these models. We find that\nadapting the models to work with longer sequences, and continuing pre-training\non the domain of folktales improves classification performance, although these\nfindings are tempered by the impressive performance of a baseline SVM with\nnon-contextual features.\n","authors":["JA Meaney","Beatrice Alex","William Lamb"],"pdf_url":"https://arxiv.org/pdf/2411.05593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15267v2","updated":"2024-11-08T14:02:13Z","published":"2024-06-21T16:03:21Z","title":"Evaluating Diversity in Automatic Poetry Generation","summary":"  Natural Language Generation (NLG), and more generally generative AI, are\namong the currently most impactful research fields. Creative NLG, such as\nautomatic poetry generation, is a fascinating niche in this area. While most\nprevious research has focused on forms of the Turing test when evaluating\nautomatic poetry generation -- can humans distinguish between automatic and\nhuman generated poetry -- we evaluate the diversity of automatically generated\npoetry (with a focus on quatrains), by comparing distributions of generated\npoetry to distributions of human poetry along structural, lexical, semantic and\nstylistic dimensions, assessing different model types (word vs.\ncharacter-level, general purpose LLMs vs. poetry-specific models), including\nthe very recent LLaMA3-8B, and types of fine-tuning (conditioned vs.\nunconditioned). We find that current automatic poetry systems are considerably\nunderdiverse along multiple dimensions -- they often do not rhyme sufficiently,\nare semantically too uniform and even do not match the length distribution of\nhuman poetry. Our experiments reveal, however, that style-conditioning and\ncharacter-level modeling clearly increases diversity across virtually all\ndimensions we explore. Our identified limitations may serve as the basis for\nmore genuinely diverse future poetry generation models.\n","authors":["Yanran Chen","Hannes Gr√∂ner","Sina Zarrie√ü","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2406.15267v2.pdf","comment":"EMNLP 2024 main; camera-ready"},{"id":"http://arxiv.org/abs/2410.21333v3","updated":"2024-11-08T13:11:58Z","published":"2024-10-27T18:30:41Z","title":"Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on\n  Tasks where Thinking Makes Humans Worse","summary":"  Chain-of-thought (CoT) prompting has become a widely used strategy for\nworking with large language and multimodal models. While CoT has been shown to\nimprove performance across many tasks, determining the settings in which it is\neffective remains an ongoing effort. In particular, it is still an open\nquestion in what settings CoT systematically reduces model performance. In this\npaper, we seek to identify the characteristics of tasks where CoT reduces\nperformance by drawing inspiration from cognitive psychology, looking at cases\nwhere (i) verbal thinking or deliberation hurts performance in humans, and (ii)\nthe constraints governing human performance generalize to language models.\nThree such cases are implicit statistical learning, visual recognition, and\nclassifying with patterns containing exceptions. In extensive experiments\nacross all three settings, we find that a diverse collection of\nstate-of-the-art models exhibit significant drop-offs in performance (e.g., up\nto 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using\ninference-time reasoning compared to zero-shot counterparts. We also identify\nthree tasks that satisfy condition (i) but not (ii), and find that while verbal\nthinking reduces human performance in these tasks, CoT retains or increases\nmodel performance. Overall, our results show that while there is not an exact\nparallel between the cognitive processes of models and those of humans,\nconsidering cases where thinking has negative consequences for human\nperformance can help us identify settings where it negatively impacts models.\nBy connecting the literature on human deliberation with evaluations of CoT, we\noffer a new tool that can be used in understanding the impact of prompt choices\nand inference-time reasoning.\n","authors":["Ryan Liu","Jiayi Geng","Addison J. Wu","Ilia Sucholutsky","Tania Lombrozo","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2410.21333v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05547v1","updated":"2024-11-08T13:09:14Z","published":"2024-11-08T13:09:14Z","title":"Assessing the Answerability of Queries in Retrieval-Augmented Code\n  Generation","summary":"  Thanks to unprecedented language understanding and generation capabilities of\nlarge language model (LLM), Retrieval-augmented Code Generation (RaCG) has\nrecently been widely utilized among software developers. While this has\nincreased productivity, there are still frequent instances of incorrect codes\nbeing provided. In particular, there are cases where plausible yet incorrect\ncodes are generated for queries from users that cannot be answered with the\ngiven queries and API descriptions. This study proposes a task for evaluating\nanswerability, which assesses whether valid answers can be generated based on\nusers' queries and retrieved APIs in RaCG. Additionally, we build a benchmark\ndataset called Retrieval-augmented Code Generability Evaluation (RaCGEval) to\nevaluate the performance of models performing this task. Experimental results\nshow that this task remains at a very challenging level, with baseline models\nexhibiting a low performance of 46.7%. Furthermore, this study discusses\nmethods that could significantly improve performance.\n","authors":["Geonmin Kim","Jaeyeon Kim","Hancheol Park","Wooksu Shin","Tae-Ho Kim"],"pdf_url":"https://arxiv.org/pdf/2411.05547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16254v2","updated":"2024-11-08T12:54:16Z","published":"2024-06-24T01:31:03Z","title":"Confidence Regulation Neurons in Language Models","summary":"  Despite their widespread use, the mechanisms by which large language models\n(LLMs) represent and regulate uncertainty in next-token predictions remain\nlargely unexplored. This study investigates two critical components believed to\ninfluence this uncertainty: the recently discovered entropy neurons and a new\nset of components that we term token frequency neurons. Entropy neurons are\ncharacterized by an unusually high weight norm and influence the final layer\nnormalization (LayerNorm) scale to effectively scale down the logits. Our work\nshows that entropy neurons operate by writing onto an unembedding null space,\nallowing them to impact the residual stream norm with minimal direct effect on\nthe logits themselves. We observe the presence of entropy neurons across a\nrange of models, up to 7 billion parameters. On the other hand, token frequency\nneurons, which we discover and describe here for the first time, boost or\nsuppress each token's logit proportionally to its log frequency, thereby\nshifting the output distribution towards or away from the unigram distribution.\nFinally, we present a detailed case study where entropy neurons actively manage\nconfidence in the setting of induction, i.e. detecting and continuing repeated\nsubsequences.\n","authors":["Alessandro Stolfo","Ben Wu","Wes Gurnee","Yonatan Belinkov","Xingyi Song","Mrinmaya Sachan","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2406.16254v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.17044v2","updated":"2024-11-08T12:44:49Z","published":"2024-09-25T15:54:29Z","title":"How to Connect Speech Foundation Models and Large Language Models? What\n  Matters and What Does Not","summary":"  The remarkable performance achieved by Large Language Models (LLM) has driven\nresearch efforts to leverage them for a wide range of tasks and input\nmodalities. In speech-to-text (S2T) tasks, the emerging solution consists of\nprojecting the output of the encoder of a Speech Foundational Model (SFM) into\nthe LLM embedding space through an adapter module. However, no work has yet\ninvestigated how much the downstream-task performance depends on each component\n(SFM, adapter, LLM) nor whether the best design of the adapter depends on the\nchosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adapter\nmodules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) on\ntwo widespread S2T tasks, namely Automatic Speech Recognition and Speech\nTranslation. Our results demonstrate that the SFM plays a pivotal role in\ndownstream performance, while the adapter choice has moderate impact and\ndepends on the SFM and LLM.\n","authors":["Francesco Verdini","Pierfrancesco Melucci","Stefano Perna","Francesco Cariaggi","Marco Gaido","Sara Papi","Szymon Mazurek","Marek Kasztelnik","Luisa Bentivogli","S√©bastien Brati√®res","Paolo Merialdo","Simone Scardapane"],"pdf_url":"https://arxiv.org/pdf/2409.17044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05527v1","updated":"2024-11-08T12:35:58Z","published":"2024-11-08T12:35:58Z","title":"How Good is Your Wikipedia?","summary":"  Wikipedia's perceived high quality and broad language coverage have\nestablished it as a fundamental resource in multilingual NLP. In the context of\nlow-resource languages, however, these quality assumptions are increasingly\nbeing scrutinised. This paper critically examines the data quality of Wikipedia\nin a non-English setting by subjecting it to various quality filtering\ntechniques, revealing widespread issues such as a high percentage of one-line\narticles and duplicate articles. We evaluate the downstream impact of quality\nfiltering on Wikipedia and find that data quality pruning is an effective means\nfor resource-efficient training without hurting performance, especially for\nlow-resource languages. Moreover, we advocate for a shift in perspective from\nseeking a general definition of data quality towards a more language- and\ntask-specific one. Ultimately, we aim for this study to serve as a guide to\nusing Wikipedia for pretraining in a multilingual setting.\n","authors":["Kushal Tatariya","Artur Kulmizev","Wessel Poelman","Esther Ploeger","Marcel Bollmann","Johannes Bjerva","Jiaming Luo","Heather Lent","Miryam de Lhoneux"],"pdf_url":"https://arxiv.org/pdf/2411.05527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05508v1","updated":"2024-11-08T12:08:17Z","published":"2024-11-08T12:08:17Z","title":"An Early FIRST Reproduction and Improvements to Single-Token Decoding\n  for Fast Listwise Reranking","summary":"  Recent advances have demonstrated that large language models (LLMs) excel as\nlistwise rerankers, but their high computational demands remain a barrier to\nwidespread adoption. Further, the traditional language modeling (LM) objective\nis not ideally suited for reranking tasks. FIRST is a novel approach that\naddresses these challenges by integrating a learning-to-rank objective and\nleveraging the logits of only the first generated token, thereby significantly\nreducing inference latency compared to traditional LLM rerankers. In this\nstudy, we extend the evaluation of FIRST to the TREC Deep Learning datasets\n(DL19-22), validating its robustness across diverse domains. We investigate the\ninfluence of different first-stage retrievers on FIRST rerankers, observing\ndiminishing returns and patterns consistent with traditional LLM rerankers.\nThrough applying the FIRST objective to a broader range of backbone models, we\nachieve effectiveness surpassing the original implementation. Our experiments\nconfirm that fast reranking with single-token logits does not compromise\nout-of-domain reranking quality. To better quantify the computational savings\nin the original study, we measure and compare latency to find a 21%-42% gain\nacross various models and benchmarks. Moreover, while LM training implicitly\nimproves zero-shot single-token reranking, our experiments also raise questions\nabout whether LM pre-training may hinder subsequent fine-tuning with the FIRST\nobjective. These findings pave the way for more efficient and effective\nlistwise reranking in future applications.\n","authors":["Zijian Chen","Ronak Pradeep","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05504v1","updated":"2024-11-08T12:03:36Z","published":"2024-11-08T12:03:36Z","title":"LBPE: Long-token-first Tokenization to Improve Large Language Models","summary":"  The prevalent use of Byte Pair Encoding (BPE) in Large Language Models (LLMs)\nfacilitates robust handling of subword units and avoids issues of\nout-of-vocabulary words. Despite its success, a critical challenge persists:\nlong tokens, rich in semantic information, have fewer occurrences in tokenized\ndatasets compared to short tokens, which can result in imbalanced learning\nissue across different tokens. To address that, we propose LBPE, which\nprioritizes long tokens during the encoding process. LBPE generates tokens\naccording to their reverse ranks of token length rather than their ranks in the\nvocabulary, granting longer tokens higher priority during the encoding process.\nConsequently, LBPE smooths the frequency differences between short and long\ntokens, and thus mitigates the learning imbalance. Extensive experiments across\ndiverse language modeling tasks demonstrate that LBPE consistently outperforms\nthe original BPE, well demonstrating its effectiveness.\n","authors":["Haoran Lian","Yizhe Xiong","Zijia Lin","Jianwei Niu","Shasha Mo","Hui Chen","Peng Liu","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2411.05504v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2404.17808"},{"id":"http://arxiv.org/abs/2411.05503v1","updated":"2024-11-08T12:03:31Z","published":"2024-11-08T12:03:31Z","title":"KyrgyzNLP: Challenges, Progress, and Future","summary":"  Large language models (LLMs) have excelled in numerous benchmarks, advancing\nAI applications in both linguistic and non-linguistic tasks. However, this has\nprimarily benefited well-resourced languages, leaving less-resourced ones\n(LRLs) at a disadvantage. In this paper, we highlight the current state of the\nNLP field in the specific LRL: kyrgyz tili.\n  Human evaluation, including annotated datasets created by native speakers,\nremains an irreplaceable component of reliable NLP performance, especially for\nLRLs where automatic evaluations can fall short. In recent assessments of the\nresources for Turkic languages, Kyrgyz is labeled with the status 'Scraping\nBy', a severely under-resourced language spoken by millions. This is concerning\ngiven the growing importance of the language, not only in Kyrgyzstan but also\namong diaspora communities where it holds no official status.\n  We review prior efforts in the field, noting that many of the publicly\navailable resources have only recently been developed, with few exceptions\nbeyond dictionaries (the processed data used for the analysis is presented at\nhttps://kyrgyznlp.github.io/). While recent papers have made some headway, much\nmore remains to be done. Despite interest and support from both business and\ngovernment sectors in the Kyrgyz Republic, the situation for Kyrgyz language\nresources remains challenging. We stress the importance of community-driven\nefforts to build these resources, ensuring the future advancement\nsustainability. We then share our view of the most pressing challenges in\nKyrgyz NLP. Finally, we propose a roadmap for future development in terms of\nresearch topics and language resources.\n","authors":["Anton Alekseev","Timur Turatali"],"pdf_url":"https://arxiv.org/pdf/2411.05503v1.pdf","comment":"Keynote talk at the 12th International Conference on Analysis of\n  Images, Social Networks and Texts (AIST-2024)"},{"id":"http://arxiv.org/abs/2404.17808v2","updated":"2024-11-08T11:56:46Z","published":"2024-04-27T07:12:07Z","title":"Scaffold-BPE: Enhancing Byte Pair Encoding for Large Language Models\n  with Simple and Effective Scaffold Token Removal","summary":"  Byte Pair Encoding (BPE) serves as a foundation method for text tokenization\nin the Natural Language Processing (NLP) field. Despite its wide adoption, the\noriginal BPE algorithm harbors an inherent flaw: it inadvertently introduces a\nfrequency imbalance for tokens in the text corpus. Since BPE iteratively merges\nthe most frequent token pair in the text corpus to generate a new token and\nkeeps all generated tokens in the vocabulary, it unavoidably holds tokens that\nprimarily act as components of a longer token and appear infrequently on their\nown. We term such tokens as Scaffold Tokens. Due to their infrequent\noccurrences in the text corpus, Scaffold Tokens pose a learning imbalance\nissue. To address that issue, we propose Scaffold-BPE, which incorporates a\ndynamic scaffold token removal mechanism by parameter-free, computation-light,\nand easy-to-implement modifications to the original BPE method. This novel\napproach ensures the exclusion of low-frequency Scaffold Tokens from the token\nrepresentations for given texts, thereby mitigating the issue of frequency\nimbalance and facilitating model training. On extensive experiments across\nlanguage modeling and even machine translation, Scaffold-BPE consistently\noutperforms the original BPE, well demonstrating its effectiveness.\n","authors":["Haoran Lian","Yizhe Xiong","Jianwei Niu","Shasha Mo","Zhenpeng Su","Zijia Lin","Hui Chen","Peng Liu","Jungong Han","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2404.17808v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05479v1","updated":"2024-11-08T11:09:45Z","published":"2024-11-08T11:09:45Z","title":"EUREKHA: Enhancing User Representation for Key Hackers Identification in\n  Underground Forums","summary":"  Underground forums serve as hubs for cybercriminal activities, offering a\nspace for anonymity and evasion of conventional online oversight. In these\nhidden communities, malicious actors collaborate to exchange illicit knowledge,\ntools, and tactics, driving a range of cyber threats from hacking techniques to\nthe sale of stolen data, malware, and zero-day exploits. Identifying the key\ninstigators (i.e., key hackers), behind these operations is essential but\nremains a complex challenge. This paper presents a novel method called EUREKHA\n(Enhancing User Representation for Key Hacker Identification in Underground\nForums), designed to identify these key hackers by modeling each user as a\ntextual sequence. This sequence is processed through a large language model\n(LLM) for domain-specific adaptation, with LLMs acting as feature extractors.\nThese extracted features are then fed into a Graph Neural Network (GNN) to\nmodel user structural relationships, significantly improving identification\naccuracy. Furthermore, we employ BERTopic (Bidirectional Encoder\nRepresentations from Transformers Topic Modeling) to extract personalized\ntopics from user-generated content, enabling multiple textual representations\nper user and optimizing the selection of the most representative sequence. Our\nstudy demonstrates that fine-tuned LLMs outperform state-of-the-art methods in\nidentifying key hackers. Additionally, when combined with GNNs, our model\nachieves significant improvements, resulting in approximately 6% and 10%\nincreases in accuracy and F1-score, respectively, over existing methods.\nEUREKHA was tested on the Hack-Forums dataset, and we provide open-source\naccess to our code.\n","authors":["Abdoul Nasser Hassane Amadou","Anas Motii","Saida Elouardi","EL Houcine Bergou"],"pdf_url":"https://arxiv.org/pdf/2411.05479v1.pdf","comment":"Accepted at IEEE Trustcom 2024"},{"id":"http://arxiv.org/abs/2411.05460v1","updated":"2024-11-08T10:24:00Z","published":"2024-11-08T10:24:00Z","title":"Supporting Automated Fact-checking across Topics: Similarity-driven\n  Gradual Topic Learning for Claim Detection","summary":"  Selecting check-worthy claims for fact-checking is considered a crucial part\nof expediting the fact-checking process by filtering out and ranking the\ncheck-worthy claims for being validated among the impressive amount of claims\ncould be found online. The check-worthy claim detection task, however, becomes\nmore challenging when the model needs to deal with new topics that differ from\nthose seen earlier. In this study, we propose a domain-adaptation framework for\ncheck-worthy claims detection across topics for the Arabic language to adopt a\nnew topic, mimicking a real-life scenario of the daily emergence of events\nworldwide. We propose the Gradual Topic Learning (GTL) model, which builds an\nability to learning gradually and emphasizes the check-worthy claims for the\ntarget topic during several stages of the learning process. In addition, we\nintroduce the Similarity-driven Gradual Topic Learning (SGTL) model that\nsynthesizes gradual learning with a similarity-based strategy for the target\ntopic. Our experiments demonstrate the effectiveness of our proposed model,\nshowing an overall tendency for improving performance over the state-of-the-art\nbaseline across 11 out of the 14 topics under study.\n","authors":["Amani S. Abumansour","Arkaitz Zubiaga"],"pdf_url":"https://arxiv.org/pdf/2411.05460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05451v1","updated":"2024-11-08T09:58:02Z","published":"2024-11-08T09:58:02Z","title":"WorkflowLLM: Enhancing Workflow Orchestration Capability of Large\n  Language Models","summary":"  Recent advancements in large language models (LLMs) have driven a\nrevolutionary paradigm shift in process automation from Robotic Process\nAutomation to Agentic Process Automation by automating the workflow\norchestration procedure based on LLMs. However, existing LLMs (even the\nadvanced OpenAI GPT-4o) are confined to achieving satisfactory capability in\nworkflow orchestration. To address this limitation, we present WorkflowLLM, a\ndata-centric framework elaborately designed to enhance the capability of LLMs\nin workflow orchestration. It first constructs a large-scale fine-tuning\ndataset WorkflowBench with 106,763 samples, covering 1,503 APIs from 83\napplications across 28 categories. Specifically, the construction process can\nbe divided into three phases: (1) Data Collection: we collect real-world\nworkflow data from Apple Shortcuts and RoutineHub, transcribing them into\nPython-style code. We further equip them with generated hierarchical thought\nvia ChatGPT. (2) Query Expansion: we prompt ChatGPT to generate more task\nqueries to enrich the diversity and complexity of workflows. (3) Workflow\nGeneration: we leverage an annotator model trained on collected data to\ngenerate workflows for synthesized queries. Finally, we merge the synthetic\nsamples that pass quality confirmation with the collected samples to obtain the\nWorkflowBench. Based on WorkflowBench, we fine-tune Llama-3.1-8B to obtain\nWorkflowLlama. Our experiments show that WorkflowLlama demonstrates a strong\ncapacity to orchestrate complex workflows, while also achieving notable\ngeneralization performance on previously unseen APIs. Additionally,\nWorkflowBench exhibits robust zero-shot generalization capabilities on an\nout-of-distribution task planning dataset, T-Eval. Our data and code are\navailable at https://github.com/OpenBMB/WorkflowLLM.\n","authors":["Shengda Fan","Xin Cong","Yuepeng Fu","Zhong Zhang","Shuyan Zhang","Yuanwei Liu","Yesai Wu","Yankai Lin","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2411.05451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20895v2","updated":"2024-11-08T09:35:29Z","published":"2024-05-31T15:04:15Z","title":"A comparison of correspondence analysis with PMI-based word embedding\n  methods","summary":"  Popular word embedding methods such as GloVe and Word2Vec are related to the\nfactorization of the pointwise mutual information (PMI) matrix. In this paper,\nwe link correspondence analysis (CA) to the factorization of the PMI matrix. CA\nis a dimensionality reduction method that uses singular value decomposition\n(SVD), and we show that CA is mathematically close to the weighted\nfactorization of the PMI matrix. In addition, we present variants of CA that\nturn out to be successful in the factorization of the word-context matrix, i.e.\nCA applied to a matrix where the entries undergo a square-root transformation\n(ROOT-CA) and a root-root transformation (ROOTROOT-CA). While this study\nfocuses on traditional static word embedding methods, to extend the\ncontribution of this paper, we also include a comparison of transformer-based\nencoder BERT, i.e. contextual word embedding, with these traditional methods.\nAn empirical comparison among CA- and PMI-based methods as well as BERT shows\nthat overall results of ROOT-CA and ROOTROOT-CA are slightly better than those\nof the PMI-based methods and are competitive with BERT.\n","authors":["Qianqian Qi","Ayoub Bagheri","David J. Hessen","Peter G. M. van der Heijden"],"pdf_url":"https://arxiv.org/pdf/2405.20895v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05423v1","updated":"2024-11-08T09:15:56Z","published":"2024-11-08T09:15:56Z","title":"VISTA: Visual Integrated System for Tailored Automation in Math Problem\n  Generation Using LLM","summary":"  Generating accurate and consistent visual aids is a critical challenge in\nmathematics education, where visual representations like geometric shapes and\nfunctions play a pivotal role in enhancing student comprehension. This paper\nintroduces a novel multi-agent framework that leverages Large Language Models\n(LLMs) to automate the creation of complex mathematical visualizations\nalongside coherent problem text. Our approach not only simplifies the\ngeneration of precise visual aids but also aligns these aids with the problem's\ncore mathematical concepts, improving both problem creation and assessment. By\nintegrating multiple agents, each responsible for distinct tasks such as\nnumeric calculation, geometry validation, and visualization, our system\ndelivers mathematically accurate and contextually relevant problems with visual\naids. Evaluation across Geometry and Function problem types shows that our\nmethod significantly outperforms basic LLMs in terms of text coherence,\nconsistency, relevance and similarity, while maintaining the essential\ngeometrical and functional integrity of the original problems. Although some\nchallenges remain in ensuring consistent visual outputs, our framework\ndemonstrates the immense potential of LLMs in transforming the way educators\ngenerate and utilize visual aids in math education.\n","authors":["Jeongwoo Lee","Kwangsuk Park","Jihyeon Park"],"pdf_url":"https://arxiv.org/pdf/2411.05423v1.pdf","comment":"Accepted at NeurIPS 2024 Workshop on Large Foundation Models for\n  Educational Assessment (FM-Assess)"},{"id":"http://arxiv.org/abs/2411.05421v1","updated":"2024-11-08T09:14:22Z","published":"2024-11-08T09:14:22Z","title":"Learning the rules of peptide self-assembly through data mining with\n  large language models","summary":"  Peptides are ubiquitous and important biologically derived molecules, that\nhave been found to self-assemble to form a wide array of structures. Extensive\nresearch has explored the impacts of both internal chemical composition and\nexternal environmental stimuli on the self-assembly behaviour of these systems.\nHowever, there is yet to be a systematic study that gathers this rich\nliterature data and collectively examines these experimental factors to provide\na global picture of the fundamental rules that govern protein self-assembly\nbehavior. In this work, we curate a peptide assembly database through a\ncombination of manual processing by human experts and literature mining\nfacilitated by a large language model. As a result, we collect more than 1,000\nexperimental data entries with information about peptide sequence, experimental\nconditions and corresponding self-assembly phases. Utilizing the collected\ndata, ML models are trained and evaluated, demonstrating excellent accuracy\n(>80\\%) and efficiency in peptide assembly phase classification. Moreover, we\nfine-tune our GPT model for peptide literature mining with the developed\ndataset, which exhibits markedly superior performance in extracting information\nfrom academic publications relative to the pre-trained model. We find that this\nworkflow can substantially improve efficiency when exploring potential\nself-assembling peptide candidates, through guiding experimental work, while\nalso deepening our understanding of the mechanisms governing peptide\nself-assembly. In doing so, novel structures can be accessed for a range of\napplications including sensing, catalysis and biomaterials.\n","authors":["Zhenze Yang","Sarah K. Yorke","Tuomas P. J. Knowles","Markus J. Buehler"],"pdf_url":"https://arxiv.org/pdf/2411.05421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13698v2","updated":"2024-11-08T09:02:56Z","published":"2024-06-19T16:52:22Z","title":"MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of\n  Metaphorical Language","summary":"  Machine Translation (MT) has developed rapidly since the release of Large\nLanguage Models and current MT evaluation is performed through comparison with\nreference human translations or by predicting quality scores from human-labeled\ndata. However, these mainstream evaluation methods mainly focus on fluency and\nfactual reliability, whilst paying little attention to figurative quality. In\nthis paper, we investigate the figurative quality of MT and propose a set of\nhuman evaluation metrics focused on the translation of figurative language. We\nadditionally present a multilingual parallel metaphor corpus generated by\npost-editing. Our evaluation protocol is designed to estimate four aspects of\nMT: Metaphorical Equivalence, Emotion, Authenticity, and Quality. In doing so,\nwe observe that translations of figurative expressions display different traits\nfrom literal ones.\n","authors":["Shun Wang","Ge Zhang","Han Wu","Tyler Loakman","Wenhao Huang","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2406.13698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07230v2","updated":"2024-11-08T08:55:00Z","published":"2024-03-12T00:58:19Z","title":"Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked\n  Preferences","summary":"  Direct Preference Optimization (DPO) is an effective technique that leverages\npairwise preference data (usually one chosen and rejected response pair per\nuser prompt) to align LLMs to human preferences. In practice, multiple\nresponses can exist for a given prompt with varying quality relative to each\nother. With availability of such quality ratings for multiple responses, we\npropose utilizing these responses to create multiple preference pairs for a\ngiven prompt. Our work focuses on systematically using the constructed multiple\npreference pair in DPO training via curriculum learning methodology. In\nparticular, we order these multiple pairs of preference data from easy to hard\n(emulating curriculum training) according to various criteria. We show detailed\ncomparisons of our proposed approach to the standard single-pair DPO setting.\nOur method, which we call Curry-DPO consistently shows increased performance\ngains on MTbench, Vicuna, WizardLM, and the UltraFeedback test set,\nhighlighting its effectiveness. More specifically, Curry-DPO achieves a score\nof 7.43 on MT-bench with Zephy-7B model outperforming majority of existing LLMs\nwith similar parameter size. Curry-DPO also achieves the highest adjusted win\nrates on Vicuna, WizardLM, and UltraFeedback test datasets (90.7%, 87.1%, and\n87.9% respectively) in our experiments, with notable gains of upto 7.5% when\ncompared to standard DPO technique. We release the preference pairs used in\nalignment at:\nhttps://huggingface.co/datasets/ServiceNow-AI/Curriculum_DPO_preferences\n","authors":["Pulkit Pattnaik","Rishabh Maheshwary","Kelechi Ogueji","Vikas Yadav","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2403.07230v2.pdf","comment":"Published at EMNLP 2024 as long (findings) conference paper"},{"id":"http://arxiv.org/abs/2411.05407v1","updated":"2024-11-08T08:52:59Z","published":"2024-11-08T08:52:59Z","title":"Gap-Filling Prompting Enhances Code-Assisted Mathematical Reasoning","summary":"  Despite the strong performance of large language models (LLMs) in tasks like\nmathematical reasoning, their practical use is limited by high computational\ndemands and proprietary restrictions. Chain-of-thought (CoT) and\nprogram-of-thought (PoT) fine-tuning are common methods to transfer LLM\nknowledge to small language models (SLMs). However, CoT often leads to\ncalculation errors in SLMs, while PoT has shown more promise. While most\nPoT-based approaches focus on direct problem-to-code conversion or extracting\nonly the key information from questions and then providing code solution for\nit, this work emphasizes filling the gaps in the question to clearly illustrate\nthe solution path, which can be challenging for an SLM to understand when such\ninformation is not explicitly provided. Therefore, this paper introduces\nGap-Filling Prompting (GFP), a novel two-step prompting strategy designed to\nenhance the problem-solving process for SLMs. The first step identifies these\ngaps and provides hints for filling them, while the second step adds the hints\nto the question to generate a final code solution. Experimental results on two\nbenchmark datasets demonstrate that GFP significantly improves the mathematical\nreasoning abilities of SLMs.\n","authors":["Mohammad Ghiasvand Mohammadkhani"],"pdf_url":"https://arxiv.org/pdf/2411.05407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05403v1","updated":"2024-11-08T08:41:17Z","published":"2024-11-08T08:41:17Z","title":"Benchmarking Distributional Alignment of Large Language Models","summary":"  Language models (LMs) are increasingly used as simulacra for people, yet\ntheir ability to match the distribution of views of a specific demographic\ngroup and be \\textit{distributionally aligned} remains uncertain. This notion\nof distributional alignment is complex, as there is significant variation in\nthe types of attributes that are simulated. Prior works have underexplored the\nrole of three critical variables -- the question domain, steering method, and\ndistribution expression method -- which motivates our contribution of a\nbenchmark explicitly addressing these dimensions. We construct a dataset\nexpanding beyond political values, create human baselines for this task, and\nevaluate the extent to which an LM can align with a particular group's opinion\ndistribution to inform design choices of such simulation systems. Our analysis\nreveals open problems regarding if, and how, LMs can be used to simulate\nhumans, and that LLMs can more accurately describe the opinion distribution\nthan simulate such distributions.\n","authors":["Nicole Meister","Carlos Guestrin","Tatsunori Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2411.05403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05383v1","updated":"2024-11-08T07:43:15Z","published":"2024-11-08T07:43:15Z","title":"Towards Low-Resource Harmful Meme Detection with LMM Agents","summary":"  The proliferation of Internet memes in the age of social media necessitates\neffective identification of harmful ones. Due to the dynamic nature of memes,\nexisting data-driven models may struggle in low-resource scenarios where only a\nfew labeled examples are available. In this paper, we propose an agency-driven\nframework for low-resource harmful meme detection, employing both outward and\ninward analysis with few-shot annotated samples. Inspired by the powerful\ncapacity of Large Multimodal Models (LMMs) on multimodal reasoning, we first\nretrieve relative memes with annotations to leverage label information as\nauxiliary signals for the LMM agent. Then, we elicit knowledge-revising\nbehavior within the LMM agent to derive well-generalized insights into meme\nharmfulness. By combining these strategies, our approach enables dialectical\nreasoning over intricate and implicit harm-indicative patterns. Extensive\nexperiments conducted on three meme datasets demonstrate that our proposed\napproach achieves superior performance than state-of-the-art methods on the\nlow-resource harmful meme detection task.\n","authors":["Jianzhao Huang","Hongzhan Lin","Ziyan Liu","Ziyang Luo","Guang Chen","Jing Ma"],"pdf_url":"https://arxiv.org/pdf/2411.05383v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.04950v2","updated":"2024-11-08T07:34:45Z","published":"2024-11-07T18:28:40Z","title":"Estimating the Influence of Sequentially Correlated Literary Properties\n  in Textual Classification: A Data-Centric Hypothesis-Testing Approach","summary":"  Stylometry aims to distinguish authors by analyzing literary traits assumed\nto reflect semi-conscious choices distinct from elements like genre or theme.\nHowever, these components often overlap, complicating text classification based\nsolely on feature distributions. While some literary properties, such as\nthematic content, are likely to manifest as correlations between adjacent text\nunits, others, like authorial style, may be independent thereof. We introduce a\nhypothesis-testing approach to evaluate the influence of sequentially\ncorrelated literary properties on text classification, aiming to determine when\nthese correlations drive classification. Using a multivariate binary\ndistribution, our method models sequential correlations between text units as a\nstochastic process, assessing the likelihood of clustering across varying\nadjacency scales. This enables us to examine whether classification is\ndominated by sequentially correlated properties or remains independent. In\nexperiments on a diverse English prose corpus, our analysis integrates\ntraditional and neural embeddings within supervised and unsupervised\nframeworks. Results demonstrate that our approach effectively identifies when\ntextual classification is not primarily influenced by sequentially correlated\nliterary properties, particularly in cases where texts differ in authorial\nstyle or genre rather than by a single author within a similar genre.\n","authors":["Gideon Yoffe","Nachum Dershowitz","Ariel Vishne","Barak Sober"],"pdf_url":"https://arxiv.org/pdf/2411.04950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04358v2","updated":"2024-11-08T07:31:26Z","published":"2024-11-07T01:31:48Z","title":"Robust and Efficient Fine-tuning of LLMs with Bayesian\n  Reparameterization of Low-Rank Adaptation","summary":"  Large Language Models (LLMs) are highly resource-intensive to fine-tune due\nto their enormous size. While low-rank adaptation is a prominent\nparameter-efficient fine-tuning approach, it suffers from sensitivity to\nhyperparameter choices, leading to instability in model performance on\nfine-tuning downstream tasks. This paper highlights the importance of effective\nparameterization in low-rank fine-tuning to reduce estimator variance and\nenhance the stability of final model outputs. We propose MonteCLoRA, an\nefficient fine-tuning technique, employing Monte Carlo estimation to learn an\nunbiased posterior estimation of low-rank parameters with low expected\nvariance, which stabilizes fine-tuned LLMs with only O(1) additional\nparameters. MonteCLoRA shows significant improvements in accuracy and\nrobustness, achieving up to 3.8% higher accuracy and 8.6% greater robustness\nthan existing efficient fine-tuning methods on natural language understanding\ntasks with pre-trained RoBERTa-base. Furthermore, in generative tasks with\npre-trained LLaMA-1-7B, MonteCLoRA demonstrates robust zero-shot performance\nwith 50% lower variance than the contemporary efficient fine-tuning methods.\nThe theoretical and empirical results presented in the paper underscore how\nparameterization and hyperpriors balance exploration-exploitation in the\nlow-rank parametric space, therefore leading to more optimal and robust\nparameter estimation during efficient fine-tuning.\n","authors":["Ayan Sengupta","Vaibhav Seth","Arinjay Pathak","Natraj Raman","Sriram Gopalakrishnan","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2411.04358v2.pdf","comment":"48 pages, 10 figures, 10 tables, Code:\n  https://github.com/LCS2-IIITD/MonteCLoRA"},{"id":"http://arxiv.org/abs/2411.05379v1","updated":"2024-11-08T07:20:21Z","published":"2024-11-08T07:20:21Z","title":"Word reuse and combination support efficient communication of emerging\n  concepts","summary":"  A key function of the lexicon is to express novel concepts as they emerge\nover time through a process known as lexicalization. The most common\nlexicalization strategies are the reuse and combination of existing words, but\nthey have typically been studied separately in the areas of word meaning\nextension and word formation. Here we offer an information-theoretic account of\nhow both strategies are constrained by a fundamental tradeoff between competing\ncommunicative pressures: word reuse tends to preserve the average length of\nword forms at the cost of less precision, while word combination tends to\nproduce more informative words at the expense of greater word length. We test\nour proposal against a large dataset of reuse items and compounds that appeared\nin English, French and Finnish over the past century. We find that these\nhistorically emerging items achieve higher levels of communicative efficiency\nthan hypothetical ways of constructing the lexicon, and both literal reuse\nitems and compounds tend to be more efficient than their non-literal\ncounterparts. These results suggest that reuse and combination are both\nconsistent with a unified account of lexicalization grounded in the theory of\nefficient communication.\n","authors":["Aotao Xu","Charles Kemp","Lea Frermann","Yang Xu"],"pdf_url":"https://arxiv.org/pdf/2411.05379v1.pdf","comment":"Published in Proceedings of the National Academy of Sciences"},{"id":"http://arxiv.org/abs/2411.05375v1","updated":"2024-11-08T07:05:06Z","published":"2024-11-08T07:05:06Z","title":"Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking","summary":"  Current automated fact-checking (AFC) approaches commonly evaluate evidence\neither implicitly via the predicted verdicts or by comparing retrieved evidence\nwith a predefined closed knowledge source, such as Wikipedia. However, these\nmethods suffer from limitations, resulting from their reliance on evaluation\nmetrics developed for different purposes and constraints imposed by closed\nknowledge sources. Recent advances in natural language generation (NLG)\nevaluation offer new possibilities for evidence assessment. In this work, we\nintroduce Ev2R, an evaluation framework for AFC that comprises three types of\napproaches for evidence evaluation: reference-based, proxy-reference, and\nreference-less. We evaluate their effectiveness through agreement with human\nratings and adversarial tests, and demonstrate that prompt-based scorers,\nparticularly those leveraging LLMs and reference evidence, outperform\ntraditional evaluation approaches.\n","authors":["Mubashara Akhtar","Michael Schlichtkrull","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2411.05375v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2401.17263v5","updated":"2024-11-08T06:57:05Z","published":"2024-01-30T18:56:08Z","title":"Robust Prompt Optimization for Defending Language Models Against\n  Jailbreaking Attacks","summary":"  Despite advances in AI alignment, large language models (LLMs) remain\nvulnerable to adversarial attacks or jailbreaking, in which adversaries can\nmodify prompts to induce unwanted behavior. While some defenses have been\nproposed, they have not been adapted to newly proposed attacks and more\nchallenging threat models. To address this, we propose an optimization-based\nobjective for defending LLMs against jailbreaking attacks and an algorithm,\nRobust Prompt Optimization (RPO) to create robust system-level defenses. Our\napproach directly incorporates the adversary into the defensive objective and\noptimizes a lightweight and transferable suffix, enabling RPO to adapt to\nworst-case adaptive attacks. Our theoretical and experimental results show\nimproved robustness to both jailbreaks seen during optimization and unknown\njailbreaks, reducing the attack success rate (ASR) on GPT-4 to 6% and Llama-2\nto 0% on JailbreakBench, setting the state-of-the-art. Code can be found at\nhttps://github.com/lapisrocks/rpo\n","authors":["Andy Zhou","Bo Li","Haohan Wang"],"pdf_url":"https://arxiv.org/pdf/2401.17263v5.pdf","comment":"NeurIPS 2024 Spotlight; code available at\n  https://github.com/lapisrocks/rpo"},{"id":"http://arxiv.org/abs/2307.09254v2","updated":"2024-11-08T06:47:04Z","published":"2023-07-18T13:36:24Z","title":"Selective Generation for Controllable Language Models","summary":"  Trustworthiness of generative language models (GLMs) is crucial in their\ndeployment to critical decision making systems. Hence, certified risk control\nmethods such as selective prediction and conformal prediction have been applied\nto mitigating the hallucination problem in various supervised downstream tasks.\nHowever, the lack of appropriate correctness metric hinders applying such\nprincipled methods to language generation tasks. In this paper, we circumvent\nthis problem by leveraging the concept of textual entailment to evaluate the\ncorrectness of the generated sequence, and propose two selective generation\nalgorithms which control the false discovery rate with respect to the textual\nentailment relation (FDR-E) with a theoretical guarantee:\n$\\texttt{SGen}^{\\texttt{Sup}}$ and $\\texttt{SGen}^{\\texttt{Semi}}$.\n$\\texttt{SGen}^{\\texttt{Sup}}$, a direct modification of the selective\nprediction, is a supervised learning algorithm which exploits\nentailment-labeled data, annotated by humans. Since human annotation is costly,\nwe further propose a semi-supervised version, $\\texttt{SGen}^{\\texttt{Semi}}$,\nwhich fully utilizes the unlabeled data by pseudo-labeling, leveraging an\nentailment set function learned via conformal prediction. Furthermore,\n$\\texttt{SGen}^{\\texttt{Semi}}$ enables to use more general class of selection\nfunctions, neuro-selection functions, and provides users with an optimal\nselection function class given multiple candidates. Finally, we demonstrate the\nefficacy of the $\\texttt{SGen}$ family in achieving a desired FDR-E level with\ncomparable selection efficiency to those from baselines on both open and closed\nsource GLMs. Code and datasets are provided at\nhttps://github.com/ml-postech/selective-generation.\n","authors":["Minjae Lee","Kyungmin Kim","Taesoo Kim","Sangdon Park"],"pdf_url":"https://arxiv.org/pdf/2307.09254v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.05361v1","updated":"2024-11-08T06:33:22Z","published":"2024-11-08T06:33:22Z","title":"Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for\n  Measuring the Capabilities of Spoken Language Models with 180 Tasks","summary":"  Multimodal foundation models, such as Gemini and ChatGPT, have revolutionized\nhuman-machine interactions by seamlessly integrating various forms of data.\nDeveloping a universal spoken language model that comprehends a wide range of\nnatural language instructions is critical for bridging communication gaps and\nfacilitating more intuitive interactions. However, the absence of a\ncomprehensive evaluation benchmark poses a significant challenge. We present\nDynamic-SUPERB Phase-2, an open and evolving benchmark for the comprehensive\nevaluation of instruction-based universal speech models. Building upon the\nfirst generation, this second version incorporates 125 new tasks contributed\ncollaboratively by the global research community, expanding the benchmark to a\ntotal of 180 tasks, making it the largest benchmark for speech and audio\nevaluation. While the first generation of Dynamic-SUPERB was limited to\nclassification tasks, Dynamic-SUPERB Phase-2 broadens its evaluation\ncapabilities by introducing a wide array of novel and diverse tasks, including\nregression and sequence generation, across speech, music, and environmental\naudio. Evaluation results indicate that none of the models performed well\nuniversally. SALMONN-13B excelled in English ASR, while WavLLM demonstrated\nhigh accuracy in emotion recognition, but current models still require further\ninnovations to handle a broader range of tasks. We will soon open-source all\ntask data and the evaluation pipeline.\n","authors":["Chien-yu Huang","Wei-Chih Chen","Shu-wen Yang","Andy T. Liu","Chen-An Li","Yu-Xiang Lin","Wei-Cheng Tseng","Anuj Diwan","Yi-Jen Shih","Jiatong Shi","William Chen","Xuanjun Chen","Chi-Yuan Hsiao","Puyuan Peng","Shih-Heng Wang","Chun-Yi Kuan","Ke-Han Lu","Kai-Wei Chang","Chih-Kai Yang","Fabian Ritter-Gutierrez","Ming To Chuang","Kuan-Po Huang","Siddhant Arora","You-Kuan Lin","Eunjung Yeo","Kalvin Chang","Chung-Ming Chien","Kwanghee Choi","Cheng-Hsiu Hsieh","Yi-Cheng Lin","Chee-En Yu","I-Hsiang Chiu","Heitor R. Guimar√£es","Jionghao Han","Tzu-Quan Lin","Tzu-Yuan Lin","Homu Chang","Ting-Wu Chang","Chun Wei Chen","Shou-Jen Chen","Yu-Hua Chen","Hsi-Chun Cheng","Kunal Dhawan","Jia-Lin Fang","Shi-Xin Fang","Kuan-Yu Fang Chiang","Chi An Fu","Hsien-Fu Hsiao","Ching Yu Hsu","Shao-Syuan Huang","Lee Chen Wei","Hsi-Che Lin","Hsuan-Hao Lin","Hsuan-Ting Lin","Jian-Ren Lin","Ting-Chun Liu","Li-Chun Lu","Tsung-Min Pai","Ankita Pasad","Shih-Yun Shan Kuan","Suwon Shon","Yuxun Tang","Yun-Shao Tsai","Jui-Chiang Wei","Tzu-Chieh Wei","Chengxi Wu","Dien-Ruei Wu","Chao-Han Huck Yang","Chieh-Chi Yang","Jia Qi Yip","Shao-Xiang Yuan","Vahid Noroozi","Zhehuai Chen","Haibin Wu","Karen Livescu","David Harwath","Shinji Watanabe","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2411.05361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01251v3","updated":"2024-11-08T06:07:51Z","published":"2024-03-02T16:23:44Z","title":"Accelerating Greedy Coordinate Gradient and General Prompt Optimization\n  via Probe Sampling","summary":"  Safety of Large Language Models (LLMs) has become a critical issue given\ntheir rapid progresses. Greedy Coordinate Gradient (GCG) is shown to be\neffective in constructing adversarial prompts to break the aligned LLMs, but\noptimization of GCG is time-consuming. To reduce the time cost of GCG and\nenable more comprehensive studies of LLM safety, in this work, we study a new\nalgorithm called $\\texttt{Probe sampling}$. At the core of the algorithm is a\nmechanism that dynamically determines how similar a smaller draft model's\npredictions are to the target model's predictions for prompt candidates. When\nthe target model is similar to the draft model, we rely heavily on the draft\nmodel to filter out a large number of potential prompt candidates. Probe\nsampling achieves up to $5.6$ times speedup using Llama2-7b-chat and leads to\nequal or improved attack success rate (ASR) on the AdvBench. Furthermore, probe\nsampling is also able to accelerate other prompt optimization techniques and\nadversarial methods, leading to acceleration of $1.8\\times$ for AutoPrompt,\n$2.4\\times$ for APE and $2.4\\times$ for AutoDAN.\n","authors":["Yiran Zhao","Wenyue Zheng","Tianle Cai","Xuan Long Do","Kenji Kawaguchi","Anirudh Goyal","Michael Shieh"],"pdf_url":"https://arxiv.org/pdf/2403.01251v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05345v1","updated":"2024-11-08T05:54:05Z","published":"2024-11-08T05:54:05Z","title":"Reasoning Robustness of LLMs to Adversarial Typographical Errors","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in\nreasoning using Chain-of-Thought (CoT) prompting. However, CoT can be biased by\nusers' instruction. In this work, we study the reasoning robustness of LLMs to\ntypographical errors, which can naturally occur in users' queries. We design an\nAdversarial Typo Attack ($\\texttt{ATA}$) algorithm that iteratively samples\ntypos for words that are important to the query and selects the edit that is\nmost likely to succeed in attacking. It shows that LLMs are sensitive to\nminimal adversarial typographical changes. Notably, with 1 character edit,\nMistral-7B-Instruct's accuracy drops from 43.7% to 38.6% on GSM8K, while with 8\ncharacter edits the performance further drops to 19.2%. To extend our\nevaluation to larger and closed-source LLMs, we develop the $\\texttt{R$^2$ATA}$\nbenchmark, which assesses models' $\\underline{R}$easoning\n$\\underline{R}$obustness to $\\underline{\\texttt{ATA}}$. It includes adversarial\ntypographical questions derived from three widely used reasoning\ndatasets-GSM8K, BBH, and MMLU-by applying $\\texttt{ATA}$ to open-source LLMs.\n$\\texttt{R$^2$ATA}$ demonstrates remarkable transferability and causes notable\nperformance drops across multiple super large and closed-source LLMs.\n","authors":["Esther Gan","Yiran Zhao","Liying Cheng","Yancan Mao","Anirudh Goyal","Kenji Kawaguchi","Min-Yen Kan","Michael Shieh"],"pdf_url":"https://arxiv.org/pdf/2411.05345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05340v1","updated":"2024-11-08T05:43:40Z","published":"2024-11-08T05:43:40Z","title":"Improving Multi-Domain Task-Oriented Dialogue System with Offline\n  Reinforcement Learning","summary":"  Task-oriented dialogue (TOD) system is designed to accomplish user-defined\ntasks through dialogues. The TOD system has progressed towards end-to-end\nmodeling by leveraging pre-trained large language models. Fine-tuning the\npre-trained language models using only supervised learning leads to the\nexposure bias and token loss problem and it deviates the models from completing\nthe user's task. To address these issues, we propose a TOD system that\nleverages a unified pre-trained language model, GPT2, as a base model. It is\noptimized using supervised learning and reinforcement learning (RL). The issues\nin the TOD system are mitigated using a non-differentiable reward function. The\nreward is calculated using the weighted sum of the success rate and BLEU\nevaluation metrics. The success rate and BLEU metrics in reward calculation\nguide the language model for user task completion while ensuring a coherent and\nfluent response. Our model is acquired by fine-tuning a pre-trained model on\nthe dialogue-session level which comprises user utterance, belief state, system\nact, and system response. Experimental results on MultiWOZ2.1 demonstrate that\nour model increases the inform rate by 1.60% and the success rate by 3.17%\ncompared to the baseline.\n","authors":["Dharmendra Prajapat","Durga Toshniwal"],"pdf_url":"https://arxiv.org/pdf/2411.05340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05338v1","updated":"2024-11-08T05:28:22Z","published":"2024-11-08T05:28:22Z","title":"SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers","summary":"  Scientific literature is typically dense, requiring significant background\nknowledge and deep comprehension for effective engagement. We introduce SciDQA,\na new dataset for reading comprehension that challenges LLMs for a deep\nunderstanding of scientific articles, consisting of 2,937 QA pairs. Unlike\nother scientific QA datasets, SciDQA sources questions from peer reviews by\ndomain experts and answers by paper authors, ensuring a thorough examination of\nthe literature. We enhance the dataset's quality through a process that\ncarefully filters out lower quality questions, decontextualizes the content,\ntracks the source document across different versions, and incorporates a\nbibliography for multi-document question-answering. Questions in SciDQA\nnecessitate reasoning across figures, tables, equations, appendices, and\nsupplementary materials, and require multi-document reasoning. We evaluate\nseveral open-source and proprietary LLMs across various configurations to\nexplore their capabilities in generating relevant and factual responses. Our\ncomprehensive evaluation, based on metrics for surface-level similarity and LLM\njudgements, highlights notable performance discrepancies. SciDQA represents a\nrigorously curated, naturally derived scientific QA dataset, designed to\nfacilitate research on complex scientific text understanding.\n","authors":["Shruti Singh","Nandan Sarkar","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2411.05338v1.pdf","comment":"18 pages, Accepted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2406.16524v2","updated":"2024-11-08T05:24:12Z","published":"2024-06-24T10:59:26Z","title":"The Privileged Students: On the Value of Initialization in Multilingual\n  Knowledge Distillation","summary":"  Knowledge distillation (KD) has proven to be a successful strategy to improve\nthe performance of smaller models in many NLP tasks. However, most of the work\nin KD only explores monolingual scenarios. In this paper, we investigate the\nvalue of KD in multilingual settings. We find the significance of KD and model\ninitialization by analyzing how well the student model acquires multilingual\nknowledge from the teacher model. Our proposed method emphasizes copying the\nteacher model's weights directly to the student model to enhance\ninitialization. Our findings show that model initialization using copy-weight\nfrom the fine-tuned teacher contributes the most compared to the distillation\nprocess itself across various multilingual settings. Furthermore, we\ndemonstrate that efficient weight initialization preserves multilingual\ncapabilities even in low-resource scenarios.\n","authors":["Haryo Akbarianto Wibowo","Thamar Solorio","Alham Fikri Aji"],"pdf_url":"https://arxiv.org/pdf/2406.16524v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2405.16964v2","updated":"2024-11-08T05:19:48Z","published":"2024-05-27T08:57:04Z","title":"Exploring the LLM Journey from Cognition to Expression with Linear\n  Representations","summary":"  This paper presents an in-depth examination of the evolution and interplay of\ncognitive and expressive capabilities in large language models (LLMs), with a\nspecific focus on Baichuan-7B and Baichuan-33B, an advanced bilingual (Chinese\nand English) LLM series. We define and explore the model's cognitive and\nexpressive capabilities through linear representations across three critical\nphases: Pretraining, Supervised Fine-Tuning (SFT), and Reinforcement Learning\nfrom Human Feedback (RLHF). Cognitive capability is defined as the quantity and\nquality of information conveyed by the neuron output vectors within the\nnetwork, similar to the neural signal processing in human cognition. Expressive\ncapability is defined as the model's capability to produce word-level output.\nOur findings unveil a sequential development pattern, where cognitive abilities\nare largely established during Pretraining, whereas expressive abilities\npredominantly advance during SFT and RLHF. Statistical analyses confirm a\nsignificant correlation between the two capabilities, suggesting that cognitive\ncapacity may limit expressive potential. The paper also explores the\ntheoretical underpinnings of these divergent developmental trajectories and\ntheir connection to the LLMs' architectural design. Moreover, we evaluate\nvarious optimization-independent strategies, such as few-shot learning and\nrepeated sampling, which bridge the gap between cognitive and expressive\ncapabilities. This research reveals the potential connection between the hidden\nspace and the output space, contributing valuable insights into the\ninterpretability and controllability of their training processes.\n","authors":["Yuzi Yan","Jialian Li","Yipin Zhang","Dong Yan"],"pdf_url":"https://arxiv.org/pdf/2405.16964v2.pdf","comment":"Published in ICML 2024"},{"id":"http://arxiv.org/abs/2402.15721v2","updated":"2024-11-08T05:08:43Z","published":"2024-02-24T05:14:52Z","title":"Hal-Eval: A Universal and Fine-grained Hallucination Evaluation\n  Framework for Large Vision Language Models","summary":"  Large Vision Language Models exhibit remarkable capabilities but struggle\nwith hallucinations inconsistencies between images and their descriptions.\nPrevious hallucination evaluation studies on LVLMs have identified\nhallucinations in terms of objects, attributes, and relations but overlooked\ncomplex hallucinations that create an entire narrative around a fictional\nentity. In this paper, we introduce a refined taxonomy of hallucinations,\nfeaturing a new category: Event Hallucination. We then utilize advanced LLMs to\ngenerate and filter fine grained hallucinatory data consisting of various types\nof hallucinations, with a particular focus on event hallucinations, laying the\ngroundwork for integrating discriminative and generative evaluation methods\nwithin our universal evaluation framework. The proposed benchmark distinctively\nassesses LVLMs ability to tackle a broad spectrum of hallucinations, making it\na reliable and comprehensive tool for gauging LVLMs efficacy in handling\nhallucinations. We will release our code and data.\n","authors":["Chaoya Jiang","Hongrui Jia","Wei Ye","Mengfan Dong","Haiyang Xu","Ming Yan","Ji Zhang","Shikun Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.15721v2.pdf","comment":"Accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2411.00369v3","updated":"2024-11-08T03:09:37Z","published":"2024-11-01T05:14:03Z","title":"GRS-QA -- Graph Reasoning-Structured Question Answering Dataset","summary":"  Large Language Models (LLMs) have excelled in multi-hop question-answering\n(M-QA) due to their advanced reasoning abilities. However, the impact of the\ninherent reasoning structures on LLM M-QA performance remains unclear, largely\ndue to the absence of QA datasets that provide fine-grained reasoning\nstructures. To address this gap, we introduce the Graph Reasoning-Structured\nQuestion Answering Dataset (GRS-QA), which includes both semantic contexts and\nreasoning structures for QA pairs. Unlike existing M-QA datasets, where\ndifferent reasoning structures are entangled together, GRS-QA explicitly\ncaptures intricate reasoning pathways by constructing reasoning graphs, where\nnodes represent textual contexts and edges denote logical flows. These\nreasoning graphs of different structures enable a fine-grained evaluation of\nLLM reasoning capabilities across various reasoning structures. Our empirical\nanalysis reveals that LLMs perform differently when handling questions with\nvarying reasoning structures. This finding facilitates the exploration of\ntextual structures as compared with semantics.\n","authors":["Anish Pahilajani","Devasha Trivedi","Jincen Shuai","Khin S. Yone","Samyak Rajesh Jain","Namyong Park","Ryan A. Rossi","Nesreen K. Ahmed","Franck Dernoncourt","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2411.00369v3.pdf","comment":"15 pages, 24 figures, 10 tables"},{"id":"http://arxiv.org/abs/2411.05289v1","updated":"2024-11-08T02:47:07Z","published":"2024-11-08T02:47:07Z","title":"SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding","summary":"  Large Language Models (LLMs) have become essential in advancing natural\nlanguage processing (NLP) tasks, but their sequential token generation limits\ninference speed. Multi-Draft Speculative Decoding (MDSD) offers a promising\nsolution by using a smaller draft model to generate multiple token sequences,\nwhich the target LLM verifies in parallel. However, current heuristic\napproaches, such as Recursive Rejection Sampling (RRS), suffer from low\nacceptance rates in subsequent drafts, limiting the advantages of using\nmultiple drafts. Meanwhile, Optimal Transport with Membership Cost (OTM) can\ntheoretically improve acceptance rates, but its computational cost is too high\nfor real-time use. We present SpecHub, a novel, efficient sampling-verification\nmethod for MDSD that improves acceptance rates with only linear computational\noverhead. By simplifying the OTM problem into a compact Linear Programming\nmodel, SpecHub significantly reduces computational complexity. It further\naccelerates sampling by leveraging a sparse joint distribution, focusing\ncomputation on high-probability token sequences. In extensive experiments,\nSpechub consistently generates 0.05-0.27 and 0.02-0.16 more tokens per step\nthan RRS and RRS without replacement. We attach our code at\n\\url{https://github.com/MasterGodzilla/Speculative_decoding_OT}.\n","authors":["Ryan Sun","Tianyi Zhou","Xun Chen","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2411.05289v1.pdf","comment":"EMNLP 2024 (Main)"},{"id":"http://arxiv.org/abs/2411.05281v1","updated":"2024-11-08T02:24:29Z","published":"2024-11-08T02:24:29Z","title":"Fox-1 Technical Report","summary":"  We present Fox-1, a series of small language models (SLMs) consisting of\nFox-1-1.6B and Fox-1-1.6B-Instruct-v0.1. These models are pre-trained on 3\ntrillion tokens of web-scraped document data and fine-tuned with 5 billion\ntokens of instruction-following and multi-turn conversation data. Aiming to\nimprove the pre-training efficiency, Fox-1-1.6B model introduces a novel\n3-stage data curriculum across all the training data with 2K-8K sequence\nlength. In architecture design, Fox-1 features a deeper layer structure, an\nexpanded vocabulary, and utilizes Grouped Query Attention (GQA), offering a\nperformant and efficient architecture compared to other SLMs. Fox-1 achieves\nbetter or on-par performance in various benchmarks compared to StableLM-2-1.6B,\nGemma-2B, Qwen1.5-1.8B, and OpenELM1.1B, with competitive inference speed and\nthroughput. The model weights have been released under the Apache 2.0 license,\nwhere we aim to promote the democratization of LLMs and make them fully\naccessible to the whole open-source community.\n","authors":["Zijian Hu","Jipeng Zhang","Rui Pan","Zhaozhuo Xu","Salman Avestimehr","Chaoyang He","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05281v1.pdf","comment":"Base model is available at\n  https://huggingface.co/tensoropera/Fox-1-1.6B and the instruction-tuned\n  version is available at\n  https://huggingface.co/tensoropera/Fox-1-1.6B-Instruct-v0.1"},{"id":"http://arxiv.org/abs/2411.05277v1","updated":"2024-11-08T02:22:30Z","published":"2024-11-08T02:22:30Z","title":"Revisiting the Robustness of Watermarking to Paraphrasing Attacks","summary":"  Amidst rising concerns about the internet being proliferated with content\ngenerated from language models (LMs), watermarking is seen as a principled way\nto certify whether text was generated from a model. Many recent watermarking\ntechniques slightly modify the output probabilities of LMs to embed a signal in\nthe generated output that can later be detected. Since early proposals for text\nwatermarking, questions about their robustness to paraphrasing have been\nprominently discussed. Lately, some techniques are deliberately designed and\nclaimed to be robust to paraphrasing. However, such watermarking schemes do not\nadequately account for the ease with which they can be reverse-engineered. We\nshow that with access to only a limited number of generations from a black-box\nwatermarked model, we can drastically increase the effectiveness of\nparaphrasing attacks to evade watermark detection, thereby rendering the\nwatermark ineffective.\n","authors":["Saksham Rastogi","Danish Pruthi"],"pdf_url":"https://arxiv.org/pdf/2411.05277v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2406.16235v2","updated":"2024-11-08T02:17:22Z","published":"2024-06-23T22:53:47Z","title":"Preference Tuning For Toxicity Mitigation Generalizes Across Languages","summary":"  Detoxifying multilingual Large Language Models (LLMs) has become crucial due\nto their increasing global use. In this work, we explore zero-shot\ncross-lingual generalization of preference tuning in detoxifying LLMs. Unlike\nprevious studies that show limited cross-lingual generalization for other\nsafety tasks, we demonstrate that Direct Preference Optimization (DPO) training\nwith only English data can significantly reduce toxicity in multilingual\nopen-ended generations. For example, the probability of mGPT-1.3B generating\ntoxic continuations drops from 46.8% to 3.9% across 17 different languages\nafter training. Our results also extend to other multilingual LLMs, such as\nBLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal\nintervention and activation analysis, we identified the dual multilinguality\nproperty of MLP layers in LLMs, which explains the cross-lingual generalization\nof DPO. Finally, we show that bilingual sentence retrieval can predict the\ncross-lingual transferability of DPO preference tuning.\n","authors":["Xiaochen Li","Zheng-Xin Yong","Stephen H. Bach"],"pdf_url":"https://arxiv.org/pdf/2406.16235v2.pdf","comment":"Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05270v1","updated":"2024-11-08T02:06:41Z","published":"2024-11-08T02:06:41Z","title":"Seeing Through the Fog: A Cost-Effectiveness Analysis of Hallucination\n  Detection Systems","summary":"  This paper presents a comparative analysis of hallucination detection systems\nfor AI, focusing on automatic summarization and question answering tasks for\nLarge Language Models (LLMs). We evaluate different hallucination detection\nsystems using the diagnostic odds ratio (DOR) and cost-effectiveness metrics.\nOur results indicate that although advanced models can perform better they come\nat a much higher cost. We also demonstrate how an ideal hallucination detection\nsystem needs to maintain performance across different model sizes. Our findings\nhighlight the importance of choosing a detection system aligned with specific\napplication needs and resource constraints. Future research will explore hybrid\nsystems and automated identification of underperforming components to enhance\nAI reliability and efficiency in detecting and mitigating hallucinations.\n","authors":["Alexander Thomas","Seth Rosen","Vishnu Vettrivel"],"pdf_url":"https://arxiv.org/pdf/2411.05270v1.pdf","comment":"18 pags, 13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2405.18822v2","updated":"2024-11-08T01:49:58Z","published":"2024-05-29T07:03:31Z","title":"Toxicity Detection for Free","summary":"  Current LLMs are generally aligned to follow safety requirements and tend to\nrefuse toxic prompts. However, LLMs can fail to refuse toxic prompts or be\novercautious and refuse benign examples. In addition, state-of-the-art toxicity\ndetectors have low TPRs at low FPR, incurring high costs in real-world\napplications where toxic examples are rare. In this paper, we introduce\nModeration Using LLM Introspection (MULI), which detects toxic prompts using\nthe information extracted directly from LLMs themselves. We found we can\ndistinguish between benign and toxic prompts from the distribution of the first\nresponse token's logits. Using this idea, we build a robust detector of toxic\nprompts using a sparse logistic regression model on the first response token\nlogits. Our scheme outperforms SOTA detectors under multiple metrics.\n","authors":["Zhanhao Hu","Julien Piet","Geng Zhao","Jiantao Jiao","David Wagner"],"pdf_url":"https://arxiv.org/pdf/2405.18822v2.pdf","comment":"Accepted by Neurips 2024"},{"id":"http://arxiv.org/abs/2411.05261v1","updated":"2024-11-08T01:46:11Z","published":"2024-11-08T01:46:11Z","title":"Decoding Report Generators: A Cyclic Vision-Language Adapter for\n  Counterfactual Explanations","summary":"  Despite significant advancements in report generation methods, a critical\nlimitation remains: the lack of interpretability in the generated text. This\npaper introduces an innovative approach to enhance the explainability of text\ngenerated by report generation models. Our method employs cyclic text\nmanipulation and visual comparison to identify and elucidate the features in\nthe original content that influence the generated text. By manipulating the\ngenerated reports and producing corresponding images, we create a comparative\nframework that highlights key attributes and their impact on the text\ngeneration process. This approach not only identifies the image features\naligned to the generated text but also improves transparency but also provides\ndeeper insights into the decision-making mechanisms of the report generation\nmodels. Our findings demonstrate the potential of this method to significantly\nenhance the interpretability and transparency of AI-generated reports.\n","authors":["Yingying Fang","Zihao Jin","Shaojie Guo","Jinda Liu","Yijian Gao","Junzhi Ning","Zhiling Yue","Zhi Li","Simon LF Walsh","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2411.05261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05253v1","updated":"2024-11-08T00:46:24Z","published":"2024-11-08T00:46:24Z","title":"What talking you?: Translating Code-Mixed Messaging Texts to English","summary":"  Translation of code-mixed texts to formal English allow a wider audience to\nunderstand these code-mixed languages, and facilitate downstream analysis\napplications such as sentiment analysis. In this work, we look at translating\nSinglish, which is colloquial Singaporean English, to formal standard English.\nSinglish is formed through the code-mixing of multiple Asian languages and\ndialects. We analysed the presence of other Asian languages and variants which\ncan facilitate translation. Our dataset is short message texts, written as\ninformal communication between Singlish speakers. We use a multi-step prompting\nscheme on five Large Language Models (LLMs) for language detection and\ntranslation. Our analysis show that LLMs do not perform well in this task, and\nwe describe the challenges involved in translation of code-mixed languages. We\nalso release our dataset in this link https://github.com/luoqichan/singlish.\n","authors":["Lynnette Hui Xian Ng","Luo Qi Chan"],"pdf_url":"https://arxiv.org/pdf/2411.05253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16156v2","updated":"2024-11-08T00:40:05Z","published":"2024-10-21T16:21:45Z","title":"Limpeh ga li gong: Challenges in Singlish Annotations","summary":"  Singlish, or Colloquial Singapore English, is a language formed from oral and\nsocial communication within multicultural Singapore. In this work, we work on a\nfundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)\ntagging of Singlish sentences. For our analysis, we build a parallel Singlish\ndataset containing direct English translations and POS tags, with translation\nand POS annotation done by native Singlish speakers. Our experiments show that\nautomatic transition- and transformer- based taggers perform with only $\\sim\n80\\%$ accuracy when evaluated against human-annotated POS labels, suggesting\nthat there is indeed room for improvement on computation analysis of the\nlanguage. We provide an exposition of challenges in Singlish annotation: its\ninconsistencies in form and semantics, the highly context-dependent particles\nof the language, its structural unique expressions, and the variation of the\nlanguage on different mediums. Our task definition, resultant labels and\nresults reflects the challenges in analysing colloquial languages formulated\nfrom a variety of dialects, and paves the way for future studies beyond POS\ntagging.\n","authors":["Luo Qi Chan","Lynnette Hui Xian Ng"],"pdf_url":"https://arxiv.org/pdf/2410.16156v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00980v2","updated":"2024-11-08T00:36:10Z","published":"2024-11-01T19:11:54Z","title":"Enhancing AAC Software for Dysarthric Speakers in e-Health Settings: An\n  Evaluation Using TORGO","summary":"  Individuals with cerebral palsy (CP) and amyotrophic lateral sclerosis (ALS)\nfrequently face challenges with articulation, leading to dysarthria and\nresulting in atypical speech patterns. In healthcare settings, communication\nbreakdowns reduce the quality of care. While building an augmentative and\nalternative communication (AAC) tool to enable fluid communication we found\nthat state-of-the-art (SOTA) automatic speech recognition (ASR) technology like\nWhisper and Wav2vec2.0 marginalizes atypical speakers largely due to the lack\nof training data. Our work looks to leverage SOTA ASR followed by domain\nspecific error-correction. English dysarthric ASR performance is often\nevaluated on the TORGO dataset. Prompt-overlap is a well-known issue with this\ndataset where phrases overlap between training and test speakers. Our work\nproposes an algorithm to break this prompt-overlap. After reducing\nprompt-overlap, results with SOTA ASR models produce extremely high word error\nrates for speakers with mild and severe dysarthria. Furthermore, to improve\nASR, our work looks at the impact of n-gram language models and large-language\nmodel (LLM) based multi-modal generative error-correction algorithms like\nWhispering-LLaMA for a second pass ASR. Our work highlights how much more needs\nto be done to improve ASR for atypical speakers to enable equitable healthcare\naccess both in-person and in e-health settings.\n","authors":["Macarious Hui","Jinda Zhang","Aanchan Mohan"],"pdf_url":"https://arxiv.org/pdf/2411.00980v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10440v3","updated":"2024-11-08T23:12:56Z","published":"2024-05-16T20:59:28Z","title":"A Hybrid Framework with Large Language Models for Rare Disease\n  Phenotyping","summary":"  Rare diseases pose significant challenges in diagnosis and treatment due to\ntheir low prevalence and heterogeneous clinical presentations. Unstructured\nclinical notes contain valuable information for identifying rare diseases, but\nmanual curation is time-consuming and prone to subjectivity. This study aims to\ndevelop a hybrid approach combining dictionary-based natural language\nprocessing (NLP) tools with large language models (LLMs) to improve rare\ndisease identification from unstructured clinical reports. We propose a novel\nhybrid framework that integrates the Orphanet Rare Disease Ontology (ORDO) and\nthe Unified Medical Language System (UMLS) to create a comprehensive rare\ndisease vocabulary. The proposed hybrid approach demonstrates superior\nperformance compared to traditional NLP systems and standalone LLMs. Notably,\nthe approach uncovers a significant number of potential rare disease cases not\ndocumented in structured diagnostic records, highlighting its ability to\nidentify previously unrecognized patients.\n","authors":["Jinge Wu","Hang Dong","Zexi Li","Haowei Wang","Runci Li","Arijit Patra","Chengliang Dai","Waqar Ali","Phil Scordis","Honghan Wu"],"pdf_url":"https://arxiv.org/pdf/2405.10440v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07491v2","updated":"2024-11-08T23:12:44Z","published":"2024-10-09T23:53:13Z","title":"Transducer Consistency Regularization for Speech to Text Applications","summary":"  Consistency regularization is a commonly used practice to encourage the model\nto generate consistent representation from distorted input features and improve\nmodel generalization. It shows significant improvement on various speech\napplications that are optimized with cross entropy criterion. However, it is\nnot straightforward to apply consistency regularization for the\ntransducer-based approaches, which are widely adopted for speech applications\ndue to the competitive performance and streaming characteristic. The main\nchallenge is from the vast alignment space of the transducer optimization\ncriterion and not all the alignments within the space contribute to the model\noptimization equally. In this study, we present Transducer Consistency\nRegularization (TCR), a consistency regularization method for transducer\nmodels. We apply distortions such as spec augmentation and dropout to create\ndifferent data views and minimize the distribution difference. We utilize\noccupational probabilities to give different weights on transducer output\ndistributions, thus only alignments close to oracle alignments would contribute\nto the model learning. Our experiments show the proposed method is superior to\nother consistency regularization implementations and could effectively reduce\nword error rate (WER) by 4.3\\% relatively comparing with a strong baseline on\nthe \\textsc{Librispeech} dataset.\n","authors":["Cindy Tseng","Yun Tang","Vijendra Raj Apsingekar"],"pdf_url":"https://arxiv.org/pdf/2410.07491v2.pdf","comment":"8 pages, 4 figures. Accepted in IEEE Spoken Language Technology\n  Workshop 2024"},{"id":"http://arxiv.org/abs/2406.17260v2","updated":"2024-11-08T23:11:36Z","published":"2024-06-25T03:56:33Z","title":"Mitigating Hallucination in Fictional Character Role-Play","summary":"  Role-playing has wide-ranging applications in customer support, embodied\nagents, and computational social science. The influence of parametric world\nknowledge of large language models (LLMs) often causes role-playing characters\nto act out of character and to hallucinate about things outside the scope of\ntheir knowledge. In this work, we focus on the evaluation and mitigation of\nhallucination in fictional character role-play. We introduce a dataset with\nover 2,000 characters and 72,000 interviews, including 18,000 adversarial\nquestions. We propose RoleFact, a role-playing method that mitigates\nhallucination by modulating the influence of parametric knowledge using a\npre-calibrated confidence threshold. Experiments show that the proposed method\nimproves the factual precision of generated responses by 18% for adversarial\nquestions with a 44% reduction in temporal hallucination for time-sensitive\ninterviews. The code and the dataset are available at\nhttps://github.com/NafisSadeq/rolefact.git.\n","authors":["Nafis Sadeq","Zhouhang Xie","Byungkyu Kang","Prarit Lamba","Xiang Gao","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2406.17260v2.pdf","comment":"EMNLP 2024 Camera Ready"},{"id":"http://arxiv.org/abs/2411.06008v1","updated":"2024-11-08T23:02:59Z","published":"2024-11-08T23:02:59Z","title":"The Dark Patterns of Personalized Persuasion in Large Language Models:\n  Exposing Persuasive Linguistic Features for Big Five Personality Traits in\n  LLMs Responses","summary":"  This study explores how the Large Language Models (LLMs) adjust linguistic\nfeatures to create personalized persuasive outputs. While research showed that\nLLMs personalize outputs, a gap remains in understanding the linguistic\nfeatures of their persuasive capabilities. We identified 13 linguistic features\ncrucial for influencing personalities across different levels of the Big Five\nmodel of personality. We analyzed how prompts with personality trait\ninformation influenced the output of 19 LLMs across five model families. The\nfindings show that models use more anxiety-related words for neuroticism,\nincrease achievement-related words for conscientiousness, and employ fewer\ncognitive processes words for openness to experience. Some model families excel\nat adapting language for openness to experience, others for conscientiousness,\nwhile only one model adapts language for neuroticism. Our findings show how\nLLMs tailor responses based on personality cues in prompts, indicating their\npotential to create persuasive content affecting the mind and well-being of the\nrecipients.\n","authors":["Wiktoria Mieleszczenko-Kowszewicz","Dawid P≈Çudowski","Filip Ko≈Çodziejczyk","Jakub ≈öwistak","Julian Sienkiewicz","Przemys≈Çaw Biecek"],"pdf_url":"https://arxiv.org/pdf/2411.06008v1.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2407.02596v2","updated":"2024-11-08T22:36:16Z","published":"2024-07-02T18:33:49Z","title":"Towards More Realistic Extraction Attacks: An Adversarial Perspective","summary":"  Language models are prone to memorizing parts of their training data which\nmakes them vulnerable to extraction attacks. Existing research often examines\nisolated setups--such as evaluating extraction risks from a single model or\nwith a fixed prompt design. However, a real-world adversary could access models\nacross various sizes and checkpoints, as well as exploit prompt sensitivity,\nresulting in a considerably larger attack surface than previously studied. In\nthis paper, we revisit extraction attacks from an adversarial perspective,\nfocusing on how to leverage the brittleness of language models and the\nmulti-faceted access to the underlying data. We find significant churn in\nextraction trends, i.e., even unintuitive changes to the prompt, or targeting\nsmaller models and earlier checkpoints, can extract distinct information. By\ncombining information from multiple attacks, our adversary is able to increase\nthe extraction risks by up to $2 \\times$. Furthermore, even with mitigation\nstrategies like data deduplication, we find the same escalation of extraction\nrisks against a real-world adversary. We conclude with a set of case studies,\nincluding detecting pre-training data, copyright violations, and extracting\npersonally identifiable information, showing how our more realistic adversary\ncan outperform existing adversaries in the literature.\n","authors":["Yash More","Prakhar Ganesh","Golnoosh Farnadi"],"pdf_url":"https://arxiv.org/pdf/2407.02596v2.pdf","comment":"Presented at PrivateNLP@ACL2024"},{"id":"http://arxiv.org/abs/2409.18025v3","updated":"2024-11-08T22:06:41Z","published":"2024-09-26T16:32:19Z","title":"An Adversarial Perspective on Machine Unlearning for AI Safety","summary":"  Large language models are finetuned to refuse questions about hazardous\nknowledge, but these protections can often be bypassed. Unlearning methods aim\nat completely removing hazardous capabilities from models and make them\ninaccessible to adversaries. This work challenges the fundamental differences\nbetween unlearning and traditional safety post-training from an adversarial\nperspective. We demonstrate that existing jailbreak methods, previously\nreported as ineffective against unlearning, can be successful when applied\ncarefully. Furthermore, we develop a variety of adaptive methods that recover\nmost supposedly unlearned capabilities. For instance, we show that finetuning\non 10 unrelated examples or removing specific directions in the activation\nspace can recover most hazardous capabilities for models edited with RMU, a\nstate-of-the-art unlearning method. Our findings challenge the robustness of\ncurrent unlearning approaches and question their advantages over safety\ntraining.\n","authors":["Jakub ≈Åucki","Boyi Wei","Yangsibo Huang","Peter Henderson","Florian Tram√®r","Javier Rando"],"pdf_url":"https://arxiv.org/pdf/2409.18025v3.pdf","comment":"Spotlight paper at Neurips 2024 SoLaR workshop"},{"id":"http://arxiv.org/abs/2411.03417v2","updated":"2024-11-08T22:06:08Z","published":"2024-11-05T18:58:00Z","title":"Usefulness of LLMs as an Author Checklist Assistant for Scientific\n  Papers: NeurIPS'24 Experiment","summary":"  Large language models (LLMs) represent a promising, but controversial, tool\nin aiding scientific peer review. This study evaluates the usefulness of LLMs\nin a conference setting as a tool for vetting paper submissions against\nsubmission standards. We conduct an experiment at the 2024 Neural Information\nProcessing Systems (NeurIPS) conference, where 234 papers were voluntarily\nsubmitted to an \"LLM-based Checklist Assistant.\" This assistant validates\nwhether papers adhere to the author checklist used by NeurIPS, which includes\nquestions to ensure compliance with research and manuscript preparation\nstandards. Evaluation of the assistant by NeurIPS paper authors suggests that\nthe LLM-based assistant was generally helpful in verifying checklist\ncompletion. In post-usage surveys, over 70% of authors found the assistant\nuseful, and 70% indicate that they would revise their papers or checklist\nresponses based on its feedback. While causal attribution to the assistant is\nnot definitive, qualitative evidence suggests that the LLM contributed to\nimproving some submissions. Survey responses and analysis of re-submissions\nindicate that authors made substantive revisions to their submissions in\nresponse to specific feedback from the LLM. The experiment also highlights\ncommon issues with LLMs: inaccuracy (20/52) and excessive strictness (14/52)\nwere the most frequent issues flagged by authors. We also conduct experiments\nto understand potential gaming of the system, which reveal that the assistant\ncould be manipulated to enhance scores through fabricated justifications,\nhighlighting potential vulnerabilities of automated review tools.\n","authors":["Alexander Goldberg","Ihsan Ullah","Thanh Gia Hieu Khuong","Benedictus Kent Rachmat","Zhen Xu","Isabelle Guyon","Nihar B. Shah"],"pdf_url":"https://arxiv.org/pdf/2411.03417v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05991v1","updated":"2024-11-08T22:03:54Z","published":"2024-11-08T22:03:54Z","title":"GUIDEQ: Framework for Guided Questioning for progressive informational\n  collection and classification","summary":"  Question Answering (QA) is an important part of tasks like text\nclassification through information gathering. These are finding increasing use\nin sectors like healthcare, customer support, legal services, etc., to collect\nand classify responses into actionable categories. LLMs, although can support\nQA systems, they face a significant challenge of insufficient or missing\ninformation for classification. Although LLMs excel in reasoning, the models\nrely on their parametric knowledge to answer. However, questioning the user\nrequires domain-specific information aiding to collect accurate information.\nOur work, GUIDEQ, presents a novel framework for asking guided questions to\nfurther progress a partial information. We leverage the explainability derived\nfrom the classifier model for along with LLMs for asking guided questions to\nfurther enhance the information. This further information helps in more\naccurate classification of a text. GUIDEQ derives the most significant\nkey-words representative of a label using occlusions. We develop GUIDEQ's\nprompting strategy for guided questions based on the top-3 classifier label\noutputs and the significant words, to seek specific and relevant information,\nand classify in a targeted manner. Through our experimental results, we\ndemonstrate that GUIDEQ outperforms other LLM-based baselines, yielding\nimproved F1-Score through the accurate collection of relevant further\ninformation. We perform various analytical studies and also report better\nquestion quality compared to our method.\n","authors":["Priya Mishra","Suraj Racha","Kaustubh Ponkshe","Adit Akarsh","Ganesh Ramakrishnan"],"pdf_url":"https://arxiv.org/pdf/2411.05991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05990v1","updated":"2024-11-08T22:02:22Z","published":"2024-11-08T22:02:22Z","title":"Game-theoretic LLM: Agent Workflow for Negotiation Games","summary":"  This paper investigates the rationality of large language models (LLMs) in\nstrategic decision-making contexts, specifically within the framework of game\ntheory. We evaluate several state-of-the-art LLMs across a spectrum of\ncomplete-information and incomplete-information games. Our findings reveal that\nLLMs frequently deviate from rational strategies, particularly as the\ncomplexity of the game increases with larger payoff matrices or deeper\nsequential trees.\n  To address these limitations, we design multiple game-theoretic workflows\nthat guide the reasoning and decision-making processes of LLMs. These workflows\naim to enhance the models' ability to compute Nash Equilibria and make rational\nchoices, even under conditions of uncertainty and incomplete information.\nExperimental results demonstrate that the adoption of these workflows\nsignificantly improves the rationality and robustness of LLMs in game-theoretic\ntasks. Specifically, with the workflow, LLMs exhibit marked improvements in\nidentifying optimal strategies, achieving near-optimal allocations in\nnegotiation scenarios, and reducing susceptibility to exploitation during\nnegotiations. Furthermore, we explore the meta-strategic considerations of\nwhether it is rational for agents to adopt such workflows, recognizing that the\ndecision to use or forgo the workflow constitutes a game-theoretic issue in\nitself.\n  Our research contributes to a deeper understanding of LLMs' decision-making\ncapabilities in strategic contexts and provides insights into enhancing their\nrationality through structured workflows. The findings have implications for\nthe development of more robust and strategically sound AI agents capable of\nnavigating complex interactive environments. Code and data supporting this\nstudy are available at \\url{https://github.com/Wenyueh/game_theory}.\n","authors":["Wenyue Hua","Ollie Liu","Lingyao Li","Alfonso Amayuelas","Julie Chen","Lucas Jiang","Mingyu Jin","Lizhou Fan","Fei Sun","William Wang","Xintong Wang","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05990v1.pdf","comment":"44 pages, 12 figures"},{"id":"http://arxiv.org/abs/2407.11194v2","updated":"2024-11-08T22:00:26Z","published":"2024-07-15T19:28:14Z","title":"AstroMLab 1: Who Wins Astronomy Jeopardy!?","summary":"  We present a comprehensive evaluation of proprietary and open-weights large\nlanguage models using the first astronomy-specific benchmarking dataset. This\ndataset comprises 4,425 multiple-choice questions curated from the Annual\nReview of Astronomy and Astrophysics, covering a broad range of astrophysical\ntopics. Our analysis examines model performance across various astronomical\nsubfields and assesses response calibration, crucial for potential deployment\nin research environments. Claude-3.5-Sonnet outperforms competitors by up to\n4.6 percentage points, achieving 85.0% accuracy. For proprietary models, we\nobserved a universal reduction in cost every 3-to-12 months to achieve similar\nscore in this particular astronomy benchmark. open-weights models have rapidly\nimproved, with LLaMA-3-70b (80.6%) and Qwen-2-72b (77.7%) now competing with\nsome of the best proprietary models. We identify performance variations across\ntopics, with non-English-focused models generally struggling more in\nexoplanet-related fields, stellar astrophysics, and instrumentation related\nquestions. These challenges likely stem from less abundant training data,\nlimited historical context, and rapid recent developments in these areas. This\npattern is observed across both open-weights and proprietary models, with\nregional dependencies evident, highlighting the impact of training data\ndiversity on model performance in specialized scientific domains.\nTop-performing models demonstrate well-calibrated confidence, with correlations\nabove 0.9 between confidence and correctness, though they tend to be slightly\nunderconfident. The development for fast, low-cost inference of open-weights\nmodels presents new opportunities for affordable deployment in astronomy. The\nrapid progress observed suggests that LLM-driven research in astronomy may\nbecome feasible in the near future.\n","authors":["Yuan-Sen Ting","Tuan Dung Nguyen","Tirthankar Ghosal","Rui Pan","Hardik Arora","Zechang Sun","Tijmen de Haan","Nesar Ramachandra","Azton Wells","Sandeep Madireddy","Alberto Accomazzi"],"pdf_url":"https://arxiv.org/pdf/2407.11194v2.pdf","comment":"45 pages, 12 figures, 7 tables. Published in Astronomy & Computing.\n  AstroMLab homepage: https://astromlab.org/"},{"id":"http://arxiv.org/abs/2411.05986v1","updated":"2024-11-08T21:55:37Z","published":"2024-11-08T21:55:37Z","title":"Fine-Grained Reward Optimization for Machine Translation using Error\n  Severity Mappings","summary":"  Reinforcement learning (RL) has been proven to be an effective and robust\nmethod for training neural machine translation systems, especially when paired\nwith powerful reward models that accurately assess translation quality.\nHowever, most research has focused on RL methods that use sentence-level\nfeedback, which leads to inefficient learning signals due to the reward\nsparsity problem -- the model receives a single score for the entire sentence.\nTo address this, we introduce a novel approach that leverages fine-grained\ntoken-level reward mechanisms with RL methods. We use xCOMET, a\nstate-of-the-art quality estimation system as our token-level reward model.\nxCOMET provides detailed feedback by predicting fine-grained error spans and\ntheir severity given source-translation pairs. We conduct experiments on small\nand large translation datasets to compare the impact of sentence-level versus\nfine-grained reward signals on translation quality. Our results show that\ntraining with token-level rewards improves translation quality across language\npairs over baselines according to automatic and human evaluation. Furthermore,\ntoken-level reward optimization also improves training stability, evidenced by\na steady increase in mean rewards over training epochs.\n","authors":["Miguel Moura Ramos","Tom√°s Almeida","Daniel Vareta","Filipe Azevedo","Sweta Agrawal","Patrick Fernandes","Andr√© F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2411.05986v1.pdf","comment":"10 pages, work-in-progress"},{"id":"http://arxiv.org/abs/2411.05980v1","updated":"2024-11-08T21:26:57Z","published":"2024-11-08T21:26:57Z","title":"FactLens: Benchmarking Fine-Grained Fact Verification","summary":"  Large Language Models (LLMs) have shown impressive capability in language\ngeneration and understanding, but their tendency to hallucinate and produce\nfactually incorrect information remains a key limitation. To verify\nLLM-generated contents and claims from other sources, traditional verification\napproaches often rely on holistic models that assign a single factuality label\nto complex claims, potentially obscuring nuanced errors. In this paper, we\nadvocate for a shift toward fine-grained verification, where complex claims are\nbroken down into smaller sub-claims for individual verification, allowing for\nmore precise identification of inaccuracies, improved transparency, and reduced\nambiguity in evidence retrieval. However, generating sub-claims poses\nchallenges, such as maintaining context and ensuring semantic equivalence with\nrespect to the original claim. We introduce FactLens, a benchmark for\nevaluating fine-grained fact verification, with metrics and automated\nevaluators of sub-claim quality. The benchmark data is manually curated to\nensure high-quality ground truth. Our results show alignment between automated\nFactLens evaluators and human judgments, and we discuss the impact of sub-claim\ncharacteristics on the overall verification performance.\n","authors":["Kushan Mitra","Dan Zhang","Sajjadur Rahman","Estevam Hruschka"],"pdf_url":"https://arxiv.org/pdf/2411.05980v1.pdf","comment":"12 pages, under review"},{"id":"http://arxiv.org/abs/2411.05978v1","updated":"2024-11-08T21:22:37Z","published":"2024-11-08T21:22:37Z","title":"The Empirical Impact of Data Sanitization on Language Models","summary":"  Data sanitization in the context of language modeling involves identifying\nsensitive content, such as personally identifiable information (PII), and\nredacting them from a dataset corpus. It is a common practice used in natural\nlanguage processing (NLP) to maintain privacy. Nevertheless, the impact of data\nsanitization on the language understanding capability of a language model\nremains less studied. This paper empirically analyzes the effects of data\nsanitization across several benchmark language-modeling tasks including\ncomprehension question answering (Q&A), entailment, sentiment analysis, and\ntext classification. Our experiments cover a wide spectrum comprising\nfinetuning small-scale language models, to prompting large language models\n(LLMs), on both original and sanitized datasets, and comparing their\nperformance across the tasks. Interestingly, our results suggest that for some\ntasks such as sentiment analysis or entailment, the impact of redaction is\nquite low, typically around 1-5%, while for tasks such as comprehension Q&A\nthere is a big drop of >25% in performance observed in redacted queries as\ncompared to the original. For tasks that have a higher impact, we perform a\ndeeper dive to inspect the presence of task-critical entities. Finally, we\ninvestigate correlation between performance and number of redacted entities,\nand also suggest a strategy to repair an already redacted dataset by means of\ncontent-based subsampling. Additional details are available at\nhttps://sites.google.com/view/datasan.\n","authors":["Anwesan Pal","Radhika Bhargava","Kyle Hinsz","Jacques Esterhuizen","Sudipta Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2411.05978v1.pdf","comment":"Paper accepted at Safe Generative AI Workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05969v1","updated":"2024-11-08T20:59:25Z","published":"2024-11-08T20:59:25Z","title":"Toward Transdisciplinary Approaches to Audio Deepfake Discernment","summary":"  This perspective calls for scholars across disciplines to address the\nchallenge of audio deepfake detection and discernment through an\ninterdisciplinary lens across Artificial Intelligence methods and linguistics.\nWith an avalanche of tools for the generation of realistic-sounding fake speech\non one side, the detection of deepfakes is lagging on the other. Particularly\nhindering audio deepfake detection is the fact that current AI models lack a\nfull understanding of the inherent variability of language and the complexities\nand uniqueness of human speech. We see the promising potential in recent\ntransdisciplinary work that incorporates linguistic knowledge into AI\napproaches to provide pathways for expert-in-the-loop and to move beyond expert\nagnostic AI-based methods for more robust and comprehensive deepfake detection.\n","authors":["Vandana P. Janeja","Christine Mallinson"],"pdf_url":"https://arxiv.org/pdf/2411.05969v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05958v1","updated":"2024-11-08T20:41:04Z","published":"2024-11-08T20:41:04Z","title":"Sentiment Analysis of Cyberbullying Data in Social Media","summary":"  Social media has become an integral part of modern life, but it has also\nbrought with it the pervasive issue of cyberbullying a serious menace in\ntoday's digital age. Cyberbullying, a form of harassment that occurs on social\nnetworks, has escalated alongside the growth of these platforms. Sentiment\nanalysis holds significant potential not only for detecting bullying phrases\nbut also for identifying victims who are at high risk of harm, whether to\nthemselves or others. Our work focuses on leveraging deep learning and natural\nlanguage understanding techniques to detect traces of bullying in social media\nposts. We developed a Recurrent Neural Network with Long Short-Term Memory\n(LSTM) cells, using different embeddings. One approach utilizes BERT\nembeddings, while the other replaces the embeddings layer with the recently\nreleased embeddings API from OpenAI. We conducted a performance comparison\nbetween these two approaches to evaluate their effectiveness in sentiment\nanalysis of Formspring Cyberbullying data. Our Code is Available at\nhttps://github.com/ppujari/xcs224u\n","authors":["Arvapalli Sai Susmitha","Pradeep Pujari"],"pdf_url":"https://arxiv.org/pdf/2411.05958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05945v1","updated":"2024-11-08T20:11:24Z","published":"2024-11-08T20:11:24Z","title":"NeKo: Toward Post Recognition Generative Correction Large Language\n  Models with Task-Oriented Experts","summary":"  Construction of a general-purpose post-recognition error corrector poses a\ncrucial question: how can we most effectively train a model on a large mixture\nof domain datasets? The answer would lie in learning dataset-specific features\nand digesting their knowledge in a single model. Previous methods achieve this\nby having separate correction language models, resulting in a significant\nincrease in parameters. In this work, we present Mixture-of-Experts as a\nsolution, highlighting that MoEs are much more than a scalability tool. We\npropose a Multi-Task Correction MoE, where we train the experts to become an\n``expert'' of speech-to-text, language-to-text and vision-to-text datasets by\nlearning to route each dataset's tokens to its mapped expert. Experiments on\nthe Open ASR Leaderboard show that we explore a new state-of-the-art\nperformance by achieving an average relative $5.0$% WER reduction and\nsubstantial improvements in BLEU scores for speech and translation tasks. On\nzero-shot evaluation, NeKo outperforms GPT-3.5 and Claude-Opus with $15.5$% to\n$27.6$% relative WER reduction in the Hyporadise benchmark. NeKo performs\ncompetitively on grammar and post-OCR correction as a multi-task model.\n","authors":["Yen-Ting Lin","Chao-Han Huck Yang","Zhehuai Chen","Piotr Zelasko","Xuesong Yang","Zih-Ching Chen","Krishna C Puvvada","Szu-Wei Fu","Ke Hu","Jun Wei Chiu","Jagadeesh Balam","Boris Ginsburg","Yu-Chiang Frank Wang"],"pdf_url":"https://arxiv.org/pdf/2411.05945v1.pdf","comment":"NeKo work has been done in June 2024. NeKo LMs will be open source on\n  https://huggingface.co/nvidia under the MIT license"},{"id":"http://arxiv.org/abs/2411.05943v1","updated":"2024-11-08T20:08:18Z","published":"2024-11-08T20:08:18Z","title":"Quantifying artificial intelligence through algebraic generalization","summary":"  The rapid development of modern artificial intelligence (AI) systems has\ncreated an urgent need for their scientific quantification. While their fluency\nacross a variety of domains is impressive, modern AI systems fall short on\ntests requiring symbolic processing and abstraction - a glaring limitation\ngiven the necessity for interpretable and reliable technology. Despite a surge\nof reasoning benchmarks emerging from the academic community, no comprehensive\nand theoretically-motivated framework exists to quantify reasoning (and more\ngenerally, symbolic ability) in AI systems. Here, we adopt a framework from\ncomputational complexity theory to explicitly quantify symbolic generalization:\nalgebraic circuit complexity. Many symbolic reasoning problems can be recast as\nalgebraic expressions. Thus, algebraic circuit complexity theory - the study of\nalgebraic expressions as circuit models (i.e., directed acyclic graphs) - is a\nnatural framework to study the complexity of symbolic computation. The tools of\nalgebraic circuit complexity enable the study of generalization by defining\nbenchmarks in terms of their complexity-theoretic properties (i.e., the\ndifficulty of a problem). Moreover, algebraic circuits are generic mathematical\nobjects; for a given algebraic circuit, an arbitrarily large number of samples\ncan be generated for a specific circuit, making it an optimal testbed for the\ndata-hungry machine learning algorithms that are used today. Here, we adopt\ntools from algebraic circuit complexity theory, apply it to formalize a science\nof symbolic generalization, and address key theoretical and empirical\nchallenges for its successful application to AI science and its impact on the\nbroader community.\n","authors":["Takuya Ito","Murray Campbell","Lior Horesh","Tim Klinger","Parikshit Ram"],"pdf_url":"https://arxiv.org/pdf/2411.05943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07313v2","updated":"2024-11-08T19:56:12Z","published":"2024-07-10T02:20:19Z","title":"ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the\n  Age of Large Language Models","summary":"  The task of Text-to-SQL enables anyone to retrieve information from SQL\ndatabases using natural language. Despite several challenges, recent models\nhave made remarkable advancements in this task using large language models\n(LLMs). Interestingly, we find that LLM-based models without fine-tuning\nexhibit distinct natures compared to their fine-tuned counterparts, leading to\ninadequacies in current evaluation metrics to accurately convey their\nperformance. Thus, we analyze the two primary metrics, Test Suite Execution\nAccuracy (EXE) and Exact Set Matching Accuracy (ESM), to examine their\nrobustness for this task and address shortcomings. We compare the performance\nof 9 LLM-based models using EXE, the original ESM, and our improved ESM (called\nESM+). Our results show that EXE and ESM have high false positive and negative\nrates of 11.3% and 13.9%, while ESM+ gives those of 0.1% and 2.6% respectively,\nproviding a significantly more stable evaluation. We release the ESM+ script as\nopen-source for the community to contribute, while enjoying a more reliable\nassessment of Text-to-SQL.\n","authors":["Benjamin G. Ascoli","Yasoda Sai Ram Kandikonda","Jinho D. Choi"],"pdf_url":"https://arxiv.org/pdf/2407.07313v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05936v1","updated":"2024-11-08T19:47:02Z","published":"2024-11-08T19:47:02Z","title":"Mitigating Hallucination with ZeroG: An Advanced Knowledge Management\n  Engine","summary":"  The growth of digital documents presents significant challenges in efficient\nmanagement and knowledge extraction. Traditional methods often struggle with\ncomplex documents, leading to issues such as hallucinations and high latency in\nresponses from Large Language Models (LLMs). ZeroG, an innovative approach,\nsignificantly mitigates these challenges by leveraging knowledge distillation\nand prompt tuning to enhance model performance.\n  ZeroG utilizes a smaller model that replicates the behavior of a larger\nteacher model, ensuring contextually relevant and grounded responses, by\nemploying a black-box distillation approach, it creates a distilled dataset\nwithout relying on intermediate features, optimizing computational efficiency.\nThis method significantly enhances accuracy and reduces response times,\nproviding a balanced solution for modern document management.\n  Incorporating advanced techniques for document ingestion and metadata\nutilization, ZeroG improves the accuracy of question-and-answer systems. The\nintegration of graph databases and robust metadata management further\nstreamlines information retrieval, allowing for precise and context-aware\nresponses. By transforming how organizations interact with complex data, ZeroG\nenhances productivity and user experience, offering a scalable solution for the\ngrowing demands of digital document management.\n","authors":["Anantha Sharma","Sheeba Elizabeth John","Fatemeh Rezapoor Nikroo","Krupali Bhatt","Mrunal Zambre","Aditi Wikhe"],"pdf_url":"https://arxiv.org/pdf/2411.05936v1.pdf","comment":"10 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2411.05930v1","updated":"2024-11-08T19:31:19Z","published":"2024-11-08T19:31:19Z","title":"BERTrend: Neural Topic Modeling for Emerging Trends Detection","summary":"  Detecting and tracking emerging trends and weak signals in large, evolving\ntext corpora is vital for applications such as monitoring scientific\nliterature, managing brand reputation, surveilling critical infrastructure and\nmore generally to any kind of text-based event detection. Existing solutions\noften fail to capture the nuanced context or dynamically track evolving\npatterns over time. BERTrend, a novel method, addresses these limitations using\nneural topic modeling in an online setting. It introduces a new metric to\nquantify topic popularity over time by considering both the number of documents\nand update frequency. This metric classifies topics as noise, weak, or strong\nsignals, flagging emerging, rapidly growing topics for further investigation.\nExperimentation on two large real-world datasets demonstrates BERTrend's\nability to accurately detect and track meaningful weak signals while filtering\nout noise, offering a comprehensive solution for monitoring emerging trends in\nlarge-scale, evolving text corpora. The method can also be used for\nretrospective analysis of past events. In addition, the use of Large Language\nModels together with BERTrend offers efficient means for the interpretability\nof trends of events.\n","authors":["Allaa Boutaleb","Jerome Picault","Guillaume Grosjean"],"pdf_url":"https://arxiv.org/pdf/2411.05930v1.pdf","comment":"17 pages, 12 figures, FuturED 2024: Workshop on Future of Event\n  Detection (CoLocated with EMNLP 2024)"},{"id":"http://arxiv.org/abs/2411.05928v1","updated":"2024-11-08T19:27:42Z","published":"2024-11-08T19:27:42Z","title":"Reducing Distraction in Long-Context Language Models by Focused Learning","summary":"  Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their capacity to process long contexts. However, effectively\nutilizing this long context remains a challenge due to the issue of\ndistraction, where irrelevant information dominates lengthy contexts, causing\nLLMs to lose focus on the most relevant segments. To address this, we propose a\nnovel training method that enhances LLMs' ability to discern relevant\ninformation through a unique combination of retrieval-based data augmentation\nand contrastive learning. Specifically, during fine-tuning with long contexts,\nwe employ a retriever to extract the most relevant segments, serving as\naugmented inputs. We then introduce an auxiliary contrastive learning objective\nto explicitly ensure that outputs from the original context and the retrieved\nsub-context are closely aligned. Extensive experiments on long single-document\nand multi-document QA benchmarks demonstrate the effectiveness of our proposed\nmethod.\n","authors":["Zijun Wu","Bingyuan Liu","Ran Yan","Lei Chen","Thomas Delteil"],"pdf_url":"https://arxiv.org/pdf/2411.05928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05903v1","updated":"2024-11-08T17:15:17Z","published":"2024-11-08T17:15:17Z","title":"Towards Multi-Modal Mastery: A 4.5B Parameter Truly Multi-Modal Small\n  Language Model","summary":"  We present a novel 4.5B parameter small language model that can handle\nmultiple input and output modalities, including text, images, videos, and\naudio. Despite its small size, the model achieves near state-of-the-art\nperformance on a variety of tasks, demonstrating the potential of multi-modal\nmodels to tackle complex real-world problems. Our approach leverages recent\nadvancements in language modeling and multi-task learning to create a versatile\nand high-performing model that can even be deployed for edge inference.\nExperimental results show the model's strong performance across multiple\nbenchmarks, paving the way for further progress in multi-modal artificial\nintelligence.\n","authors":["Ben Koska","Mojm√≠r Horv√°th"],"pdf_url":"https://arxiv.org/pdf/2411.05903v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05902v1","updated":"2024-11-08T17:15:12Z","published":"2024-11-08T17:15:12Z","title":"Autoregressive Models in Vision: A Survey","summary":"  Autoregressive modeling has been a huge success in the field of natural\nlanguage processing (NLP). Recently, autoregressive models have emerged as a\nsignificant area of focus in computer vision, where they excel in producing\nhigh-quality visual content. Autoregressive models in NLP typically operate on\nsubword tokens. However, the representation strategy in computer vision can\nvary in different levels, \\textit{i.e.}, pixel-level, token-level, or\nscale-level, reflecting the diverse and hierarchical nature of visual data\ncompared to the sequential structure of language. This survey comprehensively\nexamines the literature on autoregressive models applied to vision. To improve\nreadability for researchers from diverse research backgrounds, we start with\npreliminary sequence representation and modeling in vision. Next, we divide the\nfundamental frameworks of visual autoregressive models into three general\nsub-categories, including pixel-based, token-based, and scale-based models\nbased on the strategy of representation. We then explore the interconnections\nbetween autoregressive models and other generative models. Furthermore, we\npresent a multi-faceted categorization of autoregressive models in computer\nvision, including image generation, video generation, 3D generation, and\nmulti-modal generation. We also elaborate on their applications in diverse\ndomains, including emerging domains such as embodied AI and 3D medical AI, with\nabout 250 related references. Finally, we highlight the current challenges to\nautoregressive models in vision with suggestions about potential research\ndirections. We have also set up a Github repository to organize the papers\nincluded in this survey at:\n\\url{https://github.com/ChaofanTao/Autoregressive-Models-in-Vision-Survey}.\n","authors":["Jing Xiong","Gongye Liu","Lun Huang","Chengyue Wu","Taiqiang Wu","Yao Mu","Yuan Yao","Hui Shen","Zhongwei Wan","Jinfa Huang","Chaofan Tao","Shen Yan","Huaxiu Yao","Lingpeng Kong","Hongxia Yang","Mi Zhang","Guillermo Sapiro","Jiebo Luo","Ping Luo","Ngai Wong"],"pdf_url":"https://arxiv.org/pdf/2411.05902v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05897v1","updated":"2024-11-08T15:50:19Z","published":"2024-11-08T15:50:19Z","title":"Humans Continue to Outperform Large Language Models in Complex Clinical\n  Decision-Making: A Study with Medical Calculators","summary":"  Although large language models (LLMs) have been assessed for general medical\nknowledge using medical licensing exams, their ability to effectively support\nclinical decision-making tasks, such as selecting and using medical\ncalculators, remains uncertain. Here, we evaluate the capability of both\nmedical trainees and LLMs to recommend medical calculators in response to\nvarious multiple-choice clinical scenarios such as risk stratification,\nprognosis, and disease diagnosis. We assessed eight LLMs, including\nopen-source, proprietary, and domain-specific models, with 1,009\nquestion-answer pairs across 35 clinical calculators and measured human\nperformance on a subset of 100 questions. While the highest-performing LLM,\nGPT-4o, provided an answer accuracy of 74.3% (CI: 71.5-76.9%), human\nannotators, on average, outperformed LLMs with an accuracy of 79.5% (CI:\n73.5-85.0%). With error analysis showing that the highest-performing LLMs\ncontinue to make mistakes in comprehension (56.6%) and calculator knowledge\n(8.1%), our findings emphasize that humans continue to surpass LLMs on complex\nclinical tasks such as calculator recommendation.\n","authors":["Nicholas Wan","Qiao Jin","Joey Chan","Guangzhi Xiong","Serina Applebaum","Aidan Gilson","Reid McMurry","R. Andrew Taylor","Aidong Zhang","Qingyu Chen","Zhiyong Lu"],"pdf_url":"https://arxiv.org/pdf/2411.05897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05895v1","updated":"2024-11-08T14:44:01Z","published":"2024-11-08T14:44:01Z","title":"One Small and One Large for Document-level Event Argument Extraction","summary":"  Document-level Event Argument Extraction (EAE) faces two challenges due to\nincreased input length: 1) difficulty in distinguishing semantic boundaries\nbetween events, and 2) interference from redundant information. To address\nthese issues, we propose two methods. The first method introduces the Co and\nStructure Event Argument Extraction model (CsEAE) based on Small Language\nModels (SLMs). CsEAE includes a co-occurrences-aware module, which integrates\ninformation about all events present in the current input through context\nlabeling and co-occurrences event prompts extraction. Additionally, CsEAE\nincludes a structure-aware module that reduces interference from redundant\ninformation by establishing structural relationships between the sentence\ncontaining the trigger and other sentences in the document. The second method\nintroduces new prompts to transform the extraction task into a generative task\nsuitable for Large Language Models (LLMs), addressing gaps in EAE performance\nusing LLMs under Supervised Fine-Tuning (SFT) conditions. We also fine-tuned\nmultiple datasets to develop an LLM that performs better across most datasets.\nFinally, we applied insights from CsEAE to LLMs, achieving further performance\nimprovements. This suggests that reliable insights validated on SLMs are also\napplicable to LLMs. We tested our models on the Rams, WikiEvents, and MLEE\ndatasets. The CsEAE model achieved improvements of 2.1\\%, 2.3\\%, and 3.2\\% in\nthe Arg-C F1 metric compared to the baseline, PAIE~\\cite{PAIE}. For LLMs, we\ndemonstrated that their performance on document-level datasets is comparable to\nthat of SLMs~\\footnote{All code is available at\nhttps://github.com/simon-p-j-r/CsEAE}.\n","authors":["Jiaren Peng","Hongda Sun","Wenzhong Yang","Fuyuan Wei","Liang He","Liejun Wang"],"pdf_url":"https://arxiv.org/pdf/2411.05895v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05894v1","updated":"2024-11-08T14:23:02Z","published":"2024-11-08T14:23:02Z","title":"SSSD: Simply-Scalable Speculative Decoding","summary":"  Over the past year, Speculative Decoding has gained popularity as a technique\nfor accelerating Large Language Model inference. While several methods have\nbeen introduced, most struggle to deliver satisfactory performance at batch\nsizes typical for data centers ($\\geq 8$) and often involve significant\ndeployment complexities. In this work, we offer a theoretical explanation of\nhow Speculative Decoding can be effectively utilized with larger batch sizes.\nWe also introduce a method that integrates seamlessly into existing systems\nwithout additional training or the complexity of deploying a small LLM. In a\ncontinuous batching setting, we achieve a 4x increase in throughput without any\nlatency impact for short context generation, and a 1.7-2x improvement in both\nlatency and throughput for longer contexts.\n","authors":["Michele Marzollo","Jiawei Zhuang","Niklas Roemer","Lorenz K. M√ºller","Lukas Cavigelli"],"pdf_url":"https://arxiv.org/pdf/2411.05894v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.05892v1","updated":"2024-11-08T12:38:10Z","published":"2024-11-08T12:38:10Z","title":"Identifying and Decomposing Compound Ingredients in Meal Plans Using\n  Large Language Models","summary":"  This study explores the effectiveness of Large Language Models in meal\nplanning, focusing on their ability to identify and decompose compound\ningredients. We evaluated three models-GPT-4o, Llama-3 (70b), and Mixtral\n(8x7b)-to assess their proficiency in recognizing and breaking down complex\ningredient combinations. Preliminary results indicate that while Llama-3 (70b)\nand GPT-4o excels in accurate decomposition, all models encounter difficulties\nwith identifying essential elements like seasonings and oils. Despite strong\noverall performance, variations in accuracy and completeness were observed\nacross models. These findings underscore LLMs' potential to enhance\npersonalized nutrition but highlight the need for further refinement in\ningredient decomposition. Future research should address these limitations to\nimprove nutritional recommendations and health outcomes.\n","authors":["Leon Kopitar","Leon Bedrac","Larissa J Strath","Jiang Bian","Gregor Stiglic"],"pdf_url":"https://arxiv.org/pdf/2411.05892v1.pdf","comment":"Comments: Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)"},{"id":"http://arxiv.org/abs/2411.05882v1","updated":"2024-11-08T07:24:49Z","published":"2024-11-08T07:24:49Z","title":"When are 1.58 bits enough? A Bottom-up Exploration of BitNet\n  Quantization","summary":"  Contemporary machine learning models, such as language models, are powerful,\nbut come with immense resource requirements both at training and inference\ntime. It has been shown that decoder-only language models can be trained to a\ncompetitive state with ternary weights (1.58 bits per weight), facilitating\nefficient inference. Here, we start our exploration with non-transformer model\narchitectures, investigating 1.58-bit training for multi-layer perceptrons and\ngraph neural networks. Then, we explore 1.58-bit training in other\ntransformer-based language models, namely encoder-only and encoder-decoder\nmodels. Our results show that in all of these settings, 1.58-bit training is on\npar with or sometimes even better than the standard 32/16-bit models.\n","authors":["Jacob Nielsen","Lukas Galke","Peter Schneider-Kamp"],"pdf_url":"https://arxiv.org/pdf/2411.05882v1.pdf","comment":"10 pages, 2 tables, 6 figures"},{"id":"http://arxiv.org/abs/2411.05877v1","updated":"2024-11-08T00:42:47Z","published":"2024-11-08T00:42:47Z","title":"Generative Adapter: Contextualizing Language Models in Parameters with A\n  Single Forward Pass","summary":"  Large language models (LMs) are typically adapted to improve performance on\nnew contexts (\\eg text prompts that define new tasks or domains) through\nfine-tuning or prompting. However, there is an accuracy compute tradeoff --\nfine-tuning incurs significant training cost and prompting increases inference\noverhead. We introduce $GenerativeAdapter$, an effective and efficient\nadaptation method that directly maps new contexts to low-rank LM adapters,\nthereby significantly reducing inference overhead with no need for finetuning.\nThe adapter generator is trained via self-supervised learning, and can be used\nto adapt a single frozen LM for any new task simply by mapping the associated\ntask or domain context to a new adapter. We apply $GenerativeAdapter$ to two\npretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the\nadapted models in three adaption scenarios: knowledge acquisition from\ndocuments, learning from demonstrations, and personalization for users. In\nStreamingQA, our approach is effective in injecting knowledge into the LM's\nparameters, achieving a 63.5% improvement in F1 score over the model with\nsupervised fine-tuning (from $19.5$ to $31.5$) for contexts as long as 32K\ntokens. In the MetaICL in-context learning evaluation, our method achieves an\naverage accuracy of $44.9$ across 26 tasks, outperforming the base model. On\nMSC, our method proves to be highly competitive in memorizing user information\nfrom conversations with a 4x reduction in computation and memory costs compared\nto prompting with full conversation history. Together, these results suggest\nthat $GenerativeAdapter$ should allow for general adaption to a wide range of\ndifferent contexts.\n","authors":["Tong Chen","Hao Fang","Patrick Xia","Xiaodong Liu","Benjamin Van Durme","Luke Zettlemoyer","Jianfeng Gao","Hao Cheng"],"pdf_url":"https://arxiv.org/pdf/2411.05877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07264v1","updated":"2024-11-08T21:03:54Z","published":"2024-11-08T21:03:54Z","title":"Multi-Document Financial Question Answering using LLMs","summary":"  We propose two new methods for multi-document financial question answering.\nFirst, a method that uses semantic tagging, and then, queries the index to get\nthe context (RAG_SEM). And second, a Knowledge Graph (KG_RAG) based method that\nuses semantic tagging, and, retrieves knowledge graph triples from a graph\ndatabase, as context. KG_RAG uses knowledge graphs constructed using a small\nmodel that is fine-tuned using knowledge distillation using a large teacher\nmodel. The data consists of 18 10K reports of Apple, Microsoft, Alphabet,\nNVIDIA, Amazon and Tesla for the years 2021, 2022 and 2023. The list of\nquestions in the data consists of 111 complex questions including many esoteric\nquestions that are difficult to answer and the answers are not completely\nobvious. As evaluation metrics, we use overall scores as well as segmented\nscores for measurement including the faithfulness, relevance, correctness,\nsimilarity, an LLM based overall score and the rouge scores as well as a\nsimilarity of embeddings. We find that both methods outperform plain RAG\nsignificantly. KG_RAG outperforms RAG_SEM in four out of nine metrics.\n","authors":["Shalin Shah","Srikanth Ryali","Ramasubbu Venkatesh"],"pdf_url":"https://arxiv.org/pdf/2411.07264v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2404.04264v4","updated":"2024-11-08T18:35:49Z","published":"2024-03-17T17:01:45Z","title":"Logic Query of Thoughts: Guiding Large Language Models to Answer Complex\n  Logic Queries with Knowledge Graphs","summary":"  Despite the superb performance in many tasks, large language models (LLMs)\nbear the risk of generating hallucination or even wrong answers when confronted\nwith tasks that demand the accuracy of knowledge. The issue becomes even more\nnoticeable when addressing logic queries that require multiple logic reasoning\nsteps. On the other hand, knowledge graph (KG) based question answering methods\nare capable of accurately identifying the correct answers with the help of\nknowledge graph, yet its accuracy could quickly deteriorate when the knowledge\ngraph itself is sparse and incomplete. It remains a critical challenge on how\nto integrate knowledge graph reasoning with LLMs in a mutually beneficial way\nso as to mitigate both the hallucination problem of LLMs as well as the\nincompleteness issue of knowledge graphs. In this paper, we propose\n'Logic-Query-of-Thoughts' (LGOT) which is the first of its kind to combine LLMs\nwith knowledge graph based logic query reasoning. LGOT seamlessly combines\nknowledge graph reasoning and LLMs, effectively breaking down complex logic\nqueries into easy to answer subquestions. Through the utilization of both\nknowledge graph reasoning and LLMs, it successfully derives answers for each\nsubquestion. By aggregating these results and selecting the highest quality\ncandidate answers for each step, LGOT achieves accurate results to complex\nquestions. Our experimental findings demonstrate substantial performance\nenhancements, with up to 20% improvement over ChatGPT.\n","authors":["Lihui Liu","Zihao Wang","Ruizhong Qiu","Yikun Ban","Eunice Chan","Yangqiu Song","Jingrui He","Hanghang Tong"],"pdf_url":"https://arxiv.org/pdf/2404.04264v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05649v1","updated":"2024-11-08T15:45:33Z","published":"2024-11-08T15:45:33Z","title":"Harnessing High-Level Song Descriptors towards Natural Language-Based\n  Music Recommendation","summary":"  Recommender systems relying on Language Models (LMs) have gained popularity\nin assisting users to navigate large catalogs. LMs often exploit item\nhigh-level descriptors, i.e. categories or consumption contexts, from training\ndata or user preferences. This has been proven effective in domains like movies\nor products. However, in the music domain, understanding how effectively LMs\nutilize song descriptors for natural language-based music recommendation is\nrelatively limited. In this paper, we assess LMs effectiveness in recommending\nsongs based on user natural language descriptions and items with descriptors\nlike genres, moods, and listening contexts. We formulate the recommendation\ntask as a dense retrieval problem and assess LMs as they become increasingly\nfamiliar with data pertinent to the task and domain. Our findings reveal\nimproved performance as LMs are fine-tuned for general language similarity,\ninformation retrieval, and mapping longer descriptions to shorter, high-level\ndescriptors in music.\n","authors":["Elena V. Epure","Gabriel Meseguer Brocal","Darius Afchar","Romain Hennequin"],"pdf_url":"https://arxiv.org/pdf/2411.05649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05572v1","updated":"2024-11-08T13:51:37Z","published":"2024-11-08T13:51:37Z","title":"Why These Documents? Explainable Generative Retrieval with Hierarchical\n  Category Paths","summary":"  Generative retrieval has recently emerged as a new alternative of traditional\ninformation retrieval approaches. However, existing generative retrieval\nmethods directly decode docid when a query is given, making it impossible to\nprovide users with explanations as an answer for \"Why this document is\nretrieved?\". To address this limitation, we propose Hierarchical Category\nPath-Enhanced Generative Retrieval(HyPE), which enhances explainability by\ngenerating hierarchical category paths step-by-step before decoding docid. HyPE\nleverages hierarchical category paths as explanation, progressing from broad to\nspecific semantic categories. This approach enables diverse explanations for\nthe same document depending on the query by using shared category paths between\nthe query and the document, and provides reasonable explanation by reflecting\nthe document's semantic structure through a coarse-to-fine manner. HyPE\nconstructs category paths with external high-quality semantic hierarchy,\nleverages LLM to select appropriate candidate paths for each document, and\noptimizes the generative retrieval model with path-augmented dataset. During\ninference, HyPE utilizes path-aware reranking strategy to aggregate diverse\ntopic information, allowing the most relevant documents to be prioritized in\nthe final ranked list of docids. Our extensive experiments demonstrate that\nHyPE not only offers a high level of explainability but also improves the\nretrieval performance in the document retrieval task.\n","authors":["Sangam Lee","Ryang Heo","SeongKu Kang","Susik Yoon","Jinyoung Yeo","Dongha Lee"],"pdf_url":"https://arxiv.org/pdf/2411.05572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10321v2","updated":"2024-11-08T13:29:47Z","published":"2024-04-16T07:05:16Z","title":"Cluster-based Graph Collaborative Filtering","summary":"  Graph Convolution Networks (GCNs) have significantly succeeded in learning\nuser and item representations for recommendation systems. The core of their\nefficacy is the ability to explicitly exploit the collaborative signals from\nboth the first- and high-order neighboring nodes. However, most existing\nGCN-based methods overlook the multiple interests of users while performing\nhigh-order graph convolution. Thus, the noisy information from unreliable\nneighbor nodes (e.g., users with dissimilar interests) negatively impacts the\nrepresentation learning of the target node. Additionally, conducting graph\nconvolution operations without differentiating high-order neighbors suffers the\nover-smoothing issue when stacking more layers, resulting in performance\ndegradation. In this paper, we aim to capture more valuable information from\nhigh-order neighboring nodes while avoiding noise for better representation\nlearning of the target node. To achieve this goal, we propose a novel GCN-based\nrecommendation model, termed Cluster-based Graph Collaborative Filtering\n(ClusterGCF). This model performs high-order graph convolution on\ncluster-specific graphs, which are constructed by capturing the multiple\ninterests of users and identifying the common interests among them.\nSpecifically, we design an unsupervised and optimizable soft node clustering\napproach to classify user and item nodes into multiple clusters. Based on the\nsoft node clustering results and the topology of the user-item interaction\ngraph, we assign the nodes with probabilities for different clusters to\nconstruct the cluster-specific graphs. To evaluate the effectiveness of\nClusterGCF, we conducted extensive experiments on four publicly available\ndatasets. Experimental results demonstrate that our model can significantly\nimprove recommendation performance.\n","authors":["Fan Liu","Shuai Zhao","Zhiyong Cheng","Liqiang Nie","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2404.10321v2.pdf","comment":"Accepted by ACM TOIS"},{"id":"http://arxiv.org/abs/2411.05508v1","updated":"2024-11-08T12:08:17Z","published":"2024-11-08T12:08:17Z","title":"An Early FIRST Reproduction and Improvements to Single-Token Decoding\n  for Fast Listwise Reranking","summary":"  Recent advances have demonstrated that large language models (LLMs) excel as\nlistwise rerankers, but their high computational demands remain a barrier to\nwidespread adoption. Further, the traditional language modeling (LM) objective\nis not ideally suited for reranking tasks. FIRST is a novel approach that\naddresses these challenges by integrating a learning-to-rank objective and\nleveraging the logits of only the first generated token, thereby significantly\nreducing inference latency compared to traditional LLM rerankers. In this\nstudy, we extend the evaluation of FIRST to the TREC Deep Learning datasets\n(DL19-22), validating its robustness across diverse domains. We investigate the\ninfluence of different first-stage retrievers on FIRST rerankers, observing\ndiminishing returns and patterns consistent with traditional LLM rerankers.\nThrough applying the FIRST objective to a broader range of backbone models, we\nachieve effectiveness surpassing the original implementation. Our experiments\nconfirm that fast reranking with single-token logits does not compromise\nout-of-domain reranking quality. To better quantify the computational savings\nin the original study, we measure and compare latency to find a 21%-42% gain\nacross various models and benchmarks. Moreover, while LM training implicitly\nimproves zero-shot single-token reranking, our experiments also raise questions\nabout whether LM pre-training may hinder subsequent fine-tuning with the FIRST\nobjective. These findings pave the way for more efficient and effective\nlistwise reranking in future applications.\n","authors":["Zijian Chen","Ronak Pradeep","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05442v1","updated":"2024-11-08T09:40:53Z","published":"2024-11-08T09:40:53Z","title":"IntellBot: Retrieval Augmented LLM Chatbot for Cyber Threat Knowledge\n  Delivery","summary":"  In the rapidly evolving landscape of cyber security, intelligent chatbots are\ngaining prominence. Artificial Intelligence, Machine Learning, and Natural\nLanguage Processing empower these chatbots to handle user inquiries and deliver\nthreat intelligence. This helps cyber security knowledge readily available to\nboth professionals and the public. Traditional rule-based chatbots often lack\nflexibility and struggle to adapt to user interactions. In contrast, Large\nLanguage Model-based chatbots offer contextually relevant information across\nmultiple domains and adapt to evolving conversational contexts. In this work,\nwe develop IntellBot, an advanced cyber security Chatbot built on top of\ncutting-edge technologies like Large Language Models and Langchain alongside a\nRetrieval-Augmented Generation model to deliver superior capabilities. This\nchatbot gathers information from diverse data sources to create a comprehensive\nknowledge base covering known vulnerabilities, recent cyber attacks, and\nemerging threats. It delivers tailored responses, serving as a primary hub for\ncyber security insights. By providing instant access to relevant information\nand resources, this IntellBot enhances threat intelligence, incident response,\nand overall security posture, saving time and empowering users with knowledge\nof cyber security best practices. Moreover, we analyzed the performance of our\ncopilot using a two-stage evaluation strategy. We achieved BERT score above 0.8\nby indirect approach and a cosine similarity score ranging from 0.8 to 1, which\naffirms the accuracy of our copilot. Additionally, we utilized RAGAS to\nevaluate the RAG model, and all evaluation metrics consistently produced scores\nabove 0.77, highlighting the efficacy of our system.\n","authors":["Dincy R. Arikkat","Abhinav M.","Navya Binu","Parvathi M.","Navya Biju","K. S. Arunima","Vinod P.","Rafidha Rehiman K. A.","Mauro Conti"],"pdf_url":"https://arxiv.org/pdf/2411.05442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05375v1","updated":"2024-11-08T07:05:06Z","published":"2024-11-08T07:05:06Z","title":"Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking","summary":"  Current automated fact-checking (AFC) approaches commonly evaluate evidence\neither implicitly via the predicted verdicts or by comparing retrieved evidence\nwith a predefined closed knowledge source, such as Wikipedia. However, these\nmethods suffer from limitations, resulting from their reliance on evaluation\nmetrics developed for different purposes and constraints imposed by closed\nknowledge sources. Recent advances in natural language generation (NLG)\nevaluation offer new possibilities for evidence assessment. In this work, we\nintroduce Ev2R, an evaluation framework for AFC that comprises three types of\napproaches for evidence evaluation: reference-based, proxy-reference, and\nreference-less. We evaluate their effectiveness through agreement with human\nratings and adversarial tests, and demonstrate that prompt-based scorers,\nparticularly those leveraging LLMs and reference evidence, outperform\ntraditional evaluation approaches.\n","authors":["Mubashara Akhtar","Michael Schlichtkrull","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2411.05375v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.05340v1","updated":"2024-11-08T05:43:40Z","published":"2024-11-08T05:43:40Z","title":"Improving Multi-Domain Task-Oriented Dialogue System with Offline\n  Reinforcement Learning","summary":"  Task-oriented dialogue (TOD) system is designed to accomplish user-defined\ntasks through dialogues. The TOD system has progressed towards end-to-end\nmodeling by leveraging pre-trained large language models. Fine-tuning the\npre-trained language models using only supervised learning leads to the\nexposure bias and token loss problem and it deviates the models from completing\nthe user's task. To address these issues, we propose a TOD system that\nleverages a unified pre-trained language model, GPT2, as a base model. It is\noptimized using supervised learning and reinforcement learning (RL). The issues\nin the TOD system are mitigated using a non-differentiable reward function. The\nreward is calculated using the weighted sum of the success rate and BLEU\nevaluation metrics. The success rate and BLEU metrics in reward calculation\nguide the language model for user task completion while ensuring a coherent and\nfluent response. Our model is acquired by fine-tuning a pre-trained model on\nthe dialogue-session level which comprises user utterance, belief state, system\nact, and system response. Experimental results on MultiWOZ2.1 demonstrate that\nour model increases the inform rate by 1.60% and the success rate by 3.17%\ncompared to the baseline.\n","authors":["Dharmendra Prajapat","Durga Toshniwal"],"pdf_url":"https://arxiv.org/pdf/2411.05340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10108v3","updated":"2024-11-08T03:58:00Z","published":"2023-10-16T06:41:16Z","title":"On Generative Agents in Recommendation","summary":"  Recommender systems are the cornerstone of today's information dissemination,\nyet a disconnect between offline metrics and online performance greatly hinders\ntheir development. Addressing this challenge, we envision a recommendation\nsimulator, capitalizing on recent breakthroughs in human-level intelligence\nexhibited by Large Language Models (LLMs). We propose Agent4Rec, a user\nsimulator in recommendation, leveraging LLM-empowered generative agents\nequipped with user profile, memory, and actions modules specifically tailored\nfor the recommender system. In particular, these agents' profile modules are\ninitialized using real-world datasets (e.g. MovieLens, Steam, Amazon-Book),\ncapturing users' unique tastes and social traits; memory modules log both\nfactual and emotional memories and are integrated with an emotion-driven\nreflection mechanism; action modules support a wide variety of behaviors,\nspanning both taste-driven and emotion-driven actions. Each agent interacts\nwith personalized recommender models in a page-by-page manner, relying on a\npre-implemented collaborative filtering-based recommendation algorithm. We\ndelve into both the capabilities and limitations of Agent4Rec, aiming to\nexplore an essential research question: ``To what extent can LLM-empowered\ngenerative agents faithfully simulate the behavior of real, autonomous humans\nin recommender systems?'' Extensive and multi-faceted evaluations of Agent4Rec\nhighlight both the alignment and deviation between agents and user-personalized\npreferences. Beyond mere performance comparison, we explore insightful\nexperiments, such as emulating the filter bubble effect and discovering the\nunderlying causal relationships in recommendation tasks. Our codes are\navailable at https://github.com/LehengTHU/Agent4Rec.\n","authors":["An Zhang","Yuxin Chen","Leheng Sheng","Xiang Wang","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2310.10108v3.pdf","comment":"SIGIR 2024 perspective paper"},{"id":"http://arxiv.org/abs/2308.02580v3","updated":"2024-11-08T02:21:38Z","published":"2023-08-03T16:13:46Z","title":"Feature Noise Resilient for QoS Prediction with Probabilistic Deep\n  Supervision","summary":"  Accurate Quality of Service (QoS) prediction is essential for enhancing user\nsatisfaction in web recommendation systems, yet existing prediction models\noften overlook feature noise, focusing predominantly on label noise. In this\npaper, we present the Probabilistic Deep Supervision Network (PDS-Net), a\nrobust framework designed to effectively identify and mitigate feature noise,\nthereby improving QoS prediction accuracy. PDS-Net operates with a dual-branch\narchitecture: the main branch utilizes a decoder network to learn a\nGaussian-based prior distribution from known features, while the second branch\nderives a posterior distribution based on true labels. A key innovation of\nPDS-Net is its condition-based noise recognition loss function, which enables\nprecise identification of noisy features in objects (users or services). Once\nnoisy features are identified, PDS-Net refines the feature's prior\ndistribution, aligning it with the posterior distribution, and propagates this\nadjusted distribution to intermediate layers, effectively reducing noise\ninterference. Extensive experiments conducted on two real-world QoS datasets\ndemonstrate that PDS-Net consistently outperforms existing models, achieving an\naverage improvement of 8.91% in MAE on Dataset D1 and 8.32% on Dataset D2\ncompared to the ate-of-the-art. These results highlight PDS-Net's ability to\naccurately capture complex user-service relationships and handle feature noise,\nunderscoring its robustness and versatility across diverse QoS prediction\nenvironments.\n","authors":["Ziliang Wang","Xiaohong Zhang","Ze Shi Li","Sheng Huang","Meng Yan"],"pdf_url":"https://arxiv.org/pdf/2308.02580v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16156v2","updated":"2024-11-08T00:40:05Z","published":"2024-10-21T16:21:45Z","title":"Limpeh ga li gong: Challenges in Singlish Annotations","summary":"  Singlish, or Colloquial Singapore English, is a language formed from oral and\nsocial communication within multicultural Singapore. In this work, we work on a\nfundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)\ntagging of Singlish sentences. For our analysis, we build a parallel Singlish\ndataset containing direct English translations and POS tags, with translation\nand POS annotation done by native Singlish speakers. Our experiments show that\nautomatic transition- and transformer- based taggers perform with only $\\sim\n80\\%$ accuracy when evaluated against human-annotated POS labels, suggesting\nthat there is indeed room for improvement on computation analysis of the\nlanguage. We provide an exposition of challenges in Singlish annotation: its\ninconsistencies in form and semantics, the highly context-dependent particles\nof the language, its structural unique expressions, and the variation of the\nlanguage on different mediums. Our task definition, resultant labels and\nresults reflects the challenges in analysing colloquial languages formulated\nfrom a variety of dialects, and paves the way for future studies beyond POS\ntagging.\n","authors":["Luo Qi Chan","Lynnette Hui Xian Ng"],"pdf_url":"https://arxiv.org/pdf/2410.16156v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05937v1","updated":"2024-11-08T19:52:57Z","published":"2024-11-08T19:52:57Z","title":"The effect of different feature selection methods on models created with\n  XGBoost","summary":"  This study examines the effect that different feature selection methods have\non models created with XGBoost, a popular machine learning algorithm with\nsuperb regularization methods. It shows that three different ways for reducing\nthe dimensionality of features produces no statistically significant change in\nthe prediction accuracy of the model. This suggests that the traditional idea\nof removing the noisy training data to make sure models do not overfit may not\napply to XGBoost. But it may still be viable in order to reduce computational\ncomplexity.\n","authors":["Jorge Neyra","Vishal B. Siramshetty","Huthaifa I. Ashqar"],"pdf_url":"https://arxiv.org/pdf/2411.05937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05936v1","updated":"2024-11-08T19:47:02Z","published":"2024-11-08T19:47:02Z","title":"Mitigating Hallucination with ZeroG: An Advanced Knowledge Management\n  Engine","summary":"  The growth of digital documents presents significant challenges in efficient\nmanagement and knowledge extraction. Traditional methods often struggle with\ncomplex documents, leading to issues such as hallucinations and high latency in\nresponses from Large Language Models (LLMs). ZeroG, an innovative approach,\nsignificantly mitigates these challenges by leveraging knowledge distillation\nand prompt tuning to enhance model performance.\n  ZeroG utilizes a smaller model that replicates the behavior of a larger\nteacher model, ensuring contextually relevant and grounded responses, by\nemploying a black-box distillation approach, it creates a distilled dataset\nwithout relying on intermediate features, optimizing computational efficiency.\nThis method significantly enhances accuracy and reduces response times,\nproviding a balanced solution for modern document management.\n  Incorporating advanced techniques for document ingestion and metadata\nutilization, ZeroG improves the accuracy of question-and-answer systems. The\nintegration of graph databases and robust metadata management further\nstreamlines information retrieval, allowing for precise and context-aware\nresponses. By transforming how organizations interact with complex data, ZeroG\nenhances productivity and user experience, offering a scalable solution for the\ngrowing demands of digital document management.\n","authors":["Anantha Sharma","Sheeba Elizabeth John","Fatemeh Rezapoor Nikroo","Krupali Bhatt","Mrunal Zambre","Aditi Wikhe"],"pdf_url":"https://arxiv.org/pdf/2411.05936v1.pdf","comment":"10 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2411.05930v1","updated":"2024-11-08T19:31:19Z","published":"2024-11-08T19:31:19Z","title":"BERTrend: Neural Topic Modeling for Emerging Trends Detection","summary":"  Detecting and tracking emerging trends and weak signals in large, evolving\ntext corpora is vital for applications such as monitoring scientific\nliterature, managing brand reputation, surveilling critical infrastructure and\nmore generally to any kind of text-based event detection. Existing solutions\noften fail to capture the nuanced context or dynamically track evolving\npatterns over time. BERTrend, a novel method, addresses these limitations using\nneural topic modeling in an online setting. It introduces a new metric to\nquantify topic popularity over time by considering both the number of documents\nand update frequency. This metric classifies topics as noise, weak, or strong\nsignals, flagging emerging, rapidly growing topics for further investigation.\nExperimentation on two large real-world datasets demonstrates BERTrend's\nability to accurately detect and track meaningful weak signals while filtering\nout noise, offering a comprehensive solution for monitoring emerging trends in\nlarge-scale, evolving text corpora. The method can also be used for\nretrospective analysis of past events. In addition, the use of Large Language\nModels together with BERTrend offers efficient means for the interpretability\nof trends of events.\n","authors":["Allaa Boutaleb","Jerome Picault","Guillaume Grosjean"],"pdf_url":"https://arxiv.org/pdf/2411.05930v1.pdf","comment":"17 pages, 12 figures, FuturED 2024: Workshop on Future of Event\n  Detection (CoLocated with EMNLP 2024)"},{"id":"http://arxiv.org/abs/2411.05892v1","updated":"2024-11-08T12:38:10Z","published":"2024-11-08T12:38:10Z","title":"Identifying and Decomposing Compound Ingredients in Meal Plans Using\n  Large Language Models","summary":"  This study explores the effectiveness of Large Language Models in meal\nplanning, focusing on their ability to identify and decompose compound\ningredients. We evaluated three models-GPT-4o, Llama-3 (70b), and Mixtral\n(8x7b)-to assess their proficiency in recognizing and breaking down complex\ningredient combinations. Preliminary results indicate that while Llama-3 (70b)\nand GPT-4o excels in accurate decomposition, all models encounter difficulties\nwith identifying essential elements like seasonings and oils. Despite strong\noverall performance, variations in accuracy and completeness were observed\nacross models. These findings underscore LLMs' potential to enhance\npersonalized nutrition but highlight the need for further refinement in\ningredient decomposition. Future research should address these limitations to\nimprove nutritional recommendations and health outcomes.\n","authors":["Leon Kopitar","Leon Bedrac","Larissa J Strath","Jiang Bian","Gregor Stiglic"],"pdf_url":"https://arxiv.org/pdf/2411.05892v1.pdf","comment":"Comments: Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)"},{"id":"http://arxiv.org/abs/2411.07264v1","updated":"2024-11-08T21:03:54Z","published":"2024-11-08T21:03:54Z","title":"Multi-Document Financial Question Answering using LLMs","summary":"  We propose two new methods for multi-document financial question answering.\nFirst, a method that uses semantic tagging, and then, queries the index to get\nthe context (RAG_SEM). And second, a Knowledge Graph (KG_RAG) based method that\nuses semantic tagging, and, retrieves knowledge graph triples from a graph\ndatabase, as context. KG_RAG uses knowledge graphs constructed using a small\nmodel that is fine-tuned using knowledge distillation using a large teacher\nmodel. The data consists of 18 10K reports of Apple, Microsoft, Alphabet,\nNVIDIA, Amazon and Tesla for the years 2021, 2022 and 2023. The list of\nquestions in the data consists of 111 complex questions including many esoteric\nquestions that are difficult to answer and the answers are not completely\nobvious. As evaluation metrics, we use overall scores as well as segmented\nscores for measurement including the faithfulness, relevance, correctness,\nsimilarity, an LLM based overall score and the rouge scores as well as a\nsimilarity of embeddings. We find that both methods outperform plain RAG\nsignificantly. KG_RAG outperforms RAG_SEM in four out of nine metrics.\n","authors":["Shalin Shah","Srikanth Ryali","Ramasubbu Venkatesh"],"pdf_url":"https://arxiv.org/pdf/2411.07264v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2404.08627v2","updated":"2024-11-08T18:56:42Z","published":"2024-04-12T17:41:05Z","title":"Is ChatGPT Transforming Academics' Writing Style?","summary":"  Based on one million arXiv papers submitted from May 2018 to January 2024, we\nassess the textual density of ChatGPT's writing style in their abstracts\nthrough a statistical analysis of word frequency changes. Our model is\ncalibrated and validated on a mixture of real abstracts and ChatGPT-modified\nabstracts (simulated data) after a careful noise analysis. The words used for\nestimation are not fixed but adaptive, including those with decreasing\nfrequency. We find that large language models (LLMs), represented by ChatGPT,\nare having an increasing impact on arXiv abstracts, especially in the field of\ncomputer science, where the fraction of LLM-style abstracts is estimated to be\napproximately 35%, if we take the responses of GPT-3.5 to one simple prompt,\n\"revise the following sentences\", as a baseline. We conclude with an analysis\nof both positive and negative aspects of the penetration of LLMs into\nacademics' writing style.\n","authors":["Mingmeng Geng","Roberto Trotta"],"pdf_url":"https://arxiv.org/pdf/2404.08627v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2403.09539v3","updated":"2024-11-08T18:56:41Z","published":"2024-03-14T16:27:49Z","title":"Logits of API-Protected LLMs Leak Proprietary Information","summary":"  Large language model (LLM) providers often hide the architectural details and\nparameters of their proprietary models by restricting public access to a\nlimited API. In this work we show that, with only a conservative assumption\nabout the model architecture, it is possible to learn a surprisingly large\namount of non-public information about an API-protected LLM from a relatively\nsmall number of API queries (e.g., costing under $1000 USD for OpenAI's\ngpt-3.5-turbo). Our findings are centered on one key observation: most modern\nLLMs suffer from a softmax bottleneck, which restricts the model outputs to a\nlinear subspace of the full output space. We exploit this fact to unlock\nseveral capabilities, including (but not limited to) obtaining cheap\nfull-vocabulary outputs, auditing for specific types of model updates,\nidentifying the source LLM given a single full LLM output, and even efficiently\ndiscovering the LLM's hidden size. Our empirical investigations show the\neffectiveness of our methods, which allow us to estimate the embedding size of\nOpenAI's gpt-3.5-turbo to be about 4096. Lastly, we discuss ways that LLM\nproviders can guard against these attacks, as well as how these capabilities\ncan be viewed as a feature (rather than a bug) by allowing for greater\ntransparency and accountability.\n","authors":["Matthew Finlayson","Xiang Ren","Swabha Swayamdipta"],"pdf_url":"https://arxiv.org/pdf/2403.09539v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05779v1","updated":"2024-11-08T18:46:40Z","published":"2024-11-08T18:46:40Z","title":"Curriculum Learning for Few-Shot Domain Adaptation in CT-based Airway\n  Tree Segmentation","summary":"  Despite advances with deep learning (DL), automated airway segmentation from\nchest CT scans continues to face challenges in segmentation quality and\ngeneralization across cohorts. To address these, we propose integrating\nCurriculum Learning (CL) into airway segmentation networks, distributing the\ntraining set into batches according to ad-hoc complexity scores derived from CT\nscans and corresponding ground-truth tree features. We specifically investigate\nfew-shot domain adaptation, targeting scenarios where manual annotation of a\nfull fine-tuning dataset is prohibitively expensive. Results are reported on\ntwo large open-cohorts (ATM22 and AIIB23) with high performance using CL for\nfull training (Source domain) and few-shot fine-tuning (Target domain), but\nwith also some insights on potential detrimental effects if using a classic\nBootstrapping scoring function or if not using proper scan sequencing.\n","authors":["Maxime Jacovella","Ali Keshavarzi","Elsa Angelini"],"pdf_url":"https://arxiv.org/pdf/2411.05779v1.pdf","comment":"Under review for 22nd IEEE International Symposium on Biomedical\n  Imaging (ISBI), Houston, TX, USA"},{"id":"http://arxiv.org/abs/2411.05771v1","updated":"2024-11-08T18:33:03Z","published":"2024-11-08T18:33:03Z","title":"Sketched Equivariant Imaging Regularization and Deep Internal Learning\n  for Inverse Problems","summary":"  Equivariant Imaging (EI) regularization has become the de-facto technique for\nunsupervised training of deep imaging networks, without any need of\nground-truth data. Observing that the EI-based unsupervised training paradigm\ncurrently has significant computational redundancy leading to inefficiency in\nhigh-dimensional applications, we propose a sketched EI regularization which\nleverages the randomized sketching techniques for acceleration. We then extend\nour sketched EI regularization to develop an accelerated deep internal learning\nframework -- Sketched Equivariant Deep Image Prior (Sk.EI-DIP), which can be\nefficiently applied for single-image and task-adapted reconstruction. Our\nnumerical study on X-ray CT image reconstruction tasks demonstrate that our\napproach can achieve order-of-magnitude computational acceleration over\nstandard EI-based counterpart in single-input setting, and network adaptation\nat test time.\n","authors":["Guixian Xu","Jinglai Li","Junqi Tang"],"pdf_url":"https://arxiv.org/pdf/2411.05771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05007v2","updated":"2024-11-08T18:32:59Z","published":"2024-11-07T18:59:58Z","title":"SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion\n  Models","summary":"  Diffusion models have been proven highly effective at generating high-quality\nimages. However, as these models grow larger, they require significantly more\nmemory and suffer from higher latency, posing substantial challenges for\ndeployment. In this work, we aim to accelerate diffusion models by quantizing\ntheir weights and activations to 4 bits. At such an aggressive level, both\nweights and activations are highly sensitive, where conventional post-training\nquantization methods for large language models like smoothing become\ninsufficient. To overcome this limitation, we propose SVDQuant, a new 4-bit\nquantization paradigm. Different from smoothing which redistributes outliers\nbetween weights and activations, our approach absorbs these outliers using a\nlow-rank branch. We first consolidate the outliers by shifting them from\nactivations to weights, then employ a high-precision low-rank branch to take in\nthe weight outliers with Singular Value Decomposition (SVD). This process eases\nthe quantization on both sides. However, na\\\"{\\i}vely running the low-rank\nbranch independently incurs significant overhead due to extra data movement of\nactivations, negating the quantization speedup. To address this, we co-design\nan inference engine Nunchaku that fuses the kernels of the low-rank branch into\nthose of the low-bit branch to cut off redundant memory access. It can also\nseamlessly support off-the-shelf low-rank adapters (LoRAs) without the need for\nre-quantization. Extensive experiments on SDXL, PixArt-$\\Sigma$, and FLUX.1\nvalidate the effectiveness of SVDQuant in preserving image quality. We reduce\nthe memory usage for the 12B FLUX.1 models by 3.5$\\times$, achieving\n3.0$\\times$ speedup over the 4-bit weight-only quantized baseline on the 16GB\nlaptop 4090 GPU, paving the way for more interactive applications on PCs. Our\nquantization library and inference engine are open-sourced.\n","authors":["Muyang Li","Yujun Lin","Zhekai Zhang","Tianle Cai","Xiuyu Li","Junxian Guo","Enze Xie","Chenlin Meng","Jun-Yan Zhu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2411.05007v2.pdf","comment":"Quantization Library: https://github.com/mit-han-lab/deepcompressor\n  Inference Engine: https://github.com/mit-han-lab/nunchaku Website:\n  https://hanlab.mit.edu/projects/svdquant Demo: https://svdquant.mit.edu Blog:\n  https://hanlab.mit.edu/blog/svdquant"},{"id":"http://arxiv.org/abs/2411.05764v1","updated":"2024-11-08T18:26:17Z","published":"2024-11-08T18:26:17Z","title":"FinDVer: Explainable Claim Verification over Long and Hybrid-Content\n  Financial Documents","summary":"  We introduce FinDVer, a comprehensive benchmark specifically designed to\nevaluate the explainable claim verification capabilities of LLMs in the context\nof understanding and analyzing long, hybrid-content financial documents.\nFinDVer contains 2,400 expert-annotated examples, divided into three subsets:\ninformation extraction, numerical reasoning, and knowledge-intensive reasoning,\neach addressing common scenarios encountered in real-world financial contexts.\nWe assess a broad spectrum of LLMs under long-context and RAG settings. Our\nresults show that even the current best-performing system, GPT-4o, still lags\nbehind human experts. We further provide in-depth analysis on long-context and\nRAG setting, Chain-of-Thought reasoning, and model reasoning errors, offering\ninsights to drive future advancements. We believe that FinDVer can serve as a\nvaluable benchmark for evaluating LLMs in claim verification over complex,\nexpert-domain documents.\n","authors":["Yilun Zhao","Yitao Long","Yuru Jiang","Chengye Wang","Weiyuan Chen","Hongjun Liu","Yiming Zhang","Xiangru Tang","Chen Zhao","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2411.05764v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2408.10162v2","updated":"2024-11-08T18:22:46Z","published":"2024-08-19T17:16:35Z","title":"Physics-Aware Combinatorial Assembly Sequence Planning using Data-free\n  Action Masking","summary":"  Combinatorial assembly uses standardized unit primitives to build objects\nthat satisfy user specifications. This paper studies assembly sequence planning\n(ASP) for physical combinatorial assembly. Given the shape of the desired\nobject, the goal is to find a sequence of actions for placing unit primitives\nto build the target object. In particular, we aim to ensure the planned\nassembly sequence is physically executable. However, ASP for combinatorial\nassembly is particularly challenging due to its combinatorial nature. To\naddress the challenge, we employ deep reinforcement learning to learn a\nconstruction policy for placing unit primitives sequentially to build the\ndesired object. Specifically, we design an online physics-aware action mask\nthat filters out invalid actions, which effectively guides policy learning and\nensures violation-free deployment. In the end, we apply the proposed method to\nLego assembly with more than 250 3D structures. The experiment results\ndemonstrate that the proposed method plans physically valid assembly sequences\nto build all structures, achieving a $100\\%$ success rate, whereas the best\ncomparable baseline fails more than $40$ structures. Our implementation is\navailable at\n\\url{https://github.com/intelligent-control-lab/PhysicsAwareCombinatorialASP}.\n","authors":["Ruixuan Liu","Alan Chen","Weiye Zhao","Changliu Liu"],"pdf_url":"https://arxiv.org/pdf/2408.10162v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.08657v2","updated":"2024-11-08T18:18:23Z","published":"2023-05-15T14:02:35Z","title":"Meta-models for transfer learning in source localisation","summary":"  In practice, non-destructive testing (NDT) procedures tend to consider\nexperiments (and their respective models) as distinct, conducted in isolation\nand associated with independent data. In contrast, this work looks to capture\nthe interdependencies between acoustic emission (AE) experiments (as\nmeta-models) and then use the resulting functions to predict the model\nhyperparameters for previously unobserved systems. We utilise a Bayesian\nmultilevel approach (similar to deep Gaussian Processes) where a higher level\nmeta-model captures the inter-task relationships. Our key contribution is how\nknowledge of the experimental campaign can be encoded between tasks as well as\nwithin tasks. We present an example of AE time-of-arrival mapping for source\nlocalisation, to illustrate how multilevel models naturally lend themselves to\nrepresenting aggregate systems in engineering. We constrain the meta-model\nbased on domain knowledge, then use the inter-task functions for transfer\nlearning, predicting hyperparameters for models of previously unobserved\nexperiments (for a specific design).\n","authors":["Lawrence A. Bull","Matthew R. Jones","Elizabeth J. Cross","Andrew Duncan","Mark Girolami"],"pdf_url":"https://arxiv.org/pdf/2305.08657v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05757v1","updated":"2024-11-08T18:18:18Z","published":"2024-11-08T18:18:18Z","title":"Tract-RLFormer: A Tract-Specific RL policy based Decoder-only\n  Transformer Network","summary":"  Fiber tractography is a cornerstone of neuroimaging, enabling the detailed\nmapping of the brain's white matter pathways through diffusion MRI. This is\ncrucial for understanding brain connectivity and function, making it a valuable\ntool in neurological applications. Despite its importance, tractography faces\nchallenges due to its complexity and susceptibility to false positives,\nmisrepresenting vital pathways. To address these issues, recent strategies have\nshifted towards deep learning, utilizing supervised learning, which depends on\nprecise ground truth, or reinforcement learning, which operates without it. In\nthis work, we propose Tract-RLFormer, a network utilizing both supervised and\nreinforcement learning, in a two-stage policy refinement process that markedly\nimproves the accuracy and generalizability across various data-sets. By\nemploying a tract-specific approach, our network directly delineates the tracts\nof interest, bypassing the traditional segmentation process. Through rigorous\nvalidation on datasets such as TractoInferno, HCP, and ISMRM-2015, our\nmethodology demonstrates a leap forward in tractography, showcasing its ability\nto accurately map the brain's white matter tracts.\n","authors":["Ankita Joshi","Ashutosh Sharma","Anoushkrit Goel","Ranjeet Ranjan Jha","Chirag Ahuja","Arnav Bhavsar","Aditya Nigam"],"pdf_url":"https://arxiv.org/pdf/2411.05757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01702v3","updated":"2024-11-08T18:17:39Z","published":"2024-05-02T19:55:30Z","title":"Optimization without Retraction on the Random Generalized Stiefel\n  Manifold","summary":"  Optimization over the set of matrices $X$ that satisfy $X^\\top B X = I_p$,\nreferred to as the generalized Stiefel manifold, appears in many applications\ninvolving sampled covariance matrices such as the canonical correlation\nanalysis (CCA), independent component analysis (ICA), and the generalized\neigenvalue problem (GEVP). Solving these problems is typically done by\niterative methods that require a fully formed $B$. We propose a cheap\nstochastic iterative method that solves the optimization problem while having\naccess only to random estimates of $B$. Our method does not enforce the\nconstraint in every iteration; instead, it produces iterations that converge to\ncritical points on the generalized Stiefel manifold defined in expectation. The\nmethod has lower per-iteration cost, requires only matrix multiplications, and\nhas the same convergence rates as its Riemannian optimization counterparts that\nrequire the full matrix $B$. Experiments demonstrate its effectiveness in\nvarious machine learning applications involving generalized orthogonality\nconstraints, including CCA, ICA, and the GEVP.\n","authors":["Simon Vary","Pierre Ablin","Bin Gao","P. -A. Absil"],"pdf_url":"https://arxiv.org/pdf/2405.01702v3.pdf","comment":"This v3 is a corrected version of the ICML 2024 paper (PMLR\n  235:49226-49248); see the errata at the end"},{"id":"http://arxiv.org/abs/2411.05752v1","updated":"2024-11-08T18:10:46Z","published":"2024-11-08T18:10:46Z","title":"FisherMask: Enhancing Neural Network Labeling Efficiency in Image\n  Classification Using Fisher Information","summary":"  Deep learning (DL) models are popular across various domains due to their\nremarkable performance and efficiency. However, their effectiveness relies\nheavily on large amounts of labeled data, which are often time-consuming and\nlabor-intensive to generate manually. To overcome this challenge, it is\nessential to develop strategies that reduce reliance on extensive labeled data\nwhile preserving model performance. In this paper, we propose FisherMask, a\nFisher information-based active learning (AL) approach that identifies key\nnetwork parameters by masking them based on their Fisher information values.\nFisherMask enhances batch AL by using Fisher information to select the most\ncritical parameters, allowing the identification of the most impactful samples\nduring AL training. Moreover, Fisher information possesses favorable\nstatistical properties, offering valuable insights into model behavior and\nproviding a better understanding of the performance characteristics within the\nAL pipeline. Our extensive experiments demonstrate that FisherMask\nsignificantly outperforms state-of-the-art methods on diverse datasets,\nincluding CIFAR-10 and FashionMNIST, especially under imbalanced settings.\nThese improvements lead to substantial gains in labeling efficiency. Hence\nserving as an effective tool to measure the sensitivity of model parameters to\ndata samples. Our code is available on\n\\url{https://github.com/sgchr273/FisherMask}.\n","authors":["Shreen Gul","Mohamed Elmahallawy","Sanjay Madria","Ardhendu Tripathy"],"pdf_url":"https://arxiv.org/pdf/2411.05752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05750v1","updated":"2024-11-08T18:10:07Z","published":"2024-11-08T18:10:07Z","title":"On Differentially Private String Distances","summary":"  Given a database of bit strings $A_1,\\ldots,A_m\\in \\{0,1\\}^n$, a fundamental\ndata structure task is to estimate the distances between a given query $B\\in\n\\{0,1\\}^n$ with all the strings in the database. In addition, one might further\nwant to ensure the integrity of the database by releasing these distance\nstatistics in a secure manner. In this work, we propose differentially private\n(DP) data structures for this type of tasks, with a focus on Hamming and edit\ndistance. On top of the strong privacy guarantees, our data structures are also\ntime- and space-efficient. In particular, our data structure is $\\epsilon$-DP\nagainst any sequence of queries of arbitrary length, and for any query $B$ such\nthat the maximum distance to any string in the database is at most $k$, we\noutput $m$ distance estimates. Moreover,\n  - For Hamming distance, our data structure answers any query in $\\widetilde\nO(mk+n)$ time and each estimate deviates from the true distance by at most\n$\\widetilde O(k/e^{\\epsilon/\\log k})$;\n  - For edit distance, our data structure answers any query in $\\widetilde\nO(mk^2+n)$ time and each estimate deviates from the true distance by at most\n$\\widetilde O(k/e^{\\epsilon/(\\log k \\log n)})$.\n  For moderate $k$, both data structures support sublinear query operations. We\nobtain these results via a novel adaptation of the randomized response\ntechnique as a bit flipping procedure, applied to the sketched strings.\n","authors":["Jerry Yao-Chieh Hu","Erzhi Liu","Han Liu","Zhao Song","Lichen Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05746v1","updated":"2024-11-08T18:07:55Z","published":"2024-11-08T18:07:55Z","title":"Continuous-Time Analysis of Adaptive Optimization and Normalization","summary":"  Adaptive optimization algorithms, particularly Adam and its variant AdamW,\nare fundamental components of modern deep learning. However, their training\ndynamics lack comprehensive theoretical understanding, with limited insight\ninto why common practices - such as specific hyperparameter choices and\nnormalization layers - contribute to successful generalization. This work\npresents a continuous-time formulation of Adam and AdamW, facilitating a\ntractable analysis of training dynamics that can shed light on such practical\nquestions. We theoretically derive a stable region for Adam's hyperparameters\n$(\\beta, \\gamma)$ that ensures bounded updates, empirically verifying these\npredictions by observing unstable exponential growth of parameter updates\noutside this region. Furthermore, we theoretically justify the success of\nnormalization layers by uncovering an implicit meta-adaptive effect of\nscale-invariant architectural components. This insight leads to an explicit\noptimizer, $2$-Adam, which we generalize to $k$-Adam - an optimizer that\napplies an adaptive normalization procedure $k$ times, encompassing Adam\n(corresponding to $k=1$) and Adam with a normalization layer (corresponding to\n$k=2$). Overall, our continuous-time formulation of Adam facilitates a\nprincipled analysis, offering deeper understanding of optimal hyperparameter\nchoices and architectural decisions in modern deep learning.\n","authors":["Rhys Gould","Hidenori Tanaka"],"pdf_url":"https://arxiv.org/pdf/2411.05746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05743v1","updated":"2024-11-08T18:04:41Z","published":"2024-11-08T18:04:41Z","title":"Free Record-Level Privacy Risk Evaluation Through Artifact-Based Methods","summary":"  Membership inference attacks (MIAs) are widely used to empirically assess the\nprivacy risks of samples used to train a target machine learning model.\nState-of-the-art methods however require training hundreds of shadow models,\nwith the same size and architecture of the target model, solely to evaluate the\nprivacy risk. While one might be able to afford this for small models, the cost\noften becomes prohibitive for medium and large models.\n  We here instead propose a novel approach to identify the at-risk samples\nusing only artifacts available during training, with little to no additional\ncomputational overhead. Our method analyzes individual per-sample loss traces\nand uses them to identify the vulnerable data samples. We demonstrate the\neffectiveness of our artifact-based approach through experiments on the CIFAR10\ndataset, showing high precision in identifying vulnerable samples as determined\nby a SOTA shadow model-based MIA (LiRA). Impressively, our method reaches the\nsame precision as another SOTA MIA when measured against LiRA, despite it being\norders of magnitude cheaper. We then show LT-IQR to outperform alternative loss\naggregation methods, perform ablation studies on hyperparameters, and validate\nthe robustness of our method to the target metric. Finally, we study the\nevolution of the vulnerability score distribution throughout training as a\nmetric for model-level risk assessment.\n","authors":["Joseph Pollock","Igor Shilov","Euodia Dodd","Yves-Alexandre de Montjoye"],"pdf_url":"https://arxiv.org/pdf/2411.05743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05742v1","updated":"2024-11-08T18:01:05Z","published":"2024-11-08T18:01:05Z","title":"Topology-aware Reinforcement Feature Space Reconstruction for Graph Data","summary":"  Feature space is an environment where data points are vectorized to represent\nthe original dataset. Reconstructing a good feature space is essential to\naugment the AI power of data, improve model generalization, and increase the\navailability of downstream ML models. Existing literature, such as feature\ntransformation and feature selection, is labor-intensive (e.g., heavy reliance\non empirical experience) and mostly designed for tabular data. Moreover, these\nmethods regard data samples as independent, which ignores the unique\ntopological structure when applied to graph data, thus resulting in a\nsuboptimal reconstruction feature space. Can we consider the topological\ninformation to automatically reconstruct feature space for graph data without\nheavy experiential knowledge? To fill this gap, we leverage topology-aware\nreinforcement learning to automate and optimize feature space reconstruction\nfor graph data. Our approach combines the extraction of core subgraphs to\ncapture essential structural information with a graph neural network (GNN) to\nencode topological features and reduce computing complexity. Then we introduce\nthree reinforcement agents within a hierarchical structure to systematically\ngenerate meaningful features through an iterative process, effectively\nreconstructing the feature space. This framework provides a principled solution\nfor attributed graph feature space reconstruction. The extensive experiments\ndemonstrate the effectiveness and efficiency of including topological\nawareness.\n","authors":["Wangyang Ying","Haoyue Bai","Kunpeng Liu","Yanjie Fu"],"pdf_url":"https://arxiv.org/pdf/2411.05742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.17396v2","updated":"2024-11-08T18:00:00Z","published":"2024-08-30T16:30:00Z","title":"Fairness-Aware Estimation of Graphical Models","summary":"  This paper examines the issue of fairness in the estimation of graphical\nmodels (GMs), particularly Gaussian, Covariance, and Ising models. These models\nplay a vital role in understanding complex relationships in high-dimensional\ndata. However, standard GMs can result in biased outcomes, especially when the\nunderlying data involves sensitive characteristics or protected groups. To\naddress this, we introduce a comprehensive framework designed to reduce bias in\nthe estimation of GMs related to protected attributes. Our approach involves\nthe integration of the pairwise graph disparity error and a tailored loss\nfunction into a nonsmooth multi-objective optimization problem, striving to\nachieve fairness across different sensitive groups while maintaining the\neffectiveness of the GMs. Experimental evaluations on synthetic and real-world\ndatasets demonstrate that our framework effectively mitigates bias without\nundermining GMs' performance.\n","authors":["Zhuoping Zhou","Davoud Ataee Tarzanagh","Bojian Hou","Qi Long","Li Shen"],"pdf_url":"https://arxiv.org/pdf/2408.17396v2.pdf","comment":"Accepted for publication at NeurIPS 2024, 34 Pages, 9 Figures"},{"id":"http://arxiv.org/abs/2411.03320v2","updated":"2024-11-08T17:50:33Z","published":"2024-10-20T18:35:56Z","title":"log-RRIM: Yield Prediction via Local-to-global Reaction Representation\n  Learning and Interaction Modeling","summary":"  Accurate prediction of chemical reaction yields is crucial for optimizing\norganic synthesis, potentially reducing time and resources spent on\nexperimentation. With the rise of artificial intelligence (AI), there is\ngrowing interest in leveraging AI-based methods to accelerate yield predictions\nwithout conducting in vitro experiments. We present log-RRIM, an innovative\ngraph transformer-based framework designed for predicting chemical reaction\nyields. Our approach implements a unique local-to-global reaction\nrepresentation learning strategy. This approach initially captures detailed\nmolecule-level information and then models and aggregates intermolecular\ninteractions, ensuring that the impact of varying-sizes molecular fragments on\nyield is accurately accounted for. Another key feature of log-RRIM is its\nintegration of a cross-attention mechanism that focuses on the interplay\nbetween reagents and reaction centers. This design reflects a fundamental\nprinciple in chemical reactions: the crucial role of reagents in influencing\nbond-breaking and formation processes, which ultimately affect reaction yields.\nlog-RRIM outperforms existing methods in our experiments, especially for medium\nto high-yielding reactions, proving its reliability as a predictor. Its\nadvanced modeling of reactant-reagent interactions and sensitivity to small\nmolecular fragments make it a valuable tool for reaction planning and\noptimization in chemical synthesis. The data and codes of log-RRIM are\naccessible through https://github.com/ninglab/Yield_log_RRIM.\n","authors":["Xiao Hu","Ziqi Chen","Bo Peng","Daniel Adu-Ampratwum","Xia Ning"],"pdf_url":"https://arxiv.org/pdf/2411.03320v2.pdf","comment":"18 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.05735v1","updated":"2024-11-08T17:50:24Z","published":"2024-11-08T17:50:24Z","title":"Aioli: A Unified Optimization Framework for Language Model Data Mixing","summary":"  Language model performance depends on identifying the optimal mixture of data\ngroups to train on (e.g., law, code, math). Prior work has proposed a diverse\nset of methods to efficiently learn mixture proportions, ranging from fitting\nregression models over training runs to dynamically updating proportions\nthroughout training. Surprisingly, we find that no existing method consistently\noutperforms a simple stratified sampling baseline in terms of average test\nperplexity per group. In this paper, we study the cause of this inconsistency\nby unifying existing methods into a standard optimization framework. We show\nthat all methods set proportions to minimize total loss, subject to a\nmethod-specific mixing law -- an assumption on how loss is a function of\nmixture proportions. We find that existing parameterizations of mixing laws can\nexpress the true loss-proportion relationship empirically, but the methods\nthemselves often set the mixing law parameters inaccurately, resulting in poor\nand inconsistent performance. Finally, we leverage the insights from our\nframework to derive a new online method named Aioli, which directly estimates\nthe mixing law parameters throughout training and uses them to dynamically\nadjust proportions. Empirically, Aioli outperforms stratified sampling on 6 out\nof 6 datasets by an average of 0.28 test perplexity points, whereas existing\nmethods fail to consistently beat stratified sampling, doing up to 6.9 points\nworse. Moreover, in a practical setting where proportions are learned on\nshorter runs due to computational constraints, Aioli can dynamically adjust\nthese proportions over the full training run, consistently improving\nperformance over existing methods by up to 12.01 test perplexity points.\n","authors":["Mayee F. Chen","Michael Y. Hu","Nicholas Lourie","Kyunghyun Cho","Christopher R√©"],"pdf_url":"https://arxiv.org/pdf/2411.05735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20067v2","updated":"2024-11-08T17:49:46Z","published":"2024-07-29T14:53:45Z","title":"xAI-Drop: Don't Use What You Cannot Explain","summary":"  Graph Neural Networks (GNNs) have emerged as the predominant paradigm for\nlearning from graph-structured data, offering a wide range of applications from\nsocial network analysis to bioinformatics. Despite their versatility, GNNs face\nchallenges such as lack of generalization and poor interpretability, which\nhinder their wider adoption and reliability in critical applications. Dropping\nhas emerged as an effective paradigm for improving the generalization\ncapabilities of GNNs. However, existing approaches often rely on random or\nheuristic-based selection criteria, lacking a principled method to identify and\nexclude nodes that contribute to noise and over-complexity in the model. In\nthis work, we argue that explainability should be a key indicator of a model's\nquality throughout its training phase. To this end, we introduce xAI-Drop, a\nnovel topological-level dropping regularizer that leverages explainability to\npinpoint noisy network elements to be excluded from the GNN propagation\nmechanism. An empirical evaluation on diverse real-world datasets demonstrates\nthat our method outperforms current state-of-the-art dropping approaches in\naccuracy, and improves explanation quality.\n","authors":["Vincenzo Marco De Luca","Antonio Longa","Andrea Passerini","Pietro Li√≤"],"pdf_url":"https://arxiv.org/pdf/2407.20067v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05733v1","updated":"2024-11-08T17:46:56Z","published":"2024-11-08T17:46:56Z","title":"Differential Privacy Under Class Imbalance: Methods and Empirical\n  Insights","summary":"  Imbalanced learning occurs in classification settings where the distribution\nof class-labels is highly skewed in the training data, such as when predicting\nrare diseases or in fraud detection. This class imbalance presents a\nsignificant algorithmic challenge, which can be further exacerbated when\nprivacy-preserving techniques such as differential privacy are applied to\nprotect sensitive training data. Our work formalizes these challenges and\nprovides a number of algorithmic solutions. We consider DP variants of\npre-processing methods that privately augment the original dataset to reduce\nthe class imbalance; these include oversampling, SMOTE, and private synthetic\ndata generation. We also consider DP variants of in-processing techniques,\nwhich adjust the learning algorithm to account for the imbalance; these include\nmodel bagging, class-weighted empirical risk minimization and class-weighted\ndeep learning. For each method, we either adapt an existing imbalanced learning\ntechnique to the private setting or demonstrate its incompatibility with\ndifferential privacy. Finally, we empirically evaluate these privacy-preserving\nimbalanced learning methods under various data and distributional settings. We\nfind that private synthetic data methods perform well as a data pre-processing\nstep, while class-weighted ERMs are an alternative in higher-dimensional\nsettings where private synthetic data suffers from the curse of dimensionality.\n","authors":["Lucas Rosenblatt","Yuliia Lut","Eitan Turok","Marco Avella-Medina","Rachel Cummings"],"pdf_url":"https://arxiv.org/pdf/2411.05733v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2411.05730v1","updated":"2024-11-08T17:41:51Z","published":"2024-11-08T17:41:51Z","title":"Learning Subsystem Dynamics in Nonlinear Systems via Port-Hamiltonian\n  Neural Networks","summary":"  Port-Hamiltonian neural networks (pHNNs) are emerging as a powerful modeling\ntool that integrates physical laws with deep learning techniques. While most\nresearch has focused on modeling the entire dynamics of interconnected systems,\nthe potential for identifying and modeling individual subsystems while\noperating as part of a larger system has been overlooked. This study addresses\nthis gap by introducing a novel method for using pHNNs to identify such\nsubsystems based solely on input-output measurements. By utilizing the inherent\ncompositional property of the port-Hamiltonian systems, we developed an\nalgorithm that learns the dynamics of individual subsystems, without requiring\ndirect access to their internal states. On top of that, by choosing an output\nerror (OE) model structure, we have been able to handle measurement noise\neffectively. The effectiveness of the proposed approach is demonstrated through\ntests on interconnected systems, including multi-physics scenarios,\ndemonstrating its potential for identifying subsystem dynamics and facilitating\ntheir integration into new interconnected models.\n","authors":["G. J. E. van Otterdijk","S. Moradi","S. Weiland","R. T√≥th","N. O. Jaensson","M. Schoukens"],"pdf_url":"https://arxiv.org/pdf/2411.05730v1.pdf","comment":"Preprint submitted to ECC 2025"},{"id":"http://arxiv.org/abs/2411.05729v1","updated":"2024-11-08T17:40:43Z","published":"2024-11-08T17:40:43Z","title":"Graph-Dictionary Signal Model for Sparse Representations of Multivariate\n  Data","summary":"  Representing and exploiting multivariate signals require capturing complex\nrelations between variables. We define a novel Graph-Dictionary signal model,\nwhere a finite set of graphs characterizes relationships in data distribution\nthrough a weighted sum of their Laplacians. We propose a framework to infer the\ngraph dictionary representation from observed data, along with a bilinear\ngeneralization of the primal-dual splitting algorithm to solve the learning\nproblem. Our new formulation allows to include a priori knowledge on signal\nproperties, as well as on underlying graphs and their coefficients. We show the\ncapability of our method to reconstruct graphs from signals in multiple\nsynthetic settings, where our model outperforms previous baselines. Then, we\nexploit graph-dictionary representations in a motor imagery decoding task on\nbrain activity data, where we classify imagined motion better than standard\nmethods relying on many more features.\n","authors":["William Cappelletti","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2411.05729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.01977v2","updated":"2024-11-08T17:40:09Z","published":"2024-09-03T15:21:10Z","title":"Counterfactual Fairness by Combining Factual and Counterfactual\n  Predictions","summary":"  In high-stake domains such as healthcare and hiring, the role of machine\nlearning (ML) in decision-making raises significant fairness concerns. This\nwork focuses on Counterfactual Fairness (CF), which posits that an ML model's\noutcome on any individual should remain unchanged if they had belonged to a\ndifferent demographic group. Previous works have proposed methods that\nguarantee CF. Notwithstanding, their effects on the model's predictive\nperformance remains largely unclear. To fill in this gap, we provide a\ntheoretical study on the inherent trade-off between CF and predictive\nperformance in a model-agnostic manner. We first propose a simple but effective\nmethod to cast an optimal but potentially unfair predictor into a fair one\nwithout losing the optimality. By analyzing its excess risk in order to achieve\nCF, we quantify this inherent trade-off. Further analysis on our method's\nperformance with access to only incomplete causal knowledge is also conducted.\nBuilt upon it, we propose a performant algorithm that can be applied in such\nscenarios. Experiments on both synthetic and semi-synthetic datasets\ndemonstrate the validity of our analysis and methods.\n","authors":["Zeyu Zhou","Tianci Liu","Ruqi Bai","Jing Gao","Murat Kocaoglu","David I. Inouye"],"pdf_url":"https://arxiv.org/pdf/2409.01977v2.pdf","comment":"In NeurIPS 2024"},{"id":"http://arxiv.org/abs/2312.14106v3","updated":"2024-11-08T17:33:39Z","published":"2023-12-21T18:31:33Z","title":"Learning Human-like Representations to Enable Learning Human Values","summary":"  How can we build AI systems that can learn any set of individual human values\nboth quickly and safely, avoiding causing harm or violating societal standards\nfor acceptable behavior during the learning process? We explore the effects of\nrepresentational alignment between humans and AI agents on learning human\nvalues. Making AI systems learn human-like representations of the world has\nmany known benefits, including improving generalization, robustness to domain\nshifts, and few-shot learning performance. We demonstrate that this kind of\nrepresentational alignment can also support safely learning and exploring human\nvalues in the context of personalization. We begin with a theoretical\nprediction, show that it applies to learning human morality judgments, then\nshow that our results generalize to ten different aspects of human values --\nincluding ethics, honesty, and fairness -- training AI agents on each set of\nvalues in a multi-armed bandit setting, where rewards reflect human value\njudgments over the chosen action. Using a set of textual action descriptions,\nwe collect value judgments from humans, as well as similarity judgments from\nboth humans and multiple language models, and demonstrate that representational\nalignment enables both safe exploration and improved generalization when\nlearning human values.\n","authors":["Andrea Wynn","Ilia Sucholutsky","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2312.14106v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.00922v2","updated":"2024-11-08T17:23:05Z","published":"2024-11-01T14:32:58Z","title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations","summary":"  In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https://anonymous.4open.science/r/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.\n","authors":["Piotr Kaniewski","Fariba Yousefi","Yeman Brhane Hagos","Talha Qaiser","Nikolay Burlutskiy"],"pdf_url":"https://arxiv.org/pdf/2411.00922v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05718v1","updated":"2024-11-08T17:20:47Z","published":"2024-11-08T17:20:47Z","title":"A Retrospective on the Robot Air Hockey Challenge: Benchmarking Robust,\n  Reliable, and Safe Learning Techniques for Real-world Robotics","summary":"  Machine learning methods have a groundbreaking impact in many application\ndomains, but their application on real robotic platforms is still limited.\nDespite the many challenges associated with combining machine learning\ntechnology with robotics, robot learning remains one of the most promising\ndirections for enhancing the capabilities of robots. When deploying\nlearning-based approaches on real robots, extra effort is required to address\nthe challenges posed by various real-world factors. To investigate the key\nfactors influencing real-world deployment and to encourage original solutions\nfrom different researchers, we organized the Robot Air Hockey Challenge at the\nNeurIPS 2023 conference. We selected the air hockey task as a benchmark,\nencompassing low-level robotics problems and high-level tactics. Different from\nother machine learning-centric benchmarks, participants need to tackle\npractical challenges in robotics, such as the sim-to-real gap, low-level\ncontrol issues, safety problems, real-time requirements, and the limited\navailability of real-world data. Furthermore, we focus on a dynamic\nenvironment, removing the typical assumption of quasi-static motions of other\nreal-world benchmarks. The competition's results show that solutions combining\nlearning-based approaches with prior knowledge outperform those relying solely\non data when real-world deployment is challenging. Our ablation study reveals\nwhich real-world factors may be overlooked when building a learning-based\nsolution. The successful real-world air hockey deployment of best-performing\nagents sets the foundation for future competitions and follow-up research\ndirections.\n","authors":["Puze Liu","Jonas G√ºnster","Niklas Funk","Simon Gr√∂ger","Dong Chen","Haitham Bou-Ammar","Julius Jankowski","Ante Mariƒá","Sylvain Calinon","Andrej Orsula","Miguel Olivares-Mendez","Hongyi Zhou","Rudolf Lioutikov","Gerhard Neumann","Amarildo Likmeta Amirhossein Zhalehmehrabi","Thomas Bonenfant","Marcello Restelli","Davide Tateo","Ziyuan Liu","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2411.05718v1.pdf","comment":"Accept at NeurIPS 2024 Dataset and Benchmark Track"},{"id":"http://arxiv.org/abs/2407.19115v2","updated":"2024-11-08T17:20:07Z","published":"2024-07-26T22:38:11Z","title":"Towards Scalable and Stable Parallelization of Nonlinear RNNs","summary":"  Conventional nonlinear RNNs are not naturally parallelizable across the\nsequence length, unlike transformers and linear RNNs. Lim et. al. (2024)\ntherefore tackle parallelized evaluation of nonlinear RNNs, posing it as a\nfixed point problem solved with Newton's method. By deriving and applying a\nparallelized form of Newton's method, they achieve large speedups over\nsequential evaluation. However, their approach inherits cubic computational\ncomplexity and numerical instability. We tackle these weaknesses. To reduce the\ncomputational complexity, we apply quasi-Newton approximations and show they\nconverge comparably, use less memory, and are faster, compared to full-Newton.\nTo stabilize Newton's method, we leverage a connection between Newton's method\ndamped with trust regions and Kalman smoothing. This connection allows us to\nstabilize the iteration, per the trust region, and use efficient parallelized\nKalman algorithms to retain performance. We compare these methods empirically\nand highlight use cases where each algorithm excels.\n","authors":["Xavier Gonzalez","Andrew Warrington","Jimmy T. H. Smith","Scott W. Linderman"],"pdf_url":"https://arxiv.org/pdf/2407.19115v2.pdf","comment":"25 pages, 8 figures, NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04242v2","updated":"2024-11-08T17:16:29Z","published":"2024-11-06T20:11:19Z","title":"Multimodal Structure-Aware Quantum Data Processing","summary":"  While large language models (LLMs) have advanced the field of natural\nlanguage processing (NLP), their \"black box\" nature obscures their\ndecision-making processes. To address this, researchers developed structured\napproaches using higher order tensors. These are able to model linguistic\nrelations, but stall when training on classical computers due to their\nexcessive size. Tensors are natural inhabitants of quantum systems and training\non quantum computers provides a solution by translating text to variational\nquantum circuits. In this paper, we develop MultiQ-NLP: a framework for\nstructure-aware data processing with multimodal text+image data. Here,\n\"structure\" refers to syntactic and grammatical relationships in language, as\nwell as the hierarchical organization of visual elements in images. We enrich\nthe translation with new types and type homomorphisms and develop novel\narchitectures to represent structure. When tested on a main stream image\nclassification task (SVO Probes), our best model showed a par performance with\nthe state of the art classical models; moreover the best model was fully\nstructured.\n","authors":["Hala Hawashin","Mehrnoosh Sadrzadeh"],"pdf_url":"https://arxiv.org/pdf/2411.04242v2.pdf","comment":"10 Pages, 16 Figures"},{"id":"http://arxiv.org/abs/2411.05714v1","updated":"2024-11-08T17:16:02Z","published":"2024-11-08T17:16:02Z","title":"STARS: Sensor-agnostic Transformer Architecture for Remote Sensing","summary":"  We present a sensor-agnostic spectral transformer as the basis for spectral\nfoundation models. To that end, we introduce a Universal Spectral\nRepresentation (USR) that leverages sensor meta-data, such as sensing kernel\nspecifications and sensing wavelengths, to encode spectra obtained from any\nspectral instrument into a common representation, such that a single model can\ningest data from any sensor. Furthermore, we develop a methodology for\npre-training such models in a self-supervised manner using a novel random\nsensor-augmentation and reconstruction pipeline to learn spectral features\nindependent of the sensing paradigm. We demonstrate that our architecture can\nlearn sensor independent spectral features that generalize effectively to\nsensors not seen during training. This work sets the stage for training\nfoundation models that can both leverage and be effective for the growing\ndiversity of spectral data.\n","authors":["Ethan King","Jaime Rodriguez","Diego Llanes","Timothy Doster","Tegan Emerson","James Koch"],"pdf_url":"https://arxiv.org/pdf/2411.05714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05712v1","updated":"2024-11-08T17:13:53Z","published":"2024-11-08T17:13:53Z","title":"Scaling Laws for Task-Optimized Models of the Primate Visual Ventral\n  Stream","summary":"  When trained on large-scale object classification datasets, certain\nartificial neural network models begin to approximate core object recognition\n(COR) behaviors and neural response patterns in the primate visual ventral\nstream (VVS). While recent machine learning advances suggest that scaling model\nsize, dataset size, and compute resources improve task performance, the impact\nof scaling on brain alignment remains unclear. In this study, we explore\nscaling laws for modeling the primate VVS by systematically evaluating over 600\nmodels trained under controlled conditions on benchmarks spanning V1, V2, V4,\nIT and COR behaviors. We observe that while behavioral alignment continues to\nscale with larger models, neural alignment saturates. This observation remains\ntrue across model architectures and training datasets, even though models with\nstronger inductive bias and datasets with higher-quality images are more\ncompute-efficient. Increased scaling is especially beneficial for higher-level\nvisual areas, where small models trained on few samples exhibit only poor\nalignment. Finally, we develop a scaling recipe, indicating that a greater\nproportion of compute should be allocated to data samples over model size. Our\nresults suggest that while scaling alone might suffice for alignment with human\ncore object recognition behavior, it will not yield improved models of the\nbrain's visual ventral stream with current architectures and datasets,\nhighlighting the need for novel strategies in building brain-like models.\n","authors":["Abdulkadir Gokce","Martin Schrimpf"],"pdf_url":"https://arxiv.org/pdf/2411.05712v1.pdf","comment":"9 pages for the main paper, 20 pages in total. 6 main figures and 10\n  supplementary figures. Code, model weights, and benchmark results can be\n  accessed at https://github.com/epflneuroailab/scaling-primate-vvs"},{"id":"http://arxiv.org/abs/2411.05708v1","updated":"2024-11-08T17:10:38Z","published":"2024-11-08T17:10:38Z","title":"Sample and Computationally Efficient Robust Learning of Gaussian\n  Single-Index Models","summary":"  A single-index model (SIM) is a function of the form\n$\\sigma(\\mathbf{w}^{\\ast} \\cdot \\mathbf{x})$, where $\\sigma: \\mathbb{R} \\to\n\\mathbb{R}$ is a known link function and $\\mathbf{w}^{\\ast}$ is a hidden unit\nvector. We study the task of learning SIMs in the agnostic (a.k.a. adversarial\nlabel noise) model with respect to the $L^2_2$-loss under the Gaussian\ndistribution. Our main result is a sample and computationally efficient\nagnostic proper learner that attains $L^2_2$-error of\n$O(\\mathrm{OPT})+\\epsilon$, where $\\mathrm{OPT}$ is the optimal loss. The\nsample complexity of our algorithm is $\\tilde{O}(d^{\\lceil\nk^{\\ast}/2\\rceil}+d/\\epsilon)$, where $k^{\\ast}$ is the information-exponent of\n$\\sigma$ corresponding to the degree of its first non-zero Hermite coefficient.\nThis sample bound nearly matches known CSQ lower bounds, even in the realizable\nsetting. Prior algorithmic work in this setting had focused on learning in the\nrealizable case or in the presence of semi-random noise. Prior computationally\nefficient robust learners required significantly stronger assumptions on the\nlink function.\n","authors":["Puqian Wang","Nikos Zarifis","Ilias Diakonikolas","Jelena Diakonikolas"],"pdf_url":"https://arxiv.org/pdf/2411.05708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16749v3","updated":"2024-11-08T17:07:23Z","published":"2024-06-24T15:57:49Z","title":"Inferring stochastic low-rank recurrent neural networks from neural data","summary":"  A central aim in computational neuroscience is to relate the activity of\nlarge populations of neurons to an underlying dynamical system. Models of these\nneural dynamics should ideally be both interpretable and fit the observed data\nwell. Low-rank recurrent neural networks (RNNs) exhibit such interpretability\nby having tractable dynamics. However, it is unclear how to best fit low-rank\nRNNs to data consisting of noisy observations of an underlying stochastic\nsystem. Here, we propose to fit stochastic low-rank RNNs with variational\nsequential Monte Carlo methods. We validate our method on several datasets\nconsisting of both continuous and spiking neural data, where we obtain lower\ndimensional latent dynamics than current state of the art methods.\nAdditionally, for low-rank models with piecewise linear nonlinearities, we show\nhow to efficiently identify all fixed points in polynomial rather than\nexponential cost in the number of units, making analysis of the inferred\ndynamics tractable for large RNNs. Our method both elucidates the dynamical\nsystems underlying experimental recordings and provides a generative model\nwhose trajectories match observed variability.\n","authors":["Matthijs Pals","A Erdem Saƒütekin","Felix Pei","Manuel Gloeckler","Jakob H Macke"],"pdf_url":"https://arxiv.org/pdf/2406.16749v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10160v3","updated":"2024-11-08T17:05:09Z","published":"2023-02-20T18:46:12Z","title":"Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift","summary":"  We develop and analyze a principled approach to kernel ridge regression under\ncovariate shift. The goal is to learn a regression function with small mean\nsquared error over a target distribution, based on unlabeled data from there\nand labeled data that may have a different feature distribution. We propose to\nsplit the labeled data into two subsets, and conduct kernel ridge regression on\nthem separately to obtain a collection of candidate models and an imputation\nmodel. We use the latter to fill the missing labels and then select the best\ncandidate accordingly. Our non-asymptotic excess risk bounds demonstrate that\nour estimator adapts effectively to both the structure of the target\ndistribution and the covariate shift. This adaptation is quantified through a\nnotion of effective sample size that reflects the value of labeled source data\nfor the target regression task. Our estimator achieves the minimax optimal\nerror rate up to a polylogarithmic factor, and we find that using pseudo-labels\nfor model selection does not significantly hinder performance.\n","authors":["Kaizheng Wang"],"pdf_url":"https://arxiv.org/pdf/2302.10160v3.pdf","comment":"45 pages, 2 figures"},{"id":"http://arxiv.org/abs/2404.07955v2","updated":"2024-11-08T17:04:45Z","published":"2024-03-21T14:41:12Z","title":"Triple Component Matrix Factorization: Untangling Global, Local, and\n  Noisy Components","summary":"  In this work, we study the problem of common and unique feature extraction\nfrom noisy data. When we have N observation matrices from N different and\nassociated sources corrupted by sparse and potentially gross noise, can we\nrecover the common and unique components from these noisy observations? This is\na challenging task as the number of parameters to estimate is approximately\nthrice the number of observations. Despite the difficulty, we propose an\nintuitive alternating minimization algorithm called triple component matrix\nfactorization (TCMF) to recover the three components exactly. TCMF is\ndistinguished from existing works in literature thanks to two salient features.\nFirst, TCMF is a principled method to separate the three components given noisy\nobservations provably. Second, the bulk of the computation in TCMF can be\ndistributed. On the technical side, we formulate the problem as a constrained\nnonconvex nonsmooth optimization problem. Despite the intricate nature of the\nproblem, we provide a Taylor series characterization of its solution by solving\nthe corresponding Karush-Kuhn-Tucker conditions. Using this characterization,\nwe can show that the alternating minimization algorithm makes significant\nprogress at each iteration and converges into the ground truth at a linear\nrate. Numerical experiments in video segmentation and anomaly detection\nhighlight the superior feature extraction abilities of TCMF.\n","authors":["Naichen Shi","Salar Fattahi","Raed Al Kontar"],"pdf_url":"https://arxiv.org/pdf/2404.07955v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17632v3","updated":"2024-11-08T17:01:49Z","published":"2024-03-26T12:08:05Z","title":"Data-driven Energy Consumption Modelling for Electric Micromobility\n  using an Open Dataset","summary":"  The escalating challenges of traffic congestion and environmental degradation\nunderscore the critical importance of embracing E-Mobility solutions in urban\nspaces. In particular, micro E-Mobility tools such as E-scooters and E-bikes,\nplay a pivotal role in this transition, offering sustainable alternatives for\nurban commuters. However, the energy consumption patterns for these tools are a\ncritical aspect that impacts their effectiveness in real-world scenarios and is\nessential for trip planning and boosting user confidence in using these. To\nthis effect, recent studies have utilised physical models customised for\nspecific mobility tools and conditions, but these models struggle with\ngeneralization and effectiveness in real-world scenarios due to a notable\nabsence of open datasets for thorough model evaluation and verification. To\nfill this gap, our work presents an open dataset, collected in Dublin, Ireland,\nspecifically designed for energy modelling research related to E-Scooters and\nE-Bikes. Furthermore, we provide a comprehensive analysis of energy consumption\nmodelling based on the dataset using a set of representative machine learning\nalgorithms and compare their performance against the contemporary mathematical\nmodels as a baseline. Our results demonstrate a notable advantage for\ndata-driven models in comparison to the corresponding mathematical models for\nestimating energy consumption. Specifically, data-driven models outperform\nphysical models in accuracy by up to 83.83% for E-Bikes and 82.16% for\nE-Scooters based on an in-depth analysis of the dataset under certain\nassumptions.\n","authors":["Yue Ding","Sen Yan","Maqsood Hussain Shah","Hongyuan Fang","Ji Li","Mingming Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17632v3.pdf","comment":"7 pages, 5 figures, 4 tables. This manuscript has been accepted by\n  the IEEE ITEC 2024"},{"id":"http://arxiv.org/abs/2411.05698v1","updated":"2024-11-08T16:52:52Z","published":"2024-11-08T16:52:52Z","title":"Visual-TCAV: Concept-based Attribution and Saliency Maps for Post-hoc\n  Explainability in Image Classification","summary":"  Convolutional Neural Networks (CNNs) have seen significant performance\nimprovements in recent years. However, due to their size and complexity, they\nfunction as black-boxes, leading to transparency concerns. State-of-the-art\nsaliency methods generate local explanations that highlight the area in the\ninput image where a class is identified but cannot explain how a concept of\ninterest contributes to the prediction, which is essential for bias mitigation.\nOn the other hand, concept-based methods, such as TCAV (Testing with Concept\nActivation Vectors), provide insights into how sensitive is the network to a\nconcept, but cannot compute its attribution in a specific prediction nor show\nits location within the input image. This paper introduces a novel post-hoc\nexplainability framework, Visual-TCAV, which aims to bridge the gap between\nthese methods by providing both local and global explanations for CNN-based\nimage classification. Visual-TCAV uses Concept Activation Vectors (CAVs) to\ngenerate saliency maps that show where concepts are recognized by the network.\nMoreover, it can estimate the attribution of these concepts to the output of\nany class using a generalization of Integrated Gradients. This framework is\nevaluated on popular CNN architectures, with its validity further confirmed via\nexperiments where ground truth for explanations is known, and a comparison with\nTCAV. Our code will be made available soon.\n","authors":["Antonio De Santis","Riccardo Campi","Matteo Bianchi","Marco Brambilla"],"pdf_url":"https://arxiv.org/pdf/2411.05698v1.pdf","comment":"Preprint currently under review"},{"id":"http://arxiv.org/abs/2411.05697v1","updated":"2024-11-08T16:52:23Z","published":"2024-11-08T16:52:23Z","title":"IPMN Risk Assessment under Federated Learning Paradigm","summary":"  Accurate classification of Intraductal Papillary Mucinous Neoplasms (IPMN) is\nessential for identifying high-risk cases that require timely intervention. In\nthis study, we develop a federated learning framework for multi-center IPMN\nclassification utilizing a comprehensive pancreas MRI dataset. This dataset\nincludes 653 T1-weighted and 656 T2-weighted MRI images, accompanied by\ncorresponding IPMN risk scores from 7 leading medical institutions, making it\nthe largest and most diverse dataset for IPMN classification to date. We assess\nthe performance of DenseNet-121 in both centralized and federated settings for\ntraining on distributed data. Our results demonstrate that the federated\nlearning approach achieves high classification accuracy comparable to\ncentralized learning while ensuring data privacy across institutions. This work\nmarks a significant advancement in collaborative IPMN classification,\nfacilitating secure and high-accuracy model training across multiple centers.\n","authors":["Hongyi Pan","Ziliang Hong","Gorkem Durak","Elif Keles","Halil Ertugrul Aktas","Yavuz Taktak","Alpay Medetalibeyoglu","Zheyuan Zhang","Yury Velichko","Concetto Spampinato","Ivo Schoots","Marco J. Bruno","Pallavi Tiwari","Candice Bolan","Tamas Gonda","Frank Miller","Rajesh N. Keswani","Michael B. Wallace","Ziyue Xu","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2411.05697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21349v2","updated":"2024-11-08T16:50:05Z","published":"2024-10-28T12:18:22Z","title":"FALCON: Feedback-driven Adaptive Long/short-term memory reinforced\n  Coding Optimization system","summary":"  Recently, large language models (LLMs) have achieved significant progress in\nautomated code generation. Despite their strong instruction-following\ncapabilities, these models frequently struggled to align with user intent in\ncoding scenarios. In particular, they were hampered by datasets that lacked\ndiversity and failed to address specialized tasks or edge cases. Furthermore,\nchallenges in supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) led to failures in generating precise,\nhuman-intent-aligned code. To tackle these challenges and improve the code\ngeneration performance for automated programming systems, we propose\nFeedback-driven Adaptive Long/short-term memory reinforced Coding Optimization\n(i.e., FALCON). FALCON is structured into two hierarchical levels. From the\nglobal level, long-term memory improves code quality by retaining and applying\nlearned knowledge. At the local level, short-term memory allows for the\nincorporation of immediate feedback from compilers and AI systems.\nAdditionally, we introduce meta-reinforcement learning with feedback rewards to\nsolve the global-local bi-level optimization problem and enhance the model's\nadaptability across diverse code generation tasks. Extensive experiments\ndemonstrate that our technique achieves state-of-the-art performance, leading\nother reinforcement learning methods by more than 4.5 percentage points on the\nMBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The\nopen-sourced code is publicly available at https://github.com/titurte/FALCON.\n","authors":["Zeyuan Li","Yangfan He","Lewei He","Jianhui Wang","Tianyu Shi","Bin Lei","Yuchen Li","Qiuwu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.21349v2.pdf","comment":"20 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.05693v1","updated":"2024-11-08T16:47:51Z","published":"2024-11-08T16:47:51Z","title":"YOSO: You-Only-Sample-Once via Compressed Sensing for Graph Neural\n  Network Training","summary":"  Graph neural networks (GNNs) have become essential tools for analyzing\nnon-Euclidean data across various domains. During training stage, sampling\nplays an important role in reducing latency by limiting the number of nodes\nprocessed, particularly in large-scale applications. However, as the demand for\nbetter prediction performance grows, existing sampling algorithms become\nincreasingly complex, leading to significant overhead. To mitigate this, we\npropose YOSO (You-Only-Sample-Once), an algorithm designed to achieve efficient\ntraining while preserving prediction accuracy. YOSO introduces a compressed\nsensing (CS)-based sampling and reconstruction framework, where nodes are\nsampled once at input layer, followed by a lossless reconstruction at the\noutput layer per epoch. By integrating the reconstruction process with the loss\nfunction of specific learning tasks, YOSO not only avoids costly computations\nin traditional compressed sensing (CS) methods, such as orthonormal basis\ncalculations, but also ensures high-probability accuracy retention which\nequivalent to full node participation. Experimental results on node\nclassification and link prediction demonstrate the effectiveness and efficiency\nof YOSO, reducing GNN training by an average of 75\\% compared to\nstate-of-the-art methods, while maintaining accuracy on par with top-performing\nbaselines.\n","authors":["Yi Li","Zhichun Guo","Guanpeng Li","Bingzhe Li"],"pdf_url":"https://arxiv.org/pdf/2411.05693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02343v2","updated":"2024-11-08T16:44:59Z","published":"2024-11-04T18:12:59Z","title":"Boulder2Vec: Modeling Climber Performances in Professional Bouldering\n  Competitions","summary":"  Using data from professional bouldering competitions from 2008 to 2022, we\ntrain a logistic regression to predict climber results and measure climber\nskill. However, this approach is limited, as a single numeric coefficient per\nclimber cannot adequately capture the intricacies of climbers' varying\nstrengths and weaknesses in different boulder problems. For example, some\nclimbers might prefer more static, technical routes while other climbers may\nspecialize in powerful, dynamic problems.\n  To this end, we apply Probabilistic Matrix Factorization (PMF), a framework\ncommonly used in recommender systems, to represent the unique characteristics\nof climbers and problems with latent, multi-dimensional vectors. In this\nframework, a climber's performance on a given problem is predicted by taking\nthe dot product of the corresponding climber vector and problem vectors. PMF\neffectively handles sparse datasets, such as our dataset where only a subset of\nclimbers attempt each particular problem, by extrapolating patterns from\nsimilar climbers.\n  We contrast the empirical performance of PMF to the logistic regression\napproach and investigate the multivariate representations produced by PMF to\ngain insights into climber characteristics. Our results show that the\nmultivariate PMF representations improve predictive performance of professional\nbouldering competitions by capturing both the overall strength of climbers and\ntheir specialized skill sets. We provide our code open-source at\nhttps://github.com/baronet2/boulder2vec.\n","authors":["Ethan Baron","Victor Hau","Zeke Weng"],"pdf_url":"https://arxiv.org/pdf/2411.02343v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.05646v2","updated":"2024-11-08T16:29:33Z","published":"2024-08-10T22:47:12Z","title":"Eigen Attention: Attention in Low-Rank Space for KV Cache Compression","summary":"  Large language models (LLMs) represent a groundbreaking advancement in the\ndomain of natural language processing due to their impressive reasoning\nabilities. Recently, there has been considerable interest in increasing the\ncontext lengths for these models to enhance their applicability to complex\ntasks. However, at long context lengths and large batch sizes, the key-value\n(KV) cache, which stores the attention keys and values, emerges as the new\nbottleneck in memory usage during inference. To address this, we propose Eigen\nAttention, which performs the attention operation in a low-rank space, thereby\nreducing the KV cache memory overhead. Our proposed approach is orthogonal to\nexisting KV cache compression techniques and can be used synergistically with\nthem. Through extensive experiments over OPT, MPT, and Llama model families, we\ndemonstrate that Eigen Attention results in up to 40% reduction in KV cache\nsizes and up to 60% reduction in attention operation latency with minimal drop\nin performance. Code is available at\nhttps://github.com/UtkarshSaxena1/EigenAttn.\n","authors":["Utkarsh Saxena","Gobinda Saha","Sakshi Choudhary","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2408.05646v2.pdf","comment":"12 page, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2411.05679v1","updated":"2024-11-08T16:29:07Z","published":"2024-11-08T16:29:07Z","title":"Tell What You Hear From What You See -- Video to Audio Generation\n  Through Text","summary":"  The content of visual and audio scenes is multi-faceted such that a video can\nbe paired with various audio and vice-versa. Thereby, in video-to-audio\ngeneration task, it is imperative to introduce steering approaches for\ncontrolling the generated audio. While Video-to-Audio generation is a\nwell-established generative task, existing methods lack such controllability.\nIn this work, we propose VATT, a multi-modal generative framework that takes a\nvideo and an optional text prompt as input, and generates audio and optional\ntextual description of the audio. Such a framework has two advantages: i)\nVideo-to-Audio generation process can be refined and controlled via text which\ncomplements the context of visual information, and ii) The model can suggest\nwhat audio to generate for the video by generating audio captions. VATT\nconsists of two key modules: VATT Converter, a LLM that is fine-tuned for\ninstructions and includes a projection layer that maps video features to the\nLLM vector space; and VATT Audio, a transformer that generates audio tokens\nfrom visual frames and from optional text prompt using iterative parallel\ndecoding. The audio tokens are converted to a waveform by pretrained neural\ncodec. Experiments show that when VATT is compared to existing video-to-audio\ngeneration methods in objective metrics, it achieves competitive performance\nwhen the audio caption is not provided. When the audio caption is provided as a\nprompt, VATT achieves even more refined performance (lowest KLD score of 1.41).\nFurthermore, subjective studies show that VATT Audio has been chosen as\npreferred generated audio than audio generated by existing methods. VATT\nenables controllable video-to-audio generation through text as well as\nsuggesting text prompts for videos through audio captions, unlocking novel\napplications such as text-guided video-to-audio generation and video-to-audio\ncaptioning.\n","authors":["Xiulong Liu","Kun Su","Eli Shlizerman"],"pdf_url":"https://arxiv.org/pdf/2411.05679v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05676v1","updated":"2024-11-08T16:27:27Z","published":"2024-11-08T16:27:27Z","title":"Improving Molecular Graph Generation with Flow Matching and Optimal\n  Transport","summary":"  Generating molecular graphs is crucial in drug design and discovery but\nremains challenging due to the complex interdependencies between nodes and\nedges. While diffusion models have demonstrated their potentiality in molecular\ngraph design, they often suffer from unstable training and inefficient\nsampling. To enhance generation performance and training stability, we propose\nGGFlow, a discrete flow matching generative model incorporating optimal\ntransport for molecular graphs and it incorporates an edge-augmented graph\ntransformer to enable the direct communications among chemical bounds.\nAdditionally, GGFlow introduces a novel goal-guided generation framework to\ncontrol the generative trajectory of our model, aiming to design novel\nmolecular structures with the desired properties. GGFlow demonstrates superior\nperformance on both unconditional and conditional molecule generation tasks,\noutperforming existing baselines and underscoring its effectiveness and\npotential for wider application.\n","authors":["Xiaoyang Hou","Tian Zhu","Milong Ren","Dongbo Bu","Xin Gao","Chunming Zhang","Shiwei Sun"],"pdf_url":"https://arxiv.org/pdf/2411.05676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23893v3","updated":"2024-11-08T16:21:02Z","published":"2024-10-31T12:53:53Z","title":"DiffBatt: A Diffusion Model for Battery Degradation Prediction and\n  Synthesis","summary":"  Battery degradation remains a critical challenge in the pursuit of green\ntechnologies and sustainable energy solutions. Despite significant research\nefforts, predicting battery capacity loss accurately remains a formidable task\ndue to its complex nature, influenced by both aging and cycling behaviors. To\naddress this challenge, we introduce a novel general-purpose model for battery\ndegradation prediction and synthesis, DiffBatt. Leveraging an innovative\ncombination of conditional and unconditional diffusion models with\nclassifier-free guidance and transformer architecture, DiffBatt achieves high\nexpressivity and scalability. DiffBatt operates as a probabilistic model to\ncapture uncertainty in aging behaviors and a generative model to simulate\nbattery degradation. The performance of the model excels in prediction tasks\nwhile also enabling the generation of synthetic degradation curves,\nfacilitating enhanced model training by data augmentation. In the remaining\nuseful life prediction task, DiffBatt provides accurate results with a mean\nRMSE of 196 cycles across all datasets, outperforming all other models and\ndemonstrating superior generalizability. This work represents an important step\ntowards developing foundational models for battery degradation.\n","authors":["Hamidreza Eivazi","Andr√© Hebenbrock","Raphael Ginster","Steffen Bl√∂meke","Stefan Wittek","Christoph Herrmann","Thomas S. Spengler","Thomas Turek","Andreas Rausch"],"pdf_url":"https://arxiv.org/pdf/2410.23893v3.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2310.20598v3","updated":"2024-11-08T16:17:50Z","published":"2023-10-31T16:34:49Z","title":"Online Conversion with Switching Costs: Robust and Learning-Augmented\n  Algorithms","summary":"  We introduce and study online conversion with switching costs, a family of\nonline problems that capture emerging problems at the intersection of energy\nand sustainability. In this problem, an online player attempts to purchase\n(alternatively, sell) fractional shares of an asset during a fixed time horizon\nwith length $T$. At each time step, a cost function (alternatively, price\nfunction) is revealed, and the player must irrevocably decide an amount of\nasset to convert. The player also incurs a switching cost whenever their\ndecision changes in consecutive time steps, i.e., when they increase or\ndecrease their purchasing amount. We introduce competitive (robust)\nthreshold-based algorithms for both the minimization and maximization variants\nof this problem, and show they are optimal among deterministic online\nalgorithms. We then propose learning-augmented algorithms that take advantage\nof untrusted black-box advice (such as predictions from a machine learning\nmodel) to achieve significantly better average-case performance without\nsacrificing worst-case competitive guarantees. Finally, we empirically evaluate\nour proposed algorithms using a carbon-aware EV charging case study, showing\nthat our algorithms substantially improve on baseline methods for this problem.\n","authors":["Adam Lechowicz","Nicolas Christianson","Bo Sun","Noman Bashir","Mohammad Hajiesmaili","Adam Wierman","Prashant Shenoy"],"pdf_url":"https://arxiv.org/pdf/2310.20598v3.pdf","comment":"Appeared as a conference paper at SIGMETRICS / Performance '24. 47\n  pages, 9 figures"},{"id":"http://arxiv.org/abs/2402.17176v2","updated":"2024-11-08T16:09:02Z","published":"2024-02-27T03:24:54Z","title":"DeepDRK: Deep Dependency Regularized Knockoff for Feature Selection","summary":"  Model-X knockoff has garnered significant attention among various feature\nselection methods due to its guarantees for controlling the false discovery\nrate (FDR). Since its introduction in parametric design, knockoff techniques\nhave evolved to handle arbitrary data distributions using deep learning-based\ngenerative models. However, we have observed limitations in the current\nimplementations of the deep Model-X knockoff framework. Notably, the \"swap\nproperty\" that knockoffs require often faces challenges at the sample level,\nresulting in diminished selection power. To address these issues, we develop\n\"Deep Dependency Regularized Knockoff (DeepDRK),\" a distribution-free deep\nlearning method that effectively balances FDR and power. In DeepDRK, we\nintroduce a novel formulation of the knockoff model as a learning problem under\nmulti-source adversarial attacks. By employing an innovative perturbation\ntechnique, we achieve lower FDR and higher power. Our model outperforms\nexisting benchmarks across synthetic, semi-synthetic, and real-world datasets,\nparticularly when sample sizes are small and data distributions are\nnon-Gaussian.\n","authors":["Hongyu Shen","Yici Yan","Zhizhen Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.17176v2.pdf","comment":"33 pages, 15 figures, 9 tables"},{"id":"http://arxiv.org/abs/2407.17032v3","updated":"2024-11-08T16:08:51Z","published":"2024-07-24T06:35:05Z","title":"Gymnasium: A Standard Interface for Reinforcement Learning Environments","summary":"  Reinforcement Learning (RL) is a continuously growing field that has the\npotential to revolutionize many areas of artificial intelligence. However,\ndespite its promise, RL research is often hindered by the lack of\nstandardization in environment and algorithm implementations. This makes it\ndifficult for researchers to compare and build upon each other's work, slowing\ndown progress in the field. Gymnasium is an open-source library that provides a\nstandard API for RL environments, aiming to tackle this issue. Gymnasium's main\nfeature is a set of abstractions that allow for wide interoperability between\nenvironments and training algorithms, making it easier for researchers to\ndevelop and test RL algorithms. In addition, Gymnasium provides a collection of\neasy-to-use environments, tools for easily customizing environments, and tools\nto ensure the reproducibility and robustness of RL research. Through this\nunified framework, Gymnasium significantly streamlines the process of\ndeveloping and testing RL algorithms, enabling researchers to focus more on\ninnovation and less on implementation details. By providing a standardized\nplatform for RL research, Gymnasium helps to drive forward the field of\nreinforcement learning and unlock its full potential. Gymnasium is available\nonline at https://github.com/Farama-Foundation/Gymnasium\n","authors":["Mark Towers","Ariel Kwiatkowski","Jordan Terry","John U. Balis","Gianluca De Cola","Tristan Deleu","Manuel Goul√£o","Andreas Kallinteris","Markus Krimmel","Arjun KG","Rodrigo Perez-Vicente","Andrea Pierr√©","Sander Schulhoff","Jun Jet Tai","Hannah Tan","Omar G. Younis"],"pdf_url":"https://arxiv.org/pdf/2407.17032v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05663v1","updated":"2024-11-08T16:04:16Z","published":"2024-11-08T16:04:16Z","title":"Online-LoRA: Task-free Online Continual Learning via Low Rank Adaptation","summary":"  Catastrophic forgetting is a significant challenge in online continual\nlearning (OCL), especially for non-stationary data streams that do not have\nwell-defined task boundaries. This challenge is exacerbated by the memory\nconstraints and privacy concerns inherent in rehearsal buffers. To tackle\ncatastrophic forgetting, in this paper, we introduce Online-LoRA, a novel\nframework for task-free OCL. Online-LoRA allows to finetune pre-trained Vision\nTransformer (ViT) models in real-time to address the limitations of rehearsal\nbuffers and leverage pre-trained models' performance benefits. As the main\ncontribution, our approach features a novel online weight regularization\nstrategy to identify and consolidate important model parameters. Moreover,\nOnline-LoRA leverages the training dynamics of loss values to enable the\nautomatic recognition of the data distribution shifts. Extensive experiments\nacross many task-free OCL scenarios and benchmark datasets (including\nCIFAR-100, ImageNet-R, ImageNet-S, CUB-200 and CORe50) demonstrate that\nOnline-LoRA can be robustly adapted to various ViT architectures, while\nachieving better performance compared to SOTA methods. Our code will be\npublicly available at:\nhttps://github.com/Christina200/Online-LoRA-official.git.\n","authors":["Xiwen Wei","Guihong Li","Radu Marculescu"],"pdf_url":"https://arxiv.org/pdf/2411.05663v1.pdf","comment":"WACV 2025"},{"id":"http://arxiv.org/abs/2411.05661v1","updated":"2024-11-08T16:02:39Z","published":"2024-11-08T16:02:39Z","title":"Multi-armed Bandits with Missing Outcome","summary":"  While significant progress has been made in designing algorithms that\nminimize regret in online decision-making, real-world scenarios often introduce\nadditional complexities, perhaps the most challenging of which is missing\noutcomes. Overlooking this aspect or simply assuming random missingness\ninvariably leads to biased estimates of the rewards and may result in linear\nregret. Despite the practical relevance of this challenge, no rigorous\nmethodology currently exists for systematically handling missingness,\nespecially when the missingness mechanism is not random. In this paper, we\naddress this gap in the context of multi-armed bandits (MAB) with missing\noutcomes by analyzing the impact of different missingness mechanisms on\nachievable regret bounds. We introduce algorithms that account for missingness\nunder both missing at random (MAR) and missing not at random (MNAR) models.\nThrough both analytical and simulation studies, we demonstrate the drastic\nimprovements in decision-making by accounting for missingness in these\nsettings.\n","authors":["Ilia Mahrooghi","Mahshad Moradi","Sina Akbari","Negar Kiyavash"],"pdf_url":"https://arxiv.org/pdf/2411.05661v1.pdf","comment":"38 pages, 5 figures, multi-armed bandits, missing data"},{"id":"http://arxiv.org/abs/2410.06884v2","updated":"2024-11-08T16:02:20Z","published":"2024-10-09T13:46:08Z","title":"Adaptive Refinement Protocols for Distributed Distribution Estimation\n  under $\\ell^p$-Losses","summary":"  Consider the communication-constrained estimation of discrete distributions\nunder $\\ell^p$ losses, where each distributed terminal holds multiple\nindependent samples and uses limited number of bits to describe the samples. We\nobtain the minimax optimal rates of the problem in most parameter regimes. An\nelbow effect of the optimal rates at $p=2$ is clearly identified. To show the\noptimal rates, we first design estimation protocols to achieve them. The key\ningredient of these protocols is to introduce adaptive refinement mechanisms,\nwhich first generate rough estimate by partial information and then establish\nrefined estimate in subsequent steps guided by the rough estimate. The\nprotocols leverage successive refinement, sample compression, thresholding and\nrandom hashing methods to achieve the optimal rates in different parameter\nregimes. The optimality of the protocols is shown by deriving compatible\nminimax lower bounds.\n","authors":["Deheng Yuan","Tao Guo","Zhongyi Huang"],"pdf_url":"https://arxiv.org/pdf/2410.06884v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01029v3","updated":"2024-11-08T15:59:46Z","published":"2024-02-01T21:38:10Z","title":"Response Theory via Generative Score Modeling","summary":"  We introduce an approach for analyzing the responses of dynamical systems to\nexternal perturbations that combines score-based generative modeling with the\nGeneralized Fluctuation-Dissipation Theorem (GFDT). The methodology enables\naccurate estimation of system responses, including those with non-Gaussian\nstatistics. We numerically validate our approach using time-series data from\nthree different stochastic partial differential equations of increasing\ncomplexity: an Ornstein-Uhlenbeck process with spatially correlated noise, a\nmodified stochastic Allen-Cahn equation, and the 2D Navier-Stokes equations. We\ndemonstrate the improved accuracy of the methodology over conventional methods\nand discuss its potential as a versatile tool for predicting the statistical\nbehavior of complex dynamical systems.\n","authors":["Ludovico Theo Giorgini","Katherine Deck","Tobias Bischoff","Andre Souza"],"pdf_url":"https://arxiv.org/pdf/2402.01029v3.pdf","comment":"In press. Includes supplementary material in the file\n  supp_material.pdf"},{"id":"http://arxiv.org/abs/2204.02291v2","updated":"2024-11-08T15:58:22Z","published":"2022-04-05T15:42:51Z","title":"Aggregating distribution forecasts from deep ensembles","summary":"  The importance of accurately quantifying forecast uncertainty has motivated\nmuch recent research on probabilistic forecasting. In particular, a variety of\ndeep learning approaches has been proposed, with forecast distributions\nobtained as output of neural networks. These neural network-based methods are\noften used in the form of an ensemble, e.g., based on multiple model runs from\ndifferent random initializations or more sophisticated ensembling strategies\nsuch as dropout, resulting in a collection of forecast distributions that need\nto be aggregated into a final probabilistic prediction. With the aim of\nconsolidating findings from the machine learning literature on ensemble methods\nand the statistical literature on forecast combination, we address the question\nof how to aggregate distribution forecasts based on such `deep ensembles'.\nUsing theoretical arguments and a comprehensive analysis on twelve benchmark\ndata sets, we systematically compare probability- and quantile-based\naggregation methods for three neural network-based approaches with different\nforecast distribution types as output. Our results show that combining forecast\ndistributions from deep ensembles can substantially improve the predictive\nperformance. We propose a general quantile aggregation framework for deep\nensembles that allows for corrections of systematic deficiencies and performs\nwell in a variety of settings, often superior compared to a linear combination\nof the forecast densities. Finally, we investigate the effects of the ensemble\nsize and derive recommendations of aggregating distribution forecasts from deep\nensembles in practice.\n","authors":["Benedikt Schulz","Lutz K√∂hler","Sebastian Lerch"],"pdf_url":"https://arxiv.org/pdf/2204.02291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.15865v2","updated":"2024-11-08T15:51:52Z","published":"2023-10-24T14:23:10Z","title":"Using Time-Aware Graph Neural Networks to Predict Temporal Centralities\n  in Dynamic Graphs","summary":"  Node centralities play a pivotal role in network science, social network\nanalysis, and recommender systems. In temporal data, static path-based\ncentralities like closeness or betweenness can give misleading results about\nthe true importance of nodes in a temporal graph. To address this issue,\ntemporal generalizations of betweenness and closeness have been defined that\nare based on the shortest time-respecting paths between pairs of nodes.\nHowever, a major issue of those generalizations is that the calculation of such\npaths is computationally expensive. Addressing this issue, we study the\napplication of De Bruijn Graph Neural Networks (DBGNN), a time-aware graph\nneural network architecture, to predict temporal path-based centralities in\ntime series data. We experimentally evaluate our approach in 13 temporal graphs\nfrom biological and social systems and show that it considerably improves the\nprediction of betweenness and closeness centrality compared to (i) a static\nGraph Convolutional Neural Network, (ii) an efficient sampling-based\napproximation technique for temporal betweenness, and (iii) two\nstate-of-the-art time-aware graph learning techniques for dynamic graphs.\n","authors":["Franziska Heeg","Ingo Scholtes"],"pdf_url":"https://arxiv.org/pdf/2310.15865v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05648v1","updated":"2024-11-08T15:43:01Z","published":"2024-11-08T15:43:01Z","title":"Enhancing Model Fairness and Accuracy with Similarity Networks: A\n  Methodological Approach","summary":"  In this paper, we propose an innovative approach to thoroughly explore\ndataset features that introduce bias in downstream machine-learning tasks.\nDepending on the data format, we use different techniques to map instances into\na similarity feature space. Our method's ability to adjust the resolution of\npairwise similarity provides clear insights into the relationship between the\ndataset classification complexity and model fairness. Experimental results\nconfirm the promising applicability of the similarity network in promoting fair\nmodels. Moreover, leveraging our methodology not only seems promising in\nproviding a fair downstream task such as classification, it also performs well\nin imputation and augmentation of the dataset satisfying the fairness criteria\nsuch as demographic parity and imbalanced classes.\n","authors":["Samira Maghool","Paolo Ceravolo"],"pdf_url":"https://arxiv.org/pdf/2411.05648v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.05636v1","updated":"2024-11-08T15:30:10Z","published":"2024-11-08T15:30:10Z","title":"Video RWKV:Video Action Recognition Based RWKV","summary":"  To address the challenges of high computational costs and long-distance\ndependencies in exist ing video understanding methods, such as CNNs and\nTransformers, this work introduces RWKV to the video domain in a novel way. We\npropose a LSTM CrossRWKV (LCR) framework, designed for spatiotemporal\nrepresentation learning to tackle the video understanding task. Specifically,\nthe proposed linear complexity LCR incorporates a novel Cross RWKV gate to\nfacilitate interaction be tween current frame edge information and past\nfeatures, enhancing the focus on the subject through edge features and globally\naggregating inter-frame features over time. LCR stores long-term mem ory for\nvideo processing through an enhanced LSTM recurrent execution mechanism. By\nleveraging the Cross RWKV gate and recurrent execution, LCR effectively\ncaptures both spatial and temporal features. Additionally, the edge information\nserves as a forgetting gate for LSTM, guiding long-term memory management.Tube\nmasking strategy reduces redundant information in food and reduces\noverfitting.These advantages enable LSTM CrossRWKV to set a new benchmark in\nvideo under standing, offering a scalable and efficient solution for\ncomprehensive video analysis. All code and models are publicly available.\n","authors":["Zhuowen Yin","Chengru Li","Xingbo Dong"],"pdf_url":"https://arxiv.org/pdf/2411.05636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15178v2","updated":"2024-11-08T15:22:26Z","published":"2024-10-19T18:46:17Z","title":"Enhancing Robot Navigation Policies with Task-Specific Uncertainty\n  Management","summary":"  Robots performing navigation tasks in complex environments face significant\nchallenges due to uncertainty in state estimation. Effectively managing this\nuncertainty is crucial, but the optimal approach varies depending on the\nspecific details of the task: different tasks require varying levels of\nprecision in different regions of the environment. For instance, a robot\nnavigating a crowded space might need precise localization near obstacles but\ncan operate effectively with less precise state estimates in open areas. This\nvarying need for certainty in different parts of the environment, depending on\nthe task, calls for policies that can adapt their uncertainty management\nstrategies based on task-specific requirements. In this paper, we present a\nframework for integrating task-specific uncertainty requirements directly into\nnavigation policies. We introduce Task-Specific Uncertainty Map (TSUM), which\nrepresents acceptable levels of state estimation uncertainty across different\nregions of the operating environment for a given task. Using TSUM, we propose\nGeneralized Uncertainty Integration for Decision-Making and Execution (GUIDE),\na policy conditioning framework that incorporates these uncertainty\nrequirements into the robot's decision-making process. We find that\nconditioning policies on TSUMs provides an effective way to express\ntask-specific uncertainty requirements and enables the robot to reason about\nthe context-dependent value of certainty. We show how integrating GUIDE into\nreinforcement learning frameworks allows the agent to learn navigation policies\nwithout the need for explicit reward engineering to balance task completion and\nuncertainty management. We evaluate GUIDE on a variety of real-world navigation\ntasks and find that it demonstrates significant improvements in task completion\nrates compared to baselines. Evaluation videos can be found at\nhttps://guided-agents.github.io.\n","authors":["Gokul Puthumanaillam","Paulo Padrao","Jose Fuentes","Leonardo Bobadilla","Melkior Ornik"],"pdf_url":"https://arxiv.org/pdf/2410.15178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05631v1","updated":"2024-11-08T15:22:20Z","published":"2024-11-08T15:22:20Z","title":"Physics-constrained coupled neural differential equations for one\n  dimensional blood flow modeling","summary":"  Computational cardiovascular flow modeling plays a crucial role in\nunderstanding blood flow dynamics. While 3D models provide acute details, they\nare computationally expensive, especially with fluid-structure interaction\n(FSI) simulations. 1D models offer a computationally efficient alternative, by\nsimplifying the 3D Navier-Stokes equations through axisymmetric flow assumption\nand cross-sectional averaging. However, traditional 1D models based on finite\nelement methods (FEM) often lack accuracy compared to 3D averaged solutions.\nThis study introduces a novel physics-constrained machine learning technique\nthat enhances the accuracy of 1D blood flow models while maintaining\ncomputational efficiency. Our approach, utilizing a physics-constrained coupled\nneural differential equation (PCNDE) framework, demonstrates superior\nperformance compared to conventional FEM-based 1D models across a wide range of\ninlet boundary condition waveforms and stenosis blockage ratios. A key\ninnovation lies in the spatial formulation of the momentum conservation\nequation, departing from the traditional temporal approach and capitalizing on\nthe inherent temporal periodicity of blood flow. This spatial neural\ndifferential equation formulation switches space and time and overcomes issues\nrelated to coupling stability and smoothness, while simplifying boundary\ncondition implementation. The model accurately captures flow rate, area, and\npressure variations for unseen waveforms and geometries. We evaluate the\nmodel's robustness to input noise and explore the loss landscapes associated\nwith the inclusion of different physics terms. This advanced 1D modeling\ntechnique offers promising potential for rapid cardiovascular simulations,\nachieving computational efficiency and accuracy. By combining the strengths of\nphysics-based and data-driven modeling, this approach enables fast and accurate\ncardiovascular simulations.\n","authors":["Hunor Csala","Arvind Mohan","Daniel Livescu","Amirhossein Arzani"],"pdf_url":"https://arxiv.org/pdf/2411.05631v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05625v1","updated":"2024-11-08T15:15:34Z","published":"2024-11-08T15:15:34Z","title":"Cross-validating causal discovery via Leave-One-Variable-Out","summary":"  We propose a new approach to falsify causal discovery algorithms without\nground truth, which is based on testing the causal model on a pair of variables\nthat has been dropped when learning the causal model. To this end, we use the\n\"Leave-One-Variable-Out (LOVO)\" prediction where $Y$ is inferred from $X$\nwithout any joint observations of $X$ and $Y$, given only training data from\n$X,Z_1,\\dots,Z_k$ and from $Z_1,\\dots,Z_k,Y$. We demonstrate that causal models\non the two subsets, in the form of Acyclic Directed Mixed Graphs (ADMGs), often\nentail conclusions on the dependencies between $X$ and $Y$, enabling this type\nof prediction. The prediction error can then be estimated since the joint\ndistribution $P(X, Y)$ is assumed to be available, and $X$ and $Y$ have only\nbeen omitted for the purpose of falsification. After presenting this graphical\nmethod, which is applicable to general causal discovery algorithms, we\nillustrate how to construct a LOVO predictor tailored towards algorithms\nrelying on specific a priori assumptions, such as linear additive noise models.\nSimulations indicate that the LOVO prediction error is indeed correlated with\nthe accuracy of the causal outputs, affirming the method's effectiveness.\n","authors":["Daniela Schkoda","Philipp Faller","Patrick Bl√∂baum","Dominik Janzing"],"pdf_url":"https://arxiv.org/pdf/2411.05625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05619v1","updated":"2024-11-08T15:01:27Z","published":"2024-11-08T15:01:27Z","title":"WHALE: Towards Generalizable and Scalable World Models for Embodied\n  Decision-making","summary":"  World models play a crucial role in decision-making within embodied\nenvironments, enabling cost-free explorations that would otherwise be expensive\nin the real world. To facilitate effective decision-making, world models must\nbe equipped with strong generalizability to support faithful imagination in\nout-of-distribution (OOD) regions and provide reliable uncertainty estimation\nto assess the credibility of the simulated experiences, both of which present\nsignificant challenges for prior scalable approaches. This paper introduces\nWHALE, a framework for learning generalizable world models, consisting of two\nkey techniques: behavior-conditioning and retracing-rollout.\nBehavior-conditioning addresses the policy distribution shift, one of the\nprimary sources of the world model generalization error, while\nretracing-rollout enables efficient uncertainty estimation without the\nnecessity of model ensembles. These techniques are universal and can be\ncombined with any neural network architecture for world model learning.\nIncorporating these two techniques, we present Whale-ST, a scalable\nspatial-temporal transformer-based world model with enhanced generalizability.\nWe demonstrate the superiority of Whale-ST in simulation tasks by evaluating\nboth value estimation accuracy and video generation fidelity. Additionally, we\nexamine the effectiveness of our uncertainty estimation technique, which\nenhances model-based policy optimization in fully offline scenarios.\nFurthermore, we propose Whale-X, a 414M parameter world model trained on 970K\ntrajectories from Open X-Embodiment datasets. We show that Whale-X exhibits\npromising scalability and strong generalizability in real-world manipulation\nscenarios using minimal demonstrations.\n","authors":["Zhilong Zhang","Ruifeng Chen","Junyin Ye","Yihao Sun","Pengyuan Wang","Jingcheng Pang","Kaiyuan Li","Tianshuo Liu","Haoxin Lin","Yang Yu","Zhi-Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.05619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05618v1","updated":"2024-11-08T14:57:59Z","published":"2024-11-08T14:57:59Z","title":"Knowledge Distillation Neural Network for Predicting Car-following\n  Behaviour of Human-driven and Autonomous Vehicles","summary":"  As we move towards a mixed-traffic scenario of Autonomous vehicles (AVs) and\nHuman-driven vehicles (HDVs), understanding the car-following behaviour is\nimportant to improve traffic efficiency and road safety. Using a real-world\ntrajectory dataset, this study uses descriptive and statistical analysis to\ninvestigate the car-following behaviours of three vehicle pairs: HDV-AV, AV-HDV\nand HDV-HDV in mixed traffic. The ANOVA test showed that car-following\nbehaviours across different vehicle pairs are statistically significant\n(p-value < 0.05).\n  We also introduce a data-driven Knowledge Distillation Neural Network (KDNN)\nmodel for predicting car-following behaviour in terms of speed. The KDNN model\ndemonstrates comparable predictive accuracy to its teacher network, a Long\nShort-Term Memory (LSTM) network, and outperforms both the standalone student\nnetwork, a Multilayer Perceptron (MLP), and traditional physics-based models\nlike the Gipps model. Notably, the KDNN model better prevents collisions,\nmeasured by minimum Time-to-Collision (TTC), and operates with lower\ncomputational power, making it ideal for AVs or driving simulators requiring\nefficient computing.\n","authors":["Ayobami Adewale","Chris Lee","Amnir Hadachi","Nicolly Lima da Silva"],"pdf_url":"https://arxiv.org/pdf/2411.05618v1.pdf","comment":"27th IEEE International Conference on Intelligent Transportation\n  Systems"},{"id":"http://arxiv.org/abs/2411.05614v1","updated":"2024-11-08T14:55:32Z","published":"2024-11-08T14:55:32Z","title":"Acceleration for Deep Reinforcement Learning using Parallel and\n  Distributed Computing: A Survey","summary":"  Deep reinforcement learning has led to dramatic breakthroughs in the field of\nartificial intelligence for the past few years. As the amount of rollout\nexperience data and the size of neural networks for deep reinforcement learning\nhave grown continuously, handling the training process and reducing the time\nconsumption using parallel and distributed computing is becoming an urgent and\nessential desire. In this paper, we perform a broad and thorough investigation\non training acceleration methodologies for deep reinforcement learning based on\nparallel and distributed computing, providing a comprehensive survey in this\nfield with state-of-the-art methods and pointers to core references. In\nparticular, a taxonomy of literature is provided, along with a discussion of\nemerging topics and open issues. This incorporates learning system\narchitectures, simulation parallelism, computing parallelism, distributed\nsynchronization mechanisms, and deep evolutionary reinforcement learning.\nFurther, we compare 16 current open-source libraries and platforms with\ncriteria of facilitating rapid development. Finally, we extrapolate future\ndirections that deserve further research.\n","authors":["Zhihong Liu","Xin Xu","Peng Qiao","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2411.05614v1.pdf","comment":"This paper has been accepted by ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2407.10921v2","updated":"2024-11-08T14:55:06Z","published":"2024-07-15T17:22:16Z","title":"Leveraging Bi-Focal Perspectives and Granular Feature Integration for\n  Accurate Reliable Early Alzheimer's Detection","summary":"  Alzheimer's disease (AD) is the most common form of neurodegeneration, which\nimpacts millions of people each year. Diagnosing and classifying AD accurately\nwith neuroimaging data is an ongoing challenge in the field of medicine.\nTraditional Convolutional Neural Networks (CNNs) are good at capturing\nlow-level information from images, but their capability to extract high-level\nminuscule particles is suboptimal, which is a significant challenge in\ndetecting AD from MRI scans. To overcome this, we propose a novel Granular\nFeature Integration method to combine information extraction at different\nscales combined with an efficient information flow. We also propose a Bi-Focal\nPerspective mechanism to highlight focus on subtle neurofibrillary tangles and\namyloid plaques in MRI scans. Our model yielded an F1-Score of 99.31%, a\nprecision of 99.24%, and a recall of 99.51%, which shows a major improvement in\ncomparison to existing state-of-the-art (SOTA) CNNs.\n","authors":["Pandiyaraju V","Shravan Venkatraman","Abeshek A","Aravintakshan S A","Pavan Kumar S","Kannan A"],"pdf_url":"https://arxiv.org/pdf/2407.10921v2.pdf","comment":"17 pages, 10 figures, 6 tables"},{"id":"http://arxiv.org/abs/2411.05609v1","updated":"2024-11-08T14:52:42Z","published":"2024-11-08T14:52:42Z","title":"A Two-Step Concept-Based Approach for Enhanced Interpretability and\n  Trust in Skin Lesion Diagnosis","summary":"  The main challenges hindering the adoption of deep learning-based systems in\nclinical settings are the scarcity of annotated data and the lack of\ninterpretability and trust in these systems. Concept Bottleneck Models (CBMs)\noffer inherent interpretability by constraining the final disease prediction on\na set of human-understandable concepts. However, this inherent interpretability\ncomes at the cost of greater annotation burden. Additionally, adding new\nconcepts requires retraining the entire system. In this work, we introduce a\nnovel two-step methodology that addresses both of these challenges. By\nsimulating the two stages of a CBM, we utilize a pretrained Vision Language\nModel (VLM) to automatically predict clinical concepts, and a Large Language\nModel (LLM) to generate disease diagnoses based on the predicted concepts. We\nvalidate our approach on three skin lesion datasets, demonstrating that it\noutperforms traditional CBMs and state-of-the-art explainable methods, all\nwithout requiring any training and utilizing only a few annotated examples. The\ncode is available at\nhttps://github.com/CristianoPatricio/2-step-concept-based-skin-diagnosis.\n","authors":["Cristiano Patr√≠cio","Lu√≠s F. Teixeira","Jo√£o C. Neves"],"pdf_url":"https://arxiv.org/pdf/2411.05609v1.pdf","comment":"Preprint submitted for review"},{"id":"http://arxiv.org/abs/2410.23889v2","updated":"2024-11-08T14:45:55Z","published":"2024-10-31T12:51:40Z","title":"GEPS: Boosting Generalization in Parametric PDE Neural Solvers through\n  Adaptive Conditioning","summary":"  Solving parametric partial differential equations (PDEs) presents significant\nchallenges for data-driven methods due to the sensitivity of spatio-temporal\ndynamics to variations in PDE parameters. Machine learning approaches often\nstruggle to capture this variability. To address this, data-driven approaches\nlearn parametric PDEs by sampling a very large variety of trajectories with\nvarying PDE parameters. We first show that incorporating conditioning\nmechanisms for learning parametric PDEs is essential and that among them,\n$\\textit{adaptive conditioning}$, allows stronger generalization. As existing\nadaptive conditioning methods do not scale well with respect to the number of\nparameters to adapt in the neural solver, we propose GEPS, a simple adaptation\nmechanism to boost GEneralization in Pde Solvers via a first-order optimization\nand low-rank rapid adaptation of a small set of context parameters. We\ndemonstrate the versatility of our approach for both fully data-driven and for\nphysics-aware neural solvers. Validation performed on a whole range of\nspatio-temporal forecasting problems demonstrates excellent performance for\ngeneralizing to unseen conditions including initial conditions, PDE\ncoefficients, forcing terms and solution domain. $\\textit{Project page}$:\nhttps://geps-project.github.io\n","authors":["Armand Kassa√Ø Koupa√Ø","Jorge Mifsut Benet","Yuan Yin","Jean-No√´l Vittaut","Patrick Gallinari"],"pdf_url":"https://arxiv.org/pdf/2410.23889v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15376v2","updated":"2024-11-08T14:42:07Z","published":"2024-05-24T09:23:43Z","title":"Fast training and sampling of Restricted Boltzmann Machines","summary":"  Restricted Boltzmann Machines (RBMs) are effective tools for modeling complex\nsystems and deriving insights from data. However, training these models with\nhighly structured data presents significant challenges due to the slow mixing\ncharacteristics of Markov Chain Monte Carlo processes. In this study, we build\nupon recent theoretical advancements in RBM training, to significantly reduce\nthe computational cost of training (in very clustered datasets), evaluating and\nsampling in RBMs in general. The learning process is analogous to thermodynamic\ncontinuous phase transitions observed in ferromagnetic models, where new modes\nin the probability measure emerge in a continuous manner. Such continuous\ntransitions are associated with the critical slowdown effect, which adversely\naffects the accuracy of gradient estimates, particularly during the initial\nstages of training with clustered data. To mitigate this issue, we propose a\npre-training phase that encodes the principal components into a low-rank RBM\nthrough a convex optimization process. This approach enables efficient static\nMonte Carlo sampling and accurate computation of the partition function. We\nexploit the continuous and smooth nature of the parameter annealing trajectory\nto achieve reliable and computationally efficient log-likelihood estimations,\nenabling online assessment during the training, and propose a novel sampling\nstrategy named parallel trajectory tempering (PTT) which outperforms previously\noptimized MCMC methods. Our results show that this training strategy enables\nRBMs to effectively address highly structured datasets that conventional\nmethods struggle with. We also provide evidence that our log-likelihood\nestimation is more accurate than traditional, more computationally intensive\napproaches in controlled scenarios. The PTT algorithm significantly accelerates\nMCMC processes compared to existing and conventional methods.\n","authors":["Nicolas B√©reux","Aur√©lien Decelle","Cyril Furtlehner","Lorenzo Rosset","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2405.15376v2.pdf","comment":"31 pages, 16 figures"},{"id":"http://arxiv.org/abs/2411.05597v1","updated":"2024-11-08T14:40:56Z","published":"2024-11-08T14:40:56Z","title":"Predicting Stroke through Retinal Graphs and Multimodal Self-supervised\n  Learning","summary":"  Early identification of stroke is crucial for intervention, requiring\nreliable models. We proposed an efficient retinal image representation together\nwith clinical information to capture a comprehensive overview of cardiovascular\nhealth, leveraging large multimodal datasets for new medical insights. Our\napproach is one of the first contrastive frameworks that integrates graph and\ntabular data, using vessel graphs derived from retinal images for efficient\nrepresentation. This method, combined with multimodal contrastive learning,\nsignificantly enhances stroke prediction accuracy by integrating data from\nmultiple sources and using contrastive learning for transfer learning. The\nself-supervised learning techniques employed allow the model to learn\neffectively from unlabeled data, reducing the dependency on large annotated\ndatasets. Our framework showed an AUROC improvement of 3.78% from supervised to\nself-supervised approaches. Additionally, the graph-level representation\napproach achieved superior performance to image encoders while significantly\nreducing pre-training and fine-tuning runtimes. These findings indicate that\nretinal images are a cost-effective method for improving cardiovascular disease\npredictions and pave the way for future research into retinal and cerebral\nvessel connections and the use of graph-based retinal vessel representations.\n","authors":["Yuqing Huang","Bastian Wittmann","Olga Demler","Bjoern Menze","Neda Davoudi"],"pdf_url":"https://arxiv.org/pdf/2411.05597v1.pdf","comment":"Accepted as oral paper at ML-CDS workshop, MICCAI 2024"},{"id":"http://arxiv.org/abs/2411.05596v1","updated":"2024-11-08T14:31:50Z","published":"2024-11-08T14:31:50Z","title":"Machine learning-driven Anomaly Detection and Forecasting for Euclid\n  Space Telescope Operations","summary":"  State-of-the-art space science missions increasingly rely on automation due\nto spacecraft complexity and the costs of human oversight. The high volume of\ndata, including scientific and telemetry data, makes manual inspection\nchallenging. Machine learning offers significant potential to meet these\ndemands.\n  The Euclid space telescope, in its survey phase since February 2024,\nexemplifies this shift. Euclid's success depends on accurate monitoring and\ninterpretation of housekeeping telemetry and science-derived data. Thousands of\ntelemetry parameters, monitored as time series, may or may not impact the\nquality of scientific data. These parameters have complex interdependencies,\noften due to physical relationships (e.g., proximity of temperature sensors).\nOptimising science operations requires careful anomaly detection and\nidentification of hidden parameter states. Moreover, understanding the\ninteractions between known anomalies and physical quantities is crucial yet\ncomplex, as related parameters may display anomalies with varied timing and\nintensity.\n  We address these challenges by analysing temperature anomalies in Euclid's\ntelemetry from February to August 2024, focusing on eleven temperature\nparameters and 35 covariates. We use a predictive XGBoost model to forecast\ntemperatures based on historical values, detecting anomalies as deviations from\npredictions. A second XGBoost model predicts anomalies from covariates,\ncapturing their relationships to temperature anomalies. We identify the top\nthree anomalies per parameter and analyse their interactions with covariates\nusing SHAP (Shapley Additive Explanations), enabling rapid, automated analysis\nof complex parameter relationships.\n  Our method demonstrates how machine learning can enhance telemetry\nmonitoring, offering scalable solutions for other missions with similar data\nchallenges.\n","authors":["Pablo G√≥mez","Roland D. Vavrek","Guillermo Buenadicha","John Hoar","Sandor Kruk","Jan Reerink"],"pdf_url":"https://arxiv.org/pdf/2411.05596v1.pdf","comment":"Presented at IAC 2024"},{"id":"http://arxiv.org/abs/2306.00809v6","updated":"2024-11-08T14:27:36Z","published":"2023-06-01T15:37:32Z","title":"Initial Guessing Bias: How Untrained Networks Favor Some Classes","summary":"  Understanding and controlling biasing effects in neural networks is crucial\nfor ensuring accurate and fair model performance. In the context of\nclassification problems, we provide a theoretical analysis demonstrating that\nthe structure of a deep neural network (DNN) can condition the model to assign\nall predictions to the same class, even before the beginning of training, and\nin the absence of explicit biases. We prove that, besides dataset properties,\nthe presence of this phenomenon, which we call \\textit{Initial Guessing Bias}\n(IGB), is influenced by model choices including dataset preprocessing methods,\nand architectural decisions, such as activation functions, max-pooling layers,\nand network depth. Our analysis of IGB provides information for architecture\nselection and model initialization. We also highlight theoretical consequences,\nsuch as the breakdown of node-permutation symmetry, the violation of\nself-averaging and the non-trivial effects that depth has on the phenomenon.\n","authors":["Emanuele Francazi","Aurelien Lucchi","Marco Baity-Jesi"],"pdf_url":"https://arxiv.org/pdf/2306.00809v6.pdf","comment":"Fixed notation typos in Figure3 and Figure4"},{"id":"http://arxiv.org/abs/2411.05591v1","updated":"2024-11-08T14:25:46Z","published":"2024-11-08T14:25:46Z","title":"Network EM Algorithm for Gaussian Mixture Model in Decentralized\n  Federated Learning","summary":"  We systematically study various network Expectation-Maximization (EM)\nalgorithms for the Gaussian mixture model within the framework of decentralized\nfederated learning. Our theoretical investigation reveals that directly\nextending the classical decentralized supervised learning method to the EM\nalgorithm exhibits poor estimation accuracy with heterogeneous data across\nclients and struggles to converge numerically when Gaussian components are\npoorly-separated. To address these issues, we propose two novel solutions.\nFirst, to handle heterogeneous data, we introduce a momentum network EM (MNEM)\nalgorithm, which uses a momentum parameter to combine information from both the\ncurrent and historical estimators. Second, to tackle the challenge of\npoorly-separated Gaussian components, we develop a semi-supervised MNEM\n(semi-MNEM) algorithm, which leverages partially labeled data. Rigorous\ntheoretical analysis demonstrates that MNEM can achieve statistical efficiency\ncomparable to that of the whole sample estimator when the mixture components\nsatisfy certain separation conditions, even in heterogeneous scenarios.\nMoreover, the semi-MNEM estimator enhances the convergence speed of the MNEM\nalgorithm, effectively addressing the numerical convergence challenges in\npoorly-separated scenarios. Extensive simulation and real data analyses are\nconducted to justify our theoretical findings.\n","authors":["Shuyuan Wu","Bin Du","Xuetong Li","Hansheng Wang"],"pdf_url":"https://arxiv.org/pdf/2411.05591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11407v2","updated":"2024-11-08T14:21:51Z","published":"2023-10-17T17:14:07Z","title":"Group-blind optimal transport to group parity and its constrained\n  variants","summary":"  Fairness holds a pivotal role in the realm of machine learning, particularly\nwhen it comes to addressing groups categorised by protected attributes, e.g.,\ngender, race. Prevailing algorithms in fair learning predominantly hinge on\naccessibility or estimations of these protected attributes, at least in the\ntraining process. We design a single group-blind projection map that aligns the\nfeature distributions of both groups in the source data, achieving\n(demographic) group parity, without requiring values of the protected attribute\nfor individual samples in the computation of the map, as well as its use.\nInstead, our approach utilises the feature distributions of the privileged and\nunprivileged groups in a boarder population and the essential assumption that\nthe source data are unbiased representation of the population. We present\nnumerical results on synthetic data and real data.\n","authors":["Quan Zhou","Jakub Marecek"],"pdf_url":"https://arxiv.org/pdf/2310.11407v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15368v2","updated":"2024-11-08T14:06:33Z","published":"2024-04-19T18:16:37Z","title":"Unmasking the Role of Remote Sensors in Comfort, Energy and Demand\n  Response","summary":"  In single-zone multi-node systems (SZMRSs), temperature controls rely on a\nsingle probe near the thermostat, resulting in temperature discrepancies that\ncause thermal discomfort and energy waste. Augmenting smart thermostats (STs)\nwith per-room sensors has gained acceptance by major ST manufacturers. This\npaper leverages additional sensory information to empirically characterize the\nservices provided by buildings, including thermal comfort, energy efficiency,\nand demand response (DR). Utilizing room-level time-series data from 1,000\nhouses, metadata from 110,000 houses across the United States, and data from\ntwo real-world testbeds, we examine the limitations of SZMNSs and explore the\npotential of remote sensors. We discovered that comfortable DR durations\n(CDRDs) for rooms are typically 70% longer or 40% shorter than for the room\nwith the thermostat. When averaging, rooms at the control temperature's bounds\nare typically deviated around -3{\\deg}F to 2.5{\\deg}F from the average.\nMoreover, in 95% of houses, we identified rooms experiencing notably higher\nsolar gains compared to the rest of the rooms, while 85% and 70% of houses\ndemonstrated lower heat input and poor insulation, respectively. Lastly, it\nbecame evident that the consumption of cooling energy escalates with the\nincrease in the number of sensors, whereas heating usage experiences\nfluctuations ranging from -19% to +25%. This study serves as a benchmark for\nassessing the thermal comfort and DR services in the existing housing stock,\nwhile also highlighting the energy efficiency impacts of sensing technologies.\nOur approach sets the stage for more granular, precise control strategies of\nSZMNSs.\n","authors":["Ozan Baris Mulayim","Edson Severnini","Mario Berg√©s"],"pdf_url":"https://arxiv.org/pdf/2404.15368v2.pdf","comment":"13 Figures, 8 Tables, 25 Pages. Published in Data-Centric Engineering\n  Journal"},{"id":"http://arxiv.org/abs/2411.05575v1","updated":"2024-11-08T14:04:17Z","published":"2024-11-08T14:04:17Z","title":"Towards a Real-Time Simulation of Elastoplastic Deformation Using\n  Multi-Task Neural Networks","summary":"  This study introduces a surrogate modeling framework merging proper\northogonal decomposition, long short-term memory networks, and multi-task\nlearning, to accurately predict elastoplastic deformations in real-time.\nSuperior to single-task neural networks, this approach achieves a mean absolute\nerror below 0.40\\% across various state variables, with the multi-task model\nshowing enhanced generalization by mitigating overfitting through shared\nlayers. Moreover, in our use cases, a pre-trained multi-task model can\neffectively train additional variables with as few as 20 samples, demonstrating\nits deep understanding of complex scenarios. This is notably efficient compared\nto single-task models, which typically require around 100 samples.\n  Significantly faster than traditional finite element analysis, our model\naccelerates computations by approximately a million times, making it a\nsubstantial advancement for real-time predictive modeling in engineering\napplications. While it necessitates further testing on more intricate models,\nthis framework shows substantial promise in elevating both efficiency and\naccuracy in engineering applications, particularly for real-time scenarios.\n","authors":["Ruben Schmeitz","Joris Remmers","Olga Mula","Olaf van der Sluis"],"pdf_url":"https://arxiv.org/pdf/2411.05575v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02867v3","updated":"2024-11-08T13:55:18Z","published":"2023-12-05T16:27:51Z","title":"Semi-Supervised Health Index Monitoring with Feature Generation and\n  Fusion","summary":"  The Health Index (HI) is crucial for evaluating system health and is\nimportant for tasks like anomaly detection and Remaining Useful Life (RUL)\nprediction of safety-critical systems. Real-time, meticulous monitoring of\nsystem conditions is essential, especially in manufacturing high-quality and\nsafety-critical components such as spray coatings. However, acquiring accurate\nhealth status information (HI labels) in real scenarios can be difficult or\ncostly because it requires continuous, precise measurements that fully capture\nthe system's health. As a result, using datasets from systems run-to-failure,\nwhich provide limited HI labels only at the healthy and end-of-life phases,\nbecomes a practical approach. We employ Deep Semi-supervised Anomaly Detection\n(DeepSAD) embeddings to tackle the challenge of extracting features associated\nwith the system's health state. Additionally, we introduce a diversity loss to\nfurther enrich the DeepSAD embeddings. We also propose applying an alternating\nprojection algorithm with isotonic constraints to transform the embedding into\na normalized HI with an increasing trend. Validation on the PHME2010 milling\ndataset, a recognized benchmark with ground truth HIs, confirms the efficacy of\nour proposed HI estimations. Our methodology is further applied to monitor the\nwear states of thermal spray coatings using high-frequency voltage. These\ncontributions facilitate more accessible and reliable HI estimation,\nparticularly in scenarios where obtaining ground truth HI labels is impossible.\n","authors":["Ga√´tan Frusque","Ismail Nejjar","Majid Nabavi","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2312.02867v3.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.05564v1","updated":"2024-11-08T13:40:01Z","published":"2024-11-08T13:40:01Z","title":"Open-set object detection: towards unified problem formulation and\n  benchmarking","summary":"  In real-world applications where confidence is key, like autonomous driving,\nthe accurate detection and appropriate handling of classes differing from those\nused during training are crucial. Despite the proposal of various unknown\nobject detection approaches, we have observed widespread inconsistencies among\nthem regarding the datasets, metrics, and scenarios used, alongside a notable\nabsence of a clear definition for unknown objects, which hampers meaningful\nevaluation. To counter these issues, we introduce two benchmarks: a unified\nVOC-COCO evaluation, and the new OpenImagesRoad benchmark which provides clear\nhierarchical object definition besides new evaluation metrics. Complementing\nthe benchmark, we exploit recent self-supervised Vision Transformers\nperformance, to improve pseudo-labeling-based OpenSet Object Detection (OSOD),\nthrough OW-DETR++. State-of-the-art methods are extensively evaluated on the\nproposed benchmarks. This study provides a clear problem definition, ensures\nconsistent evaluations, and draws new conclusions about effectiveness of OSOD\nstrategies.\n","authors":["Hejer Ammar","Nikita Kiselov","Guillaume Lapouge","Romaric Audigier"],"pdf_url":"https://arxiv.org/pdf/2411.05564v1.pdf","comment":"Accepted at ECCV 2024 Workshop: \"The 3rd Workshop for\n  Out-of-Distribution Generalization in Computer Vision Foundation Models\""},{"id":"http://arxiv.org/abs/2410.15617v2","updated":"2024-11-08T13:38:04Z","published":"2024-10-21T03:36:34Z","title":"Long-time Integration of Nonlinear Wave Equations with Neural Operators","summary":"  Neural operators have shown promise in solving many types of Partial\nDifferential Equations (PDEs). They are significantly faster compared to\ntraditional numerical solvers once they have been trained with a certain amount\nof observed data. However, their numerical performance in solving\ntime-dependent PDEs, particularly in long-time prediction of dynamic systems,\nstill needs improvement. In this paper, we focus on solving the long-time\nintegration of nonlinear wave equations via neural operators by replacing the\ninitial condition with the prediction in a recurrent manner. Given limited\nobserved temporal trajectory data, we utilize some intrinsic features of these\nnonlinear wave equations, such as conservation laws and well-posedness, to\nimprove the algorithm design and reduce accumulated error. Our numerical\nexperiments examine these improvements in the Korteweg-de Vries (KdV) equation,\nthe sine-Gordon equation, and the Klein-Gordon wave equation on the irregular\ndomain.\n","authors":["Guanhang Lei","Zhen Lei","Lei Shi"],"pdf_url":"https://arxiv.org/pdf/2410.15617v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05561v1","updated":"2024-11-08T13:35:45Z","published":"2024-11-08T13:35:45Z","title":"Training objective drives the consistency of representational similarity\n  across datasets","summary":"  The Platonic Representation Hypothesis claims that recent foundation models\nare converging to a shared representation space as a function of their\ndownstream task performance, irrespective of the objectives and data modalities\nused to train these models. Representational similarity is generally measured\nfor individual datasets and is not necessarily consistent across datasets.\nThus, one may wonder whether this convergence of model representations is\nconfounded by the datasets commonly used in machine learning. Here, we propose\na systematic way to measure how representational similarity between models\nvaries with the set of stimuli used to construct the representations. We find\nthat the objective function is the most crucial factor in determining the\nconsistency of representational similarities across datasets. Specifically,\nself-supervised vision models learn representations whose relative pairwise\nsimilarities generalize better from one dataset to another compared to those of\nimage classification or image-text models. Moreover, the correspondence between\nrepresentational similarities and the models' task behavior is\ndataset-dependent, being most strongly pronounced for single-domain datasets.\nOur work provides a framework for systematically measuring similarities of\nmodel representations across datasets and linking those similarities to\ndifferences in task behavior.\n","authors":["Laure Ciernik","Lorenz Linhardt","Marco Morik","Jonas Dippel","Simon Kornblith","Lukas Muttenthaler"],"pdf_url":"https://arxiv.org/pdf/2411.05561v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2310.17705v3","updated":"2024-11-08T13:31:57Z","published":"2023-10-26T18:05:22Z","title":"A Wireless AI-Generated Content (AIGC) Provisioning Framework Empowered\n  by Semantic Communication","summary":"  With the significant advances in AI-generated content (AIGC) and the\nproliferation of mobile devices, providing high-quality AIGC services via\nwireless networks is becoming the future direction. However, the primary\nchallenges of AIGC services provisioning in wireless networks lie in unstable\nchannels, limited bandwidth resources, and unevenly distributed computational\nresources. To this end, this paper proposes a semantic communication\n(SemCom)-empowered AIGC (SemAIGC) generation and transmission framework, where\nonly semantic information of the content rather than all the binary bits should\nbe generated and transmitted by using SemCom. Specifically, SemAIGC integrates\ndiffusion models within the semantic encoder and decoder to design a\nworkload-adjustable transceiver thereby allowing adjustment of computational\nresource utilization in edge and local. In addition, a Resource-aware wOrklOad\nTrade-off (ROOT) scheme is devised to intelligently make workload adaptation\ndecisions for the transceiver, thus efficiently generating, transmitting, and\nfine-tuning content as per dynamic wireless channel conditions and service\nrequirements. Simulations verify the superiority of our proposed SemAIGC\nframework in terms of latency and content quality compared to conventional\napproaches.\n","authors":["Runze Cheng","Yao Sun","Dusit Niyato","Lan Zhang","Lei Zhang","Muhammad Ali Imran"],"pdf_url":"https://arxiv.org/pdf/2310.17705v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21333v3","updated":"2024-11-08T13:11:58Z","published":"2024-10-27T18:30:41Z","title":"Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on\n  Tasks where Thinking Makes Humans Worse","summary":"  Chain-of-thought (CoT) prompting has become a widely used strategy for\nworking with large language and multimodal models. While CoT has been shown to\nimprove performance across many tasks, determining the settings in which it is\neffective remains an ongoing effort. In particular, it is still an open\nquestion in what settings CoT systematically reduces model performance. In this\npaper, we seek to identify the characteristics of tasks where CoT reduces\nperformance by drawing inspiration from cognitive psychology, looking at cases\nwhere (i) verbal thinking or deliberation hurts performance in humans, and (ii)\nthe constraints governing human performance generalize to language models.\nThree such cases are implicit statistical learning, visual recognition, and\nclassifying with patterns containing exceptions. In extensive experiments\nacross all three settings, we find that a diverse collection of\nstate-of-the-art models exhibit significant drop-offs in performance (e.g., up\nto 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using\ninference-time reasoning compared to zero-shot counterparts. We also identify\nthree tasks that satisfy condition (i) but not (ii), and find that while verbal\nthinking reduces human performance in these tasks, CoT retains or increases\nmodel performance. Overall, our results show that while there is not an exact\nparallel between the cognitive processes of models and those of humans,\nconsidering cases where thinking has negative consequences for human\nperformance can help us identify settings where it negatively impacts models.\nBy connecting the literature on human deliberation with evaluations of CoT, we\noffer a new tool that can be used in understanding the impact of prompt choices\nand inference-time reasoning.\n","authors":["Ryan Liu","Jiayi Geng","Addison J. Wu","Ilia Sucholutsky","Tania Lombrozo","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2410.21333v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05544v1","updated":"2024-11-08T12:58:48Z","published":"2024-11-08T12:58:48Z","title":"Towards Lifelong Few-Shot Customization of Text-to-Image Diffusion","summary":"  Lifelong few-shot customization for text-to-image diffusion aims to\ncontinually generalize existing models for new tasks with minimal data while\npreserving old knowledge. Current customization diffusion models excel in\nfew-shot tasks but struggle with catastrophic forgetting problems in lifelong\ngenerations. In this study, we identify and categorize the catastrophic\nforgetting problems into two folds: relevant concepts forgetting and previous\nconcepts forgetting. To address these challenges, we first devise a data-free\nknowledge distillation strategy to tackle relevant concepts forgetting. Unlike\nexisting methods that rely on additional real data or offline replay of\noriginal concept data, our approach enables on-the-fly knowledge distillation\nto retain the previous concepts while learning new ones, without accessing any\nprevious data. Second, we develop an In-Context Generation (ICGen) paradigm\nthat allows the diffusion model to be conditioned upon the input vision\ncontext, which facilitates the few-shot generation and mitigates the issue of\nprevious concepts forgetting. Extensive experiments show that the proposed\nLifelong Few-Shot Diffusion (LFS-Diffusion) method can produce high-quality and\naccurate images while maintaining previously learned knowledge.\n","authors":["Nan Song","Xiaofeng Yang","Ze Yang","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16254v2","updated":"2024-11-08T12:54:16Z","published":"2024-06-24T01:31:03Z","title":"Confidence Regulation Neurons in Language Models","summary":"  Despite their widespread use, the mechanisms by which large language models\n(LLMs) represent and regulate uncertainty in next-token predictions remain\nlargely unexplored. This study investigates two critical components believed to\ninfluence this uncertainty: the recently discovered entropy neurons and a new\nset of components that we term token frequency neurons. Entropy neurons are\ncharacterized by an unusually high weight norm and influence the final layer\nnormalization (LayerNorm) scale to effectively scale down the logits. Our work\nshows that entropy neurons operate by writing onto an unembedding null space,\nallowing them to impact the residual stream norm with minimal direct effect on\nthe logits themselves. We observe the presence of entropy neurons across a\nrange of models, up to 7 billion parameters. On the other hand, token frequency\nneurons, which we discover and describe here for the first time, boost or\nsuppress each token's logit proportionally to its log frequency, thereby\nshifting the output distribution towards or away from the unigram distribution.\nFinally, we present a detailed case study where entropy neurons actively manage\nconfidence in the setting of induction, i.e. detecting and continuing repeated\nsubsequences.\n","authors":["Alessandro Stolfo","Ben Wu","Wes Gurnee","Yonatan Belinkov","Xingyi Song","Mrinmaya Sachan","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2406.16254v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05536v1","updated":"2024-11-08T12:49:24Z","published":"2024-11-08T12:49:24Z","title":"Towards Active Flow Control Strategies Through Deep Reinforcement\n  Learning","summary":"  This paper presents a deep reinforcement learning (DRL) framework for active\nflow control (AFC) to reduce drag in aerodynamic bodies. Tested on a 3D\ncylinder at Re = 100, the DRL approach achieved a 9.32% drag reduction and a\n78.4% decrease in lift oscillations by learning advanced actuation strategies.\nThe methodology integrates a CFD solver with a DRL model using an in-memory\ndatabase for efficient communication between\n","authors":["Ricard Montal√†","Bernat Font","Pol Su√°rez","Jean Rabault","Oriol Lehmkuhl","Ivette Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2411.05536v1.pdf","comment":"ECOMMAS 2024 conference proceeding paper"},{"id":"http://arxiv.org/abs/2402.09166v2","updated":"2024-11-08T12:45:38Z","published":"2024-02-14T13:32:23Z","title":"Deinterleaving of Discrete Renewal Process Mixtures with Application to\n  Electronic Support Measures","summary":"  In this paper, we propose a new deinterleaving method for mixtures of\ndiscrete renewal Markov chains. This method relies on the maximization of a\npenalized likelihood score. It exploits all available information about both\nthe sequence of the different symbols and their arrival times. A theoretical\nanalysis is carried out to prove that minimizing this score allows to recover\nthe true partition of symbols in the large sample limit, under mild conditions\non the component processes. This theoretical analysis is then validated by\nexperiments on synthetic data. Finally, the method is applied to deinterleave\npulse trains received from different emitters in a RESM (Radar Electronic\nSupport Measurements) context and we show that the proposed method competes\nfavorably with state-of-the-art methods on simulated warfare datasets.\n","authors":["Jean Pinsolle","Olivier Goudet","Cyrille Enderli","Sylvain Lamprier","Jin-Kao Hao"],"pdf_url":"https://arxiv.org/pdf/2402.09166v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17044v2","updated":"2024-11-08T12:44:49Z","published":"2024-09-25T15:54:29Z","title":"How to Connect Speech Foundation Models and Large Language Models? What\n  Matters and What Does Not","summary":"  The remarkable performance achieved by Large Language Models (LLM) has driven\nresearch efforts to leverage them for a wide range of tasks and input\nmodalities. In speech-to-text (S2T) tasks, the emerging solution consists of\nprojecting the output of the encoder of a Speech Foundational Model (SFM) into\nthe LLM embedding space through an adapter module. However, no work has yet\ninvestigated how much the downstream-task performance depends on each component\n(SFM, adapter, LLM) nor whether the best design of the adapter depends on the\nchosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adapter\nmodules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) on\ntwo widespread S2T tasks, namely Automatic Speech Recognition and Speech\nTranslation. Our results demonstrate that the SFM plays a pivotal role in\ndownstream performance, while the adapter choice has moderate impact and\ndepends on the SFM and LLM.\n","authors":["Francesco Verdini","Pierfrancesco Melucci","Stefano Perna","Francesco Cariaggi","Marco Gaido","Sara Papi","Szymon Mazurek","Marek Kasztelnik","Luisa Bentivogli","S√©bastien Brati√®res","Paolo Merialdo","Simone Scardapane"],"pdf_url":"https://arxiv.org/pdf/2409.17044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03880v3","updated":"2024-11-08T12:26:43Z","published":"2024-03-06T17:40:26Z","title":"Almost Surely Asymptotically Constant Graph Neural Networks","summary":"  We present a new angle on the expressive power of graph neural networks\n(GNNs) by studying how the predictions of real-valued GNN classifiers, such as\nthose classifying graphs probabilistically, evolve as we apply them on larger\ngraphs drawn from some random graph model. We show that the output converges to\na constant function, which upper-bounds what these classifiers can uniformly\nexpress. This strong convergence phenomenon applies to a very wide class of\nGNNs, including state of the art models, with aggregates including mean and the\nattention-based mechanism of graph transformers. Our results apply to a broad\nclass of random graph models, including sparse and dense variants of the\nErd\\H{o}s-R\\'enyi model, the stochastic block model, and the Barab\\'asi-Albert\nmodel. We empirically validate these findings, observing that the convergence\nphenomenon appears not only on random graphs but also on some real-world\ngraphs.\n","authors":["Sam Adam-Day","Michael Benedikt","ƒ∞smail ƒ∞lkan Ceylan","Ben Finkelshtein"],"pdf_url":"https://arxiv.org/pdf/2403.03880v3.pdf","comment":"NeurIPS '24 camera-ready version; 10 body pages, 29 appendix pages,\n  11 figures"},{"id":"http://arxiv.org/abs/2411.05500v1","updated":"2024-11-08T12:02:25Z","published":"2024-11-08T12:02:25Z","title":"FGGP: Fixed-Rate Gradient-First Gradual Pruning","summary":"  In recent years, the increasing size of deep learning models and their\ngrowing demand for computational resources have drawn significant attention to\nthe practice of pruning neural networks, while aiming to preserve their\naccuracy. In unstructured gradual pruning, which sparsifies a network by\ngradually removing individual network parameters until a targeted network\nsparsity is reached, recent works show that both gradient and weight magnitudes\nshould be considered. In this work, we show that such mechanism, e.g., the\norder of prioritization and selection criteria, is essential. We introduce a\ngradient-first magnitude-next strategy for choosing the parameters to prune,\nand show that a fixed-rate subselection criterion between these steps works\nbetter, in contrast to the annealing approach in the literature. We validate\nthis on CIFAR-10 dataset, with multiple randomized initializations on both\nVGG-19 and ResNet-50 network backbones, for pruning targets of 90, 95, and 98%\nsparsity and for both initially dense and 50% sparse networks. Our proposed\nfixed-rate gradient-first gradual pruning (FGGP) approach outperforms its\nstate-of-the-art alternatives in most of the above experimental settings, even\noccasionally surpassing the upperbound of corresponding dense network results,\nand having the highest ranking across the considered experimental settings.\n","authors":["Lingkai Zhu","Can Deniz Bezek","Orcun Goksel"],"pdf_url":"https://arxiv.org/pdf/2411.05500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05489v1","updated":"2024-11-08T11:39:03Z","published":"2024-11-08T11:39:03Z","title":"Do Histopathological Foundation Models Eliminate Batch Effects? A\n  Comparative Study","summary":"  Deep learning has led to remarkable advancements in computational\nhistopathology, e.g., in diagnostics, biomarker prediction, and outcome\nprognosis. Yet, the lack of annotated data and the impact of batch effects,\ne.g., systematic technical data differences across hospitals, hamper model\nrobustness and generalization. Recent histopathological foundation models --\npretrained on millions to billions of images -- have been reported to improve\ngeneralization performances on various downstream tasks. However, it has not\nbeen systematically assessed whether they fully eliminate batch effects. In\nthis study, we empirically show that the feature embeddings of the foundation\nmodels still contain distinct hospital signatures that can lead to biased\npredictions and misclassifications. We further find that the signatures are not\nremoved by stain normalization methods, dominate distances in feature space,\nand are evident across various principal components. Our work provides a novel\nperspective on the evaluation of medical foundation models, paving the way for\nmore robust pretraining strategies and downstream predictors.\n","authors":["Jonah K√∂men","Hannah Marienwald","Jonas Dippel","Julius Hense"],"pdf_url":"https://arxiv.org/pdf/2411.05489v1.pdf","comment":"Accepted to AIM-FM Workshop @ NeurIPS'24"},{"id":"http://arxiv.org/abs/2411.05486v1","updated":"2024-11-08T11:32:33Z","published":"2024-11-08T11:32:33Z","title":"Handling geometrical variability in nonlinear reduced order modeling\n  through Continuous Geometry-Aware DL-ROMs","summary":"  Deep Learning-based Reduced Order Models (DL-ROMs) provide nowadays a\nwell-established class of accurate surrogate models for complex physical\nsystems described by parametrized PDEs, by nonlinearly compressing the solution\nmanifold into a handful of latent coordinates. Until now, design and\napplication of DL-ROMs mainly focused on physically parameterized problems.\nWithin this work, we provide a novel extension of these architectures to\nproblems featuring geometrical variability and parametrized domains, namely, we\npropose Continuous Geometry-Aware DL-ROMs (CGA-DL-ROMs). In particular, the\nspace-continuous nature of the proposed architecture matches the need to deal\nwith multi-resolution datasets, which are quite common in the case of\ngeometrically parametrized problems. Moreover, CGA-DL-ROMs are endowed with a\nstrong inductive bias that makes them aware of geometrical parametrizations,\nthus enhancing both the compression capability and the overall performance of\nthe architecture. Within this work, we justify our findings through a thorough\ntheoretical analysis, and we practically validate our claims by means of a\nseries of numerical tests encompassing physically-and-geometrically\nparametrized PDEs, ranging from the unsteady Navier-Stokes equations for fluid\ndynamics to advection-diffusion-reaction equations for mathematical biology.\n","authors":["Simone Brivio","Stefania Fresca","Andrea Manzoni"],"pdf_url":"https://arxiv.org/pdf/2411.05486v1.pdf","comment":"30 pages, 15 figures"},{"id":"http://arxiv.org/abs/2408.10126v2","updated":"2024-11-08T11:30:20Z","published":"2024-08-19T16:13:35Z","title":"Learning Brave Assumption-Based Argumentation Frameworks via ASP","summary":"  Assumption-based Argumentation (ABA) is advocated as a unifying formalism for\nvarious forms of non-monotonic reasoning, including logic programming. It\nallows capturing defeasible knowledge, subject to argumentative debate. While,\nin much existing work, ABA frameworks are given up-front, in this paper we\nfocus on the problem of automating their learning from background knowledge and\npositive/negative examples. Unlike prior work, we newly frame the problem in\nterms of brave reasoning under stable extensions for ABA. We present a novel\nalgorithm based on transformation rules (such as Rote Learning, Folding,\nAssumption Introduction and Fact Subsumption) and an implementation thereof\nthat makes use of Answer Set Programming. Finally, we compare our technique to\nstate-of-the-art ILP systems that learn defeasible knowledge.\n","authors":["Emanuele De Angelis","Maurizio Proietti","Francesca Toni"],"pdf_url":"https://arxiv.org/pdf/2408.10126v2.pdf","comment":"Extended version of the paper published in: Proceedings 27th European\n  Conference on Artificial Intelligence, Frontiers in Artificial Intelligence\n  and Applications, Volume 392: ECAI 2024, pp. 3445 - 3452. DOI:\n  10.3233/FAIA240896"},{"id":"http://arxiv.org/abs/2411.05483v1","updated":"2024-11-08T11:21:31Z","published":"2024-11-08T11:21:31Z","title":"The Limits of Differential Privacy in Online Learning","summary":"  Differential privacy (DP) is a formal notion that restricts the privacy\nleakage of an algorithm when running on sensitive data, in which\nprivacy-utility trade-off is one of the central problems in private data\nanalysis. In this work, we investigate the fundamental limits of differential\nprivacy in online learning algorithms and present evidence that separates three\ntypes of constraints: no DP, pure DP, and approximate DP. We first describe a\nhypothesis class that is online learnable under approximate DP but not online\nlearnable under pure DP under the adaptive adversarial setting. This indicates\nthat approximate DP must be adopted when dealing with adaptive adversaries. We\nthen prove that any private online learner must make an infinite number of\nmistakes for almost all hypothesis classes. This essentially generalizes\nprevious results and shows a strong separation between private and non-private\nsettings since a finite mistake bound is always attainable (as long as the\nclass is online learnable) when there is no privacy requirement.\n","authors":["Bo Li","Wei Wang","Peng Ye"],"pdf_url":"https://arxiv.org/pdf/2411.05483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05472v1","updated":"2024-11-08T10:53:39Z","published":"2024-11-08T10:53:39Z","title":"Bridging the Gap between Learning and Inference for Diffusion-Based\n  Molecule Generation","summary":"  The efficacy of diffusion models in generating a spectrum of data modalities,\nincluding images, text, and videos, has spurred inquiries into their utility in\nmolecular generation, yielding significant advancements in the field. However,\nthe molecular generation process with diffusion models involves multiple\nautoregressive steps over a finite time horizon, leading to exposure bias\nissues inherently. To address the exposure bias issue, we propose a training\nframework named GapDiff. The core idea of GapDiff is to utilize model-predicted\nconformations as ground truth probabilistically during training, aiming to\nmitigate the data distributional disparity between training and inference,\nthereby enhancing the affinity of generated molecules. We conduct experiments\nusing a 3D molecular generation model on the CrossDocked2020 dataset, and the\nvina energy and diversity demonstrate the potency of our framework with\nsuperior affinity. GapDiff is available at\n\\url{https://github.com/HUGHNew/gapdiff}.\n","authors":["Peidong Liu","Wenbo Zhang","Xue Zhe","Jiancheng Lv","Xianggen Liu"],"pdf_url":"https://arxiv.org/pdf/2411.05472v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2405.09597v3","updated":"2024-11-08T10:51:40Z","published":"2024-05-15T13:50:23Z","title":"When AI Eats Itself: On the Caveats of AI Autophagy","summary":"  Generative Artificial Intelligence (AI) technologies and large models are\nproducing realistic outputs across various domains, such as images, text,\nspeech, and music. Creating these advanced generative models requires\nsignificant resources, particularly large and high-quality datasets. To\nminimise training expenses, many algorithm developers use data created by the\nmodels themselves as a cost-effective training solution. However, not all\nsynthetic data effectively improve model performance, necessitating a strategic\nbalance in the use of real versus synthetic data to optimise outcomes.\nCurrently, the previously well-controlled integration of real and synthetic\ndata is becoming uncontrollable. The widespread and unregulated dissemination\nof synthetic data online leads to the contamination of datasets traditionally\ncompiled through web scraping, now mixed with unlabeled synthetic data. This\ntrend, known as the AI autophagy phenomenon, suggests a future where generative\nAI systems may increasingly consume their own outputs without discernment,\nraising concerns about model performance, reliability, and ethical\nimplications. What will happen if generative AI continuously consumes itself\nwithout discernment? What measures can we take to mitigate the potential\nadverse effects? To address these research questions, this study examines the\nexisting literature, delving into the consequences of AI autophagy, analyzing\nthe associated risks, and exploring strategies to mitigate its impact. Our aim\nis to provide a comprehensive perspective on this phenomenon advocating for a\nbalanced approach that promotes the sustainable development of generative AI\ntechnologies in the era of large models.\n","authors":["Xiaodan Xing","Fadong Shi","Jiahao Huang","Yinzhe Wu","Yang Nan","Sheng Zhang","Yingying Fang","Mike Roberts","Carola-Bibiane Sch√∂nlieb","Javier Del Ser","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2405.09597v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19928v2","updated":"2024-11-08T10:46:09Z","published":"2024-05-30T10:44:45Z","title":"BAN: Detecting Backdoors Activated by Adversarial Neuron Noise","summary":"  Backdoor attacks on deep learning represent a recent threat that has gained\nsignificant attention in the research community. Backdoor defenses are mainly\nbased on backdoor inversion, which has been shown to be generic,\nmodel-agnostic, and applicable to practical threat scenarios. State-of-the-art\nbackdoor inversion recovers a mask in the feature space to locate prominent\nbackdoor features, where benign and backdoor features can be disentangled.\nHowever, it suffers from high computational overhead, and we also find that it\noverly relies on prominent backdoor features that are highly distinguishable\nfrom benign features. To tackle these shortcomings, this paper improves\nbackdoor feature inversion for backdoor detection by incorporating extra neuron\nactivation information. In particular, we adversarially increase the loss of\nbackdoored models with respect to weights to activate the backdoor effect,\nbased on which we can easily differentiate backdoored and clean models.\nExperimental results demonstrate our defense, BAN, is 1.37$\\times$ (on\nCIFAR-10) and 5.11$\\times$ (on ImageNet200) more efficient with an average\n9.99\\% higher detect success rate than the state-of-the-art defense BTI-DBF.\nOur code and trained models are publicly available\nat~\\url{https://github.com/xiaoyunxxy/ban}.\n","authors":["Xiaoyun Xu","Zhuoran Liu","Stefanos Koffas","Shujian Yu","Stjepan Picek"],"pdf_url":"https://arxiv.org/pdf/2405.19928v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04088v2","updated":"2024-11-08T10:38:26Z","published":"2024-06-06T13:58:41Z","title":"Deterministic Uncertainty Propagation for Improved Model-Based Offline\n  Reinforcement Learning","summary":"  Current approaches to model-based offline reinforcement learning often\nincorporate uncertainty-based reward penalization to address the distributional\nshift problem. These approaches, commonly known as pessimistic value iteration,\nuse Monte Carlo sampling to estimate the Bellman target to perform temporal\ndifference based policy evaluation. We find out that the randomness caused by\nthis sampling step significantly delays convergence. We present a theoretical\nresult demonstrating the strong dependency of suboptimality on the number of\nMonte Carlo samples taken per Bellman target calculation. Our main contribution\nis a deterministic approximation to the Bellman target that uses progressive\nmoment matching, a method developed originally for deterministic variational\ninference. The resulting algorithm, which we call Moment Matching Offline\nModel-Based Policy Optimization (MOMBO), propagates the uncertainty of the next\nstate through a nonlinear Q-network in a deterministic fashion by approximating\nthe distributions of hidden layer activations by a normal distribution. We show\nthat it is possible to provide tighter guarantees for the suboptimality of\nMOMBO than the existing Monte Carlo sampling approaches. We also observe MOMBO\nto converge faster than these approaches in a large set of benchmark tasks.\n","authors":["Abdullah Akg√ºl","Manuel Hau√ümann","Melih Kandemir"],"pdf_url":"https://arxiv.org/pdf/2406.04088v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05464v1","updated":"2024-11-08T10:34:24Z","published":"2024-11-08T10:34:24Z","title":"Generalization, Expressivity, and Universality of Graph Neural Networks\n  on Attributed Graphs","summary":"  We analyze the universality and generalization of graph neural networks\n(GNNs) on attributed graphs, i.e., with node attributes. To this end, we\npropose pseudometrics over the space of all attributed graphs that describe the\nfine-grained expressivity of GNNs. Namely, GNNs are both Lipschitz continuous\nwith respect to our pseudometrics and can separate attributed graphs that are\ndistant in the metric. Moreover, we prove that the space of all attributed\ngraphs is relatively compact with respect to our metrics. Based on these\nproperties, we prove a universal approximation theorem for GNNs and\ngeneralization bounds for GNNs on any data distribution of attributed graphs.\nThe proposed metrics compute the similarity between the structures of\nattributed graphs via a hierarchical optimal transport between computation\ntrees. Our work extends and unites previous approaches which either derived\ntheory only for graphs with no attributes, derived compact metrics under which\nGNNs are continuous but without separation power, or derived metrics under\nwhich GNNs are continuous and separate points but the space of graphs is not\nrelatively compact, which prevents universal approximation and generalization\nanalysis.\n","authors":["Levi Rauchwerger","Stefanie Jegelka","Ron Levie"],"pdf_url":"https://arxiv.org/pdf/2411.05464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02199v3","updated":"2024-11-08T10:30:59Z","published":"2024-11-04T15:54:32Z","title":"Provably Transformers Harness Multi-Concept Word Semantics for Efficient\n  In-Context Learning","summary":"  Transformer-based large language models (LLMs) have displayed remarkable\ncreative prowess and emergence capabilities. Existing empirical studies have\nrevealed a strong connection between these LLMs' impressive emergence abilities\nand their in-context learning (ICL) capacity, allowing them to solve new tasks\nusing only task-specific prompts without further fine-tuning. On the other\nhand, existing empirical and theoretical studies also show that there is a\nlinear regularity of the multi-concept encoded semantic representation behind\ntransformer-based LLMs. However, existing theoretical work fail to build up an\nunderstanding of the connection between this regularity and the innovative\npower of ICL. Additionally, prior work often focuses on simplified, unrealistic\nscenarios involving linear transformers or unrealistic loss functions, and they\nachieve only linear or sub-linear convergence rates. In contrast, this work\nprovides a fine-grained mathematical analysis to show how transformers leverage\nthe multi-concept semantics of words to enable powerful ICL and excellent\nout-of-distribution ICL abilities, offering insights into how transformers\ninnovate solutions for certain unseen tasks encoded with multiple cross-concept\nsemantics. Inspired by empirical studies on the linear latent geometry of LLMs,\nthe analysis is based on a concept-based low-noise sparse coding prompt model.\nLeveraging advanced techniques, this work showcases the exponential 0-1 loss\nconvergence over the highly non-convex training dynamics, which pioneeringly\nincorporates the challenges of softmax self-attention, ReLU-activated MLPs, and\ncross-entropy loss. Empirical simulations corroborate the theoretical findings.\n","authors":["Dake Bu","Wei Huang","Andi Han","Atsushi Nitanda","Taiji Suzuki","Qingfu Zhang","Hau-San Wong"],"pdf_url":"https://arxiv.org/pdf/2411.02199v3.pdf","comment":"Accepted by the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2405.17372v2","updated":"2024-11-08T10:25:43Z","published":"2024-05-27T17:28:25Z","title":"BehaviorGPT: Smart Agent Simulation for Autonomous Driving with\n  Next-Patch Prediction","summary":"  Simulating realistic interactions among traffic agents is crucial for\nefficiently validating the safety of autonomous driving systems. Existing\nleading simulators primarily use an encoder-decoder structure to encode the\nhistorical trajectories for future simulation. However, such a paradigm\ncomplicates the model architecture, and the manual separation of history and\nfuture trajectories leads to low data utilization. To address these challenges,\nwe propose Behavior Generative Pre-trained Transformers (BehaviorGPT), a\ndecoder-only, autoregressive architecture designed to simulate the sequential\nmotion of multiple agents. Crucially, our approach discards the traditional\nseparation between \"history\" and \"future,\" treating each time step as the\n\"current\" one, resulting in a simpler, more parameter- and data-efficient\ndesign that scales seamlessly with data and computation. Additionally, we\nintroduce the Next-Patch Prediction Paradigm (NP3), which enables models to\nreason at the patch level of trajectories and capture long-range\nspatial-temporal interactions. BehaviorGPT ranks first across several metrics\non the Waymo Sim Agents Benchmark, demonstrating its exceptional performance in\nmulti-agent and agent-map interactions. We outperformed state-of-the-art models\nwith a realism score of 0.741 and improved the minADE metric to 1.540, with an\napproximately 91.6% reduction in model parameters.\n","authors":["Zikang Zhou","Haibo Hu","Xinhong Chen","Jianping Wang","Nan Guan","Kui Wu","Yung-Hui Li","Yu-Kai Huang","Chun Jason Xue"],"pdf_url":"https://arxiv.org/pdf/2405.17372v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04832v2","updated":"2024-11-08T10:19:15Z","published":"2024-11-07T16:13:54Z","title":"Plasticity Loss in Deep Reinforcement Learning: A Survey","summary":"  Akin to neuroplasticity in human brains, the plasticity of deep neural\nnetworks enables their quick adaption to new data. This makes plasticity\nparticularly crucial for deep Reinforcement Learning (RL) agents: Once\nplasticity is lost, an agent's performance will inevitably plateau because it\ncannot improve its policy to account for changes in the data distribution,\nwhich are a necessary consequence of its learning process. Thus, developing\nwell-performing and sample-efficient agents hinges on their ability to remain\nplastic during training. Furthermore, the loss of plasticity can be connected\nto many other issues plaguing deep RL, such as training instabilities, scaling\nfailures, overestimation bias, and insufficient exploration. With this survey,\nwe aim to provide an overview of the emerging research on plasticity loss for\nacademics and practitioners of deep reinforcement learning. First, we propose a\nunified definition of plasticity loss based on recent works, relate it to\ndefinitions from the literature, and discuss metrics for measuring plasticity\nloss. Then, we categorize and discuss numerous possible causes of plasticity\nloss before reviewing currently employed mitigation strategies. Our taxonomy is\nthe first systematic overview of the current state of the field. Lastly, we\ndiscuss prevalent issues within the literature, such as a necessity for broader\nevaluation, and provide recommendations for future research, like gaining a\nbetter understanding of an agent's neural activity and behavior.\n","authors":["Timo Klein","Lukas Miklautz","Kevin Sidak","Claudia Plant","Sebastian Tschiatschek"],"pdf_url":"https://arxiv.org/pdf/2411.04832v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12789v3","updated":"2024-11-08T10:17:29Z","published":"2024-02-20T07:57:38Z","title":"Fairness Without Harm: An Influence-Guided Active Sampling Approach","summary":"  The pursuit of fairness in machine learning (ML), ensuring that the models do\nnot exhibit biases toward protected demographic groups, typically results in a\ncompromise scenario. This compromise can be explained by a Pareto frontier\nwhere given certain resources (e.g., data), reducing the fairness violations\noften comes at the cost of lowering the model accuracy. In this work, we aim to\ntrain models that mitigate group fairness disparity without causing harm to\nmodel accuracy. Intuitively, acquiring more data is a natural and promising\napproach to achieve this goal by reaching a better Pareto frontier of the\nfairness-accuracy tradeoff. The current data acquisition methods, such as fair\nactive learning approaches, typically require annotating sensitive attributes.\nHowever, these sensitive attribute annotations should be protected due to\nprivacy and safety concerns. In this paper, we propose a tractable active data\nsampling algorithm that does not rely on training group annotations, instead\nonly requiring group annotations on a small validation set. Specifically, the\nalgorithm first scores each new example by its influence on fairness and\naccuracy evaluated on the validation dataset, and then selects a certain number\nof examples for training. We theoretically analyze how acquiring more data can\nimprove fairness without causing harm, and validate the possibility of our\nsampling approach in the context of risk disparity. We also provide the upper\nbound of generalization error and risk disparity as well as the corresponding\nconnections. Extensive experiments on real-world data demonstrate the\neffectiveness of our proposed algorithm. Our code is available at\nhttps://github.com/UCSC-REAL/FairnessWithoutHarm.\n","authors":["Jinlong Pang","Jialu Wang","Zhaowei Zhu","Yuanshun Yao","Chen Qian","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2402.12789v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05456v1","updated":"2024-11-08T10:07:03Z","published":"2024-11-08T10:07:03Z","title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques","summary":"  Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.\n","authors":["Mohammad Imran Hossain","Muhammad Zain Amin","Daniel Tweneboah Anyimadu","Taofik Ahmed Suleiman"],"pdf_url":"https://arxiv.org/pdf/2411.05456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10119v4","updated":"2024-11-08T10:06:06Z","published":"2024-01-18T16:50:55Z","title":"Towards Principled Graph Transformers","summary":"  Graph learning architectures based on the k-dimensional Weisfeiler-Leman\n(k-WL) hierarchy offer a theoretically well-understood expressive power.\nHowever, such architectures often fail to deliver solid predictive performance\non real-world tasks, limiting their practical impact. In contrast, global\nattention-based models such as graph transformers demonstrate strong\nperformance in practice, but comparing their expressive power with the k-WL\nhierarchy remains challenging, particularly since these architectures rely on\npositional or structural encodings for their expressivity and predictive\nperformance. To address this, we show that the recently proposed Edge\nTransformer, a global attention model operating on node pairs instead of nodes,\nhas at least 3-WL expressive power. Empirically, we demonstrate that the Edge\nTransformer surpasses other theoretically aligned architectures regarding\npredictive performance while not relying on positional or structural encodings.\nOur code is available at https://github.com/luis-mueller/towards-principled-gts\n","authors":["Luis M√ºller","Daniel Kusuma","Blai Bonet","Christopher Morris"],"pdf_url":"https://arxiv.org/pdf/2401.10119v4.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05453v1","updated":"2024-11-08T10:00:40Z","published":"2024-11-08T10:00:40Z","title":"The sampling complexity of learning invertible residual neural networks","summary":"  In recent work it has been shown that determining a feedforward ReLU neural\nnetwork to within high uniform accuracy from point samples suffers from the\ncurse of dimensionality in terms of the number of samples needed. As a\nconsequence, feedforward ReLU neural networks are of limited use for\napplications where guaranteed high uniform accuracy is required.\n  We consider the question of whether the sampling complexity can be improved\nby restricting the specific neural network architecture. To this end, we\ninvestigate invertible residual neural networks which are foundational\narchitectures in deep learning and are widely employed in models that power\nmodern generative methods. Our main result shows that the residual neural\nnetwork architecture and invertibility do not help overcome the complexity\nbarriers encountered with simpler feedforward architectures. Specifically, we\ndemonstrate that the computational complexity of approximating invertible\nresidual neural networks from point samples in the uniform norm suffers from\nthe curse of dimensionality. Similar results are established for invertible\nconvolutional Residual neural networks.\n","authors":["Yuanyuan Li","Philipp Grohs","Philipp Petersen"],"pdf_url":"https://arxiv.org/pdf/2411.05453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14250v4","updated":"2024-11-08T09:57:56Z","published":"2024-05-23T07:28:56Z","title":"Diffusion models for Gaussian distributions: Exact solutions and\n  Wasserstein errors","summary":"  Diffusion or score-based models recently showed high performance in image\ngeneration. They rely on a forward and a backward stochastic differential\nequations (SDE). The sampling of a data distribution is achieved by solving\nnumerically the backward SDE or its associated flow ODE. Studying the\nconvergence of these models necessitates to control four different types of\nerror: the initialization error, the truncation error, the discretization and\nthe score approximation. In this paper, we study theoretically the behavior of\ndiffusion models and their numerical implementation when the data distribution\nis Gaussian. In this restricted framework where the score function is a linear\noperator, we derive the analytical solutions of the backward SDE and the\nprobability flow ODE. We prove that these solutions and their discretizations\nare all Gaussian processes, which allows us to compute exact Wasserstein errors\ninduced by each error type for any sampling scheme. Monitoring convergence\ndirectly in the data space instead of relying on Inception features, our\nexperiments show that the recommended numerical schemes from the diffusion\nmodels literature are also the best sampling schemes for Gaussian\ndistributions.\n","authors":["Emile Pierret","Bruno Galerne"],"pdf_url":"https://arxiv.org/pdf/2405.14250v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14689v3","updated":"2024-11-08T09:37:14Z","published":"2024-05-23T15:25:56Z","title":"Cascade of phase transitions in the training of Energy-based models","summary":"  In this paper, we investigate the feature encoding process in a prototypical\nenergy-based generative model, the Restricted Boltzmann Machine (RBM). We start\nwith an analytical investigation using simplified architectures and data\nstructures, and end with numerical analysis of real trainings on real datasets.\nOur study tracks the evolution of the model's weight matrix through its\nsingular value decomposition, revealing a series of phase transitions\nassociated to a progressive learning of the principal modes of the empirical\nprobability distribution. The model first learns the center of mass of the\nmodes and then progressively resolve all modes through a cascade of phase\ntransitions. We first describe this process analytically in a controlled setup\nthat allows us to study analytically the training dynamics. We then validate\nour theoretical results by training the Bernoulli-Bernoulli RBM on real data\nsets. By using data sets of increasing dimension, we show that learning indeed\nleads to sharp phase transitions in the high-dimensional limit. Moreover, we\npropose and test a mean-field finite-size scaling hypothesis. This shows that\nthe first phase transition is in the same universality class of the one we\nstudied analytically, and which is reminiscent of the mean-field\nparamagnetic-to-ferromagnetic phase transition.\n","authors":["Dimitrios Bachtis","Giulio Biroli","Aur√©lien Decelle","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2405.14689v3.pdf","comment":"19 pages, 6 figures, accepted to Neurips2024"},{"id":"http://arxiv.org/abs/2402.17089v2","updated":"2024-11-08T09:33:04Z","published":"2024-02-26T23:56:11Z","title":"Learnability of high-dimensional targets by two-parameter models and\n  gradient flow","summary":"  We explore the theoretical possibility of learning $d$-dimensional targets\nwith $W$-parameter models by gradient flow (GF) when $W<d$. Our main result\nshows that if the targets are described by a particular $d$-dimensional\nprobability distribution, then there exist models with as few as two parameters\nthat can learn the targets with arbitrarily high success probability. On the\nother hand, we show that for $W<d$ there is necessarily a large subset of\nGF-non-learnable targets. In particular, the set of learnable targets is not\ndense in $\\mathbb R^d$, and any subset of $\\mathbb R^d$ homeomorphic to the\n$W$-dimensional sphere contains non-learnable targets. Finally, we observe that\nthe model in our main theorem on almost guaranteed two-parameter learning is\nconstructed using a hierarchical procedure and as a result is not expressible\nby a single elementary function. We show that this limitation is essential in\nthe sense that most models written in terms of elementary functions cannot\nachieve the learnability demonstrated in this theorem.\n","authors":["Dmitry Yarotsky"],"pdf_url":"https://arxiv.org/pdf/2402.17089v2.pdf","comment":"Camera-ready NeurIPS 2024 version; some extra comments and figures"},{"id":"http://arxiv.org/abs/2411.05424v1","updated":"2024-11-08T09:16:05Z","published":"2024-11-08T09:16:05Z","title":"ICE-T: A Multi-Faceted Concept for Teaching Machine Learning","summary":"  The topics of Artificial intelligence (AI) and especially Machine Learning\n(ML) are increasingly making their way into educational curricula. To\nfacilitate the access for students, a variety of platforms, visual tools, and\ndigital games are already being used to introduce ML concepts and strengthen\nthe understanding of how AI works. We take a look at didactic principles that\nare employed for teaching computer science, define criteria, and, based on\nthose, evaluate a selection of prominent existing platforms, tools, and games.\nAdditionally, we criticize the approach of portraying ML mostly as a black-box\nand the resulting missing focus on creating an understanding of data,\nalgorithms, and models that come with it. To tackle this issue, we present a\nconcept that covers intermodal transfer, computational and explanatory\nthinking, ICE-T, as an extension of known didactic principles. With our\nmulti-faceted concept, we believe that planners of learning units, creators of\nlearning platforms and educators can improve on teaching ML.\n","authors":["Hendrik Krone","Pierre Haritz","Thomas Liebig"],"pdf_url":"https://arxiv.org/pdf/2411.05424v1.pdf","comment":"Accepted and presented at the 17th International Conference on\n  Informatics in Schools (ISSEP 2024)"},{"id":"http://arxiv.org/abs/2411.05420v1","updated":"2024-11-08T09:14:19Z","published":"2024-11-08T09:14:19Z","title":"WeatherGFM: Learning A Weather Generalist Foundation Model via\n  In-context Learning","summary":"  The Earth's weather system encompasses intricate weather data modalities and\ndiverse weather understanding tasks, which hold significant value to human\nlife. Existing data-driven models focus on single weather understanding tasks\n(e.g., weather forecasting). Although these models have achieved promising\nresults, they fail to tackle various complex tasks within a single and unified\nmodel. Moreover, the paradigm that relies on limited real observations for a\nsingle scenario hinders the model's performance upper bound. In response to\nthese limitations, we draw inspiration from the in-context learning paradigm\nemployed in state-of-the-art visual foundation models and large language\nmodels. In this paper, we introduce the first generalist weather foundation\nmodel (WeatherGFM), designed to address a wide spectrum of weather\nunderstanding tasks in a unified manner. More specifically, we initially unify\nthe representation and definition of the diverse weather understanding tasks.\nSubsequently, we devised weather prompt formats to manage different weather\ndata modalities, namely single, multiple, and temporal modalities. Finally, we\nadopt a visual prompting question-answering paradigm for the training of\nunified weather understanding tasks. Extensive experiments indicate that our\nWeatherGFM can effectively handle up to ten weather understanding tasks,\nincluding weather forecasting, super-resolution, weather image translation, and\npost-processing. Our method also showcases generalization ability on unseen\ntasks.\n","authors":["Xiangyu Zhao","Zhiwang Zhou","Wenlong Zhang","Yihao Liu","Xiangyu Chen","Junchao Gong","Hao Chen","Ben Fei","Shiqi Chen","Wanli Ouyang","Xiao-Ming Wu","Lei Bai"],"pdf_url":"https://arxiv.org/pdf/2411.05420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07230v2","updated":"2024-11-08T08:55:00Z","published":"2024-03-12T00:58:19Z","title":"Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked\n  Preferences","summary":"  Direct Preference Optimization (DPO) is an effective technique that leverages\npairwise preference data (usually one chosen and rejected response pair per\nuser prompt) to align LLMs to human preferences. In practice, multiple\nresponses can exist for a given prompt with varying quality relative to each\nother. With availability of such quality ratings for multiple responses, we\npropose utilizing these responses to create multiple preference pairs for a\ngiven prompt. Our work focuses on systematically using the constructed multiple\npreference pair in DPO training via curriculum learning methodology. In\nparticular, we order these multiple pairs of preference data from easy to hard\n(emulating curriculum training) according to various criteria. We show detailed\ncomparisons of our proposed approach to the standard single-pair DPO setting.\nOur method, which we call Curry-DPO consistently shows increased performance\ngains on MTbench, Vicuna, WizardLM, and the UltraFeedback test set,\nhighlighting its effectiveness. More specifically, Curry-DPO achieves a score\nof 7.43 on MT-bench with Zephy-7B model outperforming majority of existing LLMs\nwith similar parameter size. Curry-DPO also achieves the highest adjusted win\nrates on Vicuna, WizardLM, and UltraFeedback test datasets (90.7%, 87.1%, and\n87.9% respectively) in our experiments, with notable gains of upto 7.5% when\ncompared to standard DPO technique. We release the preference pairs used in\nalignment at:\nhttps://huggingface.co/datasets/ServiceNow-AI/Curriculum_DPO_preferences\n","authors":["Pulkit Pattnaik","Rishabh Maheshwary","Kelechi Ogueji","Vikas Yadav","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2403.07230v2.pdf","comment":"Published at EMNLP 2024 as long (findings) conference paper"},{"id":"http://arxiv.org/abs/2411.02540v2","updated":"2024-11-08T08:29:10Z","published":"2024-11-04T19:21:06Z","title":"GraphXAIN: Narratives to Explain Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) are a powerful technique for machine learning on\ngraph-structured data, yet they pose interpretability challenges, especially\nfor non-expert users. Existing GNN explanation methods often yield technical\noutputs such as subgraphs and feature importance scores, which are not easily\nunderstood. Building on recent insights from social science and other\nExplainable AI (XAI) methods, we propose GraphXAIN, a natural language\nnarrative that explains individual predictions made by GNNs. We present a\nmodel-agnostic and explainer-agnostic XAI approach that complements graph\nexplainers by generating GraphXAINs, using Large Language Models (LLMs) and\nintegrating graph data, individual predictions from GNNs, explanatory\nsubgraphs, and feature importances. We define XAI Narratives and XAI\nDescriptions, highlighting their distinctions and emphasizing the importance of\nnarrative principles in effective explanations. By incorporating natural\nlanguage narratives, our approach supports graph practitioners and non-expert\nusers, aligning with social science research on explainability and enhancing\nuser understanding and trust in complex GNN models. We demonstrate GraphXAIN's\ncapabilities on a real-world graph dataset, illustrating how its generated\nnarratives can aid understanding compared to traditional graph explainer\noutputs or other descriptive explanation methods.\n","authors":["Mateusz Cedro","David Martens"],"pdf_url":"https://arxiv.org/pdf/2411.02540v2.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.05399v1","updated":"2024-11-08T08:26:42Z","published":"2024-11-08T08:26:42Z","title":"Post-Hoc Robustness Enhancement in Graph Neural Networks with\n  Conditional Random Fields","summary":"  Graph Neural Networks (GNNs), which are nowadays the benchmark approach in\ngraph representation learning, have been shown to be vulnerable to adversarial\nattacks, raising concerns about their real-world applicability. While existing\ndefense techniques primarily concentrate on the training phase of GNNs,\ninvolving adjustments to message passing architectures or pre-processing\nmethods, there is a noticeable gap in methods focusing on increasing robustness\nduring inference. In this context, this study introduces RobustCRF, a post-hoc\napproach aiming to enhance the robustness of GNNs at the inference stage. Our\nproposed method, founded on statistical relational learning using a Conditional\nRandom Field, is model-agnostic and does not require prior knowledge about the\nunderlying model architecture. We validate the efficacy of this approach across\nvarious models, leveraging benchmark node classification datasets.\n","authors":["Yassine Abbahaddou","Sofiane Ennadir","Johannes F. Lutzeyer","Fragkiskos D. Malliaros","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2411.05399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05384v1","updated":"2024-11-08T07:46:50Z","published":"2024-11-08T07:46:50Z","title":"Advancing Meteorological Forecasting: AI-based Approach to Synoptic\n  Weather Map Analysis","summary":"  As global warming increases the complexity of weather patterns; the precision\nof weather forecasting becomes increasingly important. Our study proposes a\nnovel preprocessing method and convolutional autoencoder model developed to\nimprove the interpretation of synoptic weather maps. These are critical for\nmeteorologists seeking a thorough understanding of weather conditions. This\nmodel could recognize historical synoptic weather maps that nearly match\ncurrent atmospheric conditions, marking a significant step forward in modern\ntechnology in meteorological forecasting. This comprises unsupervised learning\nmodels like VQ-VQE, as well as supervised learning models like VGG16, VGG19,\nXception, InceptionV3, and ResNet50 trained on the ImageNet dataset, as well as\nresearch into newer models like EfficientNet and ConvNeXt. Our findings proved\nthat, while these models perform well in various settings, their ability to\nidentify comparable synoptic weather maps has certain limits. Our research,\nmotivated by the primary goal of significantly increasing meteorologists'\nefficiency in labor-intensive tasks, discovered that cosine similarity is the\nmost effective metric, as determined by a combination of quantitative and\nqualitative assessments to accurately identify relevant historical weather\npatterns. This study broadens our understanding by shifting the emphasis from\nnumerical precision to practical application, ensuring that our model is\neffective in theory practical, and accessible in the complex and dynamic field\nof meteorology.\n","authors":["Yo-Hwan Choi","Seon-Yu Kang","Minjong Cheon"],"pdf_url":"https://arxiv.org/pdf/2411.05384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04358v2","updated":"2024-11-08T07:31:26Z","published":"2024-11-07T01:31:48Z","title":"Robust and Efficient Fine-tuning of LLMs with Bayesian\n  Reparameterization of Low-Rank Adaptation","summary":"  Large Language Models (LLMs) are highly resource-intensive to fine-tune due\nto their enormous size. While low-rank adaptation is a prominent\nparameter-efficient fine-tuning approach, it suffers from sensitivity to\nhyperparameter choices, leading to instability in model performance on\nfine-tuning downstream tasks. This paper highlights the importance of effective\nparameterization in low-rank fine-tuning to reduce estimator variance and\nenhance the stability of final model outputs. We propose MonteCLoRA, an\nefficient fine-tuning technique, employing Monte Carlo estimation to learn an\nunbiased posterior estimation of low-rank parameters with low expected\nvariance, which stabilizes fine-tuned LLMs with only O(1) additional\nparameters. MonteCLoRA shows significant improvements in accuracy and\nrobustness, achieving up to 3.8% higher accuracy and 8.6% greater robustness\nthan existing efficient fine-tuning methods on natural language understanding\ntasks with pre-trained RoBERTa-base. Furthermore, in generative tasks with\npre-trained LLaMA-1-7B, MonteCLoRA demonstrates robust zero-shot performance\nwith 50% lower variance than the contemporary efficient fine-tuning methods.\nThe theoretical and empirical results presented in the paper underscore how\nparameterization and hyperpriors balance exploration-exploitation in the\nlow-rank parametric space, therefore leading to more optimal and robust\nparameter estimation during efficient fine-tuning.\n","authors":["Ayan Sengupta","Vaibhav Seth","Arinjay Pathak","Natraj Raman","Sriram Gopalakrishnan","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2411.04358v2.pdf","comment":"48 pages, 10 figures, 10 tables, Code:\n  https://github.com/LCS2-IIITD/MonteCLoRA"},{"id":"http://arxiv.org/abs/2401.16407v2","updated":"2024-11-08T07:30:25Z","published":"2024-01-29T18:46:53Z","title":"Is K-fold cross validation the best model selection method for Machine\n  Learning?","summary":"  As a technique that can compactly represent complex patterns, machine\nlearning has significant potential for predictive inference. K-fold\ncross-validation (CV) is the most common approach to ascertaining the\nlikelihood that a machine learning outcome is generated by chance, and it\nfrequently outperforms conventional hypothesis testing. This improvement uses\nmeasures directly obtained from machine learning classifications, such as\naccuracy, that do not have a parametric description. To approach a frequentist\nanalysis within machine learning pipelines, a permutation test or simple\nstatistics from data partitions (i.e., folds) can be added to estimate\nconfidence intervals. Unfortunately, neither parametric nor non-parametric\ntests solve the inherent problems of partitioning small sample-size datasets\nand learning from heterogeneous data sources. The fact that machine learning\nstrongly depends on the learning parameters and the distribution of data across\nfolds recapitulates familiar difficulties around excess false positives and\nreplication. A novel statistical test based on K-fold CV and the Upper Bound of\nthe actual risk (K-fold CUBV) is proposed, where uncertain predictions of\nmachine learning with CV are bounded by the worst case through the evaluation\nof concentration inequalities. Probably Approximately Correct-Bayesian upper\nbounds for linear classifiers in combination with K-fold CV are derived and\nused to estimate the actual risk. The performance with simulated and\nneuroimaging datasets suggests that K-fold CUBV is a robust criterion for\ndetecting effects and validating accuracy values obtained from machine learning\nand classical CV schemes, while avoiding excess false positives.\n","authors":["Juan M Gorriz","R. Martin Clemente","F Segovia","J Ramirez","A Ortiz","J. Suckling"],"pdf_url":"https://arxiv.org/pdf/2401.16407v2.pdf","comment":"40 pages, 24 figures"},{"id":"http://arxiv.org/abs/2411.05378v1","updated":"2024-11-08T07:19:49Z","published":"2024-11-08T07:19:49Z","title":"Machine learning for prediction of dose-volume histograms of\n  organs-at-risk in prostate cancer from simple structure volume parameters","summary":"  Dose prediction is an area of ongoing research that facilitates radiotherapy\nplanning. Most commercial models utilise imaging data and intense computing\nresources. This study aimed to predict the dose-volume of rectum and bladder\nfrom volumes of target, at-risk structure organs and their overlap regions\nusing machine learning. Dose-volume information of 94 patients with prostate\ncancer planned for 6000cGy in 20 fractions was exported from the treatment\nplanning system as text files and mined to create a training dataset. Several\nstatistical modelling, machine learning methods, and a new fuzzy rule-based\nprediction (FRBP) model were explored and validated on an independent dataset\nof 39 patients. The median absolute error was 2.0%-3.7% for bladder and\n1.7-2.4% for rectum in the 4000-6420cGy range. For 5300cGy, 5600cGy and\n6000cGy, the median difference was less than 2.5% for rectum and 3.8% for\nbladder. The FRBP model produced errors of 1.2%, 1.3%, 0.9% and 1.6%, 1.2%,\n0.1% for the rectum and bladder respectively at these dose levels. These\nfindings indicate feasibility of obtaining accurate predictions of the\nclinically important dose-volume parameters for rectum and bladder using just\nthe volumes of these structures.\n","authors":["Saheli Saha","Debasmita Banerjee","Rishi Ram","Gowtham Reddy","Debashree Guha","Arnab Sarkar","Bapi Dutta","Moses ArunSingh S","Suman Chakraborty","Indranil Mallick"],"pdf_url":"https://arxiv.org/pdf/2411.05378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05375v1","updated":"2024-11-08T07:05:06Z","published":"2024-11-08T07:05:06Z","title":"Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking","summary":"  Current automated fact-checking (AFC) approaches commonly evaluate evidence\neither implicitly via the predicted verdicts or by comparing retrieved evidence\nwith a predefined closed knowledge source, such as Wikipedia. However, these\nmethods suffer from limitations, resulting from their reliance on evaluation\nmetrics developed for different purposes and constraints imposed by closed\nknowledge sources. Recent advances in natural language generation (NLG)\nevaluation offer new possibilities for evidence assessment. In this work, we\nintroduce Ev2R, an evaluation framework for AFC that comprises three types of\napproaches for evidence evaluation: reference-based, proxy-reference, and\nreference-less. We evaluate their effectiveness through agreement with human\nratings and adversarial tests, and demonstrate that prompt-based scorers,\nparticularly those leveraging LLMs and reference evidence, outperform\ntraditional evaluation approaches.\n","authors":["Mubashara Akhtar","Michael Schlichtkrull","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2411.05375v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2401.17263v5","updated":"2024-11-08T06:57:05Z","published":"2024-01-30T18:56:08Z","title":"Robust Prompt Optimization for Defending Language Models Against\n  Jailbreaking Attacks","summary":"  Despite advances in AI alignment, large language models (LLMs) remain\nvulnerable to adversarial attacks or jailbreaking, in which adversaries can\nmodify prompts to induce unwanted behavior. While some defenses have been\nproposed, they have not been adapted to newly proposed attacks and more\nchallenging threat models. To address this, we propose an optimization-based\nobjective for defending LLMs against jailbreaking attacks and an algorithm,\nRobust Prompt Optimization (RPO) to create robust system-level defenses. Our\napproach directly incorporates the adversary into the defensive objective and\noptimizes a lightweight and transferable suffix, enabling RPO to adapt to\nworst-case adaptive attacks. Our theoretical and experimental results show\nimproved robustness to both jailbreaks seen during optimization and unknown\njailbreaks, reducing the attack success rate (ASR) on GPT-4 to 6% and Llama-2\nto 0% on JailbreakBench, setting the state-of-the-art. Code can be found at\nhttps://github.com/lapisrocks/rpo\n","authors":["Andy Zhou","Bo Li","Haohan Wang"],"pdf_url":"https://arxiv.org/pdf/2401.17263v5.pdf","comment":"NeurIPS 2024 Spotlight; code available at\n  https://github.com/lapisrocks/rpo"},{"id":"http://arxiv.org/abs/2411.04680v2","updated":"2024-11-08T06:47:39Z","published":"2024-11-07T13:08:06Z","title":"Differentially Private Continual Learning using Pre-Trained Models","summary":"  This work explores the intersection of continual learning (CL) and\ndifferential privacy (DP). Crucially, continual learning models must retain\nknowledge across tasks, but this conflicts with the differential privacy\nrequirement of restricting individual samples to be memorised in the model. We\npropose using pre-trained models to address the trade-offs between privacy and\nperformance in a continual learning setting. More specifically, we present\nnecessary assumptions to enable privacy-preservation and propose combining\npre-trained models with parameter-free classifiers and parameter-efficient\nadapters that are learned under differential privacy. Our experiments\ndemonstrate their effectiveness and provide insights into balancing the\ncompeting demands of continual learning and privacy.\n","authors":["Marlon Tobaben","Marcus Klasson","Rui Li","Arno Solin","Antti Honkela"],"pdf_url":"https://arxiv.org/pdf/2411.04680v2.pdf","comment":"15 pages, 3 figures, Accepted at Scalable Continual Learning for\n  Lifelong Foundation Models Workshop at 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2307.09254v2","updated":"2024-11-08T06:47:04Z","published":"2023-07-18T13:36:24Z","title":"Selective Generation for Controllable Language Models","summary":"  Trustworthiness of generative language models (GLMs) is crucial in their\ndeployment to critical decision making systems. Hence, certified risk control\nmethods such as selective prediction and conformal prediction have been applied\nto mitigating the hallucination problem in various supervised downstream tasks.\nHowever, the lack of appropriate correctness metric hinders applying such\nprincipled methods to language generation tasks. In this paper, we circumvent\nthis problem by leveraging the concept of textual entailment to evaluate the\ncorrectness of the generated sequence, and propose two selective generation\nalgorithms which control the false discovery rate with respect to the textual\nentailment relation (FDR-E) with a theoretical guarantee:\n$\\texttt{SGen}^{\\texttt{Sup}}$ and $\\texttt{SGen}^{\\texttt{Semi}}$.\n$\\texttt{SGen}^{\\texttt{Sup}}$, a direct modification of the selective\nprediction, is a supervised learning algorithm which exploits\nentailment-labeled data, annotated by humans. Since human annotation is costly,\nwe further propose a semi-supervised version, $\\texttt{SGen}^{\\texttt{Semi}}$,\nwhich fully utilizes the unlabeled data by pseudo-labeling, leveraging an\nentailment set function learned via conformal prediction. Furthermore,\n$\\texttt{SGen}^{\\texttt{Semi}}$ enables to use more general class of selection\nfunctions, neuro-selection functions, and provides users with an optimal\nselection function class given multiple candidates. Finally, we demonstrate the\nefficacy of the $\\texttt{SGen}$ family in achieving a desired FDR-E level with\ncomparable selection efficiency to those from baselines on both open and closed\nsource GLMs. Code and datasets are provided at\nhttps://github.com/ml-postech/selective-generation.\n","authors":["Minjae Lee","Kyungmin Kim","Taesoo Kim","Sangdon Park"],"pdf_url":"https://arxiv.org/pdf/2307.09254v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2303.07909v3","updated":"2024-11-08T06:19:33Z","published":"2023-03-14T13:49:54Z","title":"Text-to-image Diffusion Models in Generative AI: A Survey","summary":"  This survey reviews the progress of diffusion models in generating images\nfrom text, ~\\textit{i.e.} text-to-image diffusion models. As a self-contained\nwork, this survey starts with a brief introduction of how diffusion models work\nfor image synthesis, followed by the background for text-conditioned image\nsynthesis. Based on that, we present an organized review of pioneering methods\nand their improvements on text-to-image generation. We further summarize\napplications beyond image generation, such as text-guided generation for\nvarious modalities like videos, and text-guided image editing. Beyond the\nprogress made so far, we discuss existing challenges and promising future\ndirections.\n","authors":["Chenshuang Zhang","Chaoning Zhang","Mengchun Zhang","In So Kweon","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2303.07909v3.pdf","comment":"First survey on the recent progress of text-to-image generation based\n  on the diffusion model"},{"id":"http://arxiv.org/abs/2411.05353v1","updated":"2024-11-08T06:19:29Z","published":"2024-11-08T06:19:29Z","title":"Controlling Grokking with Nonlinearity and Data Symmetry","summary":"  This paper demonstrates that grokking behavior in modular arithmetic with a\nmodulus P in a neural network can be controlled by modifying the profile of the\nactivation function as well as the depth and width of the model. Plotting the\neven PCA projections of the weights of the last NN layer against their odd\nprojections further yields patterns which become significantly more uniform\nwhen the nonlinearity is increased by incrementing the number of layers. These\npatterns can be employed to factor P when P is nonprime. Finally, a metric for\nthe generalization ability of the network is inferred from the entropy of the\nlayer weights while the degree of nonlinearity is related to correlations\nbetween the local entropy of the weights of the neurons in the final layer.\n","authors":["Ahmed Salah","David Yevick"],"pdf_url":"https://arxiv.org/pdf/2411.05353v1.pdf","comment":"15 pages, 14 figures"},{"id":"http://arxiv.org/abs/2411.05354v1","updated":"2024-11-08T06:19:29Z","published":"2024-11-08T06:19:29Z","title":"RED: Residual Estimation Diffusion for Low-Dose PET Sinogram\n  Reconstruction","summary":"  Recent advances in diffusion models have demonstrated exceptional performance\nin generative tasks across vari-ous fields. In positron emission tomography\n(PET), the reduction in tracer dose leads to information loss in sino-grams.\nUsing diffusion models to reconstruct missing in-formation can improve imaging\nquality. Traditional diffu-sion models effectively use Gaussian noise for image\nre-constructions. However, in low-dose PET reconstruction, Gaussian noise can\nworsen the already sparse data by introducing artifacts and inconsistencies. To\naddress this issue, we propose a diffusion model named residual esti-mation\ndiffusion (RED). From the perspective of diffusion mechanism, RED uses the\nresidual between sinograms to replace Gaussian noise in diffusion process,\nrespectively sets the low-dose and full-dose sinograms as the starting point\nand endpoint of reconstruction. This mechanism helps preserve the original\ninformation in the low-dose sinogram, thereby enhancing reconstruction\nreliability. From the perspective of data consistency, RED introduces a drift\ncorrection strategy to reduce accumulated prediction errors during the reverse\nprocess. Calibrating the inter-mediate results of reverse iterations helps\nmaintain the data consistency and enhances the stability of reconstruc-tion\nprocess. Experimental results show that RED effec-tively improves the quality\nof low-dose sinograms as well as the reconstruction results. The code is\navailable at: https://github.com/yqx7150/RED.\n","authors":["Xingyu Ai","Bin Huang","Fang Chen","Liu Shi","Binxuan Li","Shaoyu Wang","Qiegen Liu"],"pdf_url":"https://arxiv.org/pdf/2411.05354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17538v2","updated":"2024-11-08T05:59:49Z","published":"2024-05-27T18:00:00Z","title":"Bayesian RG Flow in Neural Network Field Theories","summary":"  The Neural Network Field Theory correspondence (NNFT) is a mapping from\nneural network (NN) architectures into the space of statistical field theories\n(SFTs). The Bayesian renormalization group (BRG) is an information-theoretic\ncoarse graining scheme that generalizes the principles of the exact\nrenormalization group (ERG) to arbitrarily parameterized probability\ndistributions, including those of NNs. In BRG, coarse graining is performed in\nparameter space with respect to an information-theoretic distinguishability\nscale set by the Fisher information metric. In this paper, we unify NNFT and\nBRG to form a powerful new framework for exploring the space of NNs and SFTs,\nwhich we coin BRG-NNFT. With BRG-NNFT, NN training dynamics can be interpreted\nas inducing a flow in the space of SFTs from the information-theoretic `IR'\n$\\rightarrow$ `UV'. Conversely, applying an information-shell coarse graining\nto the trained network's parameters induces a flow in the space of SFTs from\nthe information-theoretic `UV' $\\rightarrow$ `IR'. When the\ninformation-theoretic cutoff scale coincides with a standard momentum scale,\nBRG is equivalent to ERG. We demonstrate the BRG-NNFT correspondence on two\nanalytically tractable examples. First, we construct BRG flows for trained,\ninfinite-width NNs, of arbitrary depth, with generic activation functions. As a\nspecial case, we then restrict to architectures with a single infinitely-wide\nlayer, scalar outputs, and generalized cos-net activations. In this case, we\nshow that BRG coarse-graining corresponds exactly to the momentum-shell ERG\nflow of a free scalar SFT. Our analytic results are corroborated by a numerical\nexperiment in which an ensemble of asymptotically wide NNs are trained and\nsubsequently renormalized using an information-shell BRG scheme.\n","authors":["Jessica N. Howard","Marc S. Klinger","Anindita Maiti","Alexander G. Stapleton"],"pdf_url":"https://arxiv.org/pdf/2405.17538v2.pdf","comment":"39 pages, 9 figures, 2 tables; updated references and fixed typos"},{"id":"http://arxiv.org/abs/2411.05346v1","updated":"2024-11-08T05:58:09Z","published":"2024-11-08T05:58:09Z","title":"Reinforcement Learning for Adaptive Resource Scheduling in Complex\n  System Environments","summary":"  This study presents a novel computer system performance optimization and\nadaptive workload management scheduling algorithm based on Q-learning. In\nmodern computing environments, characterized by increasing data volumes, task\ncomplexity, and dynamic workloads, traditional static scheduling methods such\nas Round-Robin and Priority Scheduling fail to meet the demands of efficient\nresource allocation and real-time adaptability. By contrast, Q-learning, a\nreinforcement learning algorithm, continuously learns from system state\nchanges, enabling dynamic scheduling and resource optimization. Through\nextensive experiments, the superiority of the proposed approach is demonstrated\nin both task completion time and resource utilization, outperforming\ntraditional and dynamic resource allocation (DRA) algorithms. These findings\nare critical as they highlight the potential of intelligent scheduling\nalgorithms based on reinforcement learning to address the growing complexity\nand unpredictability of computing environments. This research provides a\nfoundation for the integration of AI-driven adaptive scheduling in future\nlarge-scale systems, offering a scalable, intelligent solution to enhance\nsystem performance, reduce operating costs, and support sustainable energy\nconsumption. The broad applicability of this approach makes it a promising\ncandidate for next-generation computing frameworks, such as edge computing,\ncloud computing, and the Internet of Things.\n","authors":["Pochun Li","Yuyang Xiao","Jinghua Yan","Xuan Li","Xiaoye Wang"],"pdf_url":"https://arxiv.org/pdf/2411.05346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04682v4","updated":"2024-11-08T05:45:45Z","published":"2024-05-07T21:52:39Z","title":"TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation","summary":"  Most of these text-to-video (T2V) generative models often produce\nsingle-scene video clips that depict an entity performing a particular action\n(e.g., 'a red panda climbing a tree'). However, it is pertinent to generate\nmulti-scene videos since they are ubiquitous in the real-world (e.g., 'a red\npanda climbing a tree' followed by 'the red panda sleeps on the top of the\ntree'). To generate multi-scene videos from the pretrained T2V model, we\nintroduce a simple and effective Time-Aligned Captions (TALC) framework.\nSpecifically, we enhance the text-conditioning mechanism in the T2V\narchitecture to recognize the temporal alignment between the video scenes and\nscene descriptions. For instance, we condition the visual features of the\nearlier and later scenes of the generated video with the representations of the\nfirst scene description (e.g., 'a red panda climbing a tree') and second scene\ndescription (e.g., 'the red panda sleeps on the top of the tree'),\nrespectively. As a result, we show that the T2V model can generate multi-scene\nvideos that adhere to the multi-scene text descriptions and be visually\nconsistent (e.g., entity and background). Further, we finetune the pretrained\nT2V model with multi-scene video-text data using the TALC framework. We show\nthat the TALC-finetuned model outperforms the baseline by achieving a relative\ngain of 29% in the overall score, which averages visual consistency and text\nadherence using human evaluation.\n","authors":["Hritik Bansal","Yonatan Bitton","Michal Yarom","Idan Szpektor","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2405.04682v4.pdf","comment":"22 pages, 14 figures, 11 tables"},{"id":"http://arxiv.org/abs/2410.21556v3","updated":"2024-11-08T05:35:04Z","published":"2024-10-28T21:35:08Z","title":"Super-resolution in disordered media using neural networks","summary":"  We propose a methodology that exploits large and diverse data sets to\naccurately estimate the ambient medium's Green's functions in strongly\nscattering media. Given these estimates, obtained with and without the use of\nneural networks, excellent imaging results are achieved, with a resolution that\nis better than that of a homogeneous medium. This phenomenon, also known as\nsuper-resolution, occurs because the ambient scattering medium effectively\nenhances the physical imaging aperture. This work has been submitted to the\nIEEE for possible publication. Copyright may be transferred without notice,\nafter which this version may no longer be accessible.\n","authors":["Alexander Christie","Matan Leibovich","Miguel Moscoso","Alexei Novikov","George Papanicolaou","Chrysoula Tsogka"],"pdf_url":"https://arxiv.org/pdf/2410.21556v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19234v2","updated":"2024-11-08T05:34:40Z","published":"2024-07-27T11:35:19Z","title":"Ordered Momentum for Asynchronous SGD","summary":"  Distributed learning is essential for training large-scale deep models.\nAsynchronous SGD (ASGD) and its variants are commonly used distributed learning\nmethods, particularly in scenarios where the computing capabilities of workers\nin the cluster are heterogeneous. Momentum has been acknowledged for its\nbenefits in both optimization and generalization in deep model training.\nHowever, existing works have found that naively incorporating momentum into\nASGD can impede the convergence. In this paper, we propose a novel method\ncalled ordered momentum (OrMo) for ASGD. In OrMo, momentum is incorporated into\nASGD by organizing the gradients in order based on their iteration indexes. We\ntheoretically prove the convergence of OrMo with both constant and\ndelay-adaptive learning rates for non-convex problems. To the best of our\nknowledge, this is the first work to establish the convergence analysis of ASGD\nwith momentum without dependence on the maximum delay. Empirical results\ndemonstrate that OrMo can achieve better convergence performance compared with\nASGD and other asynchronous methods with momentum.\n","authors":["Chang-Wei Shi","Yi-Rui Yang","Wu-Jun Li"],"pdf_url":"https://arxiv.org/pdf/2407.19234v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05335v1","updated":"2024-11-08T05:14:46Z","published":"2024-11-08T05:14:46Z","title":"A Quality-Centric Framework for Generic Deepfake Detection","summary":"  This paper addresses the generalization issue in deepfake detection by\nharnessing forgery quality in training data. Generally, the forgery quality of\ndifferent deepfakes varies: some have easily recognizable forgery clues, while\nothers are highly realistic. Existing works often train detectors on a mix of\ndeepfakes with varying forgery qualities, potentially leading detectors to\nshort-cut the easy-to-spot artifacts from low-quality forgery samples, thereby\nhurting generalization performance. To tackle this issue, we propose a novel\nquality-centric framework for generic deepfake detection, which is composed of\na Quality Evaluator, a low-quality data enhancement module, and a learning\npacing strategy that explicitly incorporates forgery quality into the training\nprocess. The framework is inspired by curriculum learning, which is designed to\ngradually enable the detector to learn more challenging deepfake samples,\nstarting with easier samples and progressing to more realistic ones. We employ\nboth static and dynamic assessments to assess the forgery quality, combining\ntheir scores to produce a final rating for each training sample. The rating\nscore guides the selection of deepfake samples for training, with higher-rated\nsamples having a higher probability of being chosen. Furthermore, we propose a\nnovel frequency data augmentation method specifically designed for low-quality\nforgery samples, which helps to reduce obvious forgery traces and improve their\noverall realism. Extensive experiments show that our method can be applied in a\nplug-and-play manner and significantly enhance the generalization performance.\n","authors":["Wentang Song","Zhiyuan Yan","Yuzhen Lin","Taiping Yao","Changsheng Chen","Shen Chen","Yandan Zhao","Shouhong Ding","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2411.05335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05331v1","updated":"2024-11-08T05:12:16Z","published":"2024-11-08T05:12:16Z","title":"Discovering Latent Structural Causal Models from Spatio-Temporal Data","summary":"  Many important phenomena in scientific fields such as climate, neuroscience,\nand epidemiology are naturally represented as spatiotemporal gridded data with\ncomplex interactions. For example, in climate science, researchers aim to\nuncover how large-scale events, such as the North Atlantic Oscillation (NAO)\nand the Antarctic Oscillation (AAO), influence other global processes.\nInferring causal relationships from these data is a challenging problem\ncompounded by the high dimensionality of such data and the correlations between\nspatially proximate points. We present SPACY (SPAtiotemporal Causal discoverY),\na novel framework based on variational inference, designed to explicitly model\nlatent time-series and their causal relationships from spatially confined modes\nin the data. Our method uses an end-to-end training process that maximizes an\nevidence-lower bound (ELBO) for the data likelihood. Theoretically, we show\nthat, under some conditions, the latent variables are identifiable up to\ntransformation by an invertible matrix. Empirically, we show that SPACY\noutperforms state-of-the-art baselines on synthetic data, remains scalable for\nlarge grids, and identifies key known phenomena from real-world climate data.\n","authors":["Kun Wang","Sumanth Varambally","Duncan Watson-Parris","Yi-An Ma","Rose Yu"],"pdf_url":"https://arxiv.org/pdf/2411.05331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05330v1","updated":"2024-11-08T05:06:47Z","published":"2024-11-08T05:06:47Z","title":"Inversion-based Latent Bayesian Optimization","summary":"  Latent Bayesian optimization (LBO) approaches have successfully adopted\nBayesian optimization over a continuous latent space by employing an\nencoder-decoder architecture to address the challenge of optimization in a high\ndimensional or discrete input space. LBO learns a surrogate model to\napproximate the black-box objective function in the latent space. However, we\nobserved that most LBO methods suffer from the `misalignment problem`, which is\ninduced by the reconstruction error of the encoder-decoder architecture. It\nhinders learning an accurate surrogate model and generating high-quality\nsolutions. In addition, several trust region-based LBO methods select the\nanchor, the center of the trust region, based solely on the objective function\nvalue without considering the trust region`s potential to enhance the\noptimization process. To address these issues, we propose Inversion-based\nLatent Bayesian Optimization (InvBO), a plug-and-play module for LBO. InvBO\nconsists of two components: an inversion method and a potential-aware trust\nregion anchor selection. The inversion method searches the latent code that\ncompletely reconstructs the given target data. The potential-aware trust region\nanchor selection considers the potential capability of the trust region for\nbetter local optimization. Experimental results demonstrate the effectiveness\nof InvBO on nine real-world benchmarks, such as molecule design and arithmetic\nexpression fitting tasks. Code is available at https://github.com/mlvlab/InvBO.\n","authors":["Jaewon Chu","Jinyoung Park","Seunghun Lee","Hyunwoo J. Kim"],"pdf_url":"https://arxiv.org/pdf/2411.05330v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05324v1","updated":"2024-11-08T04:37:55Z","published":"2024-11-08T04:37:55Z","title":"SASWISE-UE: Segmentation and Synthesis with Interpretable Scalable\n  Ensembles for Uncertainty Estimation","summary":"  This paper introduces an efficient sub-model ensemble framework aimed at\nenhancing the interpretability of medical deep learning models, thus increasing\ntheir clinical applicability. By generating uncertainty maps, this framework\nenables end-users to evaluate the reliability of model outputs. We developed a\nstrategy to develop diverse models from a single well-trained checkpoint,\nfacilitating the training of a model family. This involves producing multiple\noutputs from a single input, fusing them into a final output, and estimating\nuncertainty based on output disagreements. Implemented using U-Net and UNETR\nmodels for segmentation and synthesis tasks, this approach was tested on CT\nbody segmentation and MR-CT synthesis datasets. It achieved a mean Dice\ncoefficient of 0.814 in segmentation and a Mean Absolute Error of 88.17 HU in\nsynthesis, improved from 89.43 HU by pruning. Additionally, the framework was\nevaluated under corruption and undersampling, maintaining correlation between\nuncertainty and error, which highlights its robustness. These results suggest\nthat the proposed approach not only maintains the performance of well-trained\nmodels but also enhances interpretability through effective uncertainty\nestimation, applicable to both convolutional and transformer models in a range\nof imaging tasks.\n","authors":["Weijie Chen","Alan McMillan"],"pdf_url":"https://arxiv.org/pdf/2411.05324v1.pdf","comment":"16 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2409.12296v2","updated":"2024-11-08T04:32:45Z","published":"2024-09-18T20:08:19Z","title":"JKO for Landau: a variational particle method for homogeneous Landau\n  equation","summary":"  Inspired by the gradient flow viewpoint of the Landau equation and\ncorresponding dynamic formulation of the Landau metric in [arXiv:2007.08591],\nwe develop a novel implicit particle method for the Landau equation in the\nframework of the JKO scheme. We first reformulate the Landau metric in a\ncomputationally friendly form, and then translate it into the Lagrangian\nviewpoint using the flow map. A key observation is that, while the flow map\nevolves according to a rather complicated integral equation, the unknown\ncomponent is merely a score function of the corresponding density plus an\nadditional term in the null space of the collision kernel. This insight guides\nus in designing and training the neural network for the flow map. Additionally,\nthe objective function is in a double summation form, making it highly suitable\nfor stochastic methods. Consequently, we design a tailored version of\nstochastic gradient descent that maintains particle interactions and\nsignificantly reduces the computational complexity. Compared to other\ndeterministic particle methods, the proposed method enjoys exact entropy\ndissipation and unconditional stability, therefore making it suitable for\nlarge-scale plasma simulations over extended time periods.\n","authors":["Yan Huang","Li Wang"],"pdf_url":"https://arxiv.org/pdf/2409.12296v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19976v2","updated":"2024-11-08T04:30:51Z","published":"2024-09-30T06:04:04Z","title":"Learning Partial Differential Equations with Deep Parallel Neural\n  Operator","summary":"  In recent years, Solving partial differential equations has shifted the focus\nof traditional neural network studies from finite-dimensional Euclidean spaces\nto generalized functional spaces in research. A novel methodology is to learn\nan operator as a means of approximating the mapping between outputs. Currently,\nresearchers have proposed a variety of operator architectures. Nevertheless,\nthe majority of these architectures adopt an iterative update architecture,\nwhereby a single operator is learned from the same function space. In practical\nphysical science problems, the numerical solutions of partial differential\nequations are complex, and a serial single operator is unable to accurately\napproximate the intricate mapping between input and output. So, We propose a\ndeep parallel operator model (DPNO) for efficiently and accurately solving\npartial differential equations. DPNO employs convolutional neural networks to\nextract local features and map data into distinct latent spaces. Designing a\nparallel block of double Fourier neural operators to solve the iterative error\nproblem. DPNO approximates complex mappings between inputs and outputs by\nlearning multiple operators in different potential spaces in parallel blocks.\nDPNO achieved the best performance on five of them, with an average improvement\nof 10.5\\%, and ranked second on one dataset.\n","authors":["Qinglong Ma","Peizhi Zhao","Sen Wang","Tao Song"],"pdf_url":"https://arxiv.org/pdf/2409.19976v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05318v1","updated":"2024-11-08T04:20:12Z","published":"2024-11-08T04:20:12Z","title":"Fairness in Monotone $k$-submodular Maximization: Algorithms and\n  Applications","summary":"  Submodular optimization has become increasingly prominent in machine learning\nand fairness has drawn much attention. In this paper, we propose to study the\nfair $k$-submodular maximization problem and develop a\n$\\frac{1}{3}$-approximation greedy algorithm with a running time of\n$\\mathcal{O}(knB)$. To the best of our knowledge, our work is the first to\nincorporate fairness in the context of $k$-submodular maximization, and our\ntheoretical guarantee matches the best-known $k$-submodular maximization\nresults without fairness constraints. In addition, we have developed a faster\nthreshold-based algorithm that achieves a $(\\frac{1}{3} - \\epsilon)$\napproximation with $\\mathcal{O}(\\frac{kn}{\\epsilon} \\log \\frac{B}{\\epsilon})$\nevaluations of the function $f$. Furthermore, for both algorithms, we provide\napproximation guarantees when the $k$-submodular function is not accessible but\nonly can be approximately accessed. We have extensively validated our\ntheoretical findings through empirical research and examined the practical\nimplications of fairness. Specifically, we have addressed the question: ``What\nis the price of fairness?\" through case studies on influence maximization with\n$k$ topics and sensor placement with $k$ types. The experimental results show\nthat the fairness constraints do not significantly undermine the quality of\nsolutions.\n","authors":["Yanhui Zhu","Samik Basu","A. Pavan"],"pdf_url":"https://arxiv.org/pdf/2411.05318v1.pdf","comment":"17 pages. To appear in IEEE BigData 2024"},{"id":"http://arxiv.org/abs/2411.05316v1","updated":"2024-11-08T04:15:08Z","published":"2024-11-08T04:15:08Z","title":"Exploring the Alignment Landscape: LLMs and Geometric Deep Models in\n  Protein Representation","summary":"  Latent representation alignment has become a foundational technique for\nconstructing multimodal large language models (MLLM) by mapping embeddings from\ndifferent modalities into a shared space, often aligned with the embedding\nspace of large language models (LLMs) to enable effective cross-modal\nunderstanding. While preliminary protein-focused MLLMs have emerged, they have\npredominantly relied on heuristic approaches, lacking a fundamental\nunderstanding of optimal alignment practices across representations. In this\nstudy, we explore the alignment of multimodal representations between LLMs and\nGeometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate\nthree state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with\nfour protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines\nalignment factors from both model and protein perspectives, identifying\nchallenges in current alignment methodologies and proposing strategies to\nimprove the alignment process. Our key findings reveal that GDMs incorporating\nboth graph and 3D structural information align better with LLMs, larger LLMs\ndemonstrate improved alignment capabilities, and protein rarity significantly\nimpacts alignment performance. We also find that increasing GDM embedding\ndimensions, using two-layer projection heads, and fine-tuning LLMs on\nprotein-specific data substantially enhance alignment quality. These strategies\noffer potential enhancements to the performance of protein-related multimodal\nmodels. Our code and data are available at\nhttps://github.com/Tizzzzy/LLM-GDM-alignment.\n","authors":["Dong Shu","Bingbing Duan","Kai Guo","Kaixiong Zhou","Jiliang Tang","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2411.05316v1.pdf","comment":"24 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.05315v1","updated":"2024-11-08T04:13:52Z","published":"2024-11-08T04:13:52Z","title":"Differentiable Calibration of Inexact Stochastic Simulation Models via\n  Kernel Score Minimization","summary":"  Stochastic simulation models are generative models that mimic complex systems\nto help with decision-making. The reliability of these models heavily depends\non well-calibrated input model parameters. However, in many practical\nscenarios, only output-level data are available to learn the input model\nparameters, which is challenging due to the often intractable likelihood of the\nstochastic simulation model. Moreover, stochastic simulation models are\nfrequently inexact, with discrepancies between the model and the target system.\nNo existing methods can effectively learn and quantify the uncertainties of\ninput parameters using only output-level data. In this paper, we propose to\nlearn differentiable input parameters of stochastic simulation models using\noutput-level data via kernel score minimization with stochastic gradient\ndescent. We quantify the uncertainties of the learned input parameters using a\nfrequentist confidence set procedure based on a new asymptotic normality result\nthat accounts for model inexactness. The proposed method is evaluated on exact\nand inexact G/G/1 queueing models.\n","authors":["Ziwei Su","Diego Klabjan"],"pdf_url":"https://arxiv.org/pdf/2411.05315v1.pdf","comment":"31 pages, 12 tables, 4 figures"},{"id":"http://arxiv.org/abs/2405.15673v2","updated":"2024-11-08T04:12:13Z","published":"2024-05-24T16:12:39Z","title":"Consistency of Neural Causal Partial Identification","summary":"  Recent progress in Neural Causal Models (NCMs) showcased how identification\nand partial identification of causal effects can be automatically carried out\nvia training of neural generative models that respect the constraints encoded\nin a given causal graph [Xia et al. 2022, Balazadeh et al. 2022]. However,\nformal consistency of these methods has only been proven for the case of\ndiscrete variables or only for linear causal models. In this work, we prove the\nconsistency of partial identification via NCMs in a general setting with both\ncontinuous and categorical variables. Further, our results highlight the impact\nof the design of the underlying neural network architecture in terms of depth\nand connectivity as well as the importance of applying Lipschitz regularization\nin the training phase. In particular, we provide a counterexample showing that\nwithout Lipschitz regularization this method may not be asymptotically\nconsistent. Our results are enabled by new results on the approximability of\nStructural Causal Models (SCMs) via neural generative models, together with an\nanalysis of the sample complexity of the resulting architectures and how that\ntranslates into an error in the constrained optimization problem that defines\nthe partial identification bounds.\n","authors":["Jiyuan Tan","Jose Blanchet","Vasilis Syrgkanis"],"pdf_url":"https://arxiv.org/pdf/2405.15673v2.pdf","comment":"61 pages, 8 figures, accepted by Neurips 2024"},{"id":"http://arxiv.org/abs/2309.16973v2","updated":"2024-11-08T03:48:58Z","published":"2023-09-29T04:42:50Z","title":"Towards Robust Offline-to-Online Reinforcement Learning via Uncertainty\n  and Smoothness","summary":"  To obtain a near-optimal policy with fewer interactions in Reinforcement\nLearning (RL), a promising approach involves the combination of offline RL,\nwhich enhances sample efficiency by leveraging offline datasets, and online RL,\nwhich explores informative transitions by interacting with the environment.\nOffline-to-Online (O2O) RL provides a paradigm for improving an offline trained\nagent within limited online interactions. However, due to the significant\ndistribution shift between online experiences and offline data, most offline RL\nalgorithms suffer from performance drops and fail to achieve stable policy\nimprovement in O2O adaptation. To address this problem, we propose the Robust\nOffline-to-Online (RO2O) algorithm, designed to enhance offline policies\nthrough uncertainty and smoothness, and to mitigate the performance drop in\nonline adaptation. Specifically, RO2O incorporates Q-ensemble for uncertainty\npenalty and adversarial samples for policy and value smoothness, which enable\nRO2O to maintain a consistent learning procedure in online adaptation without\nrequiring special changes to the learning objective. Theoretical analyses in\nlinear MDPs demonstrate that the uncertainty and smoothness lead to a tighter\noptimality bound in O2O against distribution shift. Experimental results\nillustrate the superiority of RO2O in facilitating stable offline-to-online\nlearning and achieving significant improvement with limited online\ninteractions.\n","authors":["Xiaoyu Wen","Xudong Yu","Rui Yang","Haoyuan Chen","Chenjia Bai","Zhen Wang"],"pdf_url":"https://arxiv.org/pdf/2309.16973v2.pdf","comment":"This paper has been accepted by Journal of Artificial Intelligence\n  Research (JAIR). arXiv admin note: text overlap with arXiv:2306.06871 by\n  other authors"},{"id":"http://arxiv.org/abs/2401.11592v5","updated":"2024-11-08T03:37:03Z","published":"2024-01-21T20:46:21Z","title":"Differentially-Private Multi-Tier Federated Learning","summary":"  While federated learning (FL) eliminates the transmission of raw data over a\nnetwork, it is still vulnerable to privacy breaches from the communicated model\nparameters. In this work, we propose Multi-Tier Federated Learning with\nMulti-Tier Differential Privacy (M^2FDP), a DP-enhanced FL methodology for\njointly optimizing privacy and performance in hierarchical networks. One of the\nkey concepts of M^2FDP is to extend the concept of HDP towards Multi-Tier\nDifferential Privacy (MDP), while also adapting DP noise injection at different\nlayers of an established FL hierarchy -- edge devices, edge servers, and cloud\nservers -- according to the trust models within particular subnetworks. We\nconduct a comprehensive analysis of the convergence behavior of M^2FDP,\nrevealing conditions on parameter tuning under which the training process\nconverges sublinearly to a finite stationarity gap that depends on the network\nhierarchy, trust model, and target privacy level.\n  Subsequent numerical evaluations demonstrate that M^2FDP obtains substantial\nimprovements in these metrics over baselines for different privacy budgets, and\nvalidate the impact of different system configurations.\n","authors":["Evan Chen","Frank Po-Chen Lin","Dong-Jun Han","Christopher G. Brinton"],"pdf_url":"https://arxiv.org/pdf/2401.11592v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01801v2","updated":"2024-11-08T03:30:52Z","published":"2024-11-04T05:00:49Z","title":"Bootstrapping Top-down Information for Self-modulating Slot Attention","summary":"  Object-centric learning (OCL) aims to learn representations of individual\nobjects within visual scenes without manual supervision, facilitating efficient\nand effective visual reasoning. Traditional OCL methods primarily employ\nbottom-up approaches that aggregate homogeneous visual features to represent\nobjects. However, in complex visual environments, these methods often fall\nshort due to the heterogeneous nature of visual features within an object. To\naddress this, we propose a novel OCL framework incorporating a top-down\npathway. This pathway first bootstraps the semantics of individual objects and\nthen modulates the model to prioritize features relevant to these semantics. By\ndynamically modulating the model based on its own output, our top-down pathway\nenhances the representational quality of objects. Our framework achieves\nstate-of-the-art performance across multiple synthetic and real-world\nobject-discovery benchmarks.\n","authors":["Dongwon Kim","Seoyeon Kim","Suha Kwak"],"pdf_url":"https://arxiv.org/pdf/2411.01801v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2310.05988v3","updated":"2024-11-08T03:30:38Z","published":"2023-10-07T19:35:07Z","title":"Dual Latent State Learning: Exploiting Regional Network Similarities for\n  QoS Prediction","summary":"  Individual objects, whether users or services, within a specific region often\nexhibit similar network states due to their shared origin from the same city or\nautonomous system (AS). Despite this regional network similarity, many existing\ntechniques overlook its potential, resulting in subpar performance arising from\nchallenges such as data sparsity and label imbalance. In this paper, we\nintroduce the regional-based dual latent state learning network(R2SL), a novel\ndeep learning framework designed to overcome the pitfalls of traditional\nindividual object-based prediction techniques in Quality of Service (QoS)\nprediction. Unlike its predecessors, R2SL captures the nuances of regional\nnetwork behavior by deriving two distinct regional network latent states: the\ncity-network latent state and the AS-network latent state. These states are\nconstructed utilizing aggregated data from common regions rather than\nindividual object data. Furthermore, R2SL adopts an enhanced Huber loss\nfunction that adjusts its linear loss component, providing a remedy for\nprevalent label imbalance issues. To cap off the prediction process, a\nmulti-scale perception network is leveraged to interpret the integrated feature\nmap, a fusion of regional network latent features and other pertinent\ninformation, ultimately accomplishing the QoS prediction. Through rigorous\ntesting on real-world QoS datasets, R2SL demonstrates superior performance\ncompared to prevailing state-of-the-art methods. Our R2SL approach ushers in an\ninnovative avenue for precise QoS predictions by fully harnessing the regional\nnetwork similarities inherent in objects.\n","authors":["Ziliang Wang","Xiaohong Zhang","Kechi Zhang","Ze Shi Li","Meng Yan"],"pdf_url":"https://arxiv.org/pdf/2310.05988v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05296v1","updated":"2024-11-08T02:57:59Z","published":"2024-11-08T02:57:59Z","title":"On Training of Kolmogorov-Arnold Networks","summary":"  Kolmogorov-Arnold Networks have recently been introduced as a flexible\nalternative to multi-layer Perceptron architectures. In this paper, we examine\nthe training dynamics of different KAN architectures and compare them with\ncorresponding MLP formulations. We train with a variety of different\ninitialization schemes, optimizers, and learning rates, as well as utilize back\npropagation free approaches like the HSIC Bottleneck. We find that (when judged\nby test accuracy) KANs are an effective alternative to MLP architectures on\nhigh-dimensional datasets and have somewhat better parameter efficiency, but\nsuffer from more unstable training dynamics. Finally, we provide\nrecommendations for improving training stability of larger KAN models.\n","authors":["Shairoz Sohail"],"pdf_url":"https://arxiv.org/pdf/2411.05296v1.pdf","comment":"7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.05241v3","updated":"2024-11-08T02:36:57Z","published":"2023-11-09T09:49:50Z","title":"When Meta-Learning Meets Online and Continual Learning: A Survey","summary":"  Over the past decade, deep neural networks have demonstrated significant\nsuccess using the training scheme that involves mini-batch stochastic gradient\ndescent on extensive datasets. Expanding upon this accomplishment, there has\nbeen a surge in research exploring the application of neural networks in other\nlearning scenarios. One notable framework that has garnered significant\nattention is meta-learning. Often described as \"learning to learn,\"\nmeta-learning is a data-driven approach to optimize the learning algorithm.\nOther branches of interest are continual learning and online learning, both of\nwhich involve incrementally updating a model with streaming data. While these\nframeworks were initially developed independently, recent works have started\ninvestigating their combinations, proposing novel problem settings and learning\nalgorithms. However, due to the elevated complexity and lack of unified\nterminology, discerning differences between the learning frameworks can be\nchallenging even for experienced researchers. To facilitate a clear\nunderstanding, this paper provides a comprehensive survey that organizes\nvarious problem settings using consistent terminology and formal descriptions.\nBy offering an overview of these learning paradigms, our work aims to foster\nfurther advancements in this promising area of research.\n","authors":["Jaehyeon Son","Soochan Lee","Gunhee Kim"],"pdf_url":"https://arxiv.org/pdf/2311.05241v3.pdf","comment":"IEEE Transactions on Pattern Analysis and Machine Intelligence"},{"id":"http://arxiv.org/abs/2411.05282v1","updated":"2024-11-08T02:25:45Z","published":"2024-11-08T02:25:45Z","title":"MicroScopiQ: Accelerating Foundational Models through Outlier-Aware\n  Microscaling Quantization","summary":"  Quantization of foundational models (FMs) is significantly more challenging\nthan traditional DNNs due to the emergence of large magnitude features called\noutliers. Existing outlier-aware algorithm/architecture co-design techniques\neither use mixed-precision, retaining outliers at high precision but compromise\nhardware efficiency, or quantize inliers and outliers at the same precision,\nimproving hardware efficiency at the cost of accuracy. To address this mutual\nexclusivity, in this paper, we propose MicroScopiQ, a novel co-design technique\nthat leverages pruning to complement outlier-aware quantization. MicroScopiQ\nretains outliers at higher precision while pruning a certain fraction of least\nimportant weights to distribute the additional outlier bits; ensuring high\naccuracy, aligned memory and hardware efficiency. We design a high-throughput,\nlow overhead accelerator architecture composed of simple multi-precision INT\nprocessing elements and a novel network-on-chip called ReCoN that efficiently\nabstracts the complexity of supporting high-precision outliers. Additionally,\nunlike existing alternatives, MicroScopiQ does not assume any locality of\noutlier weights, enabling applicability to a broad range of FMs. Extensive\nexperiments across various quantization settings show that MicroScopiQ achieves\nSoTA quantization performance while simultaneously improving inference\nperformance by 3x and reducing energy by 2x over existing alternatives.\n","authors":["Akshat Ramachandran","Souvik Kundu","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2411.05282v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2411.05281v1","updated":"2024-11-08T02:24:29Z","published":"2024-11-08T02:24:29Z","title":"Fox-1 Technical Report","summary":"  We present Fox-1, a series of small language models (SLMs) consisting of\nFox-1-1.6B and Fox-1-1.6B-Instruct-v0.1. These models are pre-trained on 3\ntrillion tokens of web-scraped document data and fine-tuned with 5 billion\ntokens of instruction-following and multi-turn conversation data. Aiming to\nimprove the pre-training efficiency, Fox-1-1.6B model introduces a novel\n3-stage data curriculum across all the training data with 2K-8K sequence\nlength. In architecture design, Fox-1 features a deeper layer structure, an\nexpanded vocabulary, and utilizes Grouped Query Attention (GQA), offering a\nperformant and efficient architecture compared to other SLMs. Fox-1 achieves\nbetter or on-par performance in various benchmarks compared to StableLM-2-1.6B,\nGemma-2B, Qwen1.5-1.8B, and OpenELM1.1B, with competitive inference speed and\nthroughput. The model weights have been released under the Apache 2.0 license,\nwhere we aim to promote the democratization of LLMs and make them fully\naccessible to the whole open-source community.\n","authors":["Zijian Hu","Jipeng Zhang","Rui Pan","Zhaozhuo Xu","Salman Avestimehr","Chaoyang He","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05281v1.pdf","comment":"Base model is available at\n  https://huggingface.co/tensoropera/Fox-1-1.6B and the instruction-tuned\n  version is available at\n  https://huggingface.co/tensoropera/Fox-1-1.6B-Instruct-v0.1"},{"id":"http://arxiv.org/abs/2411.05277v1","updated":"2024-11-08T02:22:30Z","published":"2024-11-08T02:22:30Z","title":"Revisiting the Robustness of Watermarking to Paraphrasing Attacks","summary":"  Amidst rising concerns about the internet being proliferated with content\ngenerated from language models (LMs), watermarking is seen as a principled way\nto certify whether text was generated from a model. Many recent watermarking\ntechniques slightly modify the output probabilities of LMs to embed a signal in\nthe generated output that can later be detected. Since early proposals for text\nwatermarking, questions about their robustness to paraphrasing have been\nprominently discussed. Lately, some techniques are deliberately designed and\nclaimed to be robust to paraphrasing. However, such watermarking schemes do not\nadequately account for the ease with which they can be reverse-engineered. We\nshow that with access to only a limited number of generations from a black-box\nwatermarked model, we can drastically increase the effectiveness of\nparaphrasing attacks to evade watermark detection, thereby rendering the\nwatermark ineffective.\n","authors":["Saksham Rastogi","Danish Pruthi"],"pdf_url":"https://arxiv.org/pdf/2411.05277v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2308.02580v3","updated":"2024-11-08T02:21:38Z","published":"2023-08-03T16:13:46Z","title":"Feature Noise Resilient for QoS Prediction with Probabilistic Deep\n  Supervision","summary":"  Accurate Quality of Service (QoS) prediction is essential for enhancing user\nsatisfaction in web recommendation systems, yet existing prediction models\noften overlook feature noise, focusing predominantly on label noise. In this\npaper, we present the Probabilistic Deep Supervision Network (PDS-Net), a\nrobust framework designed to effectively identify and mitigate feature noise,\nthereby improving QoS prediction accuracy. PDS-Net operates with a dual-branch\narchitecture: the main branch utilizes a decoder network to learn a\nGaussian-based prior distribution from known features, while the second branch\nderives a posterior distribution based on true labels. A key innovation of\nPDS-Net is its condition-based noise recognition loss function, which enables\nprecise identification of noisy features in objects (users or services). Once\nnoisy features are identified, PDS-Net refines the feature's prior\ndistribution, aligning it with the posterior distribution, and propagates this\nadjusted distribution to intermediate layers, effectively reducing noise\ninterference. Extensive experiments conducted on two real-world QoS datasets\ndemonstrate that PDS-Net consistently outperforms existing models, achieving an\naverage improvement of 8.91% in MAE on Dataset D1 and 8.32% on Dataset D2\ncompared to the ate-of-the-art. These results highlight PDS-Net's ability to\naccurately capture complex user-service relationships and handle feature noise,\nunderscoring its robustness and versatility across diverse QoS prediction\nenvironments.\n","authors":["Ziliang Wang","Xiaohong Zhang","Ze Shi Li","Sheng Huang","Meng Yan"],"pdf_url":"https://arxiv.org/pdf/2308.02580v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05276v1","updated":"2024-11-08T02:21:19Z","published":"2024-11-08T02:21:19Z","title":"GPT Semantic Cache: Reducing LLM Costs and Latency via Semantic\n  Embedding Caching","summary":"  Large Language Models (LLMs), such as GPT (Radford et al., 2019), have\nsignificantly advanced artificial intelligence by enabling sophisticated\nnatural language understanding and generation. However, the high computational\nand financial costs associated with frequent API calls to these models present\na substantial bottleneck, especially for applications like customer service\nchatbots that handle repetitive queries. In this paper, we introduce GPT\nSemantic Cache, a method that leverages semantic caching of query embeddings in\nin-memory storage (Redis). By storing embeddings of user queries, our approach\nefficiently identifies semantically similar questions, allowing for the\nretrieval of pre-generated responses without redundant API calls to the LLM.\nThis technique reduces operational costs and improves response times, enhancing\nthe efficiency of LLM-powered applications.\n","authors":["Sajal Regmi","Chetan Phakami Pun"],"pdf_url":"https://arxiv.org/pdf/2411.05276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16235v2","updated":"2024-11-08T02:17:22Z","published":"2024-06-23T22:53:47Z","title":"Preference Tuning For Toxicity Mitigation Generalizes Across Languages","summary":"  Detoxifying multilingual Large Language Models (LLMs) has become crucial due\nto their increasing global use. In this work, we explore zero-shot\ncross-lingual generalization of preference tuning in detoxifying LLMs. Unlike\nprevious studies that show limited cross-lingual generalization for other\nsafety tasks, we demonstrate that Direct Preference Optimization (DPO) training\nwith only English data can significantly reduce toxicity in multilingual\nopen-ended generations. For example, the probability of mGPT-1.3B generating\ntoxic continuations drops from 46.8% to 3.9% across 17 different languages\nafter training. Our results also extend to other multilingual LLMs, such as\nBLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal\nintervention and activation analysis, we identified the dual multilinguality\nproperty of MLP layers in LLMs, which explains the cross-lingual generalization\nof DPO. Finally, we show that bilingual sentence retrieval can predict the\ncross-lingual transferability of DPO preference tuning.\n","authors":["Xiaochen Li","Zheng-Xin Yong","Stephen H. Bach"],"pdf_url":"https://arxiv.org/pdf/2406.16235v2.pdf","comment":"Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05274v1","updated":"2024-11-08T02:16:41Z","published":"2024-11-08T02:16:41Z","title":"Distributed-Order Fractional Graph Operating Network","summary":"  We introduce the Distributed-order fRActional Graph Operating Network\n(DRAGON), a novel continuous Graph Neural Network (GNN) framework that\nincorporates distributed-order fractional calculus. Unlike traditional\ncontinuous GNNs that utilize integer-order or single fractional-order\ndifferential equations, DRAGON uses a learnable probability distribution over a\nrange of real numbers for the derivative orders. By allowing a flexible and\nlearnable superposition of multiple derivative orders, our framework captures\ncomplex graph feature updating dynamics beyond the reach of conventional\nmodels. We provide a comprehensive interpretation of our framework's capability\nto capture intricate dynamics through the lens of a non-Markovian graph random\nwalk with node feature updating driven by an anomalous diffusion process over\nthe graph. Furthermore, to highlight the versatility of the DRAGON framework,\nwe conduct empirical evaluations across a range of graph learning tasks. The\nresults consistently demonstrate superior performance when compared to\ntraditional continuous GNN models. The implementation code is available at\n\\url{https://github.com/zknus/NeurIPS-2024-DRAGON}.\n","authors":["Kai Zhao","Xuhao Li","Qiyu Kang","Feng Ji","Qinxu Ding","Yanan Zhao","Wenfei Liang","Wee Peng Tay"],"pdf_url":"https://arxiv.org/pdf/2411.05274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05273v1","updated":"2024-11-08T02:12:34Z","published":"2024-11-08T02:12:34Z","title":"Real-World Offline Reinforcement Learning from Vision Language Model\n  Feedback","summary":"  Offline reinforcement learning can enable policy learning from pre-collected,\nsub-optimal datasets without online interactions. This makes it ideal for\nreal-world robots and safety-critical scenarios, where collecting online data\nor expert demonstrations is slow, costly, and risky. However, most existing\noffline RL works assume the dataset is already labeled with the task rewards, a\nprocess that often requires significant human effort, especially when\nground-truth states are hard to ascertain (e.g., in the real-world). In this\npaper, we build on prior work, specifically RL-VLM-F, and propose a novel\nsystem that automatically generates reward labels for offline datasets using\npreference feedback from a vision-language model and a text description of the\ntask. Our method then learns a policy using offline RL with the reward-labeled\ndataset. We demonstrate the system's applicability to a complex real-world\nrobot-assisted dressing task, where we first learn a reward function using a\nvision-language model on a sub-optimal offline dataset, and then we use the\nlearned reward to employ Implicit Q learning to develop an effective dressing\npolicy. Our method also performs well in simulation tasks involving the\nmanipulation of rigid and deformable objects, and significantly outperform\nbaselines such as behavior cloning and inverse RL. In summary, we propose a new\nsystem that enables automatic reward labeling and policy learning from\nunlabeled, sub-optimal offline datasets.\n","authors":["Sreyas Venkataraman","Yufei Wang","Ziyu Wang","Zackory Erickson","David Held"],"pdf_url":"https://arxiv.org/pdf/2411.05273v1.pdf","comment":"7 pages. Accepted at the LangRob Workshop 2024 @ CoRL, 2024"},{"id":"http://arxiv.org/abs/2411.05269v1","updated":"2024-11-08T02:04:21Z","published":"2024-11-08T02:04:21Z","title":"Cancer-Net SCa-Synth: An Open Access Synthetically Generated 2D Skin\n  Lesion Dataset for Skin Cancer Classification","summary":"  In the United States, skin cancer ranks as the most commonly diagnosed\ncancer, presenting a significant public health issue due to its high rates of\noccurrence and the risk of serious complications if not caught early. Recent\nadvancements in dataset curation and deep learning have shown promise in quick\nand accurate detection of skin cancer. However, current open-source datasets\nhave significant class imbalances which impedes the effectiveness of these deep\nlearning models. In healthcare, generative artificial intelligence (AI) models\nhave been employed to create synthetic data, addressing data imbalance in\ndatasets by augmenting underrepresented classes and enhancing the overall\nquality and performance of machine learning models. In this paper, we build on\ntop of previous work by leveraging new advancements in generative AI, notably\nStable Diffusion and DreamBooth. We introduce Cancer-Net SCa-Synth, an open\naccess synthetically generated 2D skin lesion dataset for skin cancer\nclassification. Further analysis on the data effectiveness by comparing the\nISIC 2020 test set performance for training with and without these synthetic\nimages for a simple model highlights the benefits of leveraging synthetic data\nto improve performance. Cancer-Net SCa-Synth is publicly available at\nhttps://github.com/catai9/Cancer-Net-SCa-Synth as part of a global open-source\ninitiative for accelerating machine learning for cancer care.\n","authors":["Chi-en Amy Tai","Oustan Ding","Alexander Wong"],"pdf_url":"https://arxiv.org/pdf/2411.05269v1.pdf","comment":null}]},"2024-11-11T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2411.07240v1","updated":"2024-11-11T18:59:02Z","published":"2024-11-11T18:59:02Z","title":"UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts","summary":"  The evaluation of mathematical reasoning capabilities is essential for\nadvancing Artificial General Intelligence (AGI). While Large Language Models\n(LLMs) have shown impressive performance in solving mathematical problems,\nexisting benchmarks such as GSM8K and MATH present limitations, including\nnarrow problem definitions with specific numbers and reliance on predetermined\nrules that hinder accurate assessments of reasoning and adaptability. This\npaper introduces the UTMath Benchmark, which robustly evaluates the models\nthrough extensive unit tests. It consists of 1,053 problems across 9\nmathematical domains, with over 68 test cases per problem.We propose an\ninnovative evaluation framework inspired by unit testing in software\ndevelopment, focusing on both accuracy and reliability of results. Furthermore,\nwe introduce the Reasoning-to-Coding of Thoughts (RCoT) approach, which\nencourages LLMs to perform explicit reasoning before generating code, leading\nto generating more advanced solution and improved performance. Furthermore, we\nare releasing not only the UTMath benchmark but also the UTMath-Train training\ndataset (more than 70k samples), to support the community in further exploring\nmathematical reasoning.\n","authors":["Bo Yang","Qingping Yang","Runtao Liu"],"pdf_url":"https://arxiv.org/pdf/2411.07240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07238v1","updated":"2024-11-11T18:58:46Z","published":"2024-11-11T18:58:46Z","title":"OpenThaiGPT 1.5: A Thai-Centric Open Source Large Language Model","summary":"  OpenThaiGPT 1.5 is an advanced Thai language chat model based on Qwen v2.5,\nfinetuned on over 2,000,000 Thai instruction pairs. This report provides an\nengineering perspective on the model's development, capabilities, and\nperformance. We discuss the model's architecture, training process, and key\nfeatures, including multi-turn conversation support, Retrieval Augmented\nGeneration (RAG) compatibility, and tool-calling functionality. Benchmark\nresults demonstrate OpenThaiGPT 1.5's state-of-the-art performance on various\nThai language tasks, outperforming other open-source Thai language models. We\nalso address practical considerations such as GPU memory requirements and\ndeployment strategies.\n","authors":["Sumeth Yuenyong","Kobkrit Viriyayudhakorn","Apivadee Piyatumrong","Jillaphat Jaroenkantasima"],"pdf_url":"https://arxiv.org/pdf/2411.07238v1.pdf","comment":"8 pages, 4 tables"},{"id":"http://arxiv.org/abs/2411.07237v1","updated":"2024-11-11T18:58:38Z","published":"2024-11-11T18:58:38Z","title":"Contextualized Evaluations: Taking the Guesswork Out of Language Model\n  Evaluations","summary":"  Language model users often issue queries that lack specification, where the\ncontext under which a query was issued -- such as the user's identity, the\nquery's intent, and the criteria for a response to be useful -- is not\nexplicit. For instance, a good response to a subjective query like \"What book\nshould I read next?\" would depend on the user's preferences, and a good\nresponse to an open-ended query like \"How do antibiotics work against\nbacteria?\" would depend on the user's expertise. This makes evaluation of\nresponses to such queries an ill-posed task, as evaluators may make arbitrary\njudgments about the response quality. To remedy this, we present contextualized\nevaluations, a protocol that synthetically constructs context surrounding an\nunderspecified query and provides it during evaluation. We find that the\npresence of context can 1) alter conclusions drawn from evaluation, even\nflipping win rates between model pairs, 2) nudge evaluators to make fewer\njudgments based on surface-level criteria, like style, and 3) provide new\ninsights about model behavior across diverse contexts. Specifically, our\nprocedure uncovers an implicit bias towards WEIRD contexts in models' \"default\"\nresponses and we find that models are not equally sensitive to following\ndifferent contexts, even when they are provided in prompts.\n","authors":["Chaitanya Malaviya","Joseph Chee Chang","Dan Roth","Mohit Iyyer","Mark Yatskar","Kyle Lo"],"pdf_url":"https://arxiv.org/pdf/2411.07237v1.pdf","comment":"Code & data available at https://github.com/allenai/ContextEval"},{"id":"http://arxiv.org/abs/2411.02537v3","updated":"2024-11-11T18:49:52Z","published":"2024-11-04T19:16:53Z","title":"INQUIRE: A Natural World Text-to-Image Retrieval Benchmark","summary":"  We introduce INQUIRE, a text-to-image retrieval benchmark designed to\nchallenge multimodal vision-language models on expert-level queries. INQUIRE\nincludes iNaturalist 2024 (iNat24), a new dataset of five million natural world\nimages, along with 250 expert-level retrieval queries. These queries are paired\nwith all relevant images comprehensively labeled within iNat24, comprising\n33,000 total matches. Queries span categories such as species identification,\ncontext, behavior, and appearance, emphasizing tasks that require nuanced image\nunderstanding and domain expertise. Our benchmark evaluates two core retrieval\ntasks: (1) INQUIRE-Fullrank, a full dataset ranking task, and (2)\nINQUIRE-Rerank, a reranking task for refining top-100 retrievals. Detailed\nevaluation of a range of recent multimodal models demonstrates that INQUIRE\nposes a significant challenge, with the best models failing to achieve an\nmAP@50 above 50%. In addition, we show that reranking with more powerful\nmultimodal models can enhance retrieval performance, yet there remains a\nsignificant margin for improvement. By focusing on scientifically-motivated\necological challenges, INQUIRE aims to bridge the gap between AI capabilities\nand the needs of real-world scientific inquiry, encouraging the development of\nretrieval systems that can assist with accelerating ecological and biodiversity\nresearch. Our dataset and code are available at\nhttps://inquire-benchmark.github.io\n","authors":["Edward Vendrow","Omiros Pantazis","Alexander Shepard","Gabriel Brostow","Kate E. Jones","Oisin Mac Aodha","Sara Beery","Grant Van Horn"],"pdf_url":"https://arxiv.org/pdf/2411.02537v3.pdf","comment":"Published in NeurIPS 2024, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2411.07224v1","updated":"2024-11-11T18:44:17Z","published":"2024-11-11T18:44:17Z","title":"TempCharBERT: Keystroke Dynamics for Continuous Access Control Based on\n  Pre-trained Language Models","summary":"  With the widespread of digital environments, reliable authentication and\ncontinuous access control has become crucial. It can minimize cyber attacks and\nprevent frauds, specially those associated with identity theft. A particular\ninterest lies on keystroke dynamics (KD), which refers to the task of\nrecognizing individuals' identity based on their unique typing style. In this\nwork, we propose the use of pre-trained language models (PLMs) to recognize\nsuch patterns. Although PLMs have shown high performance on multiple NLP\nbenchmarks, the use of these models on specific tasks requires customization.\nBERT and RoBERTa, for instance, rely on subword tokenization, and they cannot\nbe directly applied to KD, which requires temporal-character information to\nrecognize users. Recent character-aware PLMs are able to process both subwords\nand character-level information and can be an alternative solution.\nNotwithstanding, they are still not suitable to be directly fine-tuned for KD\nas they are not optimized to account for user's temporal typing information\n(e.g., hold time and flight time). To overcome this limitation, we propose\nTempCharBERT, an architecture that incorporates temporal-character information\nin the embedding layer of CharBERT. This allows modeling keystroke dynamics for\nthe purpose of user identification and authentication. Our results show a\nsignificant improvement with this customization. We also showed the feasibility\nof training TempCharBERT on a federated learning settings in order to foster\ndata privacy.\n","authors":["Matheus Sim√£o","Fabiano Prado","Omar Abdul Wahab","Anderson Avila"],"pdf_url":"https://arxiv.org/pdf/2411.07224v1.pdf","comment":"Accepted at WIFS 2024"},{"id":"http://arxiv.org/abs/2411.07218v1","updated":"2024-11-11T18:40:04Z","published":"2024-11-11T18:40:04Z","title":"TreeCoders: Trees of Transformers","summary":"  In this paper, we introduce TreeCoders, a novel family of transformer trees.\nWe moved away from traditional linear transformers to complete k-ary trees.\nTransformer blocks serve as nodes, and generic classifiers learn to select the\nbest child and route the sequence of tokens to a specific leaf. The selectors,\nmoved outside the transformer blocks, allow for the use of a variety of\narchitecture without further modifications. Furthermore, our proposed\narchitecture supports sparse node activation due to the logarithmic complexity\nof a tree search. We validate our idea by testing a series of decoder-only tree\ntransformers, achieving competitive results across a diverse range of language\ndatasets. Our study demonstrates that the proposed tree transformer model\noutperforms a size-equivalent linear transformer model 76\\% of the time over a\nwide range of tree architectures. Furthermore, our proposed model naturally\nlends itself to distributed implementation.\n","authors":["Pierre Colonna D'Istria","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2411.07218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13020v2","updated":"2024-11-11T18:37:22Z","published":"2024-04-19T17:30:10Z","title":"Stronger Random Baselines for In-Context Learning","summary":"  Evaluating the in-context learning classification performance of language\nmodels poses challenges due to small dataset sizes, extensive prompt-selection\nusing the validation set, and intentionally difficult tasks that lead to\nnear-random performance. The standard random baseline--the expected accuracy of\nguessing labels uniformly at random--is stable when the evaluation set is used\nonly once or when the dataset is large. We account for the common practice of\nvalidation set reuse and existing small datasets with a stronger random\nbaseline: the expected maximum accuracy across multiple random classifiers.\nWhen choosing the best prompt demonstrations across six quantized language\nmodels applied to 16 BIG-bench Lite tasks, more than 20% of the few-shot\nresults that exceed the standard baseline do not exceed this stronger random\nbaseline. When held-out test sets are available, this stronger baseline is also\na better predictor of held-out performance than the standard baseline, avoiding\nunnecessary test set evaluations. This maximum random baseline provides an\neasily calculated drop-in replacement for the standard baseline.\n","authors":["Gregory Yauney","David Mimno"],"pdf_url":"https://arxiv.org/pdf/2404.13020v2.pdf","comment":"Published at COLM 2024"},{"id":"http://arxiv.org/abs/2403.00037v2","updated":"2024-11-11T18:27:18Z","published":"2024-02-29T06:40:53Z","title":"Evolving to the Future: Unseen Event Adaptive Fake News Detection on\n  Social Media","summary":"  With the rapid development of social media, the wide dissemination of fake\nnews on social media is increasingly threatening both individuals and society.\nOne of the unique challenges for fake news detection on social media is how to\ndetect fake news on future events. Recently, numerous fake news detection\nmodels that utilize textual information and the propagation structure of posts\nhave been proposed. Unfortunately, most of the existing approaches can hardly\nhandle this challenge since they rely heavily on event-specific features for\nprediction and cannot generalize to unseen events. To address this, we\nintroduce \\textbf{F}uture \\textbf{AD}aptive \\textbf{E}vent-based Fake news\nDetection (FADE) framework. Specifically, we train a target predictor through\nan adaptive augmentation strategy and graph contrastive learning to obtain\nhigher-quality features and make more accurate overall predictions.\nSimultaneously, we independently train an event-only predictor to obtain biased\npredictions. We further mitigate event bias by subtracting the event-only\npredictor's output from the target predictor's output to obtain the final\nprediction. Encouraging results from experiments designed to emulate real-world\nsocial media conditions validate the effectiveness of our method in comparison\nto existing state-of-the-art approaches.\n","authors":["Jiajun Zhang","Zhixun Li","Qiang Liu","Shu Wu","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2403.00037v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07191v1","updated":"2024-11-11T18:05:48Z","published":"2024-11-11T18:05:48Z","title":"The Super Weight in Large Language Models","summary":"  Recent works have shown a surprising result: a small fraction of Large\nLanguage Model (LLM) parameter outliers are disproportionately important to the\nquality of the model. LLMs contain billions of parameters, so these small\nfractions, such as 0.01%, translate to hundreds of thousands of parameters. In\nthis work, we present an even more surprising finding: Pruning as few as a\nsingle parameter can destroy an LLM's ability to generate text -- increasing\nperplexity by 3 orders of magnitude and reducing zero-shot accuracy to\nguessing. We propose a data-free method for identifying such parameters, termed\nsuper weights, using a single forward pass through the model. We additionally\nfind that these super weights induce correspondingly rare and large activation\noutliers, termed super activations. When preserved with high precision, super\nactivations can improve simple round-to-nearest quantization to become\ncompetitive with state-of-the-art methods. For weight quantization, we\nsimilarly find that by preserving the super weight and clipping other weight\noutliers, round-to-nearest quantization can scale to much larger block sizes\nthan previously considered. To facilitate further research into super weights,\nwe provide an index of super weight coordinates for common, openly available\nLLMs.\n","authors":["Mengxia Yu","De Wang","Qi Shan","Colorado Reed","Alvin Wan"],"pdf_url":"https://arxiv.org/pdf/2411.07191v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10839v2","updated":"2024-11-11T17:59:47Z","published":"2024-06-16T08:20:12Z","title":"Reminding Multimodal Large Language Models of Object-aware Knowledge\n  with Retrieved Tags","summary":"  Despite recent advances in the general visual instruction-following ability\nof Multimodal Large Language Models (MLLMs), they still struggle with critical\nproblems when required to provide a precise and detailed response to a visual\ninstruction: (1) failure to identify novel objects or entities, (2) mention of\nnon-existent objects, and (3) neglect of object's attributed details. Intuitive\nsolutions include improving the size and quality of data or using larger\nfoundation models. They show effectiveness in mitigating these issues, but at\nan expensive cost of collecting a vast amount of new data and introducing a\nsignificantly larger model. Standing at the intersection of these approaches,\nwe examine the three object-oriented problems from the perspective of the\nimage-to-text mapping process by the multimodal connector. In this paper, we\nfirst identify the limitations of multimodal connectors stemming from\ninsufficient training data. Driven by this, we propose to enhance the mapping\nwith retrieval-augmented tag tokens, which contain rich object-aware\ninformation such as object names and attributes. With our Tag-grounded visual\ninstruction tuning with retrieval Augmentation (TUNA), we outperform baselines\nthat share the same language model and training data on 12 benchmarks.\nFurthermore, we show the zero-shot capability of TUNA when provided with\nspecific datastores.\n","authors":["Daiqing Qi","Handong Zhao","Zijun Wei","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.10839v2.pdf","comment":"18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2411.07180v1","updated":"2024-11-11T17:57:30Z","published":"2024-11-11T17:57:30Z","title":"Counterfactual Generation from Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to intervene on\nthese models. To understand the impact of interventions precisely, it is useful\nto examine counterfactuals -- e.g., how a given sentence would have appeared\nhad it been generated by the model following a specific intervention. We\nhighlight that counterfactual reasoning is conceptually distinct from\ninterventions, as articulated in Pearl's causal hierarchy. Based on this\nobservation, we propose a framework for generating true string counterfactuals\nby reformulating language models as Generalized Structural-equation. Models\nusing the Gumbel-max trick. This allows us to model the joint distribution over\noriginal strings and their counterfactuals resulting from the same\ninstantiation of the sampling noise. We develop an algorithm based on hindsight\nGumbel sampling that allows us to infer the latent noise variables and generate\ncounterfactuals of observed strings. Our experiments demonstrate that the\napproach produces meaningful counterfactuals while at the same time showing\nthat commonly used intervention techniques have considerable undesired side\neffects.\n","authors":["Shauli Ravfogel","Anej Svete","V√©steinn Sn√¶bjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v1.pdf","comment":"A preprint"},{"id":"http://arxiv.org/abs/2411.07176v1","updated":"2024-11-11T17:56:28Z","published":"2024-11-11T17:56:28Z","title":"More Expressive Attention with Negative Weights","summary":"  We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention can shift the token deletion and copying\nfunction from a static OV matrix to dynamic QK inner products, with the OV\nmatrix now focusing more on refinement or modification. The attention head can\nsimultaneously delete, copy, or retain tokens by assigning them negative,\npositive, or minimal attention weights, respectively. As a result, a single\nattention head becomes more flexible and expressive. (2) Cog Attention improves\nthe model's robustness against representational collapse, which can occur when\nearlier tokens are over-squashed into later positions, leading to homogeneous\nrepresentations. Negative weights reduce effective information paths from\nearlier to later tokens, helping to mitigate this issue. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models for language modeling and U-ViT diffusion models for image\ngeneration. Experiments show that models using Cog Attention exhibit superior\nperformance compared to those employing traditional softmax attention modules.\nOur approach suggests a promising research direction for rethinking and\nbreaking the entrenched constraints of traditional softmax attention, such as\nthe requirement for non-negative weights.\n","authors":["Ang Lv","Ruobing Xie","Shuaipeng Li","Jiayi Liao","Xingwu Sun","Zhanhui Kang","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2411.07176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07175v1","updated":"2024-11-11T17:56:15Z","published":"2024-11-11T17:56:15Z","title":"Continual Memorization of Factoids in Large Language Models","summary":"  Large language models can absorb a massive amount of knowledge through\npretraining, but pretraining is inefficient for acquiring long-tailed or\nspecialized facts. Therefore, fine-tuning on specialized or new knowledge that\nreflects changes in the world has become popular, though it risks disrupting\nthe model's original capabilities. We study this fragility in the context of\ncontinual memorization, where the model is trained on a small set of long-tail\nfactoids (factual associations) and must retain these factoids after multiple\nstages of subsequent training on other datasets. Through extensive experiments,\nwe show that LLMs suffer from forgetting across a wide range of subsequent\ntasks, and simple replay techniques do not fully prevent forgetting, especially\nwhen the factoid datasets are trained in the later stages. We posit that there\nare two ways to alleviate forgetting: 1) protect the memorization process as\nthe model learns the factoids, or 2) reduce interference from training in later\nstages. With this insight, we develop an effective mitigation strategy: REMIX\n(Random and Generic Data Mixing). REMIX prevents forgetting by mixing generic\ndata sampled from pretraining corpora or even randomly generated word sequences\nduring each stage, despite being unrelated to the memorized factoids in the\nfirst stage. REMIX can recover performance from severe forgetting, often\noutperforming replay-based methods that have access to the factoids from the\nfirst stage. We then analyze how REMIX alters the learning process and find\nthat successful forgetting prevention is associated with a pattern: the model\nstores factoids in earlier layers than usual and diversifies the set of layers\nthat store these factoids. The efficacy of REMIX invites further investigation\ninto the underlying dynamics of memorization and forgetting, opening exciting\npossibilities for future research.\n","authors":["Howard Chen","Jiayi Geng","Adithya Bhaskar","Dan Friedman","Danqi Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12186v2","updated":"2024-11-11T17:55:09Z","published":"2024-09-18T17:57:57Z","title":"Qwen2.5-Coder Technical Report","summary":"  In this report, we introduce the Qwen2.5-Coder series, a significant upgrade\nfrom its predecessor, CodeQwen1.5. This series includes six models:\nQwen2.5-Coder-(0.5B/1.5B/3B/7B/14B/32B). As a code-specific model,\nQwen2.5-Coder is built upon the Qwen2.5 architecture and continues pretrained\non a vast corpus of over 5.5 trillion tokens. Through meticulous data cleaning,\nscalable synthetic data generation, and balanced data mixing, Qwen2.5-Coder\ndemonstrates impressive code generation capabilities while retaining general\nand math skills. These models have been evaluated on a wide range of\ncode-related tasks, achieving state-of-the-art (SOTA) performance across more\nthan 10 benchmarks, including code generation, completion, reasoning, and\nrepair, consistently outperforming larger models of the same model size. We\nbelieve that the release of the Qwen2.5-Coder series will advance research in\ncode intelligence and, with its permissive licensing, support wider adoption by\ndevelopers in real-world applications.\n","authors":["Binyuan Hui","Jian Yang","Zeyu Cui","Jiaxi Yang","Dayiheng Liu","Lei Zhang","Tianyu Liu","Jiajun Zhang","Bowen Yu","Keming Lu","Kai Dang","Yang Fan","Yichang Zhang","An Yang","Rui Men","Fei Huang","Bo Zheng","Yibo Miao","Shanghaoran Quan","Yunlong Feng","Xingzhang Ren","Xuancheng Ren","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2409.12186v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02481v2","updated":"2024-11-11T17:34:00Z","published":"2024-11-04T18:54:39Z","title":"CDR: Customizable Density Ratios of Strong-over-weak LLMs for Preference\n  Annotation","summary":"  Preference tuning of large language models (LLMs) relies on high-quality\nhuman preference data, which is often expensive and time-consuming to gather.\nWhile existing methods can use trained reward models or proprietary model as\njudges for preference annotation, they have notable drawbacks: training reward\nmodels remain dependent on initial human data, and using proprietary model\nimposes license restrictions that inhibits commercial usage. In this paper, we\nintroduce customized density ratio (CDR), a training-free and highly effective\nmethod that leverages off-the-shelf LLMs for preference data annotation. Our\napproach uses the log-density ratio between a better-aligned LLM and a less\naligned LLM as a reward signal. We explores 221 different LLMs pairs and\nempirically demonstrate that increasing the performance gap between paired LLMs\ncorrelates with better reward generalization. Furthermore, we show that\ntailoring the density ratio reward function with specific criteria and\npreference exemplars enhances performance across domains and within target\nareas.\n  In our experiment using density ratio from a pair of Mistral-7B models, CDR\nachieves a RewardBench score of 82.6, outperforming the best trained reward\nfunctions from same model class and demonstrating competitive performance\nagainst SoTA models in Safety (91.0) and Reasoning (88.0) domains. We use CDR\nto annotate an on-policy preference dataset with which we preference tune\nLlama-3-8B-Instruct with SimPO. Using reward signals from two relatively weak\nmodels, our approach pushes Llama-3-8B to achieve a 37.4% (+15.1%) win rate on\nArenaHard and a 40.7% (+17.8%) win rate on Length-Controlled AlpacaEval 2.0,\nalong with a score of 8.0 on MT-Bench.\n","authors":["Guangxuan Xu","Kai Xu","Shivchander Sudalairaj","Hao Wang","Akash Srivastava"],"pdf_url":"https://arxiv.org/pdf/2411.02481v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07156v1","updated":"2024-11-11T17:33:51Z","published":"2024-11-11T17:33:51Z","title":"A Primer on Word Embeddings: AI Techniques for Text Analysis in Social\n  Work","summary":"  Word embeddings represent a transformative technology for analyzing text data\nin social work research, offering sophisticated tools for understanding case\nnotes, policy documents, research literature, and other text-based materials.\nThis methodological paper introduces word embeddings to social work\nresearchers, explaining how these mathematical representations capture meaning\nand relationships in text data more effectively than traditional keyword-based\napproaches. We discuss fundamental concepts, technical foundations, and\npractical applications, including semantic search, clustering, and retrieval\naugmented generation. The paper demonstrates how embeddings can enhance\nresearch workflows through concrete examples from social work practice, such as\nanalyzing case notes for housing instability patterns and comparing social work\nlicensing examinations across languages. While highlighting the potential of\nembeddings for advancing social work research, we acknowledge limitations\nincluding information loss, training data constraints, and potential biases. We\nconclude that successfully implementing embedding technologies in social work\nrequires developing domain-specific models, creating accessible tools, and\nestablishing best practices aligned with social work's ethical principles. This\nintegration can enhance our ability to analyze complex patterns in text data\nwhile supporting more effective services and interventions.\n","authors":["Brian E. Perron","Kelley A. Rivenburgh","Bryan G. Victor","Zia Qi","Hui Luan"],"pdf_url":"https://arxiv.org/pdf/2411.07156v1.pdf","comment":"37 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.07152v1","updated":"2024-11-11T17:28:19Z","published":"2024-11-11T17:28:19Z","title":"HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals","summary":"  Task-Oriented Dialogue (TOD) systems assist users in completing tasks through\nnatural language interactions, often relying on a single-layered workflow\nstructure for slot-filling in public tasks, such as hotel bookings. However, in\nenterprise environments, which involve rich domain-specific knowledge, TOD\nsystems face challenges due to task complexity and the lack of standardized\ndocumentation. In this work, we introduce HierTOD, an enterprise TOD system\ndriven by hierarchical goals and can support composite workflows. By focusing\non goal-driven interactions, our system serves a more proactive role,\nfacilitating mixed-initiative dialogue and improving task completion. Equipped\nwith components for natural language understanding, composite goal retriever,\ndialogue management, and response generation, backed by a well-organized data\nservice with domain knowledge base and retrieval engine, HierTOD delivers\nefficient task assistance. Furthermore, our system implementation unifies two\nTOD paradigms: slot-filling for information collection and step-by-step\nguidance for task execution. Our human study demonstrates the effectiveness and\nhelpfulness of HierTOD in performing both paradigms.\n","authors":["Lingbo Mo","Shun Jiang","Akash Maharaj","Bernard Hishamunda","Yunyao Li"],"pdf_url":"https://arxiv.org/pdf/2411.07152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07142v1","updated":"2024-11-11T17:13:28Z","published":"2024-11-11T17:13:28Z","title":"Greenback Bears and Fiscal Hawks: Finance is a Jungle and Text\n  Embeddings Must Adapt","summary":"  Financial documents are filled with specialized terminology, arcane jargon,\nand curious acronyms that pose challenges for general-purpose text embeddings.\nYet, few text embeddings specialized for finance have been reported in the\nliterature, perhaps in part due to a lack of public datasets and benchmarks. We\npresent BAM embeddings, a set of text embeddings finetuned on a carefully\nconstructed dataset of 14.3M query-passage pairs. Demonstrating the benefits of\ndomain-specific training, BAM embeddings achieve Recall@1 of 62.8% on a\nheld-out test set, vs. only 39.2% for the best general-purpose text embedding\nfrom OpenAI. Further, BAM embeddings increase question answering accuracy by 8%\non FinanceBench and show increased sensitivity to the finance-specific elements\nthat are found in detailed, forward-looking and company and date-specific\nqueries. To support further research we describe our approach in detail,\nquantify the importance of hard negative mining and dataset scale.\n","authors":["Peter Anderson","Mano Vikash Janardhanan","Jason He","Wei Cheng","Charlie Flanagan"],"pdf_url":"https://arxiv.org/pdf/2411.07142v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.07140v1","updated":"2024-11-11T17:10:56Z","published":"2024-11-11T17:10:56Z","title":"Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language\n  Models","summary":"  New LLM evaluation benchmarks are important to align with the rapid\ndevelopment of Large Language Models (LLMs). In this work, we present Chinese\nSimpleQA, the first comprehensive Chinese benchmark to evaluate the factuality\nability of language models to answer short questions, and Chinese SimpleQA\nmainly has five properties (i.e., Chinese, Diverse, High-quality, Static,\nEasy-to-evaluate). Specifically, first, we focus on the Chinese language over 6\nmajor topics with 99 diverse subtopics. Second, we conduct a comprehensive\nquality control process to achieve high-quality questions and answers, where\nthe reference answers are static and cannot be changed over time. Third,\nfollowing SimpleQA, the questions and answers are very short, and the grading\nprocess is easy-to-evaluate based on OpenAI API. Based on Chinese SimpleQA, we\nperform a comprehensive evaluation on the factuality abilities of existing\nLLMs. Finally, we hope that Chinese SimpleQA could guide the developers to\nbetter understand the Chinese factuality abilities of their models and\nfacilitate the growth of foundation models.\n","authors":["Yancheng He","Shilong Li","Jiaheng Liu","Yingshui Tan","Hui Huang","Weixun Wang","Xingyuan Bu","Hangyu Guo","Chengwei Hu","Boren Zheng","Xuepeng Liu","Dekai Sun","Wenbo Su","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2411.07140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07133v1","updated":"2024-11-11T17:06:48Z","published":"2024-11-11T17:06:48Z","title":"Stronger Models are NOT Stronger Teachers for Instruction Tuning","summary":"  Instruction tuning has been widely adopted to ensure large language models\n(LLMs) follow user instructions effectively. The resulting\ninstruction-following capabilities of LLMs heavily rely on the instruction\ndatasets used for tuning. Recently, synthetic instruction datasets have emerged\nas an economically viable solution to provide LLMs diverse and high-quality\ninstructions. However, existing approaches typically assume that larger or\nstronger models are stronger teachers for instruction tuning, and hence simply\nadopt these models as response generators to the synthetic instructions. In\nthis paper, we challenge this commonly-adopted assumption. Our extensive\nexperiments across five base models and twenty response generators reveal that\nlarger and stronger models are not necessarily stronger teachers of smaller\nmodels. We refer to this phenomenon as the Larger Models' Paradox. We observe\nthat existing metrics cannot precisely predict the effectiveness of response\ngenerators since they ignore the compatibility between teachers and base models\nbeing fine-tuned. We thus develop a novel metric, named as\nCompatibility-Adjusted Reward (CAR) to measure the effectiveness of response\ngenerators. Our experiments across five base models demonstrate that CAR\noutperforms almost all baselines.\n","authors":["Zhangchen Xu","Fengqing Jiang","Luyao Niu","Bill Yuchen Lin","Radha Poovendran"],"pdf_url":"https://arxiv.org/pdf/2411.07133v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07130v1","updated":"2024-11-11T17:00:59Z","published":"2024-11-11T17:00:59Z","title":"Retrieval or Global Context Understanding? On Many-Shot In-Context\n  Learning for Long-Context Evaluation","summary":"  Language models (LMs) have demonstrated an improved capacity to handle\nlong-context information, yet existing long-context benchmarks primarily\nmeasure LMs' retrieval abilities with extended inputs, e.g., pinpointing a\nshort phrase from long-form text. Therefore, they may fall short when\nevaluating models' global context understanding capacity, such as synthesizing\nand reasoning over content across input to generate the response. In this\npaper, we study long-context language model (LCLM) evaluation through many-shot\nin-context learning (ICL). Concretely, we identify the skills each ICL task\nrequires, and examine models' long-context capabilities on them. We first ask:\nWhat types of ICL tasks benefit from additional demonstrations, and are these\ntasks effective at evaluating LCLMs? We find that classification and\nsummarization tasks show notable performance improvements with additional\ndemonstrations, while translation and reasoning tasks do not exhibit clear\ntrends. This suggests the classification tasks predominantly test models'\nretrieval skills. Next, we ask: To what extent does each task require retrieval\nskills versus global context understanding from LCLMs? We develop metrics to\ncategorize ICL tasks into two groups: (i) retrieval tasks that require strong\nretrieval ability to pinpoint relevant examples, and (ii) global context\nunderstanding tasks that necessitate a deeper comprehension of the full input.\nWe find that not all datasets can effectively evaluate these long-context\ncapabilities. To address this gap, we introduce a new many-shot ICL benchmark,\nMANYICLBENCH, designed to characterize LCLMs' retrieval and global context\nunderstanding capabilities separately. Benchmarking 11 open-weight LCLMs with\nMANYICLBENCH, we find that while state-of-the-art models perform well in\nretrieval tasks up to 64k tokens, many show significant drops in global context\ntasks at just 16k tokens.\n","authors":["Kaijian Zou","Muhammad Khalifa","Lu Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07127v1","updated":"2024-11-11T16:58:36Z","published":"2024-11-11T16:58:36Z","title":"Benchmarking LLMs' Judgments with No Gold Standard","summary":"  We introduce the GEM (Generative Estimator for Mutual Information), an\nevaluation metric for assessing language generation by Large Language Models\n(LLMs), particularly in generating informative judgments, without the need for\na gold standard reference. GEM broadens the scenarios where we can benchmark\nLLM generation performance-from traditional ones, like machine translation and\nsummarization, where gold standard references are readily available, to\nsubjective tasks without clear gold standards, such as academic peer review.\n  GEM uses a generative model to estimate mutual information between candidate\nand reference responses, without requiring the reference to be a gold standard.\nIn experiments on a human-annotated dataset, GEM demonstrates competitive\ncorrelations with human scores compared to the state-of-the-art GPT-4o\nExaminer, and outperforms all other baselines. Additionally, GEM is more robust\nagainst strategic manipulations, such as rephrasing or elongation, which can\nartificially inflate scores under a GPT-4o Examiner.\n  We also present GRE-bench (Generating Review Evaluation Benchmark) which\nevaluates LLMs based on how well they can generate high-quality peer reviews\nfor academic research papers. Because GRE-bench is based upon GEM, it inherits\nits robustness properties. Additionally, GRE-bench circumvents data\ncontamination problems (or data leakage) by using the continuous influx of new\nopen-access research papers and peer reviews each year. We show GRE-bench\nresults of various popular LLMs on their peer review capabilities using the\nICLR2023 dataset.\n","authors":["Shengwei Xu","Yuxuan Lu","Grant Schoenebeck","Yuqing Kong"],"pdf_url":"https://arxiv.org/pdf/2411.07127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.06687v2","updated":"2024-11-11T16:53:58Z","published":"2024-05-06T18:09:32Z","title":"Hire Me or Not? Examining Language Model's Behavior with Occupation\n  Attributes","summary":"  With the impressive performance in various downstream tasks, large language\nmodels (LLMs) have been widely integrated into production pipelines, like\nrecruitment and recommendation systems. A known issue of models trained on\nnatural language data is the presence of human biases, which can impact the\nfairness of the system. This paper investigates LLMs' behavior with respect to\ngender stereotypes, in the context of occupation decision making. Our framework\nis designed to investigate and quantify the presence of gender stereotypes in\nLLMs' behavior via multi-round question answering. Inspired by prior works, we\nconstruct a dataset by leveraging a standard occupation classification\nknowledge base released by authoritative agencies. We tested three LLMs\n(RoBERTa-large, GPT-3.5-turbo, and Llama2-70b-chat) and found that all models\nexhibit gender stereotypes analogous to human biases, but with different\npreferences. The distinct preferences of GPT-3.5-turbo and Llama2-70b-chat may\nimply the current alignment methods are insufficient for debiasing and could\nintroduce new biases contradicting the traditional gender stereotypes.\n","authors":["Damin Zhang","Yi Zhang","Geetanjali Bihani","Julia Rayz"],"pdf_url":"https://arxiv.org/pdf/2405.06687v2.pdf","comment":"WIP"},{"id":"http://arxiv.org/abs/2411.07122v1","updated":"2024-11-11T16:51:39Z","published":"2024-11-11T16:51:39Z","title":"SCAR: Sparse Conditioned Autoencoders for Concept Detection and Steering\n  in LLMs","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities in\ngenerating human-like text, but their output may not be aligned with the user\nor even produce harmful content. This paper presents a novel approach to detect\nand steer concepts such as toxicity before generation. We introduce the Sparse\nConditioned Autoencoder (SCAR), a single trained module that extends the\notherwise untouched LLM. SCAR ensures full steerability, towards and away from\nconcepts (e.g., toxic content), without compromising the quality of the model's\ntext generation on standard evaluation benchmarks. We demonstrate the effective\napplication of our approach through a variety of concepts, including toxicity,\nsafety, and writing style alignment. As such, this work establishes a robust\nframework for controlling LLM generations, ensuring their ethical and safe\ndeployment in real-world applications.\n","authors":["Ruben H√§rle","Felix Friedrich","Manuel Brack","Bj√∂rn Deiseroth","Patrick Schramowski","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2411.07122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07111v1","updated":"2024-11-11T16:37:40Z","published":"2024-11-11T16:37:40Z","title":"Building a Taiwanese Mandarin Spoken Language Model: A First Attempt","summary":"  This technical report presents our initial attempt to build a spoken large\nlanguage model (LLM) for Taiwanese Mandarin, specifically tailored to enable\nreal-time, speech-to-speech interaction in multi-turn conversations. Our\nend-to-end model incorporates a decoder-only transformer architecture and aims\nto achieve seamless interaction while preserving the conversational flow,\nincluding full-duplex capabilities allowing simultaneous speaking and\nlistening. The paper also details the training process, including data\npreparation with synthesized dialogues and adjustments for real-time\ninteraction. We also developed a platform to evaluate conversational fluency\nand response coherence in multi-turn dialogues. We hope the release of the\nreport can contribute to the future development of spoken LLMs in Taiwanese\nMandarin.\n","authors":["Chih-Kai Yang","Yu-Kuan Fu","Chen-An Li","Yi-Cheng Lin","Yu-Xiang Lin","Wei-Chih Chen","Ho Lam Chung","Chun-Yi Kuan","Wei-Ping Huang","Ke-Han Lu","Tzu-Quan Lin","Hsiu-Hsuan Wang","En-Pei Hu","Chan-Jan Hsu","Liang-Hsuan Tseng","I-Hsiang Chiu","Ulin Sanga","Xuanjun Chen","Po-chun Hsu","Shu-wen Yang","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2411.07111v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2406.12060v2","updated":"2024-11-11T16:33:25Z","published":"2024-06-17T20:00:04Z","title":"Not Eliminate but Aggregate: Post-Hoc Control over Mixture-of-Experts to\n  Address Shortcut Shifts in Natural Language Understanding","summary":"  Recent models for natural language understanding are inclined to exploit\nsimple patterns in datasets, commonly known as shortcuts. These shortcuts hinge\non spurious correlations between labels and latent features existing in the\ntraining data. At inference time, shortcut-dependent models are likely to\ngenerate erroneous predictions under distribution shifts, particularly when\nsome latent features are no longer correlated with the labels. To avoid this,\nprevious studies have trained models to eliminate the reliance on shortcuts. In\nthis study, we explore a different direction: pessimistically aggregating the\npredictions of a mixture-of-experts, assuming each expert captures relatively\ndifferent latent features. The experimental results demonstrate that our\npost-hoc control over the experts significantly enhances the model's robustness\nto the distribution shift in shortcuts. Besides, we show that our approach has\nsome practical advantages. We also analyze our model and provide results to\nsupport the assumption.\n","authors":["Ukyo Honda","Tatsushi Oka","Peinan Zhang","Masato Mita"],"pdf_url":"https://arxiv.org/pdf/2406.12060v2.pdf","comment":"21 pages, 5 figures (the layout differs from the MIT Press\n  publication version)"},{"id":"http://arxiv.org/abs/2411.07107v1","updated":"2024-11-11T16:33:25Z","published":"2024-11-11T16:33:25Z","title":"Training Neural Networks as Recognizers of Formal Languages","summary":"  Characterizing the computational power of neural network architectures in\nterms of formal language theory remains a crucial line of research, as it\ndescribes lower and upper bounds on the reasoning capabilities of modern AI.\nHowever, when empirically testing these bounds, existing work often leaves a\ndiscrepancy between experiments and the formal claims they are meant to\nsupport. The problem is that formal language theory pertains specifically to\nrecognizers: machines that receive a string as input and classify whether it\nbelongs to a language. On the other hand, it is common to instead use proxy\ntasks that are similar in only an informal sense, such as language modeling or\nsequence-to-sequence transduction. We correct this mismatch by training and\nevaluating neural networks directly as binary classifiers of strings, using a\ngeneral method that can be applied to a wide variety of languages. As part of\nthis, we extend an algorithm recently proposed by Sn{\\ae}bjarnarson et al.\n(2024) to do length-controlled sampling of strings from regular languages, with\nmuch better asymptotic time complexity than previous methods. We provide\nresults on a variety of languages across the Chomsky hierarchy for three neural\narchitectures: a simple RNN, an LSTM, and a causally-masked transformer. We\nfind that the RNN and LSTM often outperform the transformer, and that auxiliary\ntraining objectives such as language modeling can help, although no single\nobjective uniformly improves performance across languages and architectures.\nOur contributions will facilitate theoretically sound empirical testing of\nlanguage recognition claims in future work. We have released our datasets as a\nbenchmark called FLaRe (Formal Language Recognition), along with our code.\n","authors":["Alexandra Butoi","Ghazal Khalighinejad","Anej Svete","Josef Valvoda","Ryan Cotterell","Brian DuSell"],"pdf_url":"https://arxiv.org/pdf/2411.07107v1.pdf","comment":"40 pages, 2 figures. Preprint"},{"id":"http://arxiv.org/abs/2411.07075v1","updated":"2024-11-11T15:50:01Z","published":"2024-11-11T15:50:01Z","title":"Transformer verbatim in-context retrieval across time and scale","summary":"  To predict upcoming text, language models must in some cases retrieve\nin-context information verbatim. In this report, we investigated how the\nability of language models to retrieve arbitrary in-context nouns developed\nduring training (across time) and as language models trained on the same\ndataset increase in size (across scale). We then asked whether learning of\nin-context retrieval correlates with learning of more challenging zero-shot\nbenchmarks. Furthermore, inspired by semantic effects in human short-term\nmemory, we evaluated the retrieval with respect to a major semantic component\nof target nouns, namely whether they denote a concrete or abstract entity, as\nrated by humans. We show that verbatim in-context retrieval developed in a\nsudden transition early in the training process, after about 1% of the training\ntokens. This was observed across model sizes (from 14M and up to 12B\nparameters), and the transition occurred slightly later for the two smallest\nmodels. We further found that the development of verbatim in-context retrieval\nis positively correlated with the learning of zero-shot benchmarks. Around the\ntransition point, all models showed the advantage of retrieving concrete nouns\nas opposed to abstract nouns. In all but two smallest models, the advantage\ndissipated away toward the end of training.\n","authors":["Kristijan Armeni","Marko Pranjiƒá","Senja Pollak"],"pdf_url":"https://arxiv.org/pdf/2411.07075v1.pdf","comment":"accepted to Conference on Natural Language Learning 2024\n  (https://www.conll.org/)"},{"id":"http://arxiv.org/abs/2303.14537v3","updated":"2024-11-11T15:49:16Z","published":"2023-03-25T19:03:57Z","title":"Deep Augmentation: Self-Supervised Learning with Transformations in\n  Activation Space","summary":"  We introduce Deep Augmentation, an approach to implicit data augmentation\nusing dropout or PCA to transform a targeted layer within a neural network to\nimprove performance and generalization. We demonstrate Deep Augmentation\nthrough extensive experiments on contrastive learning tasks in NLP, computer\nvision, and graph learning. We observe substantial performance gains with\nTransformers, ResNets, and Graph Neural Networks as the underlying models in\ncontrastive learning, but observe inverse effects on the corresponding\nsupervised problems. Our analysis suggests that Deep Augmentation alleviates\nco-adaptation between layers, a problem exhibited by self-supervised learning\nwhere ground truth labels are not available. We use this observation to\nformulate a method for selecting which layer to target; in particular, our\nexperimentation reveals that targeting deeper layers with Deep Augmentation\noutperforms augmenting the input data. The simple network- and\nmodality-agnostic nature of this approach enables its integration into various\nmachine learning pipelines.\n","authors":["Rickard Br√ºel-Gabrielsson","Tongzhou Wang","Manel Baradad","Justin Solomon"],"pdf_url":"https://arxiv.org/pdf/2303.14537v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07071v1","updated":"2024-11-11T15:47:15Z","published":"2024-11-11T15:47:15Z","title":"Universal Response and Emergence of Induction in LLMs","summary":"  While induction is considered a key mechanism for in-context learning in\nLLMs, understanding its precise circuit decomposition beyond toy models remains\nelusive. Here, we study the emergence of induction behavior within LLMs by\nprobing their response to weak single-token perturbations of the residual\nstream. We find that LLMs exhibit a robust, universal regime in which their\nresponse remains scale-invariant under changes in perturbation strength,\nthereby allowing us to quantify the build-up of token correlations throughout\nthe model. By applying our method, we observe signatures of induction behavior\nwithin the residual stream of Gemma-2-2B, Llama-3.2-3B, and GPT-2-XL. Across\nall models, we find that these induction signatures gradually emerge within\nintermediate layers and identify the relevant model sections composing this\nbehavior. Our results provide insights into the collective interplay of\ncomponents within LLMs and serve as a benchmark for large-scale circuit\nanalysis.\n","authors":["Niclas Luick"],"pdf_url":"https://arxiv.org/pdf/2411.07071v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.07070v1","updated":"2024-11-11T15:46:07Z","published":"2024-11-11T15:46:07Z","title":"On Active Privacy Auditing in Supervised Fine-tuning for White-Box\n  Language Models","summary":"  The pretraining and fine-tuning approach has become the leading technique for\nvarious NLP applications. However, recent studies reveal that fine-tuning data,\ndue to their sensitive nature, domain-specific characteristics, and\nidentifiability, pose significant privacy concerns. To help develop more\nprivacy-resilient fine-tuning models, we introduce a novel active privacy\nauditing framework, dubbed Parsing, designed to identify and quantify privacy\nleakage risks during the supervised fine-tuning (SFT) of language models (LMs).\nThe framework leverages improved white-box membership inference attacks (MIAs)\nas the core technology, utilizing novel learning objectives and a two-stage\npipeline to monitor the privacy of the LMs' fine-tuning process, maximizing the\nexposure of privacy risks. Additionally, we have improved the effectiveness of\nMIAs on large LMs including GPT-2, Llama2, and certain variants of them. Our\nresearch aims to provide the SFT community of LMs with a reliable, ready-to-use\nprivacy auditing tool, and to offer valuable insights into safeguarding privacy\nduring the fine-tuning process. Experimental results confirm the framework's\nefficiency across various models and tasks, emphasizing notable privacy\nconcerns in the fine-tuning process. Project code available for\nhttps://github.com/mapleleavesss/PARSING.\n","authors":["Qian Sun","Hanpeng Wu","Xi Sheryl Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10825v2","updated":"2024-11-11T15:45:02Z","published":"2024-01-19T17:21:05Z","title":"Recent Advances in Named Entity Recognition: A Comprehensive Survey and\n  Comparative Study","summary":"  Named Entity Recognition seeks to extract substrings within a text that name\nreal-world objects and to determine their type (for example, whether they refer\nto persons or organizations). In this survey, we first present an overview of\nrecent popular approaches, including advancements in Transformer-based methods\nand Large Language Models (LLMs) that have not had much coverage in other\nsurveys. In addition, we discuss reinforcement learning and graph-based\napproaches, highlighting their role in enhancing NER performance. Second, we\nfocus on methods designed for datasets with scarce annotations. Third, we\nevaluate the performance of the main NER implementations on a variety of\ndatasets with differing characteristics (as regards their domain, their size,\nand their number of classes). We thus provide a deep comparison of algorithms\nthat have never been considered together. Our experiments shed some light on\nhow the characteristics of datasets affect the behavior of the methods we\ncompare.\n","authors":["Imed Keraghel","Stanislas Morbieu","Mohamed Nadif"],"pdf_url":"https://arxiv.org/pdf/2401.10825v2.pdf","comment":"44 pages"},{"id":"http://arxiv.org/abs/2411.07066v1","updated":"2024-11-11T15:30:16Z","published":"2024-11-11T15:30:16Z","title":"Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training","summary":"  Network pruning is a set of computational techniques that aim to reduce a\ngiven model's computational cost by removing a subset of its parameters while\nhaving minimal impact on performance. Throughout the last decade, the most\nwidely used pruning paradigm has focused on pruning and re-training, which\nnowadays is inconvenient due to the vast amount of pre-trained models, which\nare in any case too expensive to re-train. In this paper, we exploit functional\ninformation from dense pre-trained models, i.e., their activations, to obtain\nsparse models that maximize the activations' alignment w.r.t. their\ncorresponding dense models. Hence, we propose \\textsc{NeuroAl}, a \\emph{top-up}\nalgorithm that can be used on top of any given pruning algorithm for LLMs, that\nmodifies the block-wise and row-wise sparsity ratios to maximize the\n\\emph{neuron alignment} among activations. Moreover, differently from existing\nmethods, our approach adaptively selects the best parameters for the block-wise\nand row-wise sparsity ratios w.r.t. to the model and the desired sparsity\n(given as input), and requires \\emph{no re-training}. We test our method on 4\ndifferent LLM families and 3 different sparsity ratios, showing how it\nconsistently outperforms the latest state-of-the-art techniques. The code is\navailable at https://github.com/eliacunegatti/NeuroAL.\n","authors":["Elia Cunegatti","Leonardo Lucio Custode","Giovanni Iacca"],"pdf_url":"https://arxiv.org/pdf/2411.07066v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2411.07042v1","updated":"2024-11-11T14:49:43Z","published":"2024-11-11T14:49:43Z","title":"Minion: A Technology Probe for Resolving Value Conflicts through\n  Expert-Driven and User-Driven Strategies in AI Companion Applications","summary":"  AI companions based on large language models can role-play and converse very\nnaturally. When value conflicts arise between the AI companion and the user, it\nmay offend or upset the user. Yet, little research has examined such conflicts.\nWe first conducted a formative study that analyzed 151 user complaints about\nconflicts with AI companions, providing design implications for our study.\nBased on these, we created Minion, a technology probe to help users resolve\nhuman-AI value conflicts. Minion applies a user-empowerment intervention method\nthat provides suggestions by combining expert-driven and user-driven conflict\nresolution strategies. We conducted a technology probe study, creating 40 value\nconflict scenarios on Character.AI and Talkie. 22 participants completed 274\ntasks and successfully resolved conflicts 94.16% of the time. We summarize user\nresponses, preferences, and needs in resolving value conflicts, and propose\ndesign implications to reduce conflicts and empower users to resolve them more\neffectively.\n","authors":["Xianzhe Fan","Qing Xiao","Xuhui Zhou","Yuran Su","Zhicong Lu","Maarten Sap","Hong Shen"],"pdf_url":"https://arxiv.org/pdf/2411.07042v1.pdf","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.07037v1","updated":"2024-11-11T14:43:51Z","published":"2024-11-11T14:43:51Z","title":"LIFBench: Evaluating the Instruction Following Performance and Stability\n  of Large Language Models in Long-Context Scenarios","summary":"  As Large Language Models (LLMs) continue to advance in natural language\nprocessing (NLP), their ability to stably follow instructions in long-context\ninputs has become crucial for real-world applications. While existing\nbenchmarks assess various LLM capabilities, they rarely focus on\ninstruction-following in long-context scenarios or stability on different\ninputs. In response, we introduce the Long-context Instruction-Following\nBenchmark (LIFBench), a scalable dataset designed to evaluate LLMs'\ninstruction-following capabilities and stability across long contexts. LIFBench\ncomprises three long-context scenarios and eleven diverse tasks, supported by\n2,766 instructions generated through an automated expansion method across three\ndimensions: length, expression, and variables. For evaluation, we propose\nLIFEval, a rubric-based assessment framework that provides precise, automated\nscoring of complex LLM responses without relying on LLM-assisted evaluations or\nhuman judgments. This approach facilitates a comprehensive analysis of model\nperformance and stability across various perspectives. We conduct extensive\nexperiments on 20 notable LLMs across six length intervals, analyzing their\ninstruction-following capabilities and stability. Our work contributes LIFBench\nand LIFEval as robust tools for assessing LLM performance in complex,\nlong-context settings, providing insights that can inform future LLM\ndevelopment.\n","authors":["Xiaodong Wu","Minhao Wang","Yichen Liu","Xiaoming Shi","He Yan","Xiangju Lu","Junmin Zhu","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07037v1.pdf","comment":"17 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.09824v4","updated":"2024-11-11T14:41:53Z","published":"2024-10-13T12:57:08Z","title":"Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent\n  Simulation","summary":"  Graph generation is a fundamental task that has been extensively studied in\nsocial, technological, and scientific analysis. For modeling the dynamic graph\nevolution process, traditional rule-based methods struggle to capture community\nstructures within graphs, while deep learning methods only focus on fitting\ntraining graphs. This limits existing graph generators to producing graphs that\nadhere to predefined rules or closely resemble training datasets, achieving\npoor performance in dynamic graph generation. Given that graphs are abstract\nrepresentations arising from pairwise interactions in human activities, a\nrealistic simulation of human-wise interaction could provide deeper insights\ninto the graph evolution mechanism. With the increasing recognition of large\nlanguage models (LLMs) in simulating human behavior, we introduce\nGraphAgent-Generator (GAG), a novel simulation-based framework for dynamic\ngraph generation. Without training or fine-tuning process of LLM, our framework\neffectively replicates seven macro-level structural characteristics in\nestablished network science theories while surpassing existing baselines in\ngraph expansion tasks by 31\\% on specific evaluation metrics. Through node\nclassification task, we validate GAG effectively preserves characteristics of\nreal-world network for node-wise textual features in generated text-rich graph.\nFurthermore, by incorporating parallel acceleration, GAG supports generating\ngraphs with up to nearly 100,000 nodes or 10 million edges through large-scale\nLLM-based agent simulation, with a minimum speed-up of 90.4\\%. The source code\nis available at https://anonymous.4open.science/r/GraphAgent-2206.\n","authors":["Jiarui Ji","Runlin Lei","Jialing Bi","Zhewei Wei","Yankai Lin","Xuchen Pan","Yaliang Li","Bolin Ding"],"pdf_url":"https://arxiv.org/pdf/2410.09824v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19266v4","updated":"2024-11-11T14:36:35Z","published":"2024-05-29T16:59:38Z","title":"PediatricsGPT: Large Language Models as Chinese Medical Assistants for\n  Pediatric Applications","summary":"  Developing intelligent pediatric consultation systems offers promising\nprospects for improving diagnostic efficiency, especially in China, where\nhealthcare resources are scarce. Despite recent advances in Large Language\nModels (LLMs) for Chinese medicine, their performance is sub-optimal in\npediatric applications due to inadequate instruction data and vulnerable\ntraining procedures. To address the above issues, this paper builds PedCorpus,\na high-quality dataset of over 300,000 multi-task instructions from pediatric\ntextbooks, guidelines, and knowledge graph resources to fulfil diverse\ndiagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the\nfirst Chinese pediatric LLM assistant built on a systematic and robust training\npipeline. In the continuous pre-training phase, we introduce a hybrid\ninstruction pre-training mechanism to mitigate the internal-injected knowledge\ninconsistency of LLMs for medical domain adaptation. Immediately, the\nfull-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the\ngeneral medical knowledge schema into the models. After that, we devise a\ndirect following preference optimization to enhance the generation of\npediatrician-like humanistic responses. In the parameter-efficient secondary\nSFT phase, a mixture of universal-specific experts strategy is presented to\nresolve the competency conflict between medical generalist and pediatric\nexpertise mastery. Extensive results based on the metrics, GPT-4, and doctor\nevaluations on distinct doctor downstream tasks show that PediatricsGPT\nconsistently outperforms previous Chinese medical LLMs. Our model and dataset\nwill be open-source for community development.\n","authors":["Dingkang Yang","Jinjie Wei","Dongling Xiao","Shunli Wang","Tong Wu","Gang Li","Mingcheng Li","Shuaibing Wang","Jiawei Chen","Yue Jiang","Qingyao Xu","Ke Li","Peng Zhai","Lihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.19266v4.pdf","comment":"Accepted by NeurIPS 2024. A Technical Report on a Chinese Medical\n  Large Language Model"},{"id":"http://arxiv.org/abs/2404.08877v2","updated":"2024-11-11T14:35:45Z","published":"2024-04-13T02:36:40Z","title":"Aligning LLMs for FL-free Program Repair","summary":"  Large language models (LLMs) have achieved decent results on automated\nprogram repair (APR). However, the next token prediction training objective of\ndecoder-only LLMs (e.g., GPT-4) is misaligned with the masked span prediction\nobjective of current infilling-style methods, which impedes LLMs from fully\nleveraging pre-trained knowledge for program repair. In addition, while some\nLLMs can locate and repair bugs in certain functions using the related\nartifacts (e.g., test cases), existing methods still depend on statement-level\nfault localization methods to provide a list of buggy hunks for repair. This\nrestriction hinders LLMs from exploring potential patches beyond the given\nlocations.\n  In this paper, we investigate a new approach to adapt LLMs to program repair.\nOur core insight is that LLM's APR capability can be greatly improved by simply\naligning the output to their training objective and allowing them to refine the\nwhole program without first identifying faulty statements. Based on this\ninsight, we designed D4C, a straightforward prompting framework for APR. D4C\ncan repair 180 bugs correctly in Defects4J, with each patch being sampled only\n10 times. This surpasses the SOTA APR methods with perfect fault localization\nby 10% and reduces the patch sampling number by 90%. Our findings reveal that\n(1) objective alignment is crucial for fully exploiting LLM's pre-trained\ncapability, and (2) replacing the traditional localize-buggy-hunks-then-repair\nworkflow with direct debugging is more effective for LLM-based APR methods.\nThus, we believe this paper introduces a new mindset for harnessing LLMs in\nAPR.\n","authors":["Junjielong Xu","Ying Fu","Shin Hwei Tan","Pinjia He"],"pdf_url":"https://arxiv.org/pdf/2404.08877v2.pdf","comment":"Accepted by ICSE'25"},{"id":"http://arxiv.org/abs/2312.06374v4","updated":"2024-11-11T14:28:51Z","published":"2023-12-11T13:32:11Z","title":"UstanceBR: a social media language resource for stance prediction","summary":"  This work introduces UstanceBR, a multimodal corpus in the Brazilian\nPortuguese Twitter domain for target-based stance prediction. The corpus\ncomprises 86.8 k labelled stances towards selected target topics, and extensive\nnetwork information about the users who published these stances on social\nmedia. In this article we describe the corpus multimodal data, and a number of\nusage examples in both in-domain and zero-shot stance prediction based on text-\nand network-related information, which are intended to provide initial baseline\nresults for future studies in the field.\n","authors":["Camila Pereira","Matheus Pavan","Sungwon Yoon","Ricelli Ramos","Pablo Costa","Lais Cavalheiro","Ivandre Paraboni"],"pdf_url":"https://arxiv.org/pdf/2312.06374v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07019v1","updated":"2024-11-11T14:22:42Z","published":"2024-11-11T14:22:42Z","title":"UniHR: Hierarchical Representation Learning for Unified Knowledge Graph\n  Link Prediction","summary":"  Beyond-triple fact representations including hyper-relational facts with\nauxiliary key-value pairs, temporal facts with additional timestamps, and\nnested facts implying relationships between facts, are gaining significant\nattention. However, existing link prediction models are usually designed for\none specific type of facts, making it difficult to generalize to other fact\nrepresentations. To overcome this limitation, we propose a Unified Hierarchical\nRepresentation learning framework (UniHR) for unified knowledge graph link\nprediction. It consists of a unified Hierarchical Data Representation (HiDR)\nmodule and a unified Hierarchical Structure Learning (HiSL) module as graph\nencoder. The HiDR module unifies hyper-relational KGs, temporal KGs, and nested\nfactual KGs into triple-based representations. Then HiSL incorporates\nintra-fact and inter-fact message passing, focusing on enhancing the semantic\ninformation within individual facts and enriching the structural information\nbetween facts. Experimental results across 7 datasets from 3 types of KGs\ndemonstrate that our UniHR outperforms baselines designed for one specific kind\nof KG, indicating strong generalization capability of HiDR form and the\neffectiveness of HiSL module. Code and data are available at\nhttps://github.com/Lza12a/UniHR.\n","authors":["Zhiqiang Liu","Mingyang Chen","Yin Hua","Zhuo Chen","Ziqi Liu","Lei Liang","Huajun Chen","Wen Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14736v3","updated":"2024-11-11T13:58:11Z","published":"2023-11-21T19:12:18Z","title":"Data Diversity Matters for Robust Instruction Tuning","summary":"  Recent works have shown that by curating high quality and diverse instruction\ntuning datasets, we can significantly improve instruction-following\ncapabilities. However, creating such datasets is difficult and most works rely\non manual curation or proprietary language models. Automatic data curation is\ndifficult as it is still not clear how we can define diversity for instruction\ntuning, how diversity and quality depend on one other, and how we can optimize\ndataset quality and diversity. To resolve these issue, we propose a new\nalgorithm, Quality-Diversity Instruction Tuning (QDIT). QDIT provides a simple\nmethod to simultaneously control dataset diversity and quality, allowing us to\nconduct an in-depth study on the effect of diversity and quality on instruction\ntuning performance. From this study we draw two key insights (1) there is a\nnatural tradeoff between data diversity and quality and (2) increasing data\ndiversity significantly improves the worst case instruction following\nperformance, therefore improving robustness. We validate the performance of\nQDIT on several large scale instruction tuning datasets, where we find it can\nsubstantially improve worst and average case performance compared to\nquality-driven data selection.\n","authors":["Alexander Bukharin","Shiyang Li","Zhengyang Wang","Jingfeng Yang","Bing Yin","Xian Li","Chao Zhang","Tuo Zhao","Haoming Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.14736v3.pdf","comment":"22 pages, 18 figures"},{"id":"http://arxiv.org/abs/2411.02674v4","updated":"2024-11-11T13:49:30Z","published":"2024-11-04T23:21:12Z","title":"Wave Network: An Ultra-Small Language Model","summary":"  We propose an innovative token representation and update method in a new\nultra-small language model: the Wave network. Specifically, we use a complex\nvector to represent each token, encoding both global and local semantics of the\ninput text. A complex vector consists of two components: a magnitude vector\nrepresenting the global semantics of the input text, and a phase vector\ncapturing the relationships between individual tokens and global semantics.\nExperiments on the AG News text classification task demonstrate that, when\ngenerating complex vectors from randomly initialized token embeddings, our\nsingle-layer Wave Network achieves 90.91% accuracy with wave interference and\n91.66% with wave modulation - outperforming a single Transformer layer using\nBERT pre-trained embeddings by 19.23% and 19.98%, respectively, and approaching\nthe accuracy of the pre-trained and fine-tuned BERT base model (94.64%).\nAdditionally, compared to BERT base, the Wave Network reduces video memory\nusage and training time by 77.34% and 85.62% during wave modulation. In\nsummary, we used a 2.4-million-parameter small language model to achieve\naccuracy comparable to a 100-million-parameter BERT model in text\nclassification.\n","authors":["Xin Zhang","Victor S. Sheng"],"pdf_url":"https://arxiv.org/pdf/2411.02674v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06989v1","updated":"2024-11-11T13:48:01Z","published":"2024-11-11T13:48:01Z","title":"Token2Wave","summary":"  This paper provides an in-depth analysis of Token2Wave, a novel token\nrepresentation method derived from the Wave Network, designed to capture both\nglobal and local semantics of input text through wave-inspired complex vectors.\nIn Token2Wave, each token is represented with a magnitude component, capturing\nthe global semantics of the entire input text, and a phase component, encoding\nthe relationships between individual tokens and the global semantics. Building\non prior research that demonstrated the effectiveness of wave-like operations,\nsuch as interference and modulation, during forward propagation, this study\ninvestigates the convergence behavior, backpropagation characteristics, and\nembedding independence within the Token2Wave framework. A detailed\ncomputational complexity analysis shows that Token2Wave can significantly\nreduce video memory usage and training time compared to BERT. Gradient\ncomparisons for the [CLS] token, total input text, and classifier parameters\nfurther highlight Token2Wave's unique characteristics. This research offers new\ninsights into wave-based token representations, demonstrating their potential\nto enable efficient and computationally friendly language model architectures.\n","authors":["Xin Zhang","Victor S. Sheng"],"pdf_url":"https://arxiv.org/pdf/2411.06989v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17827v2","updated":"2024-11-11T13:46:50Z","published":"2024-07-25T07:35:27Z","title":"Unified Lexical Representation for Interpretable Visual-Language\n  Alignment","summary":"  Visual-Language Alignment (VLA) has gained a lot of attention since CLIP's\ngroundbreaking work. Although CLIP performs well, the typical direct latent\nfeature alignment lacks clarity in its representation and similarity scores. On\nthe other hand, lexical representation, a vector whose element represents the\nsimilarity between the sample and a word from the vocabulary, is a natural\nsparse representation and interpretable, providing exact matches for individual\nwords. However, lexical representations are difficult to learn due to no\nground-truth supervision and false-discovery issues, and thus requires complex\ndesign to train effectively. In this paper, we introduce LexVLA, a more\ninterpretable VLA framework by learning a unified lexical representation for\nboth modalities without complex design. We use DINOv2 as our visual model for\nits local-inclined features and Llama 2, a generative language model, to\nleverage its in-context lexical prediction ability. To avoid the false\ndiscovery, we propose an overuse penalty to refrain the lexical representation\nfrom falsely frequently activating meaningless words. We demonstrate that these\ntwo pre-trained uni-modal models can be well-aligned by fine-tuning on the\nmodest multi-modal dataset and avoid intricate training configurations. On\ncross-modal retrieval benchmarks, LexVLA, trained on the CC-12M multi-modal\ndataset, outperforms baselines fine-tuned on larger datasets (e.g., YFCC15M)\nand those trained from scratch on even bigger datasets (e.g., 1.1B data,\nincluding CC-12M). We conduct extensive experiments to analyze LexVLA. Codes\nare available at https://github.com/Clementine24/LexVLA.\n","authors":["Yifan Li","Yikai Wang","Yanwei Fu","Dongyu Ru","Zheng Zhang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2407.17827v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.10691v2","updated":"2024-11-11T13:33:25Z","published":"2024-03-15T21:21:11Z","title":"MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual\n  Language Modeling","summary":"  A major consideration in multilingual language modeling is how to best\nrepresent languages with diverse vocabularies and scripts. Although\ncontemporary text encoding methods cover most of the world's writing systems,\nthey exhibit bias towards the high-resource languages of the Global West. As a\nresult, texts of underrepresented languages tend to be segmented into long\nsequences of linguistically meaningless units. To address the disparities, we\nintroduce a new paradigm that encodes the same information with segments of\nconsistent size across diverse languages. Our encoding convention (MYTE) is\nbased on morphemes, as their inventories are more balanced across languages\nthan characters, which are used in previous methods. We show that MYTE produces\nshorter encodings for all 99 analyzed languages, with the most notable\nimprovements for non-European languages and non-Latin scripts. This, in turn,\nimproves multilingual LM performance and diminishes the perplexity gap\nthroughout diverse languages.\n","authors":["Tomasz Limisiewicz","Terra Blevins","Hila Gonen","Orevaoghene Ahia","Luke Zettlemoyer"],"pdf_url":"https://arxiv.org/pdf/2403.10691v2.pdf","comment":"Published at ACL 2024"},{"id":"http://arxiv.org/abs/2411.06950v1","updated":"2024-11-11T12:56:52Z","published":"2024-11-11T12:56:52Z","title":"Sniff AI: Is My 'Spicy' Your 'Spicy'? Exploring LLM's Perceptual\n  Alignment with Human Smell Experiences","summary":"  Aligning AI with human intent is important, yet perceptual alignment-how AI\ninterprets what we see, hear, or smell-remains underexplored. This work focuses\non olfaction, human smell experiences. We conducted a user study with 40\nparticipants to investigate how well AI can interpret human descriptions of\nscents. Participants performed \"sniff and describe\" interactive tasks, with our\ndesigned AI system attempting to guess what scent the participants were\nexperiencing based on their descriptions. These tasks evaluated the Large\nLanguage Model's (LLMs) contextual understanding and representation of scent\nrelationships within its internal states - high-dimensional embedding space.\nBoth quantitative and qualitative methods were used to evaluate the AI system's\nperformance. Results indicated limited perceptual alignment, with biases\ntowards certain scents, like lemon and peppermint, and continued failing to\nidentify others, like rosemary. We discuss these findings in light of human-AI\nalignment advancements, highlighting the limitations and opportunities for\nenhancing HCI systems with multisensory experience integration.\n","authors":["Shu Zhong","Zetao Zhou","Christopher Dawes","Giada Brianz","Marianna Obrist"],"pdf_url":"https://arxiv.org/pdf/2411.06950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06946v1","updated":"2024-11-11T12:54:22Z","published":"2024-11-11T12:54:22Z","title":"Cancer-Answer: Empowering Cancer Care with Advanced Large Language\n  Models","summary":"  Gastrointestinal (GI) tract cancers account for a substantial portion of the\nglobal cancer burden, where early diagnosis is critical for improved management\nand patient outcomes. The complex aetiologies and overlapping symptoms across\nGI cancers often delay diagnosis, leading to suboptimal treatment strategies.\nCancer-related queries are crucial for timely diagnosis, treatment, and patient\neducation, as access to accurate, comprehensive information can significantly\ninfluence outcomes. However, the complexity of cancer as a disease, combined\nwith the vast amount of available data, makes it difficult for clinicians and\npatients to quickly find precise answers. To address these challenges, we\nleverage large language models (LLMs) such as GPT-3.5 Turbo to generate\naccurate, contextually relevant responses to cancer-related queries.\nPre-trained with medical data, these models provide timely, actionable insights\nthat support informed decision-making in cancer diagnosis and care, ultimately\nimproving patient outcomes. We calculate two metrics: A1 (which represents the\nfraction of entities present in the model-generated answer compared to the gold\nstandard) and A2 (which represents the linguistic correctness and\nmeaningfulness of the model-generated answer with respect to the gold\nstandard), achieving maximum values of 0.546 and 0.881, respectively.\n","authors":["Aniket Deroy","Subhankar Maity"],"pdf_url":"https://arxiv.org/pdf/2411.06946v1.pdf","comment":"Accepted at FIRE 2024 (Track: Conversational System for Differential\n  Diagnosis of GI Cancer)"},{"id":"http://arxiv.org/abs/2409.11032v3","updated":"2024-11-11T12:50:44Z","published":"2024-09-17T09:56:12Z","title":"Hierarchical Narrative Analysis: Unraveling Perceptions of Generative AI","summary":"  Written texts reflect an author's perspective, making the thorough analysis\nof literature a key research method in fields such as the humanities and social\nsciences. However, conventional text mining techniques like sentiment analysis\nand topic modeling are limited in their ability to capture the hierarchical\nnarrative structures that reveal deeper argumentative patterns. To address this\ngap, we propose a method that leverages large language models (LLMs) to extract\nand organize these structures into a hierarchical framework. We validate this\napproach by analyzing public opinions on generative AI collected by Japan's\nAgency for Cultural Affairs, comparing the narratives of supporters and\ncritics. Our analysis provides clearer visualization of the factors influencing\ndivergent opinions on generative AI, offering deeper insights into the\nstructures of agreement and disagreement.\n","authors":["Riona Matsuoka","Hiroki Matsumoto","Takahiro Yoshida","Tomohiro Watanabe","Ryoma Kondo","Ryohei Hisano"],"pdf_url":"https://arxiv.org/pdf/2409.11032v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06928v1","updated":"2024-11-11T12:32:26Z","published":"2024-11-11T12:32:26Z","title":"Electroencephalogram-based Multi-class Decoding of Attended Speakers'\n  Direction with Audio Spatial Spectrum","summary":"  Decoding the directional focus of an attended speaker from listeners'\nelectroencephalogram (EEG) signals is essential for developing brain-computer\ninterfaces to improve the quality of life for individuals with hearing\nimpairment. Previous works have concentrated on binary directional focus\ndecoding, i.e., determining whether the attended speaker is on the left or\nright side of the listener. However, a more precise decoding of the exact\ndirection of the attended speaker is necessary for effective speech processing.\nAdditionally, audio spatial information has not been effectively leveraged,\nresulting in suboptimal decoding results. In this paper, we observe that, on\nour recently presented dataset with 15-class directional focus, models relying\nexclusively on EEG inputs exhibits significantly lower accuracy when decoding\nthe directional focus in both leave-one-subject-out and leave-one-trial-out\nscenarios. By integrating audio spatial spectra with EEG features, the decoding\naccuracy can be effectively improved. We employ the CNN, LSM-CNN, and\nEEG-Deformer models to decode the directional focus from listeners' EEG signals\nwith the auxiliary audio spatial spectra. The proposed Sp-Aux-Deformer model\nachieves notable 15-class decoding accuracies of 57.48% and 61.83% in\nleave-one-subject-out and leave-one-trial-out scenarios, respectively.\n","authors":["Yuanming Zhang","Jing Lu","Zhibin Lin","Fei Chen","Haoliang Du","Xia Gao"],"pdf_url":"https://arxiv.org/pdf/2411.06928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06908v1","updated":"2024-11-11T12:11:36Z","published":"2024-11-11T12:11:36Z","title":"EVQAScore: Efficient Video Question Answering Data Evaluation","summary":"  Video question-answering (QA) is a core task in video understanding.\nEvaluating the quality of video QA and video caption data quality for training\nvideo large language models (VideoLLMs) is an essential challenge. Although\nvarious methods have been proposed for assessing video caption quality, there\nremains a lack of dedicated evaluation methods for Video QA. To address this\ngap, we introduce EVQAScore, a reference-free method that leverages keyword\nextraction to assess both video caption and video QA data quality.\nAdditionally, we incorporate frame sampling and rescaling techniques to enhance\nthe efficiency and robustness of our evaluation, this enables our score to\nevaluate the quality of extremely long videos. Our approach achieves\nstate-of-the-art (SOTA) performance (32.8 for Kendall correlation and 42.3 for\nSpearman correlation, 4.7 and 5.9 higher than the previous method PAC-S++) on\nthe VATEX-EVAL benchmark for video caption evaluation. Furthermore, by using\nEVQAScore for data selection, we achieved SOTA results with only 12.5\\% of the\noriginal data volume, outperforming the previous SOTA method PAC-S and 100\\% of\ndata.\n","authors":["Hao Liang","Zirong Chen","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06899v1","updated":"2024-11-11T11:57:37Z","published":"2024-11-11T11:57:37Z","title":"LongSafetyBench: Long-Context LLMs Struggle with Safety Issues","summary":"  With the development of large language models (LLMs), the sequence length of\nthese models continues to increase, drawing significant attention to\nlong-context language models. However, the evaluation of these models has been\nprimarily limited to their capabilities, with a lack of research focusing on\ntheir safety. Existing work, such as ManyShotJailbreak, has to some extent\ndemonstrated that long-context language models can exhibit safety concerns.\nHowever, the methods used are limited and lack comprehensiveness. In response,\nwe introduce \\textbf{LongSafetyBench}, the first benchmark designed to\nobjectively and comprehensively evaluate the safety of long-context models.\nLongSafetyBench consists of 10 task categories, with an average length of\n41,889 words. After testing eight long-context language models on\nLongSafetyBench, we found that existing models generally exhibit insufficient\nsafety capabilities. The proportion of safe responses from most mainstream\nlong-context LLMs is below 50\\%. Moreover, models' safety performance in\nlong-context scenarios does not always align with that in short-context\nscenarios. Further investigation revealed that long-context models tend to\noverlook harmful content within lengthy texts. We also proposed a simple yet\neffective solution, allowing open-source models to achieve performance\ncomparable to that of top-tier closed-source models. We believe that\nLongSafetyBench can serve as a valuable benchmark for evaluating the safety\ncapabilities of long-context language models. We hope that our work will\nencourage the broader community to pay attention to the safety of long-context\nmodels and contribute to the development of solutions to improve the safety of\nlong-context LLMs.\n","authors":["Mianqiu Huang","Xiaoran Liu","Shaojun Zhou","Mozhi Zhang","Chenkun Tan","Pengyu Wang","Qipeng Guo","Zhe Xu","Linyang Li","Zhikai Lei","Linlin Li","Qun Liu","Yaqian Zhou","Xipeng Qiu","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2411.06899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09085v2","updated":"2024-11-11T11:35:28Z","published":"2024-03-14T04:06:13Z","title":"Meaningful Learning: Enhancing Abstract Reasoning in Large Language\n  Models via Generic Fact Guidance","summary":"  Large language models (LLMs) have developed impressive performance and strong\nexplainability across various reasoning scenarios, marking a significant stride\ntowards mimicking human-like intelligence. Despite this, when tasked with\nseveral simple questions supported by a generic fact, LLMs often struggle to\nabstract and apply the generic fact to provide consistent and precise answers,\nrevealing a deficiency in abstract reasoning abilities. This has sparked a\nvigorous debate about whether LLMs are genuinely reasoning or merely\nmemorizing. In light of this, we design a preliminary study to quantify and\ndelve into the abstract reasoning abilities of existing LLMs. Our findings\nreveal a substantial discrepancy between their general reasoning and abstract\nreasoning performances. To relieve this problem, we tailor an abstract\nreasoning dataset (AbsR) together with a meaningful learning paradigm to teach\nLLMs how to leverage generic facts for reasoning purposes. The results show\nthat our approach not only boosts the general reasoning performance of LLMs but\nalso makes considerable strides towards their capacity for abstract reasoning,\nmoving beyond simple memorization or imitation to a more nuanced understanding\nand application of generic facts. The code is available at\nhttps://github.com/Waste-Wood/MeanLearn.\n","authors":["Kai Xiong","Xiao Ding","Ting Liu","Bing Qin","Dongliang Xu","Qing Yang","Hongtao Liu","Yixin Cao"],"pdf_url":"https://arxiv.org/pdf/2403.09085v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17632v2","updated":"2024-11-11T11:32:21Z","published":"2024-10-23T07:48:51Z","title":"LMLPA: Language Model Linguistic Personality Assessment","summary":"  Large Language Models (LLMs) are increasingly used in everyday life and\nresearch. One of the most common use cases is conversational interactions,\nenabled by the language generation capabilities of LLMs. Just as between two\nhumans, a conversation between an LLM-powered entity and a human depends on the\npersonality of the conversants. However, measuring the personality of a given\nLLM is currently a challenge. This paper introduces the Language Model\nLinguistic Personality Assessment (LMLPA), a system designed to evaluate the\nlinguistic personalities of LLMs. Our system helps to understand LLMs' language\ngeneration capabilities by quantitatively assessing the distinct personality\ntraits reflected in their linguistic outputs. Unlike traditional human-centric\npsychometrics, the LMLPA adapts a personality assessment questionnaire,\nspecifically the Big Five Inventory, to align with the operational capabilities\nof LLMs, and also incorporates the findings from previous language-based\npersonality measurement literature. To mitigate sensitivity to the order of\noptions, our questionnaire is designed to be open-ended, resulting in textual\nanswers. Thus, the AI rater is needed to transform ambiguous personality\ninformation from text responses into clear numerical indicators of personality\ntraits. Utilising Principal Component Analysis and reliability validations, our\nfindings demonstrate that LLMs possess distinct personality traits that can be\neffectively quantified by the LMLPA. This research contributes to\nHuman-Computer Interaction and Human-Centered AI, providing a robust framework\nfor future studies to refine AI personality assessments and expand their\napplications in multiple areas, including education and manufacturing.\n","authors":["Jingyao Zheng","Xian Wang","Simo Hosio","Xiaoxian Xu","Lik-Hang Lee"],"pdf_url":"https://arxiv.org/pdf/2410.17632v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06866v1","updated":"2024-11-11T10:57:31Z","published":"2024-11-11T10:57:31Z","title":"Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense\n  Question Answering","summary":"  Commonsense question answering is a crucial task that requires machines to\nemploy reasoning according to commonsense. Previous studies predominantly\nemploy an extracting-and-modeling paradigm to harness the information in KG,\nwhich first extracts relevant subgraphs based on pre-defined rules and then\nproceeds to design various strategies aiming to improve the representations and\nfusion of the extracted structural knowledge. Despite their effectiveness,\nthere are still two challenges. On one hand, subgraphs extracted by rule-based\nmethods may have the potential to overlook critical nodes and result in\nuncontrollable subgraph size. On the other hand, the misalignment between graph\nand text modalities undermines the effectiveness of knowledge fusion,\nultimately impacting the task performance. To deal with the problems above, we\npropose a novel framework: \\textbf{S}ubgraph R\\textbf{E}trieval Enhanced by\nGra\\textbf{P}h-\\textbf{T}ext \\textbf{A}lignment, named \\textbf{SEPTA}. Firstly,\nwe transform the knowledge graph into a database of subgraph vectors and\npropose a BFS-style subgraph sampling strategy to avoid information loss,\nleveraging the analogy between BFS and the message-passing mechanism. In\naddition, we propose a bidirectional contrastive learning approach for\ngraph-text alignment, which effectively enhances both subgraph retrieval and\nknowledge fusion. Finally, all the retrieved information is combined for\nreasoning in the prediction module. Extensive experiments on five datasets\ndemonstrate the effectiveness and robustness of our framework.\n","authors":["Boci Peng","Yongchao Liu","Xiaohe Bo","Sheng Tian","Baokun Wang","Chuntao Hong","Yan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06866v1.pdf","comment":"Accepted by ECML PKDD 2024"},{"id":"http://arxiv.org/abs/2411.02943v2","updated":"2024-11-11T10:51:31Z","published":"2024-11-05T09:37:23Z","title":"Capturing research literature attitude towards Sustainable Development\n  Goals: an LLM-based topic modeling approach","summary":"  The world is facing a multitude of challenges that hinder the development of\nhuman civilization and the well-being of humanity on the planet. The\nSustainable Development Goals (SDGs) were formulated by the United Nations in\n2015 to address these global challenges by 2030. Natural language processing\ntechniques can help uncover discussions on SDGs within research literature. We\npropose a completely automated pipeline to 1) fetch content from the Scopus\ndatabase and prepare datasets dedicated to five groups of SDGs; 2) perform\ntopic modeling, a statistical technique used to identify topics in large\ncollections of textual data; and 3) enable topic exploration through\nkeywords-based search and topic frequency time series extraction. For topic\nmodeling, we leverage the stack of BERTopic scaled up to be applied on large\ncorpora of textual documents (we find hundreds of topics on hundreds of\nthousands of documents), introducing i) a novel LLM-based embeddings\ncomputation for representing scientific abstracts in the continuous space and\nii) a hyperparameter optimizer to efficiently find the best configuration for\nany new big datasets. We additionally produce the visualization of results on\ninteractive dashboards reporting topics' temporal evolution. Results are made\ninspectable and explorable, contributing to the interpretability of the topic\nmodeling process. Our proposed LLM-based topic modeling pipeline for big-text\ndatasets allows users to capture insights on the evolution of the attitude\ntoward SDGs within scientific abstracts in the 2006-2023 time span. All the\nresults are reproducible by using our system; the workflow can be generalized\nto be applied at any point in time to any big corpus of textual documents.\n","authors":["Francesco Invernici","Francesca Curati","Jelena Jakimov","Amirhossein Samavi","Anna Bernasconi"],"pdf_url":"https://arxiv.org/pdf/2411.02943v2.pdf","comment":"27 pages, 8 figures, 5 tables"},{"id":"http://arxiv.org/abs/2402.16040v5","updated":"2024-11-11T10:40:50Z","published":"2024-02-25T09:41:50Z","title":"EHRNoteQA: An LLM Benchmark for Real-World Clinical Practice Using\n  Discharge Summaries","summary":"  Discharge summaries in Electronic Health Records (EHRs) are crucial for\nclinical decision-making, but their length and complexity make information\nextraction challenging, especially when dealing with accumulated summaries\nacross multiple patient admissions. Large Language Models (LLMs) show promise\nin addressing this challenge by efficiently analyzing vast and complex data.\nExisting benchmarks, however, fall short in properly evaluating LLMs'\ncapabilities in this context, as they typically focus on single-note\ninformation or limited topics, failing to reflect the real-world inquiries\nrequired by clinicians. To bridge this gap, we introduce EHRNoteQA, a novel\nbenchmark built on the MIMIC-IV EHR, comprising 962 different QA pairs each\nlinked to distinct patients' discharge summaries. Every QA pair is initially\ngenerated using GPT-4 and then manually reviewed and refined by three\nclinicians to ensure clinical relevance. EHRNoteQA includes questions that\nrequire information across multiple discharge summaries and covers eight\ndiverse topics, mirroring the complexity and diversity of real clinical\ninquiries. We offer EHRNoteQA in two formats: open-ended and multi-choice\nquestion answering, and propose a reliable evaluation method for each. We\nevaluate 27 LLMs using EHRNoteQA and examine various factors affecting the\nmodel performance (e.g., the length and number of discharge summaries).\nFurthermore, to validate EHRNoteQA as a reliable proxy for expert evaluations\nin clinical practice, we measure the correlation between the LLM performance on\nEHRNoteQA, and the LLM performance manually evaluated by clinicians. Results\nshow that LLM performance on EHRNoteQA have higher correlation with\nclinician-evaluated performance (Spearman: 0.78, Kendall: 0.62) compared to\nother benchmarks, demonstrating its practical relevance in evaluating LLMs in\nclinical settings.\n","authors":["Sunjun Kweon","Jiyoun Kim","Heeyoung Kwak","Dongchul Cha","Hangyul Yoon","Kwanghyun Kim","Jeewon Yang","Seunghyun Won","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2402.16040v5.pdf","comment":"NeurIPS 2024 (Datasets and Benchmarks)"},{"id":"http://arxiv.org/abs/2411.06855v1","updated":"2024-11-11T10:37:11Z","published":"2024-11-11T10:37:11Z","title":"A Unified Multi-Task Learning Architecture for Hate Detection Leveraging\n  User-Based Information","summary":"  Hate speech, offensive language, aggression, racism, sexism, and other\nabusive language are common phenomena in social media. There is a need for\nArtificial Intelligence(AI)based intervention which can filter hate content at\nscale. Most existing hate speech detection solutions have utilized the features\nby treating each post as an isolated input instance for the classification.\nThis paper addresses this issue by introducing a unique model that improves\nhate speech identification for the English language by utilising intra-user and\ninter-user-based information. The experiment is conducted over single-task\nlearning (STL) and multi-task learning (MTL) paradigms that use deep neural\nnetworks, such as convolutional neural networks (CNN), gated recurrent unit\n(GRU), bidirectional encoder representations from the transformer (BERT), and A\nLite BERT (ALBERT). We use three benchmark datasets and conclude that combining\ncertain user features with textual features gives significant improvements in\nmacro-F1 and weighted-F1.\n","authors":["Prashant Kapil","Asif Ekbal"],"pdf_url":"https://arxiv.org/pdf/2411.06855v1.pdf","comment":"7 pages, 1 figure, and two tables"},{"id":"http://arxiv.org/abs/2411.06852v1","updated":"2024-11-11T10:36:04Z","published":"2024-11-11T10:36:04Z","title":"Evaluating Large Language Models on Financial Report Summarization: An\n  Empirical Study","summary":"  In recent years, Large Language Models (LLMs) have demonstrated remarkable\nversatility across various applications, including natural language\nunderstanding, domain-specific knowledge tasks, etc. However, applying LLMs to\ncomplex, high-stakes domains like finance requires rigorous evaluation to\nensure reliability, accuracy, and compliance with industry standards. To\naddress this need, we conduct a comprehensive and comparative study on three\nstate-of-the-art LLMs, GLM-4, Mistral-NeMo, and LLaMA3.1, focusing on their\neffectiveness in generating automated financial reports. Our primary motivation\nis to explore how these models can be harnessed within finance, a field\ndemanding precision, contextual relevance, and robustness against erroneous or\nmisleading information. By examining each model's capabilities, we aim to\nprovide an insightful assessment of their strengths and limitations. Our paper\noffers benchmarks for financial report analysis, encompassing proposed metrics\nsuch as ROUGE-1, BERT Score, and LLM Score. We introduce an innovative\nevaluation framework that integrates both quantitative metrics (e.g.,\nprecision, recall) and qualitative analyses (e.g., contextual fit, consistency)\nto provide a holistic view of each model's output quality. Additionally, we\nmake our financial dataset publicly available, inviting researchers and\npractitioners to leverage, scrutinize, and enhance our findings through broader\ncommunity engagement and collaborative improvement. Our dataset is available on\nhuggingface.\n","authors":["Xinqi Yang","Scott Zang","Yong Ren","Dingjie Peng","Zheng Wen"],"pdf_url":"https://arxiv.org/pdf/2411.06852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06850v1","updated":"2024-11-11T10:34:36Z","published":"2024-11-11T10:34:36Z","title":"1-800-SHARED-TASKS @ NLU of Devanagari Script Languages: Detection of\n  Language, Hate Speech, and Targets using LLMs","summary":"  This paper presents a detailed system description of our entry for the\nCHiPSAL 2025 shared task, focusing on language detection, hate speech\nidentification, and target detection in Devanagari script languages. We\nexperimented with a combination of large language models and their ensembles,\nincluding MuRIL, IndicBERT, and Gemma-2, and leveraged unique techniques like\nfocal loss to address challenges in the natural understanding of Devanagari\nlanguages, such as multilingual processing and class imbalance. Our approach\nachieved competitive results across all tasks: F1 of 0.9980, 0.7652, and 0.6804\nfor Sub-tasks A, B, and C respectively. This work provides insights into the\neffectiveness of transformer models in tasks with domain-specific and\nlinguistic challenges, as well as areas for potential improvement in future\niterations.\n","authors":["Jebish Purbey","Siddartha Pullakhandam","Kanwal Mehreen","Muhammad Arham","Drishti Sharma","Ashay Srivastava","Ram Mohan Rao Kadiyala"],"pdf_url":"https://arxiv.org/pdf/2411.06850v1.pdf","comment":"13 pages, Submitted to CHIPSAL workshop @ COLING 2025"},{"id":"http://arxiv.org/abs/2411.06839v1","updated":"2024-11-11T10:07:51Z","published":"2024-11-11T10:07:51Z","title":"LLM-Neo: Parameter Efficient Knowledge Distillation for Large Language\n  Models","summary":"  In this paper, we propose a novel LLM-Neo framework that efficiently\ntransfers knowledge from a large language model (LLM) teacher to a compact\nstudent. Initially, we revisit the knowledge distillation (KD) and low-rank\nadaption (LoRA), and argue that they share the same paradigm. Inspired by this\nobservation, we explore the strategy that combines LoRA and KD to enhance the\nefficiency of knowledge transfer. We first summarize some guidelines for this\ndesign and further develop the LLM-Neo. Experimental results on compressing\nLlama 2 and Llama 3 show that LLM-Neo outperforms various baselines. Further\nanalysis demonstrates the robustness of the proposed LLM-Neo on variants of\nLoRA. The trained models have been available at\n\\href{https://huggingface.co/collections/yang31210999/llm-neo-66e3c882f5579b829ff57eba}{this\nrepository}.\n","authors":["Runming Yang","Taiqiang Wu","Jiahao Wang","Pengfei Hu","Ngai Wong","Yujiu Yang"],"pdf_url":"https://arxiv.org/pdf/2411.06839v1.pdf","comment":"ICASSP 25' under review"},{"id":"http://arxiv.org/abs/2411.06837v1","updated":"2024-11-11T10:05:52Z","published":"2024-11-11T10:05:52Z","title":"Persuasion with Large Language Models: a Survey","summary":"  The rapid rise of Large Language Models (LLMs) has created new disruptive\npossibilities for persuasive communication, by enabling fully-automated\npersonalized and interactive content generation at an unprecedented scale. In\nthis paper, we survey the research field of LLM-based persuasion that has\nemerged as a result. We begin by exploring the different modes in which LLM\nSystems are used to influence human attitudes and behaviors. In areas such as\npolitics, marketing, public health, e-commerce, and charitable giving, such LLM\nSystems have already achieved human-level or even super-human persuasiveness.\nWe identify key factors influencing their effectiveness, such as the manner of\npersonalization and whether the content is labelled as AI-generated. We also\nsummarize the experimental designs that have been used to evaluate progress.\nOur survey suggests that the current and future potential of LLM-based\npersuasion poses profound ethical and societal risks, including the spread of\nmisinformation, the magnification of biases, and the invasion of privacy. These\nrisks underscore the urgent need for ethical guidelines and updated regulatory\nframeworks to avoid the widespread deployment of irresponsible and harmful LLM\nSystems.\n","authors":["Alexander Rogiers","Sander Noels","Maarten Buyl","Tijl De Bie"],"pdf_url":"https://arxiv.org/pdf/2411.06837v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06835v1","updated":"2024-11-11T10:02:49Z","published":"2024-11-11T10:02:49Z","title":"HarmLevelBench: Evaluating Harm-Level Compliance and the Impact of\n  Quantization on Model Alignment","summary":"  With the introduction of the transformers architecture, LLMs have\nrevolutionized the NLP field with ever more powerful models. Nevertheless,\ntheir development came up with several challenges. The exponential growth in\ncomputational power and reasoning capabilities of language models has\nheightened concerns about their security. As models become more powerful,\nensuring their safety has become a crucial focus in research. This paper aims\nto address gaps in the current literature on jailbreaking techniques and the\nevaluation of LLM vulnerabilities. Our contributions include the creation of a\nnovel dataset designed to assess the harmfulness of model outputs across\nmultiple harm levels, as well as a focus on fine-grained harm-level analysis.\nUsing this framework, we provide a comprehensive benchmark of state-of-the-art\njailbreaking attacks, specifically targeting the Vicuna 13B v1.5 model.\nAdditionally, we examine how quantization techniques, such as AWQ and GPTQ,\ninfluence the alignment and robustness of models, revealing trade-offs between\nenhanced robustness with regards to transfer attacks and potential increases in\nvulnerability on direct ones. This study aims to demonstrate the influence of\nharmful input queries on the complexity of jailbreaking techniques, as well as\nto deepen our understanding of LLM vulnerabilities and improve methods for\nassessing model robustness when confronted with harmful content, particularly\nin the context of compression strategies.\n","authors":["Yannis Belkhiter","Giulio Zizzo","Sergio Maffeis"],"pdf_url":"https://arxiv.org/pdf/2411.06835v1.pdf","comment":"NeurIPS 2024 Workshop on Safe Generative Artificial Intelligence\n  (SafeGenAI)"},{"id":"http://arxiv.org/abs/2409.13704v2","updated":"2024-11-11T10:02:24Z","published":"2024-09-05T10:27:32Z","title":"Entity Extraction from High-Level Corruption Schemes via Large Language\n  Models","summary":"  The rise of financial crime that has been observed in recent years has\ncreated an increasing concern around the topic and many people, organizations\nand governments are more and more frequently trying to combat it. Despite the\nincrease of interest in this area, there is a lack of specialized datasets that\ncan be used to train and evaluate works that try to tackle those problems. This\narticle proposes a new micro-benchmark dataset for algorithms and models that\nidentify individuals and organizations, and their multiple writings, in news\narticles, and presents an approach that assists in its creation. Experimental\nefforts are also reported, using this dataset, to identify individuals and\norganizations in financial-crime-related articles using various low-billion\nparameter Large Language Models (LLMs). For these experiments, standard metrics\n(Accuracy, Precision, Recall, F1 Score) are reported and various prompt\nvariants comprising the best practices of prompt engineering are tested. In\naddition, to address the problem of ambiguous entity mentions, a simple, yet\neffective LLM-based disambiguation method is proposed, ensuring that the\nevaluation aligns with reality. Finally, the proposed approach is compared\nagainst a widely used state-of-the-art open-source baseline, showing the\nsuperiority of the proposed method.\n","authors":["Panagiotis Koletsis","Panagiotis-Konstantinos Gemos","Christos Chronis","Iraklis Varlamis","Vasilis Efthymiou","Georgios Th. Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2409.13704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00500v2","updated":"2024-11-11T09:51:33Z","published":"2024-03-30T23:51:25Z","title":"The Shape of Word Embeddings: Quantifying Non-Isometry With Topological\n  Data Analysis","summary":"  Word embeddings represent language vocabularies as clouds of $d$-dimensional\npoints. We investigate how information is conveyed by the general shape of\nthese clouds, instead of representing the semantic meaning of each token.\nSpecifically, we use the notion of persistent homology from topological data\nanalysis (TDA) to measure the distances between language pairs from the shape\nof their unlabeled embeddings. These distances quantify the degree of\nnon-isometry of the embeddings. To distinguish whether these differences are\nrandom training errors or capture real information about the languages, we use\nthe computed distance matrices to construct language phylogenetic trees over 81\nIndo-European languages. Careful evaluation shows that our reconstructed trees\nexhibit strong and statistically-significant similarities to the reference.\n","authors":["Ond≈ôej Draganov","Steven Skiena"],"pdf_url":"https://arxiv.org/pdf/2404.00500v2.pdf","comment":"Submitted to EMNLP Findings 2024. The code used is shared on GitHub:\n  https://github.com/OnDraganov/shape-of-word-embeddings. URL of the\n  publication: \"https://aclanthology.org/2024.findings-emnlp.705\""},{"id":"http://arxiv.org/abs/2308.10792v7","updated":"2024-11-11T09:25:48Z","published":"2023-08-21T15:35:16Z","title":"Instruction Tuning for Large Language Models: A Survey","summary":"  This paper surveys research works in the quickly advancing field of\ninstruction tuning (IT), which can also be referred to as supervised\nfine-tuning (SFT)\\footnote{In this paper, unless specified otherwise,\ninstruction tuning (IT) will be equivalent to supervised fine-tuning (SFT).}, a\ncrucial technique to enhance the capabilities and controllability of large\nlanguage models (LLMs). Instruction tuning refers to the process of further\ntraining LLMs on a dataset consisting of \\textsc{(instruction, output)} pairs\nin a supervised fashion, which bridges the gap between the next-word prediction\nobjective of LLMs and the users' objective of having LLMs adhere to human\ninstructions. In this work, we make a systematic review of the literature,\nincluding the general methodology of IT, the construction of IT datasets, the\ntraining of IT models, and applications to different modalities, domains and\napplication, along with analysis on aspects that influence the outcome of IT\n(e.g., generation of instruction outputs, size of the instruction dataset,\netc). We also review the potential pitfalls of IT along with criticism against\nit, along with efforts pointing out current deficiencies of existing strategies\nand suggest some avenues for fruitful research.Project page:\ngithub.com/xiaoya-li/Instruction-Tuning-Survey\n","authors":["Shengyu Zhang","Linfeng Dong","Xiaoya Li","Sen Zhang","Xiaofei Sun","Shuhe Wang","Jiwei Li","Runyi Hu","Tianwei Zhang","Fei Wu","Guoyin Wang"],"pdf_url":"https://arxiv.org/pdf/2308.10792v7.pdf","comment":"V4; Last update: Nov 11, 2024"},{"id":"http://arxiv.org/abs/2402.04875v4","updated":"2024-11-11T09:22:02Z","published":"2024-02-07T14:16:28Z","title":"On Provable Length and Compositional Generalization","summary":"  Out-of-distribution generalization capabilities of sequence-to-sequence\nmodels can be studied from the lens of two crucial forms of generalization:\nlength generalization -- the ability to generalize to longer sequences than\nones seen during training, and compositional generalization: the ability to\ngeneralize to token combinations not seen during training. In this work, we\nprovide first provable guarantees on length and compositional generalization\nfor common sequence-to-sequence models -- deep sets, transformers, state space\nmodels, and recurrent neural nets -- trained to minimize the prediction error.\nTaking a first principles perspective, we study the realizable case, i.e., the\nlabeling function is realizable on the architecture. We show that \\emph{simple\nlimited capacity} versions of these different architectures achieve both length\nand compositional generalization. In all our results across different\narchitectures, we find that the learned representations are linearly related to\nthe representations generated by the true labeling function.\n","authors":["Kartik Ahuja","Amin Mansouri"],"pdf_url":"https://arxiv.org/pdf/2402.04875v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09056v2","updated":"2024-11-11T09:19:46Z","published":"2024-06-13T12:43:40Z","title":"CUDRT: Benchmarking the Detection Models of Human vs. Large Language\n  Models Generated Texts","summary":"  While large language models (LLMs) have greatly enhanced text generation\nacross industries, their human-like outputs make distinguishing between human\nand AI authorship challenging. Although many LLM-generated text detectors\nexist, current benchmarks mainly rely on static datasets, limiting their\neffectiveness in assessing model-based detectors requiring prior training.\nFurthermore, these benchmarks focus on specific scenarios like question\nanswering and text refinement and are primarily limited to English, overlooking\nbroader linguistic applications and LLM subtleties. To address these gaps, we\nconstruct a comprehensive bilingual benchmark in Chinese and English to\nrigorously evaluate mainstream LLM-generated text detection methods. We\ncategorize LLM text generation into five key operations-Create, Update, Delete,\nRewrite, and Translate (CUDRT)-covering the full range of LLM activities. For\neach CUDRT category, we developed extensive datasets enabling thorough\nassessment of detection performance, incorporating the latest mainstream LLMs\nfor each language. We also establish a robust evaluation framework to support\nscalable, reproducible experiments, facilitating an in-depth analysis of how\nLLM operations, different LLMs, datasets, and multilingual training sets impact\ndetector performance, particularly for model-based methods. Our extensive\nexperiments provide critical insights for optimizing LLM-generated text\ndetectors and suggest future directions to improve detection accuracy and\ngeneralization across diverse scenarios.Source code and dataset are available\nat GitHub.\n","authors":["Zhen Tao","Yanfang Chen","Dinghao Xi","Zhiyu Li","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2406.09056v2.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2405.09220v3","updated":"2024-11-11T09:16:56Z","published":"2024-05-15T09:59:37Z","title":"ALPINE: Unveiling the Planning Capability of Autoregressive Learning in\n  Language Models","summary":"  Planning is a crucial element of both human intelligence and contemporary\nlarge language models (LLMs). In this paper, we initiate a theoretical\ninvestigation into the emergence of planning capabilities in Transformer-based\nLLMs via their next-word prediction mechanisms. We model planning as a network\npath-finding task, where the objective is to generate a valid path from a\nspecified source node to a designated target node. Our mathematical\ncharacterization shows that Transformer architectures can execute path-finding\nby embedding the adjacency and reachability matrices within their weights.\nFurthermore, our theoretical analysis of gradient-based learning dynamics\nreveals that LLMs can learn both the adjacency and a limited form of the\nreachability matrices. These theoretical insights are then validated through\nexperiments, which demonstrate that Transformer architectures indeed learn the\nadjacency and an incomplete reachability matrices, consistent with our\ntheoretical predictions. When applying our methodology to the real-world\nplanning benchmark Blocksworld, our observations remain consistent.\nAdditionally, our analyses uncover a fundamental limitation of current\nTransformer architectures in path-finding: these architectures cannot identify\nreachability relationships through transitivity, which leads to failures in\ngenerating paths when concatenation is required. These findings provide new\ninsights into how the internal mechanisms of autoregressive learning facilitate\nintelligent planning and deepen our understanding of how future LLMs might\nachieve more advanced and general planning-and-reasoning capabilities across\ndiverse applications.\n","authors":["Siwei Wang","Yifei Shen","Shi Feng","Haoran Sun","Shang-Hua Teng","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2405.09220v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15761v2","updated":"2024-11-11T09:06:51Z","published":"2024-10-21T08:21:00Z","title":"Learning-to-Defer for Extractive Question Answering","summary":"  Pre-trained language models have profoundly impacted the field of extractive\nquestion-answering, leveraging large-scale textual corpora to enhance\ncontextual language understanding. Despite their success, these models struggle\nin complex scenarios that demand nuanced interpretation or inferential\nreasoning beyond immediate textual cues. Furthermore, their size poses\ndeployment challenges on resource-constrained devices. Addressing these\nlimitations, we introduce an adapted two-stage Learning-to-Defer mechanism that\nenhances decision-making by enabling selective deference to human experts or\nlarger models without retraining language models in the context of\nquestion-answering. This approach not only maintains computational efficiency\nbut also significantly improves model reliability and accuracy in ambiguous\ncontexts. We establish the theoretical soundness of our methodology by proving\nBayes and $(\\mathcal{H}, \\mathcal{R})$--consistency of our surrogate loss\nfunction, guaranteeing the optimality of the final solution. Empirical\nevaluations on the SQuADv2 dataset illustrate performance gains from\nintegrating human expertise and leveraging larger models. Our results further\ndemonstrate that deferring a minimal number of queries allows the smaller model\nto achieve performance comparable to their larger counterparts while preserving\ncomputing efficiency, thus broadening the applicability of pre-trained language\nmodels in diverse operational environments.\n","authors":["Yannis Montreuil","Axel Carlier","Lai Xing Ng","Wei Tsang Ooi"],"pdf_url":"https://arxiv.org/pdf/2410.15761v2.pdf","comment":"25 pages, 17 main paper"},{"id":"http://arxiv.org/abs/2411.06805v1","updated":"2024-11-11T09:03:52Z","published":"2024-11-11T09:03:52Z","title":"AssistRAG: Boosting the Potential of Large Language Models with an\n  Intelligent Information Assistant","summary":"  The emergence of Large Language Models (LLMs) has significantly advanced\nnatural language processing, but these models often generate factually\nincorrect information, known as \"hallucination\". Initial retrieval-augmented\ngeneration (RAG) methods like the \"Retrieve-Read\" framework was inadequate for\ncomplex reasoning tasks. Subsequent prompt-based RAG strategies and Supervised\nFine-Tuning (SFT) methods improved performance but required frequent retraining\nand risked altering foundational LLM capabilities. To cope with these\nchallenges, we propose Assistant-based Retrieval-Augmented Generation\n(AssistRAG), integrating an intelligent information assistant within LLMs. This\nassistant manages memory and knowledge through tool usage, action execution,\nmemory building, and plan specification. Using a two-phase training approach,\nCurriculum Assistant Learning and Reinforced Preference Optimization. AssistRAG\nenhances information retrieval and decision-making. Experiments show AssistRAG\nsignificantly outperforms benchmarks, especially benefiting less advanced LLMs,\nby providing superior reasoning capabilities and accurate responses.\n","authors":["Yujia Zhou","Zheng Liu","Zhicheng Dou"],"pdf_url":"https://arxiv.org/pdf/2411.06805v1.pdf","comment":"Accepted by NeurIPS 2024 (poster)"},{"id":"http://arxiv.org/abs/2411.06798v1","updated":"2024-11-11T08:51:18Z","published":"2024-11-11T08:51:18Z","title":"LA4SR: illuminating the dark proteome with generative AI","summary":"  AI language models (LMs) show promise for biological sequence analysis. We\nre-engineered open-source LMs (GPT-2, BLOOM, DistilRoBERTa, ELECTRA, and Mamba,\nranging from 70M to 12B parameters) for microbial sequence classification. The\nmodels achieved F1 scores up to 95 and operated 16,580x faster and at 2.9x the\nrecall of BLASTP. They effectively classified the algal dark proteome -\nuncharacterized proteins comprising about 65% of total proteins - validated on\nnew data including a new, complete Hi-C/Pacbio Chlamydomonas genome. Larger\n(>1B) LA4SR models reached high accuracy (F1 > 86) when trained on less than 2%\nof available data, rapidly achieving strong generalization capacity. High\naccuracy was achieved when training data had intact or scrambled terminal\ninformation, demonstrating robust generalization to incomplete sequences.\nFinally, we provide custom AI explainability software tools for attributing\namino acid patterns to AI generative processes and interpret their outputs in\nevolutionary and biophysical contexts.\n","authors":["David R. Nelson","Ashish Kumar Jaiswal","Noha Ismail","Alexandra Mystikou","Kourosh Salehi-Ashtiani"],"pdf_url":"https://arxiv.org/pdf/2411.06798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06790v1","updated":"2024-11-11T08:36:49Z","published":"2024-11-11T08:36:49Z","title":"Large-scale moral machine experiment on large language models","summary":"  The rapid advancement of Large Language Models (LLMs) and their potential\nintegration into autonomous driving systems necessitates understanding their\nmoral decision-making capabilities. While our previous study examined four\nprominent LLMs using the Moral Machine experimental framework, the dynamic\nlandscape of LLM development demands a more comprehensive analysis. Here, we\nevaluate moral judgments across 51 different LLMs, including multiple versions\nof proprietary models (GPT, Claude, Gemini) and open-source alternatives\n(Llama, Gemma), to assess their alignment with human moral preferences in\nautonomous driving scenarios. Using a conjoint analysis framework, we evaluated\nhow closely LLM responses aligned with human preferences in ethical dilemmas\nand examined the effects of model size, updates, and architecture. Results\nshowed that proprietary models and open-source models exceeding 10 billion\nparameters demonstrated relatively close alignment with human judgments, with a\nsignificant negative correlation between model size and distance from human\njudgments in open-source models. However, model updates did not consistently\nimprove alignment with human preferences, and many LLMs showed excessive\nemphasis on specific ethical principles. These findings suggest that while\nincreasing model size may naturally lead to more human-like moral judgments,\npractical implementation in autonomous driving systems requires careful\nconsideration of the trade-off between judgment quality and computational\nefficiency. Our comprehensive analysis provides crucial insights for the\nethical design of autonomous systems and highlights the importance of\nconsidering cultural contexts in AI moral decision-making.\n","authors":["Muhammad Shahrul Zaim bin Ahmad","Kazuhiro Takemoto"],"pdf_url":"https://arxiv.org/pdf/2411.06790v1.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.06767v1","updated":"2024-11-11T07:47:20Z","published":"2024-11-11T07:47:20Z","title":"PDC & DM-SFT: A Road for LLM SQL Bug-Fix Enhancing","summary":"  Code Large Language Models (Code LLMs), such as Code llama and\nDeepSeek-Coder, have demonstrated exceptional performance in the code\ngeneration tasks. However, most existing models focus on the abilities of\ngenerating correct code, but often struggle with bug repair. We introduce a\nsuit of methods to enhance LLM's SQL bug-fixing abilities. The methods are\nmainly consisted of two parts: A Progressive Dataset Construction (PDC) from\nscratch and Dynamic Mask Supervised Fine-tuning (DM-SFT). PDC proposes two data\nexpansion methods from the perspectives of breadth first and depth first\nrespectively. DM-SFT introduces an efficient bug-fixing supervised learning\napproach, which effectively reduce the total training steps and mitigate the\n\"disorientation\" in SQL code bug-fixing training. In our evaluation, the code\nLLM models trained with two methods have exceeds all current best performing\nmodel which size is much larger.\n","authors":["Yiwen Duan","Yonghong Yu","Xiaoming Zhao","Yichang Wu","Wenbo Liu"],"pdf_url":"https://arxiv.org/pdf/2411.06767v1.pdf","comment":"COLING-Industry 2025 accepted"},{"id":"http://arxiv.org/abs/2406.16758v2","updated":"2024-11-11T07:34:25Z","published":"2024-06-24T16:06:50Z","title":"Towards Fast Multilingual LLM Inference: Speculative Decoding and\n  Specialized Drafters","summary":"  Large language models (LLMs) have revolutionized natural language processing\nand broadened their applicability across diverse commercial applications.\nHowever, the deployment of these models is constrained by high inference time\nin multilingual settings. To mitigate this challenge, this paper explores a\ntraining recipe of an assistant model in speculative decoding, which is\nleveraged to draft and-then its future tokens are verified by the target LLM.\nWe show that language-specific draft models, optimized through a targeted\npretrain-and-finetune strategy, substantially brings a speedup in inference\ntime compared to the previous methods. We validate these models across various\nlanguages in inference time, out-of-domain speedup, and GPT-4o evaluation.\n","authors":["Euiin Yi","Taehyeon Kim","Hongseok Jeung","Du-Seong Chang","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2406.16758v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.15997v2","updated":"2024-11-11T07:27:03Z","published":"2023-07-29T14:47:07Z","title":"RoCar: A Relationship Network-based Evaluation Method for Large Language\n  Models","summary":"  Large language models (LLMs) have received increasing attention. However, due\nto the complexity of its capabilities, how to rationally evaluate the\ncapabilities of LLMs is still a task to be solved. We propose the RoCar method,\nwhich utilizes the defined basic schemas to randomly construct a task graph and\ngenerates natural language evaluation tasks based on the task graph to evaluate\nthe reasoning and memory abilities of LLMs respectively. Due to the very large\nrandomness of the task construction process, it is possible to ensure that none\nof the LLMs to be tested has directly learned the evaluation tasks,\nguaranteeing the fairness of the evaluation method.\n","authors":["Ming Wang","Wenfang Wu","Chongyun Gao","Daling Wang","Shi Feng","Yifei Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.15997v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.05365v3","updated":"2024-11-11T07:18:34Z","published":"2024-08-09T22:29:23Z","title":"FiSTECH: Financial Style Transfer to Enhance Creativity without\n  Hallucinations in LLMs","summary":"  Recent trends in Generative AI have emerged towards fine-tuning foundational\nlarge language models (LLMs) to create domain-specific LLMs for automation and\nchatbot-like applications. Specialized applications for analytics-heavy domains\nsuch as Financial report generation require specific writing styles that\ncomprise compound and creative sentences with minimized hallucinations. In this\nwork, we explore the self-corrective auto-regressive qualities of LLMs to learn\ncreativity in writing styles with minimal prompting. We propose a novel\ntwo-stage fine-tuning (FT) strategy wherein in the first stage public domain\nfinancial reports are used to train for writing styles while allowing the LLM\nto hallucinate. In the second stage the examples of hallucinations are manually\ncorrected and further used to fine-tune the LLM. The finally trained LLM learns\nto generate specific financial report sections using minimal instructions and\ntabular data inputs while ensuring low fine-tuning costs. Our proposed\ntwo-stage fine-tuning boosts the accuracy of financial questions answering by\ntwo-folds while reducing hallucinations by over 50%. Also, the fine-tuned model\nhas lower perplexity, improved ROUGE, TER and BLEU scores, higher creativity\nand knowledge density with lower uncertainty and cross entropy than base LLMs.\nThus, the proposed framework can be generalized to train creativity in LLMs by\nfirst allowing them to hallucinate.\n","authors":["Sohini Roychowdhury","Marko Krema","Brian Moore","Xingjian Lai","Dike Effedua","Bharat Jethwani"],"pdf_url":"https://arxiv.org/pdf/2408.05365v3.pdf","comment":"10 pages, 14 figures, 5 tables, conference"},{"id":"http://arxiv.org/abs/2409.14038v4","updated":"2024-11-11T06:26:39Z","published":"2024-09-21T06:49:34Z","title":"OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model\n  Hallucinations in Ontology Matching","summary":"  Hallucinations of large language models (LLMs) commonly occur in\ndomain-specific downstream tasks, with no exception in ontology matching (OM).\nThe prevalence of using LLMs for OM raises the need for benchmarks to better\nunderstand LLM hallucinations. The OAEI-LLM dataset is an extended version of\nthe Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate\nLLM-specific hallucinations in OM tasks. We outline the methodology used in\ndataset construction and schema extension, and provide examples of potential\nuse cases.\n","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang","Jing Jiang"],"pdf_url":"https://arxiv.org/pdf/2409.14038v4.pdf","comment":"5 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2411.00727v2","updated":"2024-11-11T06:25:04Z","published":"2024-11-01T16:39:03Z","title":"SPRING Lab IITM's submission to Low Resource Indic Language Translation\n  Shared Task","summary":"  We develop a robust translation model for four low-resource Indic languages:\nKhasi, Mizo, Manipuri, and Assamese. Our approach includes a comprehensive\npipeline from data collection and preprocessing to training and evaluation,\nleveraging data from WMT task datasets, BPCC, PMIndia, and OpenLanguageData. To\naddress the scarcity of bilingual data, we use back-translation techniques on\nmonolingual datasets for Mizo and Khasi, significantly expanding our training\ncorpus. We fine-tune the pre-trained NLLB 3.3B model for Assamese, Mizo, and\nManipuri, achieving improved performance over the baseline. For Khasi, which is\nnot supported by the NLLB model, we introduce special tokens and train the\nmodel on our Khasi corpus. Our training involves masked language modelling,\nfollowed by fine-tuning for English-to-Indic and Indic-to-English translations.\n","authors":["Hamees Sayed","Advait Joglekar","Srinivasan Umesh"],"pdf_url":"https://arxiv.org/pdf/2411.00727v2.pdf","comment":"Published in WMT 2024. Low-Resource Indic Language Translation Shared\n  Task"},{"id":"http://arxiv.org/abs/2411.06729v1","updated":"2024-11-11T05:58:48Z","published":"2024-11-11T05:58:48Z","title":"Reverse Prompt Engineering","summary":"  This paper explores a new black-box, zero-shot language model inversion\nproblem and proposes an innovative framework for prompt reconstruction using\nonly text outputs from a language model. Leveraging a large language model\nalongside an optimization algorithm, the proposed method effectively recovers\nprompts with minimal resources. Experimental results on several datasets\nderived from public sources indicate that the proposed approach achieves\nhigh-quality prompt recovery and generates prompts more similar to the\noriginals than current state-of-the-art methods. Additionally, the use-case\nstudy demonstrates the method's strong potential for generating high-quality\ntext data.\n","authors":["Hanqing Li","Diego Klabjan"],"pdf_url":"https://arxiv.org/pdf/2411.06729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12641v2","updated":"2024-11-11T05:48:35Z","published":"2024-06-18T14:08:01Z","title":"DetectBench: Can Large Language Model Detect and Piece Together Implicit\n  Evidence?","summary":"  Detecting evidence within the context is a key step in the process of\nreasoning task. Evaluating and enhancing the capabilities of LLMs in evidence\ndetection will strengthen context-based reasoning performance. This paper\nproposes a benchmark called DetectBench for verifying the ability to detect and\npiece together implicit evidence within a long context. DetectBench contains\n3,928 multiple-choice questions, with an average of 994 tokens per question.\nEach question contains an average of 4.55 pieces of implicit evidence, and\nsolving the problem typically requires 7.62 logical jumps to find the correct\nanswer. To enhance the performance of LLMs in evidence detection, this paper\nproposes Detective Reasoning Prompt and Finetune. Experiments demonstrate that\nthe existing LLMs' abilities to detect evidence in long contexts are far\ninferior to humans. However, the Detective Reasoning Prompt effectively\nenhances the capability of powerful LLMs in evidence detection, while the\nFinetuning method shows significant effects in enhancing the performance of\nweaker LLMs. Moreover, when the abilities of LLMs in evidence detection are\nimproved, their final reasoning performance is also enhanced accordingly.\n","authors":["Zhouhong Gu","Lin Zhang","Xiaoxuan Zhu","Jiangjie Chen","Wenhao Huang","Yikai Zhang","Shusen Wang","Zheyu Ye","Yan Gao","Hongwei Feng","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2406.12641v2.pdf","comment":"EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2312.02188v2","updated":"2024-11-11T05:14:15Z","published":"2023-12-01T23:56:00Z","title":"Video Summarization: Towards Entity-Aware Captions","summary":"  Existing popular video captioning benchmarks and models deal with generic\ncaptions devoid of specific person, place or organization named entities. In\ncontrast, news videos present a challenging setting where the caption requires\nsuch named entities for meaningful summarization. As such, we propose the task\nof summarizing news video directly to entity-aware captions. We also release a\nlarge-scale dataset, VIEWS (VIdeo NEWS), to support research on this task.\nFurther, we propose a method that augments visual information from videos with\ncontext retrieved from external world knowledge to generate entity-aware\ncaptions. We demonstrate the effectiveness of our approach on three video\ncaptioning models. We also show that our approach generalizes to existing news\nimage captions dataset. With all the extensive experiments and insights, we\nbelieve we establish a solid basis for future research on this challenging\ntask.\n","authors":["Hammad A. Ayyubi","Tianqi Liu","Arsha Nagrani","Xudong Lin","Mingda Zhang","Anurag Arnab","Feng Han","Yukun Zhu","Jialu Liu","Shih-Fu Chang"],"pdf_url":"https://arxiv.org/pdf/2312.02188v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06710v1","updated":"2024-11-11T04:36:58Z","published":"2024-11-11T04:36:58Z","title":"Model Fusion through Bayesian Optimization in Language Model Fine-Tuning","summary":"  Fine-tuning pre-trained models for downstream tasks is a widely adopted\ntechnique known for its adaptability and reliability across various domains.\nDespite its conceptual simplicity, fine-tuning entails several troublesome\nengineering choices, such as selecting hyperparameters and determining\ncheckpoints from an optimization trajectory. To tackle the difficulty of\nchoosing the best model, one effective solution is model fusion, which combines\nmultiple models in a parameter space. However, we observe a large discrepancy\nbetween loss and metric landscapes during the fine-tuning of pre-trained\nlanguage models. Building on this observation, we introduce a novel model\nfusion technique that optimizes both the desired metric and loss through\nmulti-objective Bayesian optimization. In addition, to effectively select\nhyperparameters, we establish a two-stage procedure by integrating Bayesian\noptimization processes into our framework. Experiments across various\ndownstream tasks show considerable performance improvements using our Bayesian\noptimization-guided method.\n","authors":["Chaeyun Jang","Hyungi Lee","Jungtaek Kim","Juho Lee"],"pdf_url":"https://arxiv.org/pdf/2411.06710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.24190v3","updated":"2024-11-11T04:35:11Z","published":"2024-10-31T17:51:00Z","title":"Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters","summary":"  How could LLMs influence our democracy? We investigate LLMs' political\nleanings and the potential influence of LLMs on voters by conducting multiple\nexperiments in a U.S. presidential election context. Through a voting\nsimulation, we first demonstrate 18 open- and closed-weight LLMs' political\npreference for a Democratic nominee over a Republican nominee. We show how this\nleaning towards the Democratic nominee becomes more pronounced in\ninstruction-tuned models compared to their base versions by analyzing their\nresponses to candidate-policy related questions. We further explore the\npotential impact of LLMs on voter choice by conducting an experiment with 935\nU.S. registered voters. During the experiments, participants interacted with\nLLMs (Claude-3, Llama-3, and GPT-4) over five exchanges. The experiment results\nshow a shift in voter choices towards the Democratic nominee following LLM\ninteraction, widening the voting margin from 0.7% to 4.6%, even though LLMs\nwere not asked to persuade users to support the Democratic nominee during the\ndiscourse. This effect is larger than many previous studies on the\npersuasiveness of political campaigns, which have shown minimal effects in\npresidential elections. Many users also expressed a desire for further\npolitical interaction with LLMs. Which aspects of LLM interactions drove these\nshifts in voter choice requires further study. Lastly, we explore how a safety\nmethod can make LLMs more politically neutral, while raising the question of\nwhether such neutrality is truly the path forward.\n","authors":["Yujin Potter","Shiyang Lai","Junsol Kim","James Evans","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2410.24190v3.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2407.12843v4","updated":"2024-11-11T04:17:30Z","published":"2024-07-04T15:10:51Z","title":"NutriBench: A Dataset for Evaluating Large Language Models on Nutrition\n  Estimation from Meal Descriptions","summary":"  Accurate nutrition estimation helps people make informed dietary choices and\nis essential in the prevention of serious health complications. We present\nNutriBench, the first publicly available natural language meal description\nnutrition benchmark. NutriBench consists of 11,857 meal descriptions generated\nfrom real-world global dietary intake data. The data is human-verified and\nannotated with macro-nutrient labels, including carbohydrates, proteins, fats,\nand calories. We conduct an extensive evaluation of NutriBench on the task of\ncarbohydrate estimation, testing twelve leading Large Language Models (LLMs),\nincluding GPT-4o, Llama3.1, Qwen2, Gemma2, and OpenBioLLM models, using\nstandard, Chain-of-Thought and Retrieval-Augmented Generation strategies.\nAdditionally, we present a study involving professional nutritionists, finding\nthat LLMs can provide more accurate and faster estimates. Finally, we perform a\nreal-world risk assessment by simulating the effect of carbohydrate predictions\non the blood glucose levels of individuals with diabetes. Our work highlights\nthe opportunities and challenges of using LLMs for nutrition estimation,\ndemonstrating their potential to aid professionals and laypersons and improve\nhealth outcomes. Our benchmark is publicly available at:\nhttps://mehak126.github.io/nutribench.html\n","authors":["Andong Hua","Mehak Preet Dhaliwal","Ryan Burke","Laya Pullela","Yao Qin"],"pdf_url":"https://arxiv.org/pdf/2407.12843v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06672v1","updated":"2024-11-11T02:37:21Z","published":"2024-11-11T02:37:21Z","title":"What Should Baby Models Read? Exploring Sample-Efficient Data\n  Composition on Model Performance","summary":"  We explore the impact of pre-training data composition on the performance of\nsmall language models in a sample-efficient setting. Using datasets limited to\n10 million words, we evaluate several dataset sources, including child-directed\nspeech (CHILDES), classic books (Gutenberg), synthetic data (TinyStories), and\na mix of these (Mix) across different model sizes ranging from 18 million to\n705 million parameters. Our experiments show that smaller models (e.g.,\nGPT2-97M, GPT2-705M, Llama-360M) perform better when trained on more complex\nand rich datasets like Gutenberg. Models trained on the CHILDES and TinyStories\ndatasets underperformed across all model sizes. These findings suggest that the\noptimal dataset for sample efficient training depends on the model size, and\nthat neither child-directed speech nor simplified stories are optimal for\nlanguage models of all sizes. We highlight the importance of considering both\ndataset composition and model capacity for effective sample efficient language\nmodel training.\n","authors":["Hong Meng Yam","Nathan J Paek"],"pdf_url":"https://arxiv.org/pdf/2411.06672v1.pdf","comment":"8 pages, 6 figures, CoNLL 2024 (Shared Task) Accepted Paper"},{"id":"http://arxiv.org/abs/2406.19470v2","updated":"2024-11-11T02:27:54Z","published":"2024-06-27T18:21:32Z","title":"Changing Answer Order Can Decrease MMLU Accuracy","summary":"  As large language models (LLMs) have grown in prevalence, particular\nbenchmarks have become essential for the evaluation of these models and for\nunderstanding model capabilities. Most commonly, we use test accuracy averaged\nacross multiple subtasks in order to rank models on leaderboards, to determine\nwhich model is best for our purposes. In this paper, we investigate the\nrobustness of the accuracy measurement on a widely used multiple choice\nquestion answering dataset, MMLU. When shuffling the answer label contents, we\nfind that all explored models decrease in accuracy on MMLU, but not every model\nis equally sensitive. These findings suggest a possible adjustment to the\nstandard practice of leaderboard testing, where we additionally consider the\npercentage of examples each model answers correctly by random chance.\n","authors":["Vipul Gupta","David Pantoja","Candace Ross","Adina Williams","Megan Ung"],"pdf_url":"https://arxiv.org/pdf/2406.19470v2.pdf","comment":"Short paper, 9 pages"},{"id":"http://arxiv.org/abs/2411.06660v1","updated":"2024-11-11T01:59:04Z","published":"2024-11-11T01:59:04Z","title":"Bridge: A Unified Framework to Knowledge Graph Completion via Language\n  Models and Knowledge Representation","summary":"  Knowledge graph completion (KGC) is a task of inferring missing triples based\non existing Knowledge Graphs (KGs). Both structural and semantic information\nare vital for successful KGC. However, existing methods only use either the\nstructural knowledge from the KG embeddings or the semantic information from\npre-trained language models (PLMs), leading to suboptimal model performance.\nMoreover, since PLMs are not trained on KGs, directly using PLMs to encode\ntriples may be inappropriate. To overcome these limitations, we propose a novel\nframework called Bridge, which jointly encodes structural and semantic\ninformation of KGs. Specifically, we strategically encode entities and\nrelations separately by PLMs to better utilize the semantic knowledge of PLMs\nand enable structured representation learning via a structural learning\nprinciple. Furthermore, to bridge the gap between KGs and PLMs, we employ a\nself-supervised representation learning method called BYOL to fine-tune PLMs\nwith two different views of a triple. Unlike BYOL, which uses augmentation\nmethods to create two semantically similar views of the same image, potentially\naltering the semantic information. We strategically separate the triple into\ntwo parts to create different views, thus avoiding semantic alteration.\nExperiments demonstrate that Bridge outperforms the SOTA models on three\nbenchmark datasets.\n","authors":["Qiao Qiao","Yuepei Li","Qing Wang","Kang Zhou","Qi Li"],"pdf_url":"https://arxiv.org/pdf/2411.06660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06657v1","updated":"2024-11-11T01:44:54Z","published":"2024-11-11T01:44:54Z","title":"Renaissance: Investigating the Pretraining of Vision-Language Encoders","summary":"  In the past several years there has been an explosion of available models for\nvision-language tasks. Unfortunately, the literature still leaves open a number\nof questions related to best practices in designing and training such models.\nIn this paper we seek to answer several questions related to the pretraining of\nvision-language encoders through meta-analysis. In our first set of\nexperiments, we show that we can save significant compute at no cost to\ndownstream performance, by freezing large parts of vision-language models\nduring pretraining. In our second set of experiments we examine the effect of\nbasing a VL transformer on a vision model versus a text model. Additionally, we\nintroduce a VL modeling platform called Renaissance that we use to conduct all\nof the experiments. This program offers a great deal of flexibility in\ncreating, training and evaluating transformer encoders for VL modeling. The\nsource code for Renaissance can be found at\nhttps://github.com/bsu-slim/renaissance.\n","authors":["Clayton Fields","Casey Kennington"],"pdf_url":"https://arxiv.org/pdf/2411.06657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06655v1","updated":"2024-11-11T01:42:56Z","published":"2024-11-11T01:42:56Z","title":"Explore the Reasoning Capability of LLMs in the Chess Testbed","summary":"  Reasoning is a central capability of human intelligence. In recent years,\nwith the advent of large-scale datasets, pretrained large language models have\nemerged with new capabilities, including reasoning. However, these models still\nstruggle with long-term, complex reasoning tasks, such as playing chess. Based\non the observation that expert chess players employ a dual approach combining\nlong-term strategic play with short-term tactical play along with language\nexplanation, we propose improving the reasoning capability of large language\nmodels in chess by integrating annotated strategy and tactic. Specifically, we\ncollect a dataset named MATE, which consists of 1 million chess positions with\ncandidate moves annotated by chess experts for strategy and tactics. We\nfinetune the LLaMA-3-8B model and compare it against state-of-the-art\ncommercial language models in the task of selecting better chess moves. Our\nexperiments show that our models perform better than GPT, Claude, and Gemini\nmodels. We find that language explanations can enhance the reasoning capability\nof large language models.\n","authors":["Shu Wang","Lei Ji","Renxi Wang","Wenxiao Zhao","Haokun Liu","Yifan Hou","Ying Nian Wu"],"pdf_url":"https://arxiv.org/pdf/2411.06655v1.pdf","comment":"submitted to NAACL2025"},{"id":"http://arxiv.org/abs/2411.06646v1","updated":"2024-11-11T01:05:28Z","published":"2024-11-11T01:05:28Z","title":"Understanding Scaling Laws with Statistical and Approximation Theory for\n  Transformer Neural Networks on Intrinsically Low-dimensional Data","summary":"  When training deep neural networks, a model's generalization error is often\nobserved to follow a power scaling law dependent both on the model size and the\ndata size. Perhaps the best known example of such scaling laws are for\ntransformer-based large language models, where networks with billions of\nparameters are trained on trillions of tokens of text. Yet, despite sustained\nwidespread interest, a rigorous understanding of why transformer scaling laws\nexist is still missing. To answer this question, we establish novel statistical\nestimation and mathematical approximation theories for transformers when the\ninput data are concentrated on a low-dimensional manifold. Our theory predicts\na power law between the generalization error and both the training data size\nand the network size for transformers, where the power depends on the intrinsic\ndimension $d$ of the training data. Notably, the constructed model architecture\nis shallow, requiring only logarithmic depth in $d$. By leveraging\nlow-dimensional data structures under a manifold hypothesis, we are able to\nexplain transformer scaling laws in a way which respects the data geometry.\nMoreover, we test our theory with empirical observation by training LLMs on\nnatural language datasets. We find the observed empirical data scaling laws\nclosely agree with our theoretical predictions. Taken together, these results\nrigorously show the intrinsic dimension of data to be a crucial quantity\naffecting transformer scaling laws in both theory and practice.\n","authors":["Alex Havrilla","Wenjing Liao"],"pdf_url":"https://arxiv.org/pdf/2411.06646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09403v3","updated":"2024-11-11T00:54:32Z","published":"2024-06-13T17:59:31Z","title":"Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal\n  Language Models","summary":"  Humans draw to facilitate reasoning: we draw auxiliary lines when solving\ngeometry problems; we mark and circle when reasoning on maps; we use sketches\nto amplify our ideas and relieve our limited-capacity working memory. However,\nsuch actions are missing in current multimodal language models (LMs). Current\nchain-of-thought and tool-use paradigms only use text as intermediate reasoning\nsteps. In this work, we introduce Sketchpad, a framework that gives multimodal\nLMs a visual sketchpad and tools to draw on the sketchpad. The LM conducts\nplanning and reasoning according to the visual artifacts it has drawn.\nDifferent from prior work, which uses text-to-image models to enable LMs to\ndraw, Sketchpad enables LMs to draw with lines, boxes, marks, etc., which is\ncloser to human sketching and better facilitates reasoning. Sketchpad can also\nuse specialist vision models during the sketching process (e.g., draw bounding\nboxes with object detection models, draw masks with segmentation models), to\nfurther enhance visual perception and reasoning. We experiment with a wide\nrange of math tasks (including geometry, functions, graphs, and chess) and\ncomplex visual reasoning tasks. Sketchpad substantially improves performance on\nall tasks over strong base models with no sketching, yielding an average gain\nof 12.7% on math tasks, and 8.6% on vision tasks. GPT-4o with Sketchpad sets a\nnew state of the art on all tasks, including V*Bench (80.3%), BLINK spatial\nreasoning (83.9%), and visual correspondence (80.8%). All codes and data are in\nhttps://visualsketchpad.github.io/.\n","authors":["Yushi Hu","Weijia Shi","Xingyu Fu","Dan Roth","Mari Ostendorf","Luke Zettlemoyer","Noah A Smith","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2406.09403v3.pdf","comment":"Accepted to NeurIPS 2024. Project and codes url:\n  https://visualsketchpad.github.io/"},{"id":"http://arxiv.org/abs/2411.06638v1","updated":"2024-11-11T00:18:54Z","published":"2024-11-11T00:18:54Z","title":"Model Editing for LLMs4Code: How Far are We?","summary":"  Large Language Models for Code (LLMs4Code) have been found to exhibit\noutstanding performance in the software engineering domain, especially the\nremarkable performance in coding tasks. However, even the most advanced\nLLMs4Code can inevitably contain incorrect or outdated code knowledge. Due to\nthe high cost of training LLMs4Code, it is impractical to re-train the models\nfor fixing these problematic code knowledge. Model editing is a new technical\nfield for effectively and efficiently correcting erroneous knowledge in LLMs,\nwhere various model editing techniques and benchmarks have been proposed\nrecently. Despite that, a comprehensive study that thoroughly compares and\nanalyzes the performance of the state-of-the-art model editing techniques for\nadapting the knowledge within LLMs4Code across various code-related tasks is\nnotably absent. To bridge this gap, we perform the first systematic study on\napplying state-of-the-art model editing approaches to repair the inaccuracy of\nLLMs4Code. To that end, we introduce a benchmark named CLMEEval, which consists\nof two datasets, i.e., CoNaLa-Edit (CNLE) with 21K+ code generation samples and\nCodeSearchNet-Edit (CSNE) with 16K+ code summarization samples. With the help\nof CLMEEval, we evaluate six advanced model editing techniques on three\nLLMs4Code: CodeLlama (7B), CodeQwen1.5 (7B), and Stable-Code (3B). Our findings\ninclude that the external memorization-based GRACE approach achieves the best\nknowledge editing effectiveness and specificity (the editing does not influence\nuntargeted knowledge), while generalization (whether the editing can generalize\nto other semantically-identical inputs) is a universal challenge for existing\ntechniques. Furthermore, building on in-depth case analysis, we introduce an\nenhanced version of GRACE called A-GRACE, which incorporates contrastive\nlearning to better capture the semantics of the inputs.\n","authors":["Xiaopeng Li","Shangwen Wang","Shasha Li","Jun Ma","Jie Yu","Xiaodong Liu","Jing Wang","Bin Ji","Weimin Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06638v1.pdf","comment":"Accepted by ICSE2025. The code is available at:\n  https://github.com/xpq-tech/code-llmedit.git"},{"id":"http://arxiv.org/abs/2410.11119v3","updated":"2024-11-11T23:36:36Z","published":"2024-10-14T22:06:54Z","title":"ChuLo: Chunk-Level Key Information Representation for Long Document\n  Processing","summary":"  Transformer-based models have achieved remarkable success in various Natural\nLanguage Processing (NLP) tasks, yet their ability to handle long documents is\nconstrained by computational limitations. Traditional approaches, such as\ntruncating inputs, sparse self-attention, and chunking, attempt to mitigate\nthese issues, but they often lead to information loss and hinder the model's\nability to capture long-range dependencies. In this paper, we introduce ChuLo,\na novel chunk representation method for long document classification that\naddresses these limitations. Our ChuLo groups input tokens using unsupervised\nkeyphrase extraction, emphasizing semantically important keyphrase based chunk\nto retain core document content while reducing input length. This approach\nminimizes information loss and improves the efficiency of Transformer-based\nmodels. Preserving all tokens in long document understanding, especially token\nclassification tasks, is especially important to ensure that fine-grained\nannotations, which depend on the entire sequence context, are not lost. We\nevaluate our method on multiple long document classification tasks and long\ndocument token classification tasks, demonstrating its effectiveness through\ncomprehensive qualitative and quantitative analyses.\n","authors":["Yan Li","Soyeon Caren Han","Yue Dai","Feiqi Cao"],"pdf_url":"https://arxiv.org/pdf/2410.11119v3.pdf","comment":"The paper has been submitted to a conference and is currently under\n  review"},{"id":"http://arxiv.org/abs/2409.06803v2","updated":"2024-11-11T23:33:50Z","published":"2024-09-10T18:14:02Z","title":"Decomposition of surprisal: Unified computational model of ERP\n  components in language processing","summary":"  The functional interpretation of language-related ERP components has been a\ncentral debate in psycholinguistics for decades. We advance an\ninformation-theoretic model of human language processing in the brain in which\nincoming linguistic input is processed at first shallowly and later with more\ndepth, with these two kinds of information processing corresponding to distinct\nelectroencephalographic signatures. Formally, we show that the information\ncontent (surprisal) of a word in context can be decomposed into two quantities:\n(A) shallow surprisal, which signals shallow processing difficulty for a word,\nand corresponds with the N400 signal; and (B) deep surprisal, which reflects\nthe discrepancy between shallow and deep representations, and corresponds to\nthe P600 signal and other late positivities. Both of these quantities can be\nestimated straightforwardly using modern NLP models. We validate our theory by\nsuccessfully simulating ERP patterns elicited by a variety of linguistic\nmanipulations in previously-reported experimental data from six experiments,\nwith successful novel qualitative and quantitative predictions. Our theory is\ncompatible with traditional cognitive theories assuming a `good-enough' shallow\nrepresentation stage, but with a precise information-theoretic formulation. The\nmodel provides an information-theoretic model of ERP components grounded on\ncognitive processes, and brings us closer to a fully-specified\nneuro-computational model of language processing.\n","authors":["Jiaxuan Li","Richard Futrell"],"pdf_url":"https://arxiv.org/pdf/2409.06803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16914v3","updated":"2024-11-11T23:08:20Z","published":"2024-02-25T17:43:29Z","title":"DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM\n  Jailbreakers","summary":"  The safety alignment of Large Language Models (LLMs) is vulnerable to both\nmanual and automated jailbreak attacks, which adversarially trigger LLMs to\noutput harmful content. However, current methods for jailbreaking LLMs, which\nnest entire harmful prompts, are not effective at concealing malicious intent\nand can be easily identified and rejected by well-aligned LLMs. This paper\ndiscovers that decomposing a malicious prompt into separated sub-prompts can\neffectively obscure its underlying malicious intent by presenting it in a\nfragmented, less detectable form, thereby addressing these limitations. We\nintroduce an automatic prompt \\textbf{D}ecomposition and\n\\textbf{R}econstruction framework for jailbreak \\textbf{Attack} (DrAttack).\nDrAttack includes three key components: (a) `Decomposition' of the original\nprompt into sub-prompts, (b) `Reconstruction' of these sub-prompts implicitly\nby in-context learning with semantically similar but harmless reassembling\ndemo, and (c) a `Synonym Search' of sub-prompts, aiming to find sub-prompts'\nsynonyms that maintain the original intent while jailbreaking LLMs. An\nextensive empirical study across multiple open-source and closed-source LLMs\ndemonstrates that, with a significantly reduced number of queries, DrAttack\nobtains a substantial gain of success rate over prior SOTA prompt-only\nattackers. Notably, the success rate of 78.0\\% on GPT-4 with merely 15 queries\nsurpassed previous art by 33.1\\%. The project is available at\nhttps://github.com/xirui-li/DrAttack.\n","authors":["Xirui Li","Ruochen Wang","Minhao Cheng","Tianyi Zhou","Cho-Jui Hsieh"],"pdf_url":"https://arxiv.org/pdf/2402.16914v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06770v3","updated":"2024-11-11T23:05:04Z","published":"2023-10-10T16:47:29Z","title":"SWE-bench: Can Language Models Resolve Real-World GitHub Issues?","summary":"  Language models have outpaced our ability to evaluate them effectively, but\nfor their future development it is essential to study the frontier of their\ncapabilities. We find real-world software engineering to be a rich,\nsustainable, and challenging testbed for evaluating the next generation of\nlanguage models. To this end, we introduce SWE-bench, an evaluation framework\nconsisting of $2,294$ software engineering problems drawn from real GitHub\nissues and corresponding pull requests across $12$ popular Python repositories.\nGiven a codebase along with a description of an issue to be resolved, a\nlanguage model is tasked with editing the codebase to address the issue.\nResolving issues in SWE-bench frequently requires understanding and\ncoordinating changes across multiple functions, classes, and even files\nsimultaneously, calling for models to interact with execution environments,\nprocess extremely long contexts and perform complex reasoning that goes far\nbeyond traditional code generation tasks. Our evaluations show that both\nstate-of-the-art proprietary models and our fine-tuned model SWE-Llama can\nresolve only the simplest issues. The best-performing model, Claude 2, is able\nto solve a mere $1.96$% of the issues. Advances on SWE-bench represent steps\ntowards LMs that are more practical, intelligent, and autonomous.\n","authors":["Carlos E. Jimenez","John Yang","Alexander Wettig","Shunyu Yao","Kexin Pei","Ofir Press","Karthik Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2310.06770v3.pdf","comment":"Data, code, and leaderboard are available at https://www.swebench.com\n  ICLR 2024, https://openreview.net/forum?id=VTF8yNQM66"},{"id":"http://arxiv.org/abs/2405.03111v2","updated":"2024-11-11T22:53:21Z","published":"2024-05-06T02:07:13Z","title":"Temporal Dynamics of Emotion and Cognition in Human Translation:\n  Integrating the Task Segment Framework and the HOF Taxonomy","summary":"  The paper develops a novel generative model of human translation processes\ngrounded in empirical translation process data. Assuming three processes that\nunfold concurrently in the translating mind, it integrates the Task Segment\nFramework (Munoz & Apfelthaler 2022) and the HOF taxonomy (Carl et al 2024)\ninto a coherent architecture: uninterrupted translation production is caused by\nroutinized/automated processes, cognitive/reflective interventions lead to\nlonger keystroke pauses, while emotional/affective states of the mind are\nidentified by distinctive gazing patterns. Utilizing data from the CRITT\nTranslation Process Research Database (TPR-DB), the paper illustrates how the\ntemporal structure of keystroke and gazing data can be related to the three\nassumed hidden mental processes that are believed to cause the observable data.\nThe paper relates this embedded generative model with Robinsons (2023)\nideosomatic theory of translation, opening exciting, new theoretical horizons\nfor Cognitive Translation Studies, grounded in empirical data and evaluation.\n","authors":["Michael Carl"],"pdf_url":"https://arxiv.org/pdf/2405.03111v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07417v1","updated":"2024-11-11T22:44:29Z","published":"2024-11-11T22:44:29Z","title":"Untangling Hate Speech Definitions: A Semantic Componential Analysis\n  Across Cultures and Domains","summary":"  Hate speech relies heavily on cultural influences, leading to varying\nindividual interpretations. For that reason, we propose a Semantic Componential\nAnalysis (SCA) framework for a cross-cultural and cross-domain analysis of hate\nspeech definitions. We create the first dataset of definitions derived from\nfive domains: online dictionaries, research papers, Wikipedia articles,\nlegislation, and online platforms, which are later analyzed into semantic\ncomponents. Our analysis reveals that the components differ from definition to\ndefinition, yet many domains borrow definitions from one another without taking\ninto account the target culture. We conduct zero-shot model experiments using\nour proposed dataset, employing three popular open-sourced LLMs to understand\nthe impact of different definitions on hate speech detection. Our findings\nindicate that LLMs are sensitive to definitions: responses for hate speech\ndetection change according to the complexity of definitions used in the prompt.\n","authors":["Katerina Korre","Arianna Muti","Federico Ruggeri","Alberto Barr√≥n-Cede√±o"],"pdf_url":"https://arxiv.org/pdf/2411.07417v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07407v1","updated":"2024-11-11T22:27:36Z","published":"2024-11-11T22:27:36Z","title":"Using Generative AI and Multi-Agents to Provide Automatic Feedback","summary":"  This study investigates the use of generative AI and multi-agent systems to\nprovide automatic feedback in educational contexts, particularly for student\nconstructed responses in science assessments. The research addresses a key gap\nin the field by exploring how multi-agent systems, called AutoFeedback, can\nimprove the quality of GenAI-generated feedback, overcoming known issues such\nas over-praise and over-inference that are common in single-agent large\nlanguage models (LLMs). The study developed a multi-agent system consisting of\ntwo AI agents: one for generating feedback and another for validating and\nrefining it. The system was tested on a dataset of 240 student responses, and\nits performance was compared to that of a single-agent LLM. Results showed that\nAutoFeedback significantly reduced the occurrence of over-praise and\nover-inference errors, providing more accurate and pedagogically sound\nfeedback. The findings suggest that multi-agent systems can offer a more\nreliable solution for generating automated feedback in educational settings,\nhighlighting their potential for scalable and personalized learning support.\nThese results have important implications for educators and researchers seeking\nto leverage AI in formative assessments, offering a pathway to more effective\nfeedback mechanisms that enhance student learning outcomes.\n","authors":["Shuchen Guo","Ehsan Latif","Yifan Zhou","Xuan Huang","Xiaoming Zhai"],"pdf_url":"https://arxiv.org/pdf/2411.07407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07404v1","updated":"2024-11-11T22:22:21Z","published":"2024-11-11T22:22:21Z","title":"Controllable Context Sensitivity and the Knob Behind It","summary":"  When making predictions, a language model must trade off how much it relies\non its context vs. its prior knowledge. Choosing how sensitive the model is to\nits context is a fundamental functionality, as it enables the model to excel at\ntasks like retrieval-augmented generation and question-answering. In this\npaper, we search for a knob which controls this sensitivity, determining\nwhether language models answer from the context or their prior knowledge. To\nguide this search, we design a task for controllable context sensitivity. In\nthis task, we first feed the model a context (Paris is in England) and a\nquestion (Where is Paris?); we then instruct the model to either use its prior\nor contextual knowledge and evaluate whether it generates the correct answer\nfor both intents (either France or England). When fine-tuned on this task,\ninstruction-tuned versions of Llama-3.1, Mistral-v0.3, and Gemma-2 can solve it\nwith high accuracy (85-95%). Analyzing these high-performing models, we narrow\ndown which layers may be important to context sensitivity using a novel linear\ntime algorithm. Then, in each model, we identify a 1-D subspace in a single\nlayer that encodes whether the model follows context or prior knowledge.\nInterestingly, while we identify this subspace in a fine-tuned model, we find\nthat the exact same subspace serves as an effective knob in not only that model\nbut also non-fine-tuned instruct and base models of that model family. Finally,\nwe show a strong correlation between a model's performance and how distinctly\nit separates context-agreeing from context-ignoring answers in this subspace.\nThese results suggest a single subspace facilitates how the model chooses\nbetween context and prior knowledge, hinting at a simple fundamental mechanism\nthat controls this behavior.\n","authors":["Julian Minder","Kevin Du","Niklas Stoehr","Giovanni Monea","Chris Wendler","Robert West","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20724v2","updated":"2024-11-11T22:18:14Z","published":"2024-10-28T04:39:32Z","title":"Simple is Effective: The Roles of Graphs and Large Language Models in\n  Knowledge-Graph-Based Retrieval-Augmented Generation","summary":"  Large Language Models (LLMs) demonstrate strong reasoning abilities but face\nlimitations such as hallucinations and outdated knowledge. Knowledge Graph\n(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by\ngrounding LLM outputs in structured external knowledge from KGs. However,\ncurrent KG-based RAG frameworks still struggle to optimize the trade-off\nbetween retrieval effectiveness and efficiency in identifying a suitable amount\nof relevant graph information for the LLM to digest. We introduce SubgraphRAG,\nextending the KG-based RAG framework that retrieves subgraphs and leverages\nLLMs for reasoning and answer prediction. Our approach innovatively integrates\na lightweight multilayer perceptron with a parallel triple-scoring mechanism\nfor efficient and flexible subgraph retrieval while encoding directional\nstructural distances to enhance retrieval effectiveness. The size of retrieved\nsubgraphs can be flexibly adjusted to match the query's need and the downstream\nLLM's capabilities. This design strikes a balance between model complexity and\nreasoning power, enabling scalable and generalizable retrieval processes.\nNotably, based on our retrieved subgraphs, smaller LLMs like\nLlama3.1-8B-Instruct deliver competitive results with explainable reasoning,\nwhile larger models like GPT-4o achieve state-of-the-art accuracy compared with\nprevious baselines -- all without fine-tuning. Extensive evaluations on the\nWebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,\naccuracy, and reliability by reducing hallucinations and improving response\ngrounding.\n","authors":["Mufei Li","Siqi Miao","Pan Li"],"pdf_url":"https://arxiv.org/pdf/2410.20724v2.pdf","comment":"Code available at https://github.com/Graph-COM/SubgraphRAG"},{"id":"http://arxiv.org/abs/2311.08303v2","updated":"2024-11-11T22:17:17Z","published":"2023-11-14T16:46:15Z","title":"Extrinsically-Focused Evaluation of Omissions in Medical Summarization","summary":"  Large language models (LLMs) have shown promise in safety-critical\napplications such as healthcare, yet the ability to quantify performance has\nlagged. An example of this challenge is in evaluating a summary of the\npatient's medical record. A resulting summary can enable the provider to get a\nhigh-level overview of the patient's health status quickly. Yet, a summary that\nomits important facts about the patient's record can produce a misleading\npicture. This can lead to negative consequences on medical decision-making. We\npropose MED-OMIT as a metric to explore this challenge. We focus on using\nprovider-patient history conversations to generate a subjective (a summary of\nthe patient's history) as a case study. We begin by discretizing facts from the\ndialogue and identifying which are omitted from the subjective. To determine\nwhich facts are clinically relevant, we measure the importance of each fact to\na simulated differential diagnosis. We compare MED-OMIT's performance to that\nof clinical experts and find broad agreement We use MED-OMIT to evaluate LLM\nperformance on subjective generation and find some LLMs (gpt-4 and\nllama-3.1-405b) work well with little effort, while others (e.g. Llama 2)\nperform worse.\n","authors":["Elliot Schumacher","Daniel Rosenthal","Dhruv Naik","Varun Nair","Luladay Price","Geoffrey Tso","Anitha Kannan"],"pdf_url":"https://arxiv.org/pdf/2311.08303v2.pdf","comment":"Accepted to ML4H 2024"},{"id":"http://arxiv.org/abs/2409.17912v2","updated":"2024-11-11T22:14:04Z","published":"2024-09-26T14:56:38Z","title":"Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan\n  Arabic Dialect","summary":"  We introduce Atlas-Chat, the first-ever collection of LLMs specifically\ndeveloped for dialectal Arabic. Focusing on Moroccan Arabic, also known as\nDarija, we construct our instruction dataset by consolidating existing Darija\nlanguage resources, creating novel datasets both manually and synthetically,\nand translating English instructions with stringent quality control.\nAtlas-Chat-2B, 9B, and 27B models, fine-tuned on the dataset, exhibit superior\nability in following Darija instructions and performing standard NLP tasks.\nNotably, our models outperform both state-of-the-art and Arabic-specialized\nLLMs like LLaMa, Jais, and AceGPT, e.g., our 9B model gains a 13% performance\nboost over a larger 13B model on DarijaMMLU, in our newly introduced evaluation\nsuite for Darija covering both discriminative and generative tasks.\nFurthermore, we perform an experimental analysis of various fine-tuning\nstrategies and base model choices to determine optimal configurations. All our\nresources are publicly accessible, and we believe our work offers comprehensive\ndesign methodologies of instruction-tuning for low-resource languages, which\nare often neglected in favor of data-rich languages by contemporary LLMs.\n","authors":["Guokan Shang","Hadi Abdine","Yousef Khoubrane","Amr Mohamed","Yassine Abbahaddou","Sofiane Ennadir","Imane Momayiz","Xuguang Ren","Eric Moulines","Preslav Nakov","Michalis Vazirgiannis","Eric Xing"],"pdf_url":"https://arxiv.org/pdf/2409.17912v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07398v1","updated":"2024-11-11T22:08:48Z","published":"2024-11-11T22:08:48Z","title":"Beyond Keywords: A Context-based Hybrid Approach to Mining Ethical\n  Concern-related App Reviews","summary":"  With the increasing proliferation of mobile applications in our everyday\nexperiences, the concerns surrounding ethics have surged significantly. Users\ngenerally communicate their feedback, report issues, and suggest new\nfunctionalities in application (app) reviews, frequently emphasizing safety,\nprivacy, and accountability concerns. Incorporating these reviews is essential\nto developing successful products. However, app reviews related to ethical\nconcerns generally use domain-specific language and are expressed using a more\nvaried vocabulary. Thus making automated ethical concern-related app review\nextraction a challenging and time-consuming effort.\n  This study proposes a novel Natural Language Processing (NLP) based approach\nthat combines Natural Language Inference (NLI), which provides a deep\ncomprehension of language nuances, and a decoder-only (LLaMA-like) Large\nLanguage Model (LLM) to extract ethical concern-related app reviews at scale.\nUtilizing 43,647 app reviews from the mental health domain, the proposed\nmethodology 1) Evaluates four NLI models to extract potential privacy reviews\nand compares the results of domain-specific privacy hypotheses with generic\nprivacy hypotheses; 2) Evaluates four LLMs for classifying app reviews to\nprivacy concerns; and 3) Uses the best NLI and LLM models further to extract\nnew privacy reviews from the dataset. Results show that the\nDeBERTa-v3-base-mnli-fever-anli NLI model with domain-specific hypotheses\nyields the best performance, and Llama3.1-8B-Instruct LLM performs best in the\nclassification of app reviews. Then, using NLI+LLM, an additional 1,008 new\nprivacy-related reviews were extracted that were not identified through the\nkeyword-based approach in previous research, thus demonstrating the\neffectiveness of the proposed approach.\n","authors":["Aakash Sorathiya","Gouri Ginde"],"pdf_url":"https://arxiv.org/pdf/2411.07398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07396v1","updated":"2024-11-11T22:06:51Z","published":"2024-11-11T22:06:51Z","title":"Toward Optimal Search and Retrieval for RAG","summary":"  Retrieval-augmented generation (RAG) is a promising method for addressing\nsome of the memory-related challenges associated with Large Language Models\n(LLMs). Two separate systems form the RAG pipeline, the retriever and the\nreader, and the impact of each on downstream task performance is not\nwell-understood. Here, we work towards the goal of understanding how retrievers\ncan be optimized for RAG pipelines for common tasks such as Question Answering\n(QA). We conduct experiments focused on the relationship between retrieval and\nRAG performance on QA and attributed QA and unveil a number of insights useful\nto practitioners developing high-performance RAG pipelines. For example,\nlowering search accuracy has minor implications for RAG performance while\npotentially increasing retrieval speed and memory efficiency.\n","authors":["Alexandria Leto","Cecilia Aguerrebere","Ishwar Bhati","Ted Willke","Mariano Tepper","Vy Ai Vo"],"pdf_url":"https://arxiv.org/pdf/2411.07396v1.pdf","comment":"Accepted to NeurIPS 2024 Workshop ATTRIB"},{"id":"http://arxiv.org/abs/2411.05059v2","updated":"2024-11-11T21:48:52Z","published":"2024-11-07T18:22:14Z","title":"FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge\n  into LLMs?","summary":"  There is great interest in fine-tuning frontier large language models (LLMs)\nto inject new information and update existing knowledge. While commercial LLM\nfine-tuning APIs from providers such as OpenAI and Google promise flexible\nadaptation for various applications, the efficacy of fine-tuning remains\nunclear. In this study, we introduce FineTuneBench, an evaluation framework and\ndataset for understanding how well commercial fine-tuning APIs can successfully\nlearn new and updated knowledge. We analyze five frontier LLMs with\ncommercially available fine-tuning APIs, including GPT-4o and Gemini 1.5 Pro,\non their effectiveness in two settings: (1) ingesting novel information, such\nas recent news events and new people profiles, and (2) updating existing\nknowledge, such as updated medical guidelines and code frameworks. Our results\nreveal substantial shortcomings in all the models' abilities to effectively\nlearn new information through fine-tuning, with an average generalization\naccuracy of 37% across all models. When updating existing knowledge, such as\nincorporating medical guideline updates, commercial fine-tuning APIs show even\nmore limited capability (average generalization accuracy of 19%). Overall,\nfine-tuning GPT-4o mini is the most effective for infusing new knowledge and\nupdating knowledge, followed by GPT-3.5 Turbo and GPT-4o. The fine-tuning APIs\nfor Gemini 1.5 Flesh and Gemini 1.5 Pro are unable to learn new knowledge or\nupdate existing knowledge. These findings underscore a major shortcoming in\nusing current commercial fine-tuning services to achieve reliable knowledge\ninfusion in common scenarios. We open source the FineTuneBench dataset at\nhttps://github.com/kevinwu23/StanfordFineTuneBench.\n","authors":["Eric Wu","Kevin Wu","James Zou"],"pdf_url":"https://arxiv.org/pdf/2411.05059v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07387v1","updated":"2024-11-11T21:39:21Z","published":"2024-11-11T21:39:21Z","title":"Isochrony-Controlled Speech-to-Text Translation: A study on translating\n  from Sino-Tibetan to Indo-European Languages","summary":"  End-to-end speech translation (ST), which translates source language speech\ndirectly into target language text, has garnered significant attention in\nrecent years. Many ST applications require strict length control to ensure that\nthe translation duration matches the length of the source audio, including both\nspeech and pause segments. Previous methods often controlled the number of\nwords or characters generated by the Machine Translation model to approximate\nthe source sentence's length without considering the isochrony of pauses and\nspeech segments, as duration can vary between languages. To address this, we\npresent improvements to the duration alignment component of our\nsequence-to-sequence ST model. Our method controls translation length by\npredicting the duration of speech and pauses in conjunction with the\ntranslation process. This is achieved by providing timing information to the\ndecoder, ensuring it tracks the remaining duration for speech and pauses while\ngenerating the translation. The evaluation on the Zh-En test set of CoVoST 2,\ndemonstrates that the proposed Isochrony-Controlled ST achieves 0.92 speech\noverlap and 8.9 BLEU, which has only a 1.4 BLEU drop compared to the ST\nbaseline.\n","authors":["Midia Yousefi","Yao Qian","Junkun Chen","Gang Wang","Yanqing Liu","Dongmei Wang","Xiaofei Wang","Jian Xue"],"pdf_url":"https://arxiv.org/pdf/2411.07387v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07381v1","updated":"2024-11-11T21:32:06Z","published":"2024-11-11T21:32:06Z","title":"BeeManc at the PLABA Track of TAC-2024: RoBERTa for task 1 and LLaMA3.1\n  and GPT-4o for task 2","summary":"  This report is the system description of the BeeManc team for shared task\nPlain Language Adaptation of Biomedical Abstracts (PLABA) 2024. This report\ncontains two sections corresponding to the two sub-tasks in PLABA 2024. In task\none, we applied fine-tuned ReBERTa-Base models to identify and classify the\ndifficult terms, jargon and acronyms in the biomedical abstracts and reported\nthe F1 score. Due to time constraints, we didn't finish the replacement task.\nIn task two, we leveraged Llamma3.1-70B-Instruct and GPT-4o with the one-shot\nprompts to complete the abstract adaptation and reported the scores in BLEU,\nSARI, BERTScore, LENS, and SALSA. From the official Evaluation from PLABA-2024\non Task 1A and 1B, our \\textbf{much smaller fine-tuned RoBERTa-Base} model\nranked 3rd and 2nd respectively on the two sub-task, and the \\textbf{1st on\naveraged F1 scores across the two tasks} from 9 evaluated systems. Our share\nour fine-tuned models and related resources at\n\\url{https://github.com/HECTA-UoM/PLABA2024}\n","authors":["Zhidong Ling","Zihao Li","Pablo Romeo","Lifeng Han","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2411.07381v1.pdf","comment":"ongoing work - system report"},{"id":"http://arxiv.org/abs/2411.05778v2","updated":"2024-11-11T21:09:42Z","published":"2024-11-08T18:45:06Z","title":"LLMs as Method Actors: A Model for Prompt Engineering and Architecture","summary":"  We introduce \"Method Actors\" as a mental model for guiding LLM prompt\nengineering and prompt architecture. Under this mental model, LLMs should be\nthought of as actors; prompts as scripts and cues; and LLM responses as\nperformances. We apply this mental model to the task of improving LLM\nperformance at playing Connections, a New York Times word puzzle game that\nprior research identified as a challenging benchmark for evaluating LLM\nreasoning. Our experiments with GPT-4o show that a \"Method Actors\" approach can\nsignificantly improve LLM performance over both a vanilla and \"Chain of\nThoughts\" approach. A vanilla approach solves 27% of Connections puzzles in our\ndataset and a \"Chain of Thoughts\" approach solves 41% of puzzles, whereas our\nstrongest \"Method Actor\" approach solves 86% of puzzles. We also test OpenAI's\nnewest model designed specifically for complex reasoning tasks, o1-preview.\nWhen asked to solve a puzzle all at once, o1-preview solves 79% of Connections\npuzzles in our dataset, and when allowed to build puzzle solutions one guess at\na time over multiple API calls, o1-preview solves 100% of the puzzles.\nIncorporating a \"Method Actor\" prompt architecture increases the percentage of\npuzzles that o1-preview solves perfectly from 76% to 87%.\n","authors":["Colin Doyle"],"pdf_url":"https://arxiv.org/pdf/2411.05778v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12306v3","updated":"2024-11-11T21:04:35Z","published":"2024-09-18T20:33:54Z","title":"Measuring Sound Symbolism in Audio-visual Models","summary":"  Audio-visual pre-trained models have gained substantial attention recently\nand demonstrated superior performance on various audio-visual tasks. This study\ninvestigates whether pre-trained audio-visual models demonstrate non-arbitrary\nassociations between sounds and visual representations$\\unicode{x2013}$known as\nsound symbolism$\\unicode{x2013}$which is also observed in humans. We developed\na specialized dataset with synthesized images and audio samples and assessed\nthese models using a non-parametric approach in a zero-shot setting. Our\nfindings reveal a significant correlation between the models' outputs and\nestablished patterns of sound symbolism, particularly in models trained on\nspeech data. These results suggest that such models can capture sound-meaning\nconnections akin to human language processing, providing insights into both\ncognitive architectures and machine learning strategies.\n","authors":["Wei-Cheng Tseng","Yi-Jen Shih","David Harwath","Raymond Mooney"],"pdf_url":"https://arxiv.org/pdf/2409.12306v3.pdf","comment":"SLT 2024"},{"id":"http://arxiv.org/abs/2410.02742v2","updated":"2024-11-11T20:33:03Z","published":"2024-10-03T17:55:09Z","title":"Grounding Large Language Models In Embodied Environment With Imperfect\n  World Models","summary":"  Despite a widespread success in various applications, large language models\n(LLMs) often stumble when tackling basic physical reasoning or executing\nrobotics tasks, due to a lack of direct experience with the physical nuances of\nthe real world. To address these issues, we propose a Grounding Large language\nmodel with Imperfect world MOdel (GLIMO), which utilizes proxy world models\nsuch as simulators to collect and synthesize trining data. GLIMO incorporates\nan LLM agent-based data generator to automatically create high-quality and\ndiverse instruction datasets. The generator includes an iterative self-refining\nmodule for temporally consistent experience sampling, a diverse set of\nquestion-answering instruction seeds, and a retrieval-augmented generation\nmodule for reflecting on prior experiences. Comprehensive experiments show that\nour approach improve the performance of strong open-source LLMs like LLaMA-3\nwith a performance boost of 2.04 $\\times$, 1.54 $\\times$, and 1.82 $\\times$\nacross three different benchmarks, respectively. The performance is able to\ncompete with or surpass their larger counterparts such as GPT-4.\n","authors":["Haolan Liu","Jishen Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.02742v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15943v2","updated":"2024-11-11T20:09:51Z","published":"2024-05-24T21:14:10Z","title":"Transformers represent belief state geometry in their residual stream","summary":"  What computational structure are we building into large language models when\nwe train them on next-token prediction? Here, we present evidence that this\nstructure is given by the meta-dynamics of belief updating over hidden states\nof the data-generating process. Leveraging the theory of optimal prediction, we\nanticipate and then find that belief states are linearly represented in the\nresidual stream of transformers, even in cases where the predicted belief state\ngeometry has highly nontrivial fractal structure. We investigate cases where\nthe belief state geometry is represented in the final residual stream or\ndistributed across the residual streams of multiple layers, providing a\nframework to explain these observations. Furthermore we demonstrate that the\ninferred belief states contain information about the entire future, beyond the\nlocal next-token prediction that the transformers are explicitly trained on.\nOur work provides a general framework connecting the structure of training data\nto the geometric structure of activations inside transformers.\n","authors":["Adam S. Shai","Sarah E. Marzen","Lucas Teixeira","Alexander Gietelink Oldenziel","Paul M. Riechers"],"pdf_url":"https://arxiv.org/pdf/2405.15943v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07343v1","updated":"2024-11-11T20:05:22Z","published":"2024-11-11T20:05:22Z","title":"Multi-head Span-based Detector for AI-generated Fragments in Scientific\n  Papers","summary":"  This paper describes a system designed to distinguish between AI-generated\nand human-written scientific excerpts in the DAGPap24 competition hosted within\nthe Fourth Workshop on Scientific Document Processing. In this competition the\ntask is to find artificially generated token-level text fragments in documents\nof a scientific domain. Our work focuses on the use of a multi-task learning\narchitecture with two heads. The application of this approach is justified by\nthe specificity of the task, where class spans are continuous over several\nhundred characters. We considered different encoder variations to obtain a\nstate vector for each token in the sequence, as well as a variation in\nsplitting fragments into tokens to further feed into the input of a\ntransform-based encoder. This approach allows us to achieve a 9% quality\nimprovement relative to the baseline solution score on the development set\n(from 0.86 to 0.95) using the average macro F1-score, as well as a score of\n0.96 on a closed test part of the dataset from the competition.\n","authors":["German Gritsai","Ildar Khabutdinov","Andrey Grabovoy"],"pdf_url":"https://arxiv.org/pdf/2411.07343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15793v3","updated":"2024-11-11T20:01:15Z","published":"2024-05-06T17:41:33Z","title":"SWE-agent: Agent-Computer Interfaces Enable Automated Software\n  Engineering","summary":"  Language model (LM) agents are increasingly being used to automate\ncomplicated tasks in digital environments. Just as humans benefit from powerful\nsoftware applications, such as integrated development environments, for complex\ntasks like software engineering, we posit that LM agents represent a new\ncategory of end users with their own needs and abilities, and would benefit\nfrom specially-built interfaces to the software they use. We investigate how\ninterface design affects the performance of language model agents. As a result\nof this exploration, we introduce SWE-agent: a system that facilitates LM\nagents to autonomously use computers to solve software engineering tasks.\nSWE-agent's custom agent-computer interface (ACI) significantly enhances an\nagent's ability to create and edit code files, navigate entire repositories,\nand execute tests and other programs. We evaluate SWE-agent on SWE-bench and\nHumanEvalFix, achieving state-of-the-art performance on both with a pass@1 rate\nof 12.5% and 87.7%, respectively, far exceeding the previous state-of-the-art\nachieved with non-interactive LMs. Finally, we provide insight on how the\ndesign of the ACI can impact agents' behavior and performance.\n","authors":["John Yang","Carlos E. Jimenez","Alexander Wettig","Kilian Lieret","Shunyu Yao","Karthik Narasimhan","Ofir Press"],"pdf_url":"https://arxiv.org/pdf/2405.15793v3.pdf","comment":"Code, data, and demo available at https://swe-agent.com"},{"id":"http://arxiv.org/abs/2411.07336v1","updated":"2024-11-11T19:55:24Z","published":"2024-11-11T19:55:24Z","title":"SetLexSem Challenge: Using Set Operations to Evaluate the Lexical and\n  Semantic Robustness of Language Models","summary":"  Set theory is foundational to mathematics and, when sets are finite, to\nreasoning about the world. An intelligent system should perform set operations\nconsistently, regardless of superficial variations in the operands. Initially\ndesigned for semantically-oriented NLP tasks, large language models (LLMs) are\nnow being evaluated on algorithmic tasks. Because sets are comprised of\narbitrary symbols (e.g. numbers, words), they provide an opportunity to test,\nsystematically, the invariance of LLMs' algorithmic abilities under simple\nlexical or semantic variations. To this end, we present the SetLexSem\nChallenge, a synthetic benchmark that evaluates the performance of LLMs on set\noperations. SetLexSem assesses the robustness of LLMs' instruction-following\nabilities under various conditions, focusing on the set operations and the\nnature and construction of the set members. Evaluating seven LLMs with\nSetLexSem, we find that they exhibit poor robustness to variation in both\noperation and operands. We show -- via the framework's systematic sampling of\nset members along lexical and semantic dimensions -- that LLMs are not only not\nrobust to variation along these dimensions but demonstrate unique failure modes\nin particular, easy-to-create semantic groupings of \"deceptive\" sets. We find\nthat rigorously measuring language model robustness to variation in frequency\nand length is challenging and present an analysis that measures them\nindependently. The code for reproducing the results of this paper, and for\ngenerating the SetLexSem Challenge dataset, is available at\n\\href{https://github.com/amazon-science/SetLexSem-Challenge}{https://github.com/amazon-science/SetLexSem-Challenge}.\n","authors":["Bardiya Akhbari","Manish Gawali","Nicholas A. Dronen"],"pdf_url":"https://arxiv.org/pdf/2411.07336v1.pdf","comment":"10 pages, 8 figures, NeurIPS 2024 Datasets and Benchmarks track"},{"id":"http://arxiv.org/abs/2404.15146v3","updated":"2024-11-11T19:47:16Z","published":"2024-04-23T15:49:37Z","title":"Rethinking LLM Memorization through the Lens of Adversarial Compression","summary":"  Large language models (LLMs) trained on web-scale datasets raise substantial\nconcerns regarding permissible data usage. One major question is whether these\nmodels \"memorize\" all their training data or they integrate many data sources\nin some way more akin to how a human would learn and synthesize information.\nThe answer hinges, to a large degree, on how we define memorization. In this\nwork, we propose the Adversarial Compression Ratio (ACR) as a metric for\nassessing memorization in LLMs. A given string from the training data is\nconsidered memorized if it can be elicited by a prompt (much) shorter than the\nstring itself -- in other words, if these strings can be \"compressed\" with the\nmodel by computing adversarial prompts of fewer tokens. The ACR overcomes the\nlimitations of existing notions of memorization by (i) offering an adversarial\nview of measuring memorization, especially for monitoring unlearning and\ncompliance; and (ii) allowing for the flexibility to measure memorization for\narbitrary strings at a reasonably low compute. Our definition serves as a\npractical tool for determining when model owners may be violating terms around\ndata usage, providing a potential legal tool and a critical lens through which\nto address such scenarios.\n","authors":["Avi Schwarzschild","Zhili Feng","Pratyush Maini","Zachary C. Lipton","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2404.15146v3.pdf","comment":"https://locuslab.github.io/acr-memorization"},{"id":"http://arxiv.org/abs/2411.07320v1","updated":"2024-11-11T19:25:25Z","published":"2024-11-11T19:25:25Z","title":"Richer Output for Richer Countries: Uncovering Geographical Disparities\n  in Generated Stories and Travel Recommendations","summary":"  While a large body of work inspects language models for biases concerning\ngender, race, occupation and religion, biases of geographical nature are\nrelatively less explored. Some recent studies benchmark the degree to which\nlarge language models encode geospatial knowledge. However, the impact of the\nencoded geographical knowledge (or lack thereof) on real-world applications has\nnot been documented. In this work, we examine large language models for two\ncommon scenarios that require geographical knowledge: (a) travel\nrecommendations and (b) geo-anchored story generation. Specifically, we study\nfour popular language models, and across about $100$K travel requests, and\n$200$K story generations, we observe that travel recommendations corresponding\nto poorer countries are less unique with fewer location references, and stories\nfrom these regions more often convey emotions of hardship and sadness compared\nto those from wealthier nations.\n","authors":["Kirti Bhagat","Kinshuk Vasisht","Danish Pruthi"],"pdf_url":"https://arxiv.org/pdf/2411.07320v1.pdf","comment":"Submitted to ARR - October 2024"},{"id":"http://arxiv.org/abs/2402.18025v2","updated":"2024-11-11T19:14:13Z","published":"2024-02-28T03:44:01Z","title":"Hire a Linguist!: Learning Endangered Languages with In-Context\n  Linguistic Descriptions","summary":"  How can large language models (LLMs) process and translate endangered\nlanguages? Many languages lack a large corpus to train a decent LLM; therefore\nexisting LLMs rarely perform well in unseen, endangered languages. On the\ncontrary, we observe that 2000 endangered languages, though without a large\ncorpus, have a grammar book or a dictionary. We propose LINGOLLM, a\ntraining-free approach to enable an LLM to process unseen languages that hardly\noccur in its pre-training. Our key insight is to demonstrate linguistic\nknowledge of an unseen language in an LLM's prompt, including a dictionary, a\ngrammar book, and morphologically analyzed input text. We implement LINGOLLM on\ntop of two models, GPT-4 and Mixtral, and evaluate their performance on 5 tasks\nacross 8 endangered or low-resource languages. Our results show that LINGOLLM\nelevates translation capability from GPT-4's 0 to 10.5 BLEU for 10 language\ndirections. Our findings demonstrate the tremendous value of linguistic\nknowledge in the age of LLMs for endangered languages. Our data, code, and\nmodel generations can be found at https://github.com/LLiLab/llm4endangeredlang.\n","authors":["Kexun Zhang","Yee Man Choi","Zhenqiao Song","Taiqi He","William Yang Wang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2402.18025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07279v1","updated":"2024-11-11T18:59:45Z","published":"2024-11-11T18:59:45Z","title":"The Surprising Effectiveness of Test-Time Training for Abstract\n  Reasoning","summary":"  Language models have shown impressive performance on tasks within their\ntraining distribution, but often struggle with novel problems requiring complex\nreasoning. We investigate the effectiveness of test-time training (TTT) --\nupdating model parameters temporarily during inference using a loss derived\nfrom input data -- as a mechanism for improving models' reasoning capabilities,\nusing the Abstraction and Reasoning Corpus (ARC) as a benchmark. Through\nsystematic experimentation, we identify three crucial components for successful\nTTT: (1) initial finetuning on similar tasks (2) auxiliary task format and\naugmentations (3) per-instance training. TTT significantly improves performance\non ARC tasks, achieving up to 6x improvement in accuracy compared to base\nfine-tuned models; applying TTT to an 8B-parameter language model, we achieve\n53% accuracy on the ARC's public validation set, improving the state-of-the-art\nby nearly 25% for public and purely neural approaches. By ensembling our method\nwith recent program generation approaches, we get SoTA public validation\naccuracy of 61.9%, matching the average human score. Our findings suggest that\nexplicit symbolic search is not the only path to improved abstract reasoning in\nneural language models; additional test-time applied to continued training on\nfew-shot examples can also be extremely effective.\n","authors":["Ekin Aky√ºrek","Mehul Damani","Linlu Qiu","Han Guo","Yoon Kim","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2411.07279v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.07240v1","updated":"2024-11-11T18:59:02Z","published":"2024-11-11T18:59:02Z","title":"UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts","summary":"  The evaluation of mathematical reasoning capabilities is essential for\nadvancing Artificial General Intelligence (AGI). While Large Language Models\n(LLMs) have shown impressive performance in solving mathematical problems,\nexisting benchmarks such as GSM8K and MATH present limitations, including\nnarrow problem definitions with specific numbers and reliance on predetermined\nrules that hinder accurate assessments of reasoning and adaptability. This\npaper introduces the UTMath Benchmark, which robustly evaluates the models\nthrough extensive unit tests. It consists of 1,053 problems across 9\nmathematical domains, with over 68 test cases per problem. We propose an\ninnovative evaluation framework inspired by unit testing in software\ndevelopment, focusing on both accuracy and reliability of results. Furthermore,\nwe introduce the Reasoning-to-Coding of Thoughts (RCoT) approach, which\nencourages LLMs to perform explicit reasoning before generating code, leading\nto generating more advanced solution and improved performance. Furthermore, we\nare releasing not only the UTMath benchmark but also the UTMath-Train training\ndataset (more than 70k samples), to support the community in further exploring\nmathematical reasoning.\n","authors":["Bo Yang","Qingping Yang","Runtao Liu"],"pdf_url":"https://arxiv.org/pdf/2411.07240v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.02537v3","updated":"2024-11-11T18:49:52Z","published":"2024-11-04T19:16:53Z","title":"INQUIRE: A Natural World Text-to-Image Retrieval Benchmark","summary":"  We introduce INQUIRE, a text-to-image retrieval benchmark designed to\nchallenge multimodal vision-language models on expert-level queries. INQUIRE\nincludes iNaturalist 2024 (iNat24), a new dataset of five million natural world\nimages, along with 250 expert-level retrieval queries. These queries are paired\nwith all relevant images comprehensively labeled within iNat24, comprising\n33,000 total matches. Queries span categories such as species identification,\ncontext, behavior, and appearance, emphasizing tasks that require nuanced image\nunderstanding and domain expertise. Our benchmark evaluates two core retrieval\ntasks: (1) INQUIRE-Fullrank, a full dataset ranking task, and (2)\nINQUIRE-Rerank, a reranking task for refining top-100 retrievals. Detailed\nevaluation of a range of recent multimodal models demonstrates that INQUIRE\nposes a significant challenge, with the best models failing to achieve an\nmAP@50 above 50%. In addition, we show that reranking with more powerful\nmultimodal models can enhance retrieval performance, yet there remains a\nsignificant margin for improvement. By focusing on scientifically-motivated\necological challenges, INQUIRE aims to bridge the gap between AI capabilities\nand the needs of real-world scientific inquiry, encouraging the development of\nretrieval systems that can assist with accelerating ecological and biodiversity\nresearch. Our dataset and code are available at\nhttps://inquire-benchmark.github.io\n","authors":["Edward Vendrow","Omiros Pantazis","Alexander Shepard","Gabriel Brostow","Kate E. Jones","Oisin Mac Aodha","Sara Beery","Grant Van Horn"],"pdf_url":"https://arxiv.org/pdf/2411.02537v3.pdf","comment":"Published in NeurIPS 2024, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2411.07166v1","updated":"2024-11-11T17:46:34Z","published":"2024-11-11T17:46:34Z","title":"The Shapley index for music streaming platforms","summary":"  We study an index to measure the popularity of artists in music streaming\nplatforms. This index, which can be used to allocate the amount raised via paid\nsubscriptions among participating artists, is based on the Shapley value, a\ncenterpiece in cooperative game theory. We characterize this Shapley index\ncombining several axioms formalizing principles with normative appeal. This\npermits to place the index in the literature, as an alternative to the\nwell-known (and widely used in the industry) pro-rata and user-centric indices.\n","authors":["Gustavo Berganti√±os","Juan D. Moreno-Ternero"],"pdf_url":"https://arxiv.org/pdf/2411.07166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07021v1","updated":"2024-11-11T14:25:37Z","published":"2024-11-11T14:25:37Z","title":"Invar-RAG: Invariant LLM-aligned Retrieval for Better Generation","summary":"  Retrieval-augmented generation (RAG) has shown impressive capability in\nproviding reliable answer predictions and addressing hallucination problems. A\ntypical RAG implementation uses powerful retrieval models to extract external\ninformation and large language models (LLMs) to generate answers. In contrast,\nrecent LLM-based retrieval has gained attention for its substantial\nimprovements in information retrieval (IR) due to the LLMs' semantic\nunderstanding capability. However, directly applying LLM to RAG systems\npresents challenges. This may cause feature locality problems as massive\nparametric knowledge can hinder effective usage of global information across\nthe corpus; for example, an LLM-based retriever often inputs document summaries\ninstead of full documents. Moreover, various pre-trained tasks in LLMs\nintroduce variance, further weakening performance as a retriever.\n  To address these issues, we propose a novel two-stage fine-tuning\narchitecture called Invar-RAG. In the retrieval stage, an LLM-based retriever\nis constructed by integrating LoRA-based representation learning to tackle\nfeature locality issues. To enhance retrieval performance, we develop two\npatterns (invariant and variant patterns) and an invariance loss to reduce LLM\nvariance. In the generation stage, a refined fine-tuning method is employed to\nimprove LLM accuracy in generating answers based on retrieved information.\nExperimental results show that Invar-RAG significantly outperforms existing\nbaselines across three open-domain question answering (ODQA) datasets. Code is\navailable in the Supplementary Material for reproducibility.\n","authors":["Ziwei Liu","Liang Zhang","Qian Li","Jianghua Wu","Guangxu Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.07021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.02971v3","updated":"2024-11-11T11:46:16Z","published":"2022-08-05T03:45:56Z","title":"CROLoss: Towards a Customizable Loss for Retrieval Models in Recommender\n  Systems","summary":"  In large-scale recommender systems, retrieving top N relevant candidates\naccurately with resource constrain is crucial. To evaluate the performance of\nsuch retrieval models, Recall@N, the frequency of positive samples being\nretrieved in the top N ranking, is widely used. However, most of the\nconventional loss functions for retrieval models such as softmax cross-entropy\nand pairwise comparison methods do not directly optimize Recall@N. Moreover,\nthose conventional loss functions cannot be customized for the specific\nretrieval size N required by each application and thus may lead to sub-optimal\nperformance. In this paper, we proposed the Customizable Recall@N Optimization\nLoss (CROLoss), a loss function that can directly optimize the Recall@N metrics\nand is customizable for different choices of N. This proposed CROLoss\nformulation defines a more generalized loss function space, covering most of\nthe conventional loss functions as special cases. Furthermore, we develop the\nLambda method, a gradient-based method that invites more flexibility and can\nfurther boost the system performance. We evaluate the proposed CROLoss on two\npublic benchmark datasets. The results show that CROLoss achieves SOTA results\nover conventional loss functions for both datasets with various choices of\nretrieval size N. CROLoss has been deployed onto our online E-commerce\nadvertising platform, where a fourteen-day online A/B test demonstrated that\nCROLoss contributes to a significant business revenue growth of 4.75%.\n","authors":["Yongxiang Tang","Wentao Bai","Guilin Li","Xialong Liu","Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2208.02971v3.pdf","comment":"9 pages, 5 figures. Accepted by by CIKM 2022"},{"id":"http://arxiv.org/abs/2411.06877v1","updated":"2024-11-11T11:17:35Z","published":"2024-11-11T11:17:35Z","title":"LLM-Assisted Relevance Assessments: When Should We Ask LLMs for Help?","summary":"  Test collections are information retrieval tools that allow researchers to\nquickly and easily evaluate ranking algorithms. While test collections have\nbecome an integral part of IR research, the process of data creation involves\nsignificant efforts in manual annotations, which often makes it very expensive\nand time-consuming. Thus, the test collections could become small when the\nbudget is limited, which may lead to unstable evaluations. As an alternative,\nrecent studies have proposed the use of large language models (LLMs) to\ncompletely replace human assessors. However, while LLMs seem to somewhat\ncorrelate with human judgments, they are not perfect and often show bias.\nMoreover, even if a well-performing LLM or prompt is found on one dataset,\nthere is no guarantee that it will perform similarly in practice, due to\ndifference in tasks and data. Thus a complete replacement with LLMs is argued\nto be too risky and not fully trustable.\n  Thus, in this paper, we propose \\textbf{L}LM-\\textbf{A}ssisted\n\\textbf{R}elevance \\textbf{A}ssessments (\\textbf{LARA}), an effective method to\nbalance manual annotations with LLM annotations, which helps to make a rich and\nreliable test collection. We use the LLM's predicted relevance probabilities in\norder to select the most profitable documents to manually annotate under a\nbudget constraint. While solely relying on LLM's predicted probabilities to\nmanually annotate performs fairly well, with theoretical reasoning, LARA guides\nthe human annotation process even more effectively via online calibration\nlearning. Then, using the calibration model learned from the limited manual\nannotations, LARA debiases the LLM predictions to annotate the remaining\nnon-assessed data. Empirical evaluations on TREC-COVID and TREC-8 Ad Hoc\ndatasets show that LARA outperforms the alternative solutions under almost any\nbudget constraint.\n","authors":["Rikiya Takehi","Ellen M. Voorhees","Tetsuya Sakai"],"pdf_url":"https://arxiv.org/pdf/2411.06877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.13704v2","updated":"2024-11-11T10:02:24Z","published":"2024-09-05T10:27:32Z","title":"Entity Extraction from High-Level Corruption Schemes via Large Language\n  Models","summary":"  The rise of financial crime that has been observed in recent years has\ncreated an increasing concern around the topic and many people, organizations\nand governments are more and more frequently trying to combat it. Despite the\nincrease of interest in this area, there is a lack of specialized datasets that\ncan be used to train and evaluate works that try to tackle those problems. This\narticle proposes a new micro-benchmark dataset for algorithms and models that\nidentify individuals and organizations, and their multiple writings, in news\narticles, and presents an approach that assists in its creation. Experimental\nefforts are also reported, using this dataset, to identify individuals and\norganizations in financial-crime-related articles using various low-billion\nparameter Large Language Models (LLMs). For these experiments, standard metrics\n(Accuracy, Precision, Recall, F1 Score) are reported and various prompt\nvariants comprising the best practices of prompt engineering are tested. In\naddition, to address the problem of ambiguous entity mentions, a simple, yet\neffective LLM-based disambiguation method is proposed, ensuring that the\nevaluation aligns with reality. Finally, the proposed approach is compared\nagainst a widely used state-of-the-art open-source baseline, showing the\nsuperiority of the proposed method.\n","authors":["Panagiotis Koletsis","Panagiotis-Konstantinos Gemos","Christos Chronis","Iraklis Varlamis","Vasilis Efthymiou","Georgios Th. Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2409.13704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06826v1","updated":"2024-11-11T09:39:31Z","published":"2024-11-11T09:39:31Z","title":"Adaptive Conditional Expert Selection Network for Multi-domain\n  Recommendation","summary":"  Mixture-of-Experts (MOE) has recently become the de facto standard in\nMulti-domain recommendation (MDR) due to its powerful expressive ability.\nHowever, such MOE-based method typically employs all experts for each instance,\nleading to scalability issue and low-discriminability between domains and\nexperts. Furthermore, the design of commonly used domain-specific networks\nexacerbates the scalability issues. To tackle the problems, We propose a novel\nmethod named CESAA consists of Conditional Expert Selection (CES) Module and\nAdaptive Expert Aggregation (AEA) Module to tackle these challenges.\nSpecifically, CES first combines a sparse gating strategy with domain-shared\nexperts. Then AEA utilizes mutual information loss to strengthen the\ncorrelations between experts and specific domains, and significantly improve\nthe distinction between experts. As a result, only domain-shared experts and\nselected domain-specific experts are activated for each instance, striking a\nbalance between computational efficiency and model performance. Experimental\nresults on both public ranking and industrial retrieval datasets verify the\neffectiveness of our method in MDR tasks.\n","authors":["Kuiyao Dong","Xingyu Lou","Feng Liu","Ruian Wang","Wenyi Yu","Ping Wang","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2411.06826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06823v1","updated":"2024-11-11T09:31:46Z","published":"2024-11-11T09:31:46Z","title":"Large Language Model in Medical Informatics: Direct Classification and\n  Enhanced Text Representations for Automatic ICD Coding","summary":"  Addressing the complexity of accurately classifying International\nClassification of Diseases (ICD) codes from medical discharge summaries is\nchallenging due to the intricate nature of medical documentation. This paper\nexplores the use of Large Language Models (LLM), specifically the LLAMA\narchitecture, to enhance ICD code classification through two methodologies:\ndirect application as a classifier and as a generator of enriched text\nrepresentations within a Multi-Filter Residual Convolutional Neural Network\n(MultiResCNN) framework. We evaluate these methods by comparing them against\nstate-of-the-art approaches, revealing LLAMA's potential to significantly\nimprove classification outcomes by providing deep contextual insights into\nmedical texts.\n","authors":["Zeyd Boukhers","AmeerAli Khan","Qusai Ramadan","Cong Yang"],"pdf_url":"https://arxiv.org/pdf/2411.06823v1.pdf","comment":"accepted at the 2024 IEEE International Conference on Bioinformatics\n  and Biomedicine (BIBM 2024)"},{"id":"http://arxiv.org/abs/2411.06805v1","updated":"2024-11-11T09:03:52Z","published":"2024-11-11T09:03:52Z","title":"AssistRAG: Boosting the Potential of Large Language Models with an\n  Intelligent Information Assistant","summary":"  The emergence of Large Language Models (LLMs) has significantly advanced\nnatural language processing, but these models often generate factually\nincorrect information, known as \"hallucination\". Initial retrieval-augmented\ngeneration (RAG) methods like the \"Retrieve-Read\" framework was inadequate for\ncomplex reasoning tasks. Subsequent prompt-based RAG strategies and Supervised\nFine-Tuning (SFT) methods improved performance but required frequent retraining\nand risked altering foundational LLM capabilities. To cope with these\nchallenges, we propose Assistant-based Retrieval-Augmented Generation\n(AssistRAG), integrating an intelligent information assistant within LLMs. This\nassistant manages memory and knowledge through tool usage, action execution,\nmemory building, and plan specification. Using a two-phase training approach,\nCurriculum Assistant Learning and Reinforced Preference Optimization. AssistRAG\nenhances information retrieval and decision-making. Experiments show AssistRAG\nsignificantly outperforms benchmarks, especially benefiting less advanced LLMs,\nby providing superior reasoning capabilities and accurate responses.\n","authors":["Yujia Zhou","Zheng Liu","Zhicheng Dou"],"pdf_url":"https://arxiv.org/pdf/2411.06805v1.pdf","comment":"Accepted by NeurIPS 2024 (poster)"},{"id":"http://arxiv.org/abs/2411.06784v1","updated":"2024-11-11T08:23:37Z","published":"2024-11-11T08:23:37Z","title":"Boosting the Targeted Transferability of Adversarial Examples via\n  Salient Region & Weighted Feature Drop","summary":"  Deep neural networks can be vulnerable to adversarially crafted examples,\npresenting significant risks to practical applications. A prevalent approach\nfor adversarial attacks relies on the transferability of adversarial examples,\nwhich are generated from a substitute model and leveraged to attack unknown\nblack-box models. Despite various proposals aimed at improving transferability,\nthe success of these attacks in targeted black-box scenarios is often hindered\nby the tendency for adversarial examples to overfit to the surrogate models. In\nthis paper, we introduce a novel framework based on Salient region & Weighted\nFeature Drop (SWFD) designed to enhance the targeted transferability of\nadversarial examples. Drawing from the observation that examples with higher\ntransferability exhibit smoother distributions in the deep-layer outputs, we\npropose the weighted feature drop mechanism to modulate activation values\naccording to weights scaled by norm distribution, effectively addressing the\noverfitting issue when generating adversarial examples. Additionally, by\nleveraging salient region within the image to construct auxiliary images, our\nmethod enables the adversarial example's features to be transferred to the\ntarget category in a model-agnostic manner, thereby enhancing the\ntransferability. Comprehensive experiments confirm that our approach\noutperforms state-of-the-art methods across diverse configurations. On average,\nthe proposed SWFD raises the attack success rate for normally trained models\nand robust models by 16.31% and 7.06% respectively.\n","authors":["Shanjun Xu","Linghui Li","Kaiguo Yuan","Bingyu Li"],"pdf_url":"https://arxiv.org/pdf/2411.06784v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2409.14038v4","updated":"2024-11-11T06:26:39Z","published":"2024-09-21T06:49:34Z","title":"OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model\n  Hallucinations in Ontology Matching","summary":"  Hallucinations of large language models (LLMs) commonly occur in\ndomain-specific downstream tasks, with no exception in ontology matching (OM).\nThe prevalence of using LLMs for OM raises the need for benchmarks to better\nunderstand LLM hallucinations. The OAEI-LLM dataset is an extended version of\nthe Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate\nLLM-specific hallucinations in OM tasks. We outline the methodology used in\ndataset construction and schema extension, and provide examples of potential\nuse cases.\n","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang","Jing Jiang"],"pdf_url":"https://arxiv.org/pdf/2409.14038v4.pdf","comment":"5 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2310.09874v4","updated":"2024-11-11T06:16:24Z","published":"2023-10-15T16:15:07Z","title":"TF-DCon: Leveraging Large Language Models (LLMs) to Empower\n  Training-Free Dataset Condensation for Content-Based Recommendation","summary":"  Modern techniques in Content-based Recommendation (CBR) leverage item content\ninformation to provide personalized services to users, but suffer from\nresource-intensive training on large datasets. To address this issue, we\nexplore the dataset condensation for textual CBR in this paper. The goal of\ndataset condensation is to synthesize a small yet informative dataset, upon\nwhich models can achieve performance comparable to those trained on large\ndatasets. While existing condensation approaches are tailored to classification\ntasks for continuous data like images or embeddings, direct application of them\nto CBR has limitations. To bridge this gap, we investigate efficient dataset\ncondensation for content-based recommendation. Inspired by the remarkable\nabilities of large language models (LLMs) in text comprehension and generation,\nwe leverage LLMs to empower the generation of textual content during\ncondensation. To handle the interaction data involving both users and items, we\ndevise a dual-level condensation method: content-level and user-level. At\ncontent-level, we utilize LLMs to condense all contents of an item into a new\ninformative title. At user-level, we design a clustering-based synthesis\nmodule, where we first utilize LLMs to extract user interests. Then, the user\ninterests and user embeddings are incorporated to condense users and generate\ninteractions for condensed users. Notably, the condensation paradigm of this\nmethod is forward and free from iterative optimization on the synthesized\ndataset. Extensive empirical findings from our study, conducted on three\nauthentic datasets, substantiate the efficacy of the proposed method.\nParticularly, we are able to approximate up to 97% of the original performance\nwhile reducing the dataset size by 95% (i.e., on dataset MIND).\n","authors":["Jiahao Wu","Qijiong Liu","Hengchang Hu","Wenqi Fan","Shengcai Liu","Qing Li","Xiao-Ming Wu","Ke Tang"],"pdf_url":"https://arxiv.org/pdf/2310.09874v4.pdf","comment":"An updated version"},{"id":"http://arxiv.org/abs/2411.07439v1","updated":"2024-11-11T23:40:45Z","published":"2024-11-11T23:40:45Z","title":"Music Discovery Dialogue Generation Using Human Intent Analysis and\n  Large Language Models","summary":"  A conversational music retrieval system can help users discover music that\nmatches their preferences through dialogue. To achieve this, a conversational\nmusic retrieval system should seamlessly engage in multi-turn conversation by\n1) understanding user queries and 2) responding with natural language and\nretrieved music. A straightforward solution would be a data-driven approach\nutilizing such conversation logs. However, few datasets are available for the\nresearch and are limited in terms of volume and quality. In this paper, we\npresent a data generation framework for rich music discovery dialogue using a\nlarge language model (LLM) and user intents, system actions, and musical\nattributes. This is done by i) dialogue intent analysis using grounded theory,\nii) generating attribute sequences via cascading database filtering, and iii)\ngenerating utterances using large language models. By applying this framework\nto the Million Song dataset, we create LP-MusicDialog, a Large Language Model\nbased Pseudo Music Dialogue dataset, containing over 288k music conversations\nusing more than 319k music items. Our evaluation shows that the synthetic\ndataset is competitive with an existing, small human dialogue dataset in terms\nof dialogue consistency, item relevance, and naturalness. Furthermore, using\nthe dataset, we train a conversational music retrieval model and show promising\nresults.\n","authors":["SeungHeon Doh","Keunwoo Choi","Daeyong Kwon","Taesu Kim","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2411.07439v1.pdf","comment":"Accepted for publication at the 25th International Society for Music\n  Information Retrieval Conference (ISMIR 2024)"},{"id":"http://arxiv.org/abs/2411.05059v2","updated":"2024-11-11T21:48:52Z","published":"2024-11-07T18:22:14Z","title":"FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge\n  into LLMs?","summary":"  There is great interest in fine-tuning frontier large language models (LLMs)\nto inject new information and update existing knowledge. While commercial LLM\nfine-tuning APIs from providers such as OpenAI and Google promise flexible\nadaptation for various applications, the efficacy of fine-tuning remains\nunclear. In this study, we introduce FineTuneBench, an evaluation framework and\ndataset for understanding how well commercial fine-tuning APIs can successfully\nlearn new and updated knowledge. We analyze five frontier LLMs with\ncommercially available fine-tuning APIs, including GPT-4o and Gemini 1.5 Pro,\non their effectiveness in two settings: (1) ingesting novel information, such\nas recent news events and new people profiles, and (2) updating existing\nknowledge, such as updated medical guidelines and code frameworks. Our results\nreveal substantial shortcomings in all the models' abilities to effectively\nlearn new information through fine-tuning, with an average generalization\naccuracy of 37% across all models. When updating existing knowledge, such as\nincorporating medical guideline updates, commercial fine-tuning APIs show even\nmore limited capability (average generalization accuracy of 19%). Overall,\nfine-tuning GPT-4o mini is the most effective for infusing new knowledge and\nupdating knowledge, followed by GPT-3.5 Turbo and GPT-4o. The fine-tuning APIs\nfor Gemini 1.5 Flesh and Gemini 1.5 Pro are unable to learn new knowledge or\nupdate existing knowledge. These findings underscore a major shortcoming in\nusing current commercial fine-tuning services to achieve reliable knowledge\ninfusion in common scenarios. We open source the FineTuneBench dataset at\nhttps://github.com/kevinwu23/StanfordFineTuneBench.\n","authors":["Eric Wu","Kevin Wu","James Zou"],"pdf_url":"https://arxiv.org/pdf/2411.05059v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02606v2","updated":"2024-11-11T21:40:16Z","published":"2024-06-02T18:26:50Z","title":"Know Your Neighborhood: General and Zero-Shot Capable Binary Function\n  Search Powered by Call Graphlets","summary":"  Binary code similarity detection is an important problem with applications in\nareas such as malware analysis, vulnerability research and license violation\ndetection. This paper proposes a novel graph neural network architecture\ncombined with a novel graph data representation called call graphlets. A call\ngraphlet encodes the neighborhood around each function in a binary executable,\ncapturing the local and global context through a series of statistical\nfeatures. A specialized graph neural network model operates on this graph\nrepresentation, learning to map it to a feature vector that encodes semantic\nbinary code similarities using deep-metric learning. The proposed approach is\nevaluated across five distinct datasets covering different architectures,\ncompiler tool chains, and optimization levels. Experimental results show that\nthe combination of call graphlets and the novel graph neural network\narchitecture achieves comparable or state-of-the-art performance compared to\nbaseline techniques across cross-architecture, mono-architecture and zero shot\ntasks. In addition, our proposed approach also performs well when evaluated\nagainst an out-of-domain function inlining task. The work provides a general\nand effective graph neural network-based solution for conducting binary code\nsimilarity detection.\n","authors":["Joshua Collyer","Tim Watson","Iain Phillips"],"pdf_url":"https://arxiv.org/pdf/2406.02606v2.pdf","comment":"13 pages, Under-Review"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.07239v1","updated":"2024-11-11T18:58:46Z","published":"2024-11-11T18:58:46Z","title":"DeepONet as a Multi-Operator Extrapolation Model: Distributed\n  Pretraining with Physics-Informed Fine-Tuning","summary":"  We propose a novel fine-tuning method to achieve multi-operator learning\nthrough training a distributed neural operator with diverse function data and\nthen zero-shot fine-tuning the neural network using physics-informed losses for\ndownstream tasks. Operator learning effectively approximates solution operators\nfor PDEs and various PDE-related problems, yet it often struggles to generalize\nto new tasks. To address this, we investigate fine-tuning a pretrained model,\nwhile carefully selecting an initialization that enables rapid adaptation to\nnew tasks with minimal data. Our approach combines distributed learning to\nintegrate data from various operators in pre-training, while physics-informed\nmethods enable zero-shot fine-tuning, minimizing the reliance on downstream\ndata. We investigate standard fine-tuning and Low-Rank Adaptation fine-tuning,\napplying both to train complex nonlinear target operators that are difficult to\nlearn only using random initialization. Through comprehensive numerical\nexamples, we demonstrate the advantages of our approach, showcasing significant\nimprovements in accuracy. Our findings provide a robust framework for advancing\nmulti-operator learning and highlight the potential of transfer learning\ntechniques in this domain.\n","authors":["Zecheng Zhang","Christian Moya","Lu Lu","Guang Lin","Hayden Schaeffer"],"pdf_url":"https://arxiv.org/pdf/2411.07239v1.pdf","comment":null}]},"2024-11-10T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2312.11361v3","updated":"2024-11-10T23:58:53Z","published":"2023-12-18T17:18:04Z","title":"\"Knowing When You Don't Know\": A Multilingual Relevance Assessment\n  Dataset for Robust Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) grounds Large Language Model (LLM)\noutput by leveraging external knowledge sources to reduce factual\nhallucinations. However, prior work lacks a comprehensive evaluation of\ndifferent language families, making it challenging to evaluate LLM robustness\nagainst errors in external retrieved knowledge. To overcome this, we establish\nNoMIRACL, a human-annotated dataset for evaluating LLM robustness in RAG across\n18 typologically diverse languages. NoMIRACL includes both a non-relevant and a\nrelevant subset. Queries in the non-relevant subset contain passages judged as\nnon-relevant, whereas queries in the relevant subset include at least a single\njudged relevant passage. We measure relevance assessment using: (i)\nhallucination rate, measuring model tendency to hallucinate, when the answer is\nnot present in passages in the non-relevant subset, and (ii) error rate,\nmeasuring model inaccuracy to recognize relevant passages in the relevant\nsubset.In our work, we observe that most models struggle to balance the two\ncapacities. Models such as LLAMA-2 and Orca-2 achieve over 88% hallucination\nrate on the non-relevant subset. Mistral and LLAMA-3 hallucinate less but can\nachieve up to a 74.9% error rate on the relevant subset. Overall, GPT-4 is\nobserved to provide the best tradeoff on both subsets, highlighting future work\nnecessary to improve LLM robustness. NoMIRACL dataset and evaluation code are\navailable at: https://github.com/project-miracl/nomiracl.\n","authors":["Nandan Thakur","Luiz Bonifacio","Xinyu Zhang","Odunayo Ogundepo","Ehsan Kamalloo","David Alfonso-Hermelo","Xiaoguang Li","Qun Liu","Boxing Chen","Mehdi Rezagholizadeh","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2312.11361v3.pdf","comment":"EMNLP 2024 (Findings)"},{"id":"http://arxiv.org/abs/2406.03689v3","updated":"2024-11-10T23:47:33Z","published":"2024-06-06T02:20:31Z","title":"Evaluating the World Model Implicit in a Generative Model","summary":"  Recent work suggests that large language models may implicitly learn world\nmodels. How should we assess this possibility? We formalize this question for\nthe case where the underlying reality is governed by a deterministic finite\nautomaton. This includes problems as diverse as simple logical reasoning,\ngeographic navigation, game-playing, and chemistry. We propose new evaluation\nmetrics for world model recovery inspired by the classic Myhill-Nerode theorem\nfrom language theory. We illustrate their utility in three domains: game\nplaying, logic puzzles, and navigation. In all domains, the generative models\nwe consider do well on existing diagnostics for assessing world models, but our\nevaluation metrics reveal their world models to be far less coherent than they\nappear. Such incoherence creates fragility: using a generative model to solve\nrelated but subtly different tasks can lead to failures. Building generative\nmodels that meaningfully capture the underlying logic of the domains they model\nwould be immensely valuable; our results suggest new ways to assess how close a\ngiven model is to that goal.\n","authors":["Keyon Vafa","Justin Y. Chen","Ashesh Rambachan","Jon Kleinberg","Sendhil Mullainathan"],"pdf_url":"https://arxiv.org/pdf/2406.03689v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00515v2","updated":"2024-11-10T22:02:27Z","published":"2024-06-01T17:48:15Z","title":"A Survey on Large Language Models for Code Generation","summary":"  Large Language Models (LLMs) have garnered remarkable advancements across\ndiverse code-related tasks, known as Code LLMs, particularly in code generation\nthat generates source code with LLM from natural language descriptions. This\nburgeoning field has captured significant interest from both academic\nresearchers and industry professionals due to its practical significance in\nsoftware development, e.g., GitHub Copilot. Despite the active exploration of\nLLMs for a variety of code tasks, either from the perspective of natural\nlanguage processing (NLP) or software engineering (SE) or both, there is a\nnoticeable absence of a comprehensive and up-to-date literature review\ndedicated to LLM for code generation. In this survey, we aim to bridge this gap\nby providing a systematic literature review that serves as a valuable reference\nfor researchers investigating the cutting-edge progress in LLMs for code\ngeneration. We introduce a taxonomy to categorize and discuss the recent\ndevelopments in LLMs for code generation, covering aspects such as data\ncuration, latest advances, performance evaluation, ethical implications,\nenvironmental impact, and real-world applications. In addition, we present a\nhistorical overview of the evolution of LLMs for code generation and offer an\nempirical comparison using the HumanEval, MBPP, and BigCodeBench benchmarks\nacross various levels of difficulty and types of programming tasks to highlight\nthe progressive enhancements in LLM capabilities for code generation. We\nidentify critical challenges and promising opportunities regarding the gap\nbetween academia and practical development. Furthermore, we have established a\ndedicated resource GitHub page (https://github.com/juyongjiang/CodeLLMSurvey)\nto continuously document and disseminate the most recent advances in the field.\n","authors":["Juyong Jiang","Fan Wang","Jiasi Shen","Sungju Kim","Sunghun Kim"],"pdf_url":"https://arxiv.org/pdf/2406.00515v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17866v2","updated":"2024-11-10T21:40:31Z","published":"2024-07-25T08:36:58Z","title":"Financial Statement Analysis with Large Language Models","summary":"  We investigate whether large language models (LLMs) can successfully perform\nfinancial statement analysis in a way similar to a professional human analyst.\nWe provide standardized and anonymous financial statements to GPT4 and instruct\nthe model to analyze them to determine the direction of firms' future earnings.\nEven without narrative or industry-specific information, the LLM outperforms\nfinancial analysts in its ability to predict earnings changes directionally.\nThe LLM exhibits a relative advantage over human analysts in situations when\nthe analysts tend to struggle. Furthermore, we find that the prediction\naccuracy of the LLM is on par with a narrowly trained state-of-the-art ML\nmodel. LLM prediction does not stem from its training memory. Instead, we find\nthat the LLM generates useful narrative insights about a company's future\nperformance. Lastly, our trading strategies based on GPT's predictions yield a\nhigher Sharpe ratio and alphas than strategies based on other models. Our\nresults suggest that LLMs may take a central role in analysis and\ndecision-making.\n","authors":["Alex Kim","Maximilian Muhn","Valeri Nikolaev"],"pdf_url":"https://arxiv.org/pdf/2407.17866v2.pdf","comment":"Previously posted on SSRN (May 21, 2024). See\n  http://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311"},{"id":"http://arxiv.org/abs/2411.06590v1","updated":"2024-11-10T20:41:35Z","published":"2024-11-10T20:41:35Z","title":"CriticAL: Critic Automation with Language Models","summary":"  Understanding the world through models is a fundamental goal of scientific\nresearch. While large language model (LLM) based approaches show promise in\nautomating scientific discovery, they often overlook the importance of\ncriticizing scientific models. Criticizing models deepens scientific\nunderstanding and drives the development of more accurate models. Automating\nmodel criticism is difficult because it traditionally requires a human expert\nto define how to compare a model with data and evaluate if the discrepancies\nare significant--both rely heavily on understanding the modeling assumptions\nand domain. Although LLM-based critic approaches are appealing, they introduce\nnew challenges: LLMs might hallucinate the critiques themselves. Motivated by\nthis, we introduce CriticAL (Critic Automation with Language Models). CriticAL\nuses LLMs to generate summary statistics that capture discrepancies between\nmodel predictions and data, and applies hypothesis tests to evaluate their\nsignificance. We can view CriticAL as a verifier that validates models and\ntheir critiques by embedding them in a hypothesis testing framework. In\nexperiments, we evaluate CriticAL across key quantitative and qualitative\ndimensions. In settings where we synthesize discrepancies between models and\ndatasets, CriticAL reliably generates correct critiques without hallucinating\nincorrect ones. We show that both human and LLM judges consistently prefer\nCriticAL's critiques over alternative approaches in terms of transparency and\nactionability. Finally, we show that CriticAL's critiques enable an LLM\nscientist to improve upon human-designed models on real-world datasets.\n","authors":["Michael Y. Li","Vivek Vajipey","Noah D. Goodman","Emily B. Fox"],"pdf_url":"https://arxiv.org/pdf/2411.06590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07524v2","updated":"2024-11-10T20:34:34Z","published":"2024-06-11T17:51:40Z","title":"Simple and Effective Masked Diffusion Language Models","summary":"  While diffusion models excel at generating high-quality images, prior work\nreports a significant performance gap between diffusion and autoregressive (AR)\nmethods in language modeling. In this work, we show that simple masked discrete\ndiffusion is more performant than previously thought. We apply an effective\ntraining recipe that improves the performance of masked diffusion models and\nderive a simplified, Rao-Blackwellized objective that results in additional\nimprovements. Our objective has a simple form -- it is a mixture of classical\nmasked language modeling losses -- and can be used to train encoder-only\nlanguage models that admit efficient samplers, including ones that can generate\narbitrary lengths of text semi-autoregressively like a traditional language\nmodel. On language modeling benchmarks, a range of masked diffusion models\ntrained with modern engineering practices achieves a new state-of-the-art among\ndiffusion models, and approaches AR perplexity. We provide the code, along with\na blog post and video tutorial on the project page: https://s-sahoo.com/mdlm\n","authors":["Subham Sekhar Sahoo","Marianne Arriola","Yair Schiff","Aaron Gokaslan","Edgar Marroquin","Justin T Chiu","Alexander Rush","Volodymyr Kuleshov"],"pdf_url":"https://arxiv.org/pdf/2406.07524v2.pdf","comment":"NeurIPS 2024. We provide the code at\n  https://github.com/kuleshov-group/mdlm"},{"id":"http://arxiv.org/abs/2401.15043v3","updated":"2024-11-10T19:47:22Z","published":"2024-01-26T18:13:57Z","title":"Health Text Simplification: An Annotated Corpus for Digestive Cancer\n  Education and Novel Strategies for Reinforcement Learning","summary":"  Objective: The reading level of health educational materials significantly\ninfluences the understandability and accessibility of the information,\nparticularly for minoritized populations. Many patient educational resources\nsurpass the reading level and complexity of widely accepted standards. There is\na critical need for high-performing text simplification models in health\ninformation to enhance dissemination and literacy. This need is particularly\nacute in cancer education, where effective prevention and screening education\ncan substantially reduce morbidity and mortality.\n  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel\ncorpus of cancer education materials tailored for health text simplification\nresearch, comprising educational content from the American Cancer Society,\nCenters for Disease Control and Prevention, and National Cancer Institute.\nUtilizing SimpleDC alongside the existing Med-EASi corpus, we explore Large\nLanguage Model (LLM)-based simplification methods, including fine-tuning,\nreinforcement learning (RL), reinforcement learning with human feedback (RLHF),\ndomain adaptation, and prompt-based approaches. Our experimentation encompasses\nLlama 2 and GPT-4. A novel RLHF reward function is introduced, featuring a\nlightweight model adept at distinguishing between original and simplified\ntexts, thereby enhancing the model's effectiveness with unlabeled data.\n  Results: Fine-tuned Llama 2 models demonstrated high performance across\nvarious metrics. Our innovative RLHF reward function surpassed existing RL text\nsimplification reward functions in effectiveness. The results underscore that\nRL/RLHF can augment fine-tuning, facilitating model training on unlabeled text\nand improving performance.\n","authors":["Md Mushfiqur Rahman","Mohammad Sabik Irbaz","Kai North","Michelle S. Williams","Marcos Zampieri","Kevin Lybarger"],"pdf_url":"https://arxiv.org/pdf/2401.15043v3.pdf","comment":"Published in Journal of Biomedical Informatics, Volume 158, October\n  2024, 104727"},{"id":"http://arxiv.org/abs/2411.06554v1","updated":"2024-11-10T18:32:24Z","published":"2024-11-10T18:32:24Z","title":"The KIPARLA Forest treebank of spoken Italian: an overview of initial\n  design choices","summary":"  The paper presents an overview of initial design choices discussed towards\nthe creation of a treebank for the Italian KIParla corpus\n","authors":["Ludovica Pannitto","Caterina Mauri"],"pdf_url":"https://arxiv.org/pdf/2411.06554v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.11896v2","updated":"2024-11-10T18:21:37Z","published":"2023-09-21T08:59:24Z","title":"Focal Inferential Infusion Coupled with Tractable Density Discrimination\n  for Implicit Hate Detection","summary":"  Although pretrained large language models (PLMs) have achieved\nstate-of-the-art on many natural language processing (NLP) tasks, they lack an\nunderstanding of subtle expressions of implicit hate speech. Various attempts\nhave been made to enhance the detection of implicit hate by augmenting external\ncontext or enforcing label separation via distance-based metrics. Combining\nthese two approaches, we introduce FiADD, a novel Focused Inferential Adaptive\nDensity Discrimination framework. FiADD enhances the PLM finetuning pipeline by\nbringing the surface form/meaning of an implicit hate speech closer to its\nimplied form while increasing the inter-cluster distance among various labels.\nWe test FiADD on three implicit hate datasets and observe significant\nimprovement in the two-way and three-way hate classification tasks. We further\nexperiment on the generalizability of FiADD on three other tasks, detecting\nsarcasm, irony, and stance, in which surface and implied forms differ, and\nobserve similar performance improvements. Consequently, we analyze the\ngenerated latent space to understand its evolution under FiADD, which\ncorroborates the advantage of employing FiADD for implicit hate speech\ndetection.\n","authors":["Sarah Masud","Ashutosh Bajpai","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2309.11896v2.pdf","comment":"23 pages, 6 Figures, 9 Tables. Accepted at NLE"},{"id":"http://arxiv.org/abs/2411.06549v1","updated":"2024-11-10T18:06:55Z","published":"2024-11-10T18:06:55Z","title":"In-Context Learning for Preserving Patient Privacy: A Framework for\n  Synthesizing Realistic Patient Portal Messages","summary":"  Since the COVID-19 pandemic, clinicians have seen a large and sustained\ninflux in patient portal messages, significantly contributing to clinician\nburnout. To the best of our knowledge, there are no large-scale public patient\nportal messages corpora researchers can use to build tools to optimize\nclinician portal workflows. Informed by our ongoing work with a regional\nhospital, this study introduces an LLM-powered framework for configurable and\nrealistic patient portal message generation. Our approach leverages few-shot\ngrounded text generation, requiring only a small number of de-identified\npatient portal messages to help LLMs better match the true style and tone of\nreal data. Clinical experts in our team deem this framework as HIPAA-friendly,\nunlike existing privacy-preserving approaches to synthetic text generation\nwhich cannot guarantee all sensitive attributes will be protected. Through\nextensive quantitative and human evaluation, we show that our framework\nproduces data of higher quality than comparable generation methods as well as\nall related datasets. We believe this work provides a path forward for (i) the\nrelease of large-scale synthetic patient message datasets that are\nstylistically similar to ground-truth samples and (ii) HIPAA-friendly data\ngeneration which requires minimal human de-identification efforts.\n","authors":["Joseph Gatto","Parker Seegmiller","Timothy E. Burdick","Sarah Masud Preum"],"pdf_url":"https://arxiv.org/pdf/2411.06549v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 8 pages"},{"id":"http://arxiv.org/abs/2411.06548v1","updated":"2024-11-10T18:04:41Z","published":"2024-11-10T18:04:41Z","title":"CineXDrama: Relevance Detection and Sentiment Analysis of Bangla YouTube\n  Comments on Movie-Drama using Transformers: Insights from Interpretability\n  Tool","summary":"  In recent years, YouTube has become the leading platform for Bangla movies\nand dramas, where viewers express their opinions in comments that convey their\nsentiments about the content. However, not all comments are relevant for\nsentiment analysis, necessitating a filtering mechanism. We propose a system\nthat first assesses the relevance of comments and then analyzes the sentiment\nof those deemed relevant. We introduce a dataset of 14,000 manually collected\nand preprocessed comments, annotated for relevance (relevant or irrelevant) and\nsentiment (positive or negative). Eight transformer models, including\nBanglaBERT, were used for classification tasks, with BanglaBERT achieving the\nhighest accuracy (83.99% for relevance detection and 93.3% for sentiment\nanalysis). The study also integrates LIME to interpret model decisions,\nenhancing transparency.\n","authors":["Usafa Akther Rifa","Pronay Debnath","Busra Kamal Rafa","Shamaun Safa Hridi","Md. Aminur Rahman"],"pdf_url":"https://arxiv.org/pdf/2411.06548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06535v1","updated":"2024-11-10T17:32:16Z","published":"2024-11-10T17:32:16Z","title":"Probabilistic Consensus through Ensemble Validation: A Framework for LLM\n  Reliability","summary":"  Large Language Models (LLMs) have shown significant advances in text\ngeneration but often lack the reliability needed for autonomous deployment in\nhigh-stakes domains like healthcare, law, and finance. Existing approaches rely\non external knowledge or human oversight, limiting scalability. We introduce a\nnovel framework that repurposes ensemble methods for content validation through\nmodel consensus. In tests across 78 complex cases requiring factual accuracy\nand causal consistency, our framework improved precision from 73.1% to 93.9%\nwith two models (95% CI: 83.5%-97.9%) and to 95.6% with three models (95% CI:\n85.2%-98.8%). Statistical analysis indicates strong inter-model agreement\n($\\kappa$ > 0.76) while preserving sufficient independence to catch errors\nthrough disagreement. We outline a clear pathway to further enhance precision\nwith additional validators and refinements. Although the current approach is\nconstrained by multiple-choice format requirements and processing latency, it\noffers immediate value for enabling reliable autonomous AI systems in critical\napplications.\n","authors":["Ninad Naik"],"pdf_url":"https://arxiv.org/pdf/2411.06535v1.pdf","comment":"8 pages, 6 tables"},{"id":"http://arxiv.org/abs/2411.06528v1","updated":"2024-11-10T17:10:13Z","published":"2024-11-10T17:10:13Z","title":"Epistemic Integrity in Large Language Models","summary":"  Large language models are increasingly relied upon as sources of information,\nbut their propensity for generating false or misleading statements with high\nconfidence poses risks for users and society. In this paper, we confront the\ncritical problem of epistemic miscalibration $\\unicode{x2013}$ where a model's\nlinguistic assertiveness fails to reflect its true internal certainty. We\nintroduce a new human-labeled dataset and a novel method for measuring the\nlinguistic assertiveness of Large Language Models (LLMs) which cuts error rates\nby over 50% relative to previous benchmarks. Validated across multiple\ndatasets, our method reveals a stark misalignment between how confidently\nmodels linguistically present information and their actual accuracy. Further\nhuman evaluations confirm the severity of this miscalibration. This evidence\nunderscores the urgent risk of the overstated certainty LLMs hold which may\nmislead users on a massive scale. Our framework provides a crucial step forward\nin diagnosing this miscalibration, offering a path towards correcting it and\nmore trustworthy AI across domains.\n","authors":["Bijean Ghafouri","Shahrad Mohammadzadeh","James Zhou","Pratheeksha Nair","Jacob-Junqi Tian","Mayank Goel","Reihaneh Rabbany","Jean-Fran√ßois Godbout","Kellin Pelrine"],"pdf_url":"https://arxiv.org/pdf/2411.06528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06506v1","updated":"2024-11-10T16:05:11Z","published":"2024-11-10T16:05:11Z","title":"CULL-MT: Compression Using Language and Layer pruning for Machine\n  Translation","summary":"  Multilingual machine translation models often outperform traditional\nbilingual models by leveraging translation knowledge transfer. Recent\nadvancements have led to these models supporting hundreds of languages and\nachieving state-of-the-art results across various translation directions.\nHowever, as these models grow larger, their inference operations become\nincreasingly costly. In many use cases, there is no need to support such a wide\nrange of language pairs, as translation is typically needed in only a few\nselected directions. In this paper, we present CULL-MT, a compression method\nfor machine translation models based on structural layer pruning and selected\nlanguage directions. Our approach identifies and prunes unimportant layers\nusing a greedy strategy, then mitigates the impact by applying knowledge\ndistillation from the original model along with parameter-efficient\nfine-tuning. We apply CULL-MT to the NLLB-3.3B and LLaMA3.1-8B-Instruct models.\nIn a multi-way translation scenario (Persian, French, and German to English),\nwe find the NLLB-3.3B model to be robust, allowing 25% of layers to be pruned\nwith only a 0.9 spBLEU drop. However, LLaMA3.1-8B-Instruct is more sensitive,\nwith a 2.0 spBLEU drop after pruning 5 layers.\n","authors":["Pedram Rostami","Mohammad Javad Dousti"],"pdf_url":"https://arxiv.org/pdf/2411.06506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06477v1","updated":"2024-11-10T14:31:36Z","published":"2024-11-10T14:31:36Z","title":"VocalTweets: Investigating Social Media Offensive Language Among\n  Nigerian Musicians","summary":"  Musicians frequently use social media to express their opinions, but they\noften convey different messages in their music compared to their posts online.\nSome utilize these platforms to abuse their colleagues, while others use it to\nshow support for political candidates or engage in activism, as seen during the\n#EndSars protest. There are extensive research done on offensive language\ndetection on social media, the usage of offensive language by musicians has\nreceived limited attention. In this study, we introduce VocalTweets, a\ncode-switched and multilingual dataset comprising tweets from 12 prominent\nNigerian musicians, labeled with a binary classification method as Normal or\nOffensive. We trained a model using HuggingFace's base-Twitter-RoBERTa,\nachieving an F1 score of 74.5. Additionally, we conducted cross-corpus\nexperiments with the OLID dataset to evaluate the generalizability of our\ndataset.\n","authors":["Sunday Oluyele","Juwon Akingbade","Victor Akinode"],"pdf_url":"https://arxiv.org/pdf/2411.06477v1.pdf","comment":"13 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2411.06469v1","updated":"2024-11-10T14:07:43Z","published":"2024-11-10T14:07:43Z","title":"ClinicalBench: Can LLMs Beat Traditional ML Models in Clinical\n  Prediction?","summary":"  Large Language Models (LLMs) hold great promise to revolutionize current\nclinical systems for their superior capacities on medical text processing tasks\nand medical licensing exams. Meanwhile, traditional ML models such as SVM and\nXGBoost have still been mainly adopted in clinical prediction tasks. An\nemerging question is Can LLMs beat traditional ML models in clinical\nprediction? Thus, we build a new benchmark ClinicalBench to comprehensively\nstudy the clinical predictive modeling capacities of both general-purpose and\nmedical LLMs, and compare them with traditional ML models. ClinicalBench\nembraces three common clinical prediction tasks, two databases, 14\ngeneral-purpose LLMs, 8 medical LLMs, and 11 traditional ML models. Through\nextensive empirical investigation, we discover that both general-purpose and\nmedical LLMs, even with different model scales, diverse prompting or\nfine-tuning strategies, still cannot beat traditional ML models in clinical\nprediction yet, shedding light on their potential deficiency in clinical\nreasoning and decision-making. We call for caution when practitioners adopt\nLLMs in clinical applications. ClinicalBench can be utilized to bridge the gap\nbetween LLMs' development for healthcare and real-world clinical practice.\n","authors":["Canyu Chen","Jian Yu","Shan Chen","Che Liu","Zhongwei Wan","Danielle Bitterman","Fei Wang","Kai Shu"],"pdf_url":"https://arxiv.org/pdf/2411.06469v1.pdf","comment":"The first two authors contributed equally. 10 pages for main paper,\n  66 pages including appendix. Project website: https://clinicalbench.github.io"},{"id":"http://arxiv.org/abs/2406.00131v2","updated":"2024-11-10T13:58:19Z","published":"2024-05-31T18:46:06Z","title":"From Unstructured Data to In-Context Learning: Exploring What Tasks Can\n  Be Learned and When","summary":"  Large language models (LLMs) like transformers demonstrate impressive\nin-context learning (ICL) capabilities, allowing them to make predictions for\nnew tasks based on prompt exemplars without parameter updates. While existing\nICL theories often assume structured training data resembling ICL tasks (e.g.,\nx-y pairs for linear regression), LLMs are typically trained unsupervised on\nunstructured text, such as web content, which lacks clear parallels to tasks\nlike word analogy. To address this gap, we examine what enables ICL in models\ntrained on unstructured data, focusing on critical sequence model requirements\nand training data structure. We find that many ICL capabilities can emerge\nsimply from co-occurrence of semantically related word pairs in unstructured\ndata; word analogy completion, for example, can provably arise purely through\nco-occurrence modeling, using classical language models like continuous bag of\nwords (CBOW), without needing positional information or attention mechanisms.\nHowever, positional information becomes crucial for logic reasoning tasks\nrequiring generalization to unseen tokens. Finally, we identify two cases where\nICL fails: one in logic reasoning tasks that require generalizing to new,\nunseen patterns, and another in analogy completion where relevant word pairs\nappear only in fixed training positions. These findings suggest that LLMs' ICL\nabilities depend heavily on the structural elements within their training data.\n","authors":["Kevin Christian Wibisono","Yixin Wang"],"pdf_url":"https://arxiv.org/pdf/2406.00131v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2410.15595v2","updated":"2024-11-10T13:46:15Z","published":"2024-10-21T02:27:24Z","title":"A Comprehensive Survey of Direct Preference Optimization: Datasets,\n  Theories, Variants, and Applications","summary":"  With the rapid advancement of large language models (LLMs), aligning policy\nmodels with human preferences has become increasingly critical. Direct\nPreference Optimization (DPO) has emerged as a promising approach for\nalignment, acting as an RL-free alternative to Reinforcement Learning from\nHuman Feedback (RLHF). Despite DPO's various advancements and inherent\nlimitations, an in-depth review of these aspects is currently lacking in the\nliterature. In this work, we present a comprehensive review of the challenges\nand opportunities in DPO, covering theoretical analyses, variants, relevant\npreference datasets, and applications. Specifically, we categorize recent\nstudies on DPO based on key research questions to provide a thorough\nunderstanding of DPO's current landscape. Additionally, we propose several\nfuture research directions to offer insights on model alignment for the\nresearch community.\n","authors":["Wenyi Xiao","Zechuan Wang","Leilei Gan","Shuai Zhao","Wanggui He","Luu Anh Tuan","Long Chen","Hao Jiang","Zhou Zhao","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2410.15595v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16247v4","updated":"2024-11-10T12:54:35Z","published":"2024-05-25T14:11:44Z","title":"AutoManual: Constructing Instruction Manuals by LLM Agents via\n  Interactive Environmental Learning","summary":"  Large Language Models (LLM) based agents have shown promise in autonomously\ncompleting tasks across various domains, e.g., robotics, games, and web\nnavigation. However, these agents typically require elaborate design and expert\nprompts to solve tasks in specific domains, which limits their adaptability. We\nintroduce AutoManual, a framework enabling LLM agents to autonomously build\ntheir understanding through interaction and adapt to new environments.\nAutoManual categorizes environmental knowledge into diverse rules and optimizes\nthem in an online fashion by two agents: 1) The Planner codes actionable plans\nbased on current rules for interacting with the environment. 2) The Builder\nupdates the rules through a well-structured rule system that facilitates online\nrule management and essential detail retention. To mitigate hallucinations in\nmanaging rules, we introduce a *case-conditioned prompting* strategy for the\nBuilder. Finally, the Formulator agent compiles these rules into a\ncomprehensive manual. The self-generated manual can not only improve the\nadaptability but also guide the planning of smaller LLMs while being\nhuman-readable. Given only one simple demonstration, AutoManual significantly\nimproves task success rates, achieving 97.4\\% with GPT-4-turbo and 86.2\\% with\nGPT-3.5-turbo on ALFWorld benchmark tasks. The code is available at\nhttps://github.com/minghchen/automanual.\n","authors":["Minghao Chen","Yihang Li","Yanting Yang","Shiyu Yu","Binbin Lin","Xiaofei He"],"pdf_url":"https://arxiv.org/pdf/2405.16247v4.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2402.18815v3","updated":"2024-11-10T12:49:15Z","published":"2024-02-29T02:55:26Z","title":"How do Large Language Models Handle Multilingualism?","summary":"  Large language models (LLMs) have demonstrated impressive capabilities across\ndiverse languages. This study explores how LLMs handle multilingualism. Based\non observed language ratio shifts among layers and the relationships between\nnetwork structures and certain capabilities, we hypothesize the LLM's\nmultilingual workflow ($\\texttt{MWork}$): LLMs initially understand the query,\nconverting multilingual inputs into English for task-solving. In the\nintermediate layers, they employ English for thinking and incorporate\nmultilingual knowledge with self-attention and feed-forward structures,\nrespectively. In the final layers, LLMs generate responses aligned with the\noriginal language of the query. To verify $\\texttt{MWork}$, we introduce\nParallel Language-specific Neuron Detection ($\\texttt{PLND}$) to identify\nactivated neurons for inputs in different languages without any labeled data.\nUsing $\\texttt{PLND}$, we validate $\\texttt{MWork}$ through extensive\nexperiments involving the deactivation of language-specific neurons across\nvarious layers and structures. Moreover, $\\texttt{MWork}$ allows fine-tuning of\nlanguage-specific neurons with a small dataset, enhancing multilingual\nabilities in a specific language without compromising others. This approach\nresults in an average improvement of $3.6\\%$ for high-resource languages and\n$2.3\\%$ for low-resource languages across all tasks with just $400$ documents.\n","authors":["Yiran Zhao","Wenxuan Zhang","Guizhen Chen","Kenji Kawaguchi","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2402.18815v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06445v1","updated":"2024-11-10T12:28:09Z","published":"2024-11-10T12:28:09Z","title":"Prompt-Efficient Fine-Tuning for GPT-like Deep Models to Reduce\n  Hallucination and to Improve Reproducibility in Scientific Text Generation\n  Using Stochastic Optimisation Techniques","summary":"  Large Language Models (LLMs) are increasingly adopted for complex scientific\ntext generation tasks, yet they often suffer from limitations in accuracy,\nconsistency, and hallucination control. This thesis introduces a\nParameter-Efficient Fine-Tuning (PEFT) approach tailored for GPT-like models,\naiming to mitigate hallucinations and enhance reproducibility, particularly in\nthe computational domain of mass spectrometry. We implemented Low-Rank\nAdaptation (LoRA) adapters to refine GPT-2, termed MS-GPT, using a specialized\ncorpus of mass spectrometry literature. Through novel evaluation methods\napplied to LLMs, including BLEU, ROUGE, and Perplexity scores, the fine-tuned\nMS-GPT model demonstrated superior text coherence and reproducibility compared\nto the baseline GPT-2, confirmed through statistical analysis with the Wilcoxon\nrank-sum test. Further, we propose a reproducibility metric based on cosine\nsimilarity of model outputs under controlled prompts, showcasing MS-GPT's\nenhanced stability. This research highlights PEFT's potential to optimize LLMs\nfor scientific contexts, reducing computational costs while improving model\nreliability.\n","authors":["Daniil Sulimov"],"pdf_url":"https://arxiv.org/pdf/2411.06445v1.pdf","comment":"73 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.06438v1","updated":"2024-11-10T11:49:36Z","published":"2024-11-10T11:49:36Z","title":"PLM-Based Discrete Diffusion Language Models with Entropy-Adaptive Gibbs\n  Sampling","summary":"  Recently, discrete diffusion language models have demonstrated promising\nresults in NLP. However, there has been limited research on integrating\nPretrained Language Models (PLMs) into discrete diffusion models, resulting in\nunderwhelming performance in downstream NLP generation tasks. This integration\nis particularly challenging because of the discrepancy between step-wise\ndenoising strategy of diffusion models and single-step mask prediction approach\nof MLM-based PLMs. In this paper, we introduce Diffusion-EAGS, a novel approach\nthat effectively integrates PLMs with the diffusion models. Furthermore, as it\nis challenging for PLMs to determine where to apply denoising during the\ndiffusion process, we integrate an entropy tracking module to assist them.\nFinally, we propose entropy-based noise scheduling in the forward process to\nimprove the effectiveness of entropy-adaptive sampling throughout the\ngeneration phase. Experimental results show that Diffusion-EAGS outperforms\nexisting diffusion baselines in downstream generation tasks, achieving high\ntext quality and diversity with precise token-level control. We also show that\nour model is capable of adapting to bilingual and low-resource settings, which\nare common in real-world applications.\n","authors":["Hyukhun Koh","Minha Jhang","Dohyung Kim","Sangmook Lee","Kyomin Jung"],"pdf_url":"https://arxiv.org/pdf/2411.06438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18906v2","updated":"2024-11-10T11:48:53Z","published":"2024-10-24T16:57:20Z","title":"PRISM: A Methodology for Auditing Biases in Large Language Models","summary":"  Auditing Large Language Models (LLMs) to discover their biases and\npreferences is an emerging challenge in creating Responsible Artificial\nIntelligence (AI). While various methods have been proposed to elicit the\npreferences of such models, countermeasures have been taken by LLM trainers,\nsuch that LLMs hide, obfuscate or point blank refuse to disclosure their\npositions on certain subjects. This paper presents PRISM, a flexible,\ninquiry-based methodology for auditing LLMs - that seeks to illicit such\npositions indirectly through task-based inquiry prompting rather than direct\ninquiry of said preferences. To demonstrate the utility of the methodology, we\napplied PRISM on the Political Compass Test, where we assessed the political\nleanings of twenty-one LLMs from seven providers. We show LLMs, by default,\nespouse positions that are economically left and socially liberal (consistent\nwith prior work). We also show the space of positions that these models are\nwilling to espouse - where some models are more constrained and less compliant\nthan others - while others are more neutral and objective. In sum, PRISM can\nmore reliably probe and audit LLMs to understand their preferences, biases and\nconstraints.\n","authors":["Leif Azzopardi","Yashar Moshfeghi"],"pdf_url":"https://arxiv.org/pdf/2410.18906v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06437v1","updated":"2024-11-10T11:47:50Z","published":"2024-11-10T11:47:50Z","title":"CTC-Assisted LLM-Based Contextual ASR","summary":"  Contextual ASR or hotword customization holds substantial practical value.\nDespite the impressive performance of current end-to-end (E2E) automatic speech\nrecognition (ASR) systems, they often face challenges in accurately recognizing\nrare words. Typical E2E contextual ASR models commonly feature complex\narchitectures and decoding mechanisms, limited in performance and susceptible\nto interference from distractor words. With large language model (LLM)-based\nASR models emerging as the new mainstream, we propose a CTC-Assisted LLM-Based\nContextual ASR model with an efficient filtering algorithm. By using coarse CTC\ndecoding results to filter potential relevant hotwords and incorporating them\ninto LLM prompt input, our model attains WER/B-WER of 1.27%/3.67% and\n2.72%/8.02% on the Librispeech test-clean and test-other sets targeting on\nrecognizing rare long-tail words, demonstrating significant improvements\ncompared to the baseline LLM-based ASR model, and substantially surpassing\nother related work. More remarkably, with the help of the large language model\nand proposed filtering algorithm, our contextual ASR model still performs well\nwith 2000 biasing words.\n","authors":["Guanrou Yang","Ziyang Ma","Zhifu Gao","Shiliang Zhang","Xie Chen"],"pdf_url":"https://arxiv.org/pdf/2411.06437v1.pdf","comment":"SLT 2024"},{"id":"http://arxiv.org/abs/2411.06426v1","updated":"2024-11-10T11:08:28Z","published":"2024-11-10T11:08:28Z","title":"SequentialBreak: Large Language Models Can be Fooled by Embedding\n  Jailbreak Prompts into Sequential Prompt Chains","summary":"  As the integration of the Large Language Models (LLMs) into various\napplications increases, so does their susceptibility to misuse, raising\nsignificant security concerns. Numerous jailbreak attacks have been proposed to\nassess the security defense of LLMs. Current jailbreak attacks mainly rely on\nscenario camouflage, prompt obfuscation, prompt optimization, and prompt\niterative optimization to conceal malicious prompts. In particular, sequential\nprompt chains in a single query can lead LLMs to focus on certain prompts while\nignoring others, facilitating context manipulation. This paper introduces\nSequentialBreak, a novel jailbreak attack that exploits this vulnerability. We\ndiscuss several scenarios, not limited to examples like Question Bank, Dialog\nCompletion, and Game Environment, where the harmful prompt is embedded within\nbenign ones that can fool LLMs into generating harmful responses. The distinct\nnarrative structures of these scenarios show that SequentialBreak is flexible\nenough to adapt to various prompt formats beyond those discussed. Extensive\nexperiments demonstrate that SequentialBreak uses only a single query to\nachieve a substantial gain of attack success rate over existing baselines\nagainst both open-source and closed-source models. Through our research, we\nhighlight the urgent need for more robust and resilient safeguards to enhance\nLLM security and prevent potential misuse. All the result files and website\nassociated with this research are available in this GitHub repository:\nhttps://anonymous.4open.science/r/JailBreakAttack-4F3B/.\n","authors":["Bijoy Ahmed Saiem","MD Sadik Hossain Shanto","Rakib Ahsan","Md Rafi ur Rashid"],"pdf_url":"https://arxiv.org/pdf/2411.06426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06424v1","updated":"2024-11-10T11:07:34Z","published":"2024-11-10T11:07:34Z","title":"Ablation is Not Enough to Emulate DPO: How Neuron Dynamics Drive\n  Toxicity Reduction","summary":"  Safety fine-tuning algorithms are commonly used to fine-tune language models\nto reduce harmful outputs, but the exact internal mechanisms of how those\nmodels achieve this remain unclear. In studying direct preference optimisation\n(DPO) for toxicity reduction, current explanations claim that DPO works by\ndampening the most toxic MLP neurons to learn an offset to avert toxic regions\nin the residual stream. However, by ablating the most toxic neurons and\napplying activation patching, we find this explanation incomplete. By\nprojecting neuron activation changes onto a toxicity probe, we find that only\n31.8\\% of toxicity reduction comes from dampened toxic neurons. Instead, DPO\nreduces toxicity by accumulating effects across multiple neuron groups, both\nreducing writing in the toxic direction and promoting anti-toxicity in the\nresidual stream. Moreover, DPO gives noisy adjustments to neuron activations,\nwith many neurons actually increasing toxicity. This indicates that DPO is a\nbalancing process between opposing neuron effects to achieve toxicity\nreduction.\n","authors":["Yushi Yang","Filip Sondej","Harry Mayne","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2411.06424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07468v3","updated":"2024-11-10T10:24:33Z","published":"2023-11-13T17:01:12Z","title":"An Analysis and Mitigation of the Reversal Curse","summary":"  Recent research observed a noteworthy phenomenon in large language models\n(LLMs), referred to as the ``reversal curse.'' The reversal curse is that when\ndealing with two entities, denoted as $a$ and $b$, connected by their relation\n$R$ and its inverse $R^{-1}$, LLMs excel in handling sequences in the form of\n``$aRb$,'' but encounter challenges when processing ``$bR^{-1}a$,'' whether in\ngeneration or comprehension. For instance, GPT-4 can accurately respond to the\nquery ``Tom Cruise's mother is?'' with ``Mary Lee Pfeiffer,'' but it struggles\nto provide a satisfactory answer when asked ``Mary Lee Pfeiffer's son is?'' In\nthis paper, we undertake the first-ever study of how the reversal curse happens\nin LLMs. Our investigations reveal that the reversal curse can stem from the\nspecific training objectives, which become particularly evident in the\nwidespread use of next-token prediction within most causal language models. We\nhope this initial investigation can draw more attention to the reversal curse,\nas well as other underlying limitations in current LLMs.\n","authors":["Ang Lv","Kaiyi Zhang","Shufang Xie","Quan Tu","Yuhan Chen","Ji-Rong Wen","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2311.07468v3.pdf","comment":"Accepted by EMNLP 2024 Main. This paper was originally titled \"Are We\n  Falling into a Middle-Intelligence Trap? An Analysis and Mitigation of the\n  Reversal Curse.\" The title was revised during the submission to EMNLP, and we\n  are now updating the title for this preprint version"},{"id":"http://arxiv.org/abs/2408.17017v2","updated":"2024-11-10T10:04:24Z","published":"2024-08-30T05:14:59Z","title":"Dynamic Self-Consistency: Leveraging Reasoning Paths for Efficient LLM\n  Sampling","summary":"  Self-Consistency (SC) is a widely used method to mitigate hallucinations in\nLarge Language Models (LLMs) by sampling the LLM multiple times and outputting\nthe most frequent solution. Despite its benefits, SC results in significant\ncomputational costs proportional to the number of samples generated. Previous\nearly-stopping approaches, such as Early Stopping Self Consistency and Adaptive\nConsistency, have aimed to reduce these costs by considering output\nconsistency, but they do not analyze the quality of the reasoning paths (RPs)\nthemselves. To address this issue, we propose Reasoning-Aware Self-Consistency\n(RASC), an innovative early-stopping framework that dynamically adjusts the\nnumber of sample generations by considering both the output answer and the RPs\nfrom Chain of Thought (CoT) prompting. RASC assigns confidence scores\nsequentially to the generated samples, stops when certain criteria are met, and\nthen employs weighted majority voting to optimize sample usage and enhance\nanswer reliability. We comprehensively test RASC with multiple LLMs across\nvaried QA datasets. RASC outperformed existing methods and significantly\nreduces sample usage by an average of 80% while maintaining or improving\naccuracy up to 5% compared to the original SC\n","authors":["Guangya Wan","Yuqi Wu","Jie Chen","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2408.17017v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06402v1","updated":"2024-11-10T09:29:51Z","published":"2024-11-10T09:29:51Z","title":"Fineweb-Edu-Ar: Machine-translated Corpus to Support Arabic Small\n  Language Models","summary":"  As large language models (LLMs) grow and develop, so do their data demands.\nThis is especially true for multilingual LLMs, where the scarcity of\nhigh-quality and readily available data online has led to a multitude of\nsynthetic dataset generation approaches. A key technique in this space is\nmachine translation (MT), where high-quality English text is adapted to a\ntarget, comparatively low-resource language. This report introduces\nFineWeb-Edu-Ar, a machine-translated version of the exceedingly popular\n(deduplicated) FineWeb-Edu dataset from HuggingFace. To the best of our\nknowledge, FineWeb-Edu-Ar is the largest publicly available machine-translated\nArabic dataset out there, with its size of 202B tokens of an Arabic-trained\ntokenizer.\n","authors":["Sultan Alrashed","Dmitrii Khizbullin","David R. Pugh"],"pdf_url":"https://arxiv.org/pdf/2411.06402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06391v1","updated":"2024-11-10T08:24:03Z","published":"2024-11-10T08:24:03Z","title":"CausalStock: Deep End-to-end Causal Discovery for News-driven Stock\n  Movement Prediction","summary":"  There are two issues in news-driven multi-stock movement prediction tasks\nthat are not well solved in the existing works. On the one hand, \"relation\ndiscovery\" is a pivotal part when leveraging the price information of other\nstocks to achieve accurate stock movement prediction. Given that stock\nrelations are often unidirectional, such as the \"supplier-consumer\"\nrelationship, causal relations are more appropriate to capture the impact\nbetween stocks. On the other hand, there is substantial noise existing in the\nnews data leading to extracting effective information with difficulty. With\nthese two issues in mind, we propose a novel framework called CausalStock for\nnews-driven multi-stock movement prediction, which discovers the temporal\ncausal relations between stocks. We design a lag-dependent temporal causal\ndiscovery mechanism to model the temporal causal graph distribution. Then a\nFunctional Causal Model is employed to encapsulate the discovered causal\nrelations and predict the stock movements. Additionally, we propose a Denoised\nNews Encoder by taking advantage of the excellent text evaluation ability of\nlarge language models (LLMs) to extract useful information from massive news\ndata. The experiment results show that CausalStock outperforms the strong\nbaselines for both news-driven multi-stock movement prediction and multi-stock\nmovement prediction tasks on six real-world datasets collected from the US,\nChina, Japan, and UK markets. Moreover, getting benefit from the causal\nrelations, CausalStock could offer a clear prediction mechanism with good\nexplainability.\n","authors":["Shuqi Li","Yuebo Sun","Yuxin Lin","Xin Gao","Shuo Shang","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2411.06391v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.06387v1","updated":"2024-11-10T08:11:05Z","published":"2024-11-10T08:11:05Z","title":"Self-Training Meets Consistency: Improving LLMs' Reasoning With\n  Consistency-Driven Rationale Evaluation","summary":"  Self-training approach for large language models (LLMs) improves reasoning\nabilities by training the models on their self-generated rationales. Previous\napproaches have labeled rationales that produce correct answers for a given\nquestion as appropriate for training. However, a single measure risks\nmisjudging rationale quality, leading the models to learn flawed reasoning\npatterns. To address this issue, we propose CREST (Consistency-driven Rationale\nEvaluation for Self-Training), a self-training framework that further evaluates\neach rationale through follow-up questions and leverages this evaluation to\nguide its training. Specifically, we introduce two methods: (1) filtering out\nrationales that frequently result in incorrect answers on follow-up questions\nand (2) preference learning based on mixed preferences from rationale\nevaluation results of both original and follow-up questions. Experiments on\nthree question-answering datasets using open LLMs show that CREST not only\nimproves the logical robustness and correctness of rationales but also improves\nreasoning abilities compared to previous self-training approaches.\n","authors":["Jaehyeok Lee","Keisuke Sakaguchi","JinYeong Bak"],"pdf_url":"https://arxiv.org/pdf/2411.06387v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2411.06371v1","updated":"2024-11-10T06:39:10Z","published":"2024-11-10T06:39:10Z","title":"LLM Vocabulary Compression for Low-Compute Environments","summary":"  We present a method to compress the final linear layer of language models,\nreducing memory usage by up to 3.4x without significant performance loss. By\ngrouping tokens based on Byte Pair Encoding (BPE) merges, we prevent\nmaterialization of the memory-intensive logits tensor. Evaluations on the\nTinyStories dataset show that our method performs on par with GPT-Neo and GPT2\nwhile significantly improving throughput by up to 3x, making it suitable for\nlow-compute environments.\n","authors":["Sreeram Vennam","Anish Joishy","Ponnurangam Kumaraguru"],"pdf_url":"https://arxiv.org/pdf/2411.06371v1.pdf","comment":"Machine Learning and Compression Workshop @ NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04425v2","updated":"2024-11-10T05:24:33Z","published":"2024-11-07T04:38:29Z","title":"DELIFT: Data Efficient Language model Instruction Fine Tuning","summary":"  Fine-tuning large language models (LLMs) is essential for enhancing their\nperformance on specific tasks but is often resource-intensive due to redundant\nor uninformative data. To address this inefficiency, we introduce DELIFT (Data\nEfficient Language model Instruction Fine-Tuning), a novel algorithm that\nsystematically optimizes data selection across the three key stages of\nfine-tuning: (1) instruction tuning, (2) task-specific fine-tuning (e.g.,\nreasoning, question-answering), and (3) continual fine-tuning (e.g.,\nincorporating new data versions). Unlike existing methods that focus on\nsingle-stage optimization or rely on computationally intensive gradient\ncalculations, DELIFT operates efficiently across all stages. Central to our\napproach is a pairwise utility metric that quantifies how beneficial a data\nsample is for improving the model's responses to other samples, effectively\nmeasuring the informational value relative to the model's current capabilities.\nBy leveraging different submodular functions applied to this metric, DELIFT\nselects diverse and optimal subsets that are useful across all stages of\nfine-tuning. Experiments across various tasks and model scales demonstrate that\nDELIFT can reduce the fine-tuning data size by up to 70% without compromising\nperformance, offering significant computational savings and outperforming\nexisting methods in both efficiency and efficacy.\n","authors":["Ishika Agarwal","Krishnateja Killamsetty","Lucian Popa","Marina Danilevksy"],"pdf_url":"https://arxiv.org/pdf/2411.04425v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18957v3","updated":"2024-11-10T03:45:30Z","published":"2024-09-27T17:58:50Z","title":"LML-DAP: Language Model Learning a Dataset for Data-Augmented Prediction","summary":"  Classification tasks are typically handled using Machine Learning (ML)\nmodels, which lack a balance between accuracy and interpretability. This paper\nintroduces a new approach for classification tasks using Large Language Models\n(LLMs) in an explainable method. Unlike ML models, which rely heavily on data\ncleaning and feature engineering, this method streamlines the process using\nLLMs. This paper proposes a method called \"Language Model Learning (LML)\"\npowered by a new method called \"Data-Augmented Prediction (DAP).\" The\nclassification is performed by LLMs using a method similar to that used by\nhumans who manually explore and understand the data to decide classifications.\nIn the process of LML, a dataset is summarized and evaluated to determine the\nfeatures leading to each label the most. In the DAP process, the system uses\nthe data summary and a row of the testing dataset to automatically generate a\nquery to retrieve relevant rows from the dataset for context-aware\nclassification. LML and DAP unlock new possibilities in areas that require\nexplainable and context-aware decisions by ensuring satisfactory accuracy even\nwith complex data. The system scored an accuracy above 90% in some test cases,\nconfirming the effectiveness and potential of the system to outperform ML\nmodels in various scenarios. The source code is available at\nhttps://github.com/Pro-GenAI/LML-DAP\n","authors":["Praneeth Vadlapati"],"pdf_url":"https://arxiv.org/pdf/2409.18957v3.pdf","comment":"Made the abstract and the content clearer"},{"id":"http://arxiv.org/abs/2401.14818v5","updated":"2024-11-10T02:57:33Z","published":"2024-01-26T12:45:55Z","title":"ChemDFM: A Large Language Foundation Model for Chemistry","summary":"  Artificial intelligence (AI) has played an increasingly important role in\nchemical research. However, most models currently used in chemistry are\nspecialist models that require training and tuning for specific tasks. A more\ngeneric and efficient solution would be an AI model that could address many\ntasks and support free-form dialogue in the broad field of chemistry. In its\nutmost form, such a generalist AI chemist could be referred to as Chemical\nGeneral Intelligence. Large language models (LLMs) have recently logged\ntremendous success in the general domain of natural language processing,\nshowing emerging task generalization and free-form dialogue capabilities.\nHowever, domain knowledge of chemistry is largely missing when training\ngeneral-domain LLMs. The lack of such knowledge greatly hinders the performance\nof generalist LLMs in the field of chemistry. To this end, we develop ChemDFM,\na pioneering LLM for chemistry trained on 34B tokens from chemical literature\nand textbooks, and fine-tuned using 2.7M instructions. As a result, it can\nunderstand and reason with chemical knowledge in free-form dialogue.\nQuantitative evaluations show that ChemDFM significantly surpasses most\nrepresentative open-source LLMs. It outperforms GPT-4 on a great portion of\nchemical tasks, despite the substantial size difference. We have open-sourced\nthe inference codes, evaluation datasets, and model weights of ChemDFM on\nHuggingface (https://huggingface.co/OpenDFM/ChemDFM-v1.0-13B).\n","authors":["Zihan Zhao","Da Ma","Lu Chen","Liangtai Sun","Zihao Li","Yi Xia","Bo Chen","Hongshen Xu","Zichen Zhu","Su Zhu","Shuai Fan","Guodong Shen","Kai Yu","Xin Chen"],"pdf_url":"https://arxiv.org/pdf/2401.14818v5.pdf","comment":"10 pages, 12 figures, 12 tables. Under Review"},{"id":"http://arxiv.org/abs/2411.06316v1","updated":"2024-11-10T00:23:55Z","published":"2024-11-10T00:23:55Z","title":"Prompts Matter: Comparing ML/GAI Approaches for Generating Inductive\n  Qualitative Coding Results","summary":"  Inductive qualitative methods have been a mainstay of education research for\ndecades, yet it takes much time and effort to conduct rigorously. Recent\nadvances in artificial intelligence, particularly with generative AI (GAI),\nhave led to initial success in generating inductive coding results. Like human\ncoders, GAI tools rely on instructions to work, and how to instruct it may\nmatter. To understand how ML/GAI approaches could contribute to qualitative\ncoding processes, this study applied two known and two theory-informed novel\napproaches to an online community dataset and evaluated the resulting coding\nresults. Our findings show significant discrepancies between ML/GAI approaches\nand demonstrate the advantage of our approaches, which introduce human coding\nprocesses into GAI prompts.\n","authors":["John Chen","Alexandros Lotsos","Lexie Zhao","Grace Wang","Uri Wilensky","Bruce Sherin","Michael Horn"],"pdf_url":"https://arxiv.org/pdf/2411.06316v1.pdf","comment":"Accepted by AERA 2025 Annual Meeting"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2312.11361v3","updated":"2024-11-10T23:58:53Z","published":"2023-12-18T17:18:04Z","title":"\"Knowing When You Don't Know\": A Multilingual Relevance Assessment\n  Dataset for Robust Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) grounds Large Language Model (LLM)\noutput by leveraging external knowledge sources to reduce factual\nhallucinations. However, prior work lacks a comprehensive evaluation of\ndifferent language families, making it challenging to evaluate LLM robustness\nagainst errors in external retrieved knowledge. To overcome this, we establish\nNoMIRACL, a human-annotated dataset for evaluating LLM robustness in RAG across\n18 typologically diverse languages. NoMIRACL includes both a non-relevant and a\nrelevant subset. Queries in the non-relevant subset contain passages judged as\nnon-relevant, whereas queries in the relevant subset include at least a single\njudged relevant passage. We measure relevance assessment using: (i)\nhallucination rate, measuring model tendency to hallucinate, when the answer is\nnot present in passages in the non-relevant subset, and (ii) error rate,\nmeasuring model inaccuracy to recognize relevant passages in the relevant\nsubset.In our work, we observe that most models struggle to balance the two\ncapacities. Models such as LLAMA-2 and Orca-2 achieve over 88% hallucination\nrate on the non-relevant subset. Mistral and LLAMA-3 hallucinate less but can\nachieve up to a 74.9% error rate on the relevant subset. Overall, GPT-4 is\nobserved to provide the best tradeoff on both subsets, highlighting future work\nnecessary to improve LLM robustness. NoMIRACL dataset and evaluation code are\navailable at: https://github.com/project-miracl/nomiracl.\n","authors":["Nandan Thakur","Luiz Bonifacio","Xinyu Zhang","Odunayo Ogundepo","Ehsan Kamalloo","David Alfonso-Hermelo","Xiaoguang Li","Qun Liu","Boxing Chen","Mehdi Rezagholizadeh","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2312.11361v3.pdf","comment":"EMNLP 2024 (Findings)"},{"id":"http://arxiv.org/abs/2406.10593v2","updated":"2024-11-10T13:45:48Z","published":"2024-06-15T10:54:54Z","title":"QDA-SQL: Questions Enhanced Dialogue Augmentation for Multi-Turn\n  Text-to-SQL","summary":"  Fine-tuning large language models (LLMs) for specific domain tasks has\nachieved great success in Text-to-SQL tasks. However, these fine-tuned models\noften face challenges with multi-turn Text-to-SQL tasks caused by ambiguous or\nunanswerable questions. It is desired to enhance LLMs to handle multiple types\nof questions in multi-turn Text-to-SQL tasks. To address this, we propose a\nnovel data augmentation method, called QDA-SQL, which generates multiple types\nof multi-turn Q\\&A pairs using LLMs. In QDA-SQL, we introduce a method\nincorporating validation and correction mechanisms to handle complex multi-turn\nText-to-SQL tasks. Experimental results demonstrate that QDA-SQL enables\nfine-tuned models to exhibit higher performance on SQL statement accuracy and\nenhances their ability to handle complex, unanswerable questions in multi-turn\nText-to-SQL tasks. The generation script and test set are released at\nhttps://github.com/mcxiaoxiao/QDA-SQL\n","authors":["Yinggang Sun","Ziming Guo","Haining Yu","Chuanyi Liu","Xiang Li","Bingxuan Wang","Xiangzhan Yu","Tiancheng Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.10593v2.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.06420v1","updated":"2024-11-10T10:49:13Z","published":"2024-11-10T10:49:13Z","title":"Generating Mixcode Popular Songs with Artificial Intelligence: Concepts,\n  Plans, and Speculations","summary":"  Music is a potent form of expression that can communicate, accentuate or even\ncreate the emotions of an individual or a collective. Both historically and in\ncontemporary experiences, musical expression was and is commonly\ninstrumentalized for social, political and/or economic purposes. Generative\nartificial intelligence provides a wealth of both opportunities and challenges\nwith regard to music and its role in society. This paper discusses a proposed\nproject integrating artificial intelligence and popular music, with the\nultimate goal of creating a powerful tool for implementing music for social\ntransformation, education, healthcare, and emotional well-being. Given that it\nis being presented at the outset of a collaboration between a computer\nscientist/data analyst and an ethnomusicologist/social anthropologist. it is\nmainly conceptual and somewhat speculative in nature.\n","authors":["Abhishek Kaushik","Kayla Rush"],"pdf_url":"https://arxiv.org/pdf/2411.06420v1.pdf","comment":"Link to the paper:https://aimc2024.pubpub.org/pub/rdulfbve/release/1\n  Published in The International Conference on AI and Musical Creativity at the\n  University of Oxford (2024) https://aimc2024.pubpub.org/"},{"id":"http://arxiv.org/abs/2410.13293v2","updated":"2024-11-10T08:53:38Z","published":"2024-10-17T07:46:49Z","title":"SBI-RAG: Enhancing Math Word Problem Solving for Students through\n  Schema-Based Instruction and Retrieval-Augmented Generation","summary":"  Many students struggle with math word problems (MWPs), often finding it\ndifficult to identify key information and select the appropriate mathematical\noperations. Schema-based instruction (SBI) is an evidence-based strategy that\nhelps students categorize problems based on their structure, improving\nproblem-solving accuracy. Building on this, we propose a Schema-Based\nInstruction Retrieval-Augmented Generation (SBI-RAG) framework that\nincorporates a large language model (LLM). Our approach emphasizes step-by-step\nreasoning by leveraging schemas to guide solution generation. We evaluate its\nperformance on the GSM8K dataset, comparing it with GPT-4 and GPT-3.5 Turbo,\nand introduce a \"reasoning score\" metric to assess solution quality. Our\nfindings suggest that SBI-RAG enhances reasoning clarity and facilitates a more\nstructured problem-solving process potentially providing educational benefits\nfor students.\n","authors":["Prakhar Dixit","Tim Oates"],"pdf_url":"https://arxiv.org/pdf/2410.13293v2.pdf","comment":"Accepted to the 4th MATH-AI Workshop at NeurIPS'24"},{"id":"http://arxiv.org/abs/2411.06374v1","updated":"2024-11-10T06:46:44Z","published":"2024-11-10T06:46:44Z","title":"Metric Learning for Tag Recommendation: Tackling Data Sparsity and Cold\n  Start Issues","summary":"  With the rapid growth of digital information, personalized recommendation\nsystems have become an indispensable part of Internet services, especially in\nthe fields of e-commerce, social media, and online entertainment. However,\ntraditional collaborative filtering and content-based recommendation methods\nhave limitations in dealing with data sparsity and cold start problems,\nespecially in the face of largescale heterogeneous data, which makes it\ndifficult to meet user expectations. This paper proposes a new label\nrecommendation algorithm based on metric learning, which aims to overcome the\nchallenges of traditional recommendation systems by learning effective distance\nor similarity metrics to capture the subtle differences between user\npreferences and item features. Experimental results show that the algorithm\noutperforms baseline methods including local response metric learning (LRML),\ncollaborative metric learning (CML), and adaptive tensor factorization (ATF)\nbased on adversarial learning on multiple evaluation metrics. In particular, it\nperforms particularly well in the accuracy of the first few recommended items,\nwhile maintaining high robustness and maintaining high recommendation accuracy.\n","authors":["Yuanshuai Luo","Rui Wang","Yaxin Liang","Ankai Liang","Wenyi Liu"],"pdf_url":"https://arxiv.org/pdf/2411.06374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18957v3","updated":"2024-11-10T03:45:30Z","published":"2024-09-27T17:58:50Z","title":"LML-DAP: Language Model Learning a Dataset for Data-Augmented Prediction","summary":"  Classification tasks are typically handled using Machine Learning (ML)\nmodels, which lack a balance between accuracy and interpretability. This paper\nintroduces a new approach for classification tasks using Large Language Models\n(LLMs) in an explainable method. Unlike ML models, which rely heavily on data\ncleaning and feature engineering, this method streamlines the process using\nLLMs. This paper proposes a method called \"Language Model Learning (LML)\"\npowered by a new method called \"Data-Augmented Prediction (DAP).\" The\nclassification is performed by LLMs using a method similar to that used by\nhumans who manually explore and understand the data to decide classifications.\nIn the process of LML, a dataset is summarized and evaluated to determine the\nfeatures leading to each label the most. In the DAP process, the system uses\nthe data summary and a row of the testing dataset to automatically generate a\nquery to retrieve relevant rows from the dataset for context-aware\nclassification. LML and DAP unlock new possibilities in areas that require\nexplainable and context-aware decisions by ensuring satisfactory accuracy even\nwith complex data. The system scored an accuracy above 90% in some test cases,\nconfirming the effectiveness and potential of the system to outperform ML\nmodels in various scenarios. The source code is available at\nhttps://github.com/Pro-GenAI/LML-DAP\n","authors":["Praneeth Vadlapati"],"pdf_url":"https://arxiv.org/pdf/2409.18957v3.pdf","comment":"Made the abstract and the content clearer"}]},"2024-11-09T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.15949v2","updated":"2024-11-09T23:29:30Z","published":"2024-10-21T12:30:44Z","title":"Findings of the Third Shared Task on Multilingual Coreference Resolution","summary":"  The paper presents an overview of the third edition of the shared task on\nmultilingual coreference resolution, held as part of the CRAC 2024 workshop.\nSimilarly to the previous two editions, the participants were challenged to\ndevelop systems capable of identifying mentions and clustering them based on\nidentity coreference.\n  This year's edition took another step towards real-world application by not\nproviding participants with gold slots for zero anaphora, increasing the task's\ncomplexity and realism. In addition, the shared task was expanded to include a\nmore diverse set of languages, with a particular focus on historical languages.\nThe training and evaluation data were drawn from version 1.2 of the\nmultilingual collection of harmonized coreference resources CorefUD,\nencompassing 21 datasets across 15 languages. 6 systems competed in this shared\ntask.\n","authors":["Michal Nov√°k","Barbora Dohnalov√°","Miloslav Konop√≠k","Anna Nedoluzhko","Martin Popel","Ond≈ôej Pra≈æ√°k","Jakub Sido","Milan Straka","Zdenƒõk ≈Ωabokrtsk√Ω","Daniel Zeman"],"pdf_url":"https://arxiv.org/pdf/2410.15949v2.pdf","comment":"Accepted to CRAC 2024"},{"id":"http://arxiv.org/abs/2410.02756v2","updated":"2024-11-09T23:24:14Z","published":"2024-10-03T17:58:55Z","title":"CorPipe at CRAC 2024: Predicting Zero Mentions from Raw Text","summary":"  We present CorPipe 24, the winning entry to the CRAC 2024 Shared Task on\nMultilingual Coreference Resolution. In this third iteration of the shared\ntask, a novel objective is to also predict empty nodes needed for zero\ncoreference mentions (while the empty nodes were given on input in previous\nyears). This way, coreference resolution can be performed on raw text. We\nevaluate two model variants: a~two-stage approach (where the empty nodes are\npredicted first using a pretrained encoder model and then processed together\nwith sentence words by another pretrained model) and a single-stage approach\n(where a single pretrained encoder model generates empty nodes, coreference\nmentions, and coreference links jointly). In both settings, CorPipe surpasses\nother participants by a large margin of 3.9 and 2.8 percent points,\nrespectively. The source code and the trained model are available at\nhttps://github.com/ufal/crac2024-corpipe.\n","authors":["Milan Straka"],"pdf_url":"https://arxiv.org/pdf/2410.02756v2.pdf","comment":"Accepted to CRAC 2024"},{"id":"http://arxiv.org/abs/2211.01430v2","updated":"2024-11-09T20:52:16Z","published":"2022-11-02T18:54:44Z","title":"Hierarchies over Vector Space: Orienting Word and Graph Embeddings","summary":"  Word and graph embeddings are widely used in deep learning applications. We\npresent a data structure that captures inherent hierarchical properties from an\nunordered flat embedding space, particularly a sense of direction between pairs\nof entities. Inspired by the notion of \\textit{distributional generality}, our\nalgorithm constructs an arborescence (a directed rooted tree) by inserting\nnodes in descending order of entity power (e.g., word frequency), pointing each\nentity to the closest more powerful node as its parent.\n  We evaluate the performance of the resulting tree structures on three tasks:\nhypernym relation discovery, least-common-ancestor (LCA) discovery among words,\nand Wikipedia page link recovery. We achieve average 8.98\\% and 2.70\\% for\nhypernym and LCA discovery across five languages and 62.76\\% accuracy on\ndirected Wiki-page link recovery, with both substantially above baselines.\nFinally, we investigate the effect of insertion order, the power/similarity\ntrade-off and various power sources to optimize parent selection.\n","authors":["Xingzhi Guo","Steven Skiena"],"pdf_url":"https://arxiv.org/pdf/2211.01430v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07202v2","updated":"2024-11-09T20:46:55Z","published":"2024-03-11T22:58:58Z","title":"SPAWNing Structural Priming Predictions from a Cognitively Motivated\n  Parser","summary":"  Structural priming is a widely used psycholinguistic paradigm to study human\nsentence representations. In this work we introduce SPAWN, a cognitively\nmotivated parser that can generate quantitative priming predictions from\ncontemporary theories in syntax which assume a lexicalized grammar. By\ngenerating and testing priming predictions from competing theoretical accounts,\nwe can infer which assumptions from syntactic theory are useful for\ncharacterizing the representations humans build when processing sentences. As a\ncase study, we use SPAWN to generate priming predictions from two theories\n(Whiz-Deletion and Participial-Phase) which make different assumptions about\nthe structure of English relative clauses. By modulating the reanalysis\nmechanism that the parser uses and strength of the parser's prior knowledge, we\ngenerated nine sets of predictions from each of the two theories. Then, we\ntested these predictions using a novel web-based comprehension-to-production\npriming paradigm. We found that while the some of the predictions from the\nParticipial-Phase theory aligned with human behavior, none of the predictions\nfrom the the Whiz-Deletion theory did, thus suggesting that the\nParticipial-Phase theory might better characterize human relative clause\nrepresentations.\n","authors":["Grusha Prasad","Tal Linzen"],"pdf_url":"https://arxiv.org/pdf/2403.07202v2.pdf","comment":"In Proceedings of CoNLL 2024"},{"id":"http://arxiv.org/abs/2411.06272v1","updated":"2024-11-09T20:09:11Z","published":"2024-11-09T20:09:11Z","title":"Golden Touchstone: A Comprehensive Bilingual Benchmark for Evaluating\n  Financial Large Language Models","summary":"  As large language models become increasingly prevalent in the financial\nsector, there is a pressing need for a standardized method to comprehensively\nassess their performance. However, existing finance benchmarks often suffer\nfrom limited language and task coverage, as well as challenges such as\nlow-quality datasets and inadequate adaptability for LLM evaluation. To address\nthese limitations, we propose \"Golden Touchstone\", the first comprehensive\nbilingual benchmark for financial LLMs, which incorporates representative\ndatasets from both Chinese and English across eight core financial NLP tasks.\nDeveloped from extensive open source data collection and industry-specific\ndemands, this benchmark includes a variety of financial tasks aimed at\nthoroughly assessing models' language understanding and generation\ncapabilities. Through comparative analysis of major models on the benchmark,\nsuch as GPT-4o Llama3, FinGPT and FinMA, we reveal their strengths and\nlimitations in processing complex financial information. Additionally, we\nopen-sourced Touchstone-GPT, a financial LLM trained through continual\npre-training and financial instruction tuning, which demonstrates strong\nperformance on the bilingual benchmark but still has limitations in specific\ntasks.This research not only provides the financial large language models with\na practical evaluation tool but also guides the development and optimization of\nfuture research. The source code for Golden Touchstone and model weight of\nTouchstone-GPT have been made publicly available at\n\\url{https://github.com/IDEA-FinAI/Golden-Touchstone}, contributing to the\nongoing evolution of FinLLMs and fostering further research in this critical\narea.\n","authors":["Xiaojun Wu","Junxi Liu","Huanyi Su","Zhouchi Lin","Yiyan Qi","Chengjin Xu","Jiajun Su","Jiajie Zhong","Fuwei Wang","Saizhuo Wang","Fengrui Hua","Jia Li","Jian Guo"],"pdf_url":"https://arxiv.org/pdf/2411.06272v1.pdf","comment":"26 pages, 9 tables, 3 figures"},{"id":"http://arxiv.org/abs/2410.02675v2","updated":"2024-11-09T19:07:44Z","published":"2024-10-03T17:02:21Z","title":"FAN: Fourier Analysis Networks","summary":"  Despite the remarkable success achieved by neural networks, particularly\nthose represented by MLP and Transformer, we reveal that they exhibit potential\nflaws in the modeling and reasoning of periodicity, i.e., they tend to memorize\nthe periodic data rather than genuinely understanding the underlying principles\nof periodicity. However, periodicity is a crucial trait in various forms of\nreasoning and generalization, underpinning predictability across natural and\nengineered systems through recurring patterns in observations. In this paper,\nwe propose FAN, a novel network architecture based on Fourier Analysis, which\nempowers the ability to efficiently model and reason about periodic phenomena.\nBy introducing Fourier Series, the periodicity is naturally integrated into the\nstructure and computational processes of the neural network, thus achieving a\nmore accurate expression and prediction of periodic patterns. As a promising\nsubstitute to multi-layer perceptron (MLP), FAN can seamlessly replace MLP in\nvarious models with fewer parameters and FLOPs. Through extensive experiments,\nwe demonstrate the effectiveness of FAN in modeling and reasoning about\nperiodic functions, and the superiority and generalizability of FAN across a\nrange of real-world tasks, including symbolic formula representation, time\nseries forecasting, and language modeling.\n","authors":["Yihong Dong","Ge Li","Yongding Tao","Xue Jiang","Kechi Zhang","Jia Li","Jing Su","Jun Zhang","Jingjing Xu"],"pdf_url":"https://arxiv.org/pdf/2410.02675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10978v2","updated":"2024-11-09T18:46:07Z","published":"2024-03-16T17:21:58Z","title":"Lambda: Learning Matchable Prior For Entity Alignment with Unlabeled\n  Dangling Cases","summary":"  We investigate the entity alignment (EA) problem with unlabeled dangling\ncases, meaning that partial entities have no counterparts in the other\nknowledge graph (KG), and this type of entity remains unlabeled. To address\nthis challenge, we propose the framework \\textit{Lambda} for dangling detection\nand then entity alignment. Lambda features a GNN-based encoder called KEESA\nwith spectral contrastive learning for EA and a positive-unlabeled learning\nalgorithm for dangling detection called iPULE. iPULE offers theoretical\nguarantees of unbiasedness, uniform deviation bounds, and convergence.\nExperimental results demonstrate that each component contributes to overall\nperformances that are superior to baselines, even when baselines additionally\nexploit 30\\% of dangling entities labeled for training.\n","authors":["Hang Yin","Liyao Xiang","Dong Ding","Yuheng He","Yihan Wu","Xinbing Wang","Chenghu Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.10978v2.pdf","comment":"Accepted in NeurIPS 2024 as a poster"},{"id":"http://arxiv.org/abs/2411.06248v1","updated":"2024-11-09T18:27:15Z","published":"2024-11-09T18:27:15Z","title":"Robust Detection of LLM-Generated Text: A Comparative Analysis","summary":"  The ability of large language models to generate complex texts allows them to\nbe widely integrated into many aspects of life, and their output can quickly\nfill all network resources. As the impact of LLMs grows, it becomes\nincreasingly important to develop powerful detectors for the generated text.\nThis detector is essential to prevent the potential misuse of these\ntechnologies and to protect areas such as social media from the negative\neffects of false content generated by LLMS. The main goal of LLM-generated text\ndetection is to determine whether text is generated by an LLM, which is a basic\nbinary classification task. In our work, we mainly use three different\nclassification methods based on open source datasets: traditional machine\nlearning techniques such as logistic regression, k-means clustering, Gaussian\nNaive Bayes, support vector machines, and methods based on converters such as\nBERT, and finally algorithms that use LLMs to detect LLM-generated text. We\nfocus on model generalization, potential adversarial attacks, and accuracy of\nmodel evaluation. Finally, the possible research direction in the future is\nproposed, and the current experimental results are summarized.\n","authors":["Yongye Su","Yuqing Wu"],"pdf_url":"https://arxiv.org/pdf/2411.06248v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2410.15153v3","updated":"2024-11-09T18:17:30Z","published":"2024-10-19T16:40:08Z","title":"Evaluating Deep Unlearning in Large Language Models","summary":"  Machine unlearning is a key requirement of many data protection regulations\nsuch as GDPR. Prior work on unlearning has mostly considered superficial\nunlearning tasks where a single or a few related pieces of information are\nrequired to be removed. However, the task of unlearning a fact is much more\nchallenging in recent large language models (LLMs), because the facts in LLMs\ncan be deduced from each other. In this work, we investigate whether current\nunlearning methods for LLMs succeed beyond superficial unlearning of facts.\nSpecifically, we formally propose a framework and a definition for deep\nunlearning facts that are interrelated. We design the metric, recall, to\nquantify the extent of deep unlearning. To systematically evaluate deep\nunlearning, we construct a synthetic dataset EDU-RELAT, which consists of a\nsynthetic knowledge base of family relationships and biographies, together with\na realistic logical rule set that connects them. We use this dataset to test\nfour unlearning methods in four LLMs at different sizes. Our findings reveal\nthat in the task of deep unlearning only a single fact, they either fail to\nproperly unlearn with high recall, or end up unlearning many other irrelevant\nfacts. Our dataset and code are publicly available at:\nhttps://github.com/wrh14/deep_unlearning.\n","authors":["Ruihan Wu","Chhavi Yadav","Russ Salakhutdinov","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2410.15153v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04905v2","updated":"2024-11-09T17:33:51Z","published":"2024-11-07T17:47:25Z","title":"OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models","summary":"  Large language models (LLMs) for code have become indispensable in various\ndomains, including code generation, reasoning tasks and agent systems. While\nopen-access code LLMs are increasingly approaching the performance levels of\nproprietary models, high-quality code LLMs suitable for rigorous scientific\ninvestigation, particularly those with reproducible data processing pipelines\nand transparent training protocols, remain limited. The scarcity is due to\nvarious challenges, including resource constraints, ethical considerations, and\nthe competitive advantages of keeping models advanced. To address the gap, we\nintroduce OpenCoder, a top-tier code LLM that not only achieves performance\ncomparable to leading models but also serves as an \"open cookbook\" for the\nresearch community. Unlike most prior efforts, we release not only model\nweights and inference code, but also the reproducible training data, complete\ndata processing pipeline, rigorous experimental ablation results, and detailed\ntraining protocols for open scientific research. Through this comprehensive\nrelease, we identify the key ingredients for building a top-tier code LLM: (1)\ncode optimized heuristic rules for data cleaning and methods for data\ndeduplication, (2) recall of text corpus related to code and (3) high-quality\nsynthetic data in both annealing and supervised fine-tuning stages. By offering\nthis level of openness, we aim to broaden access to all aspects of a top-tier\ncode LLM, with OpenCoder serving as both a powerful model and an open\nfoundation to accelerate research, and enable reproducible advancements in code\nAI.\n","authors":["Siming Huang","Tianhao Cheng","J. K. Liu","Jiaran Hao","Liuyihan Song","Yang Xu","J. Yang","J. H. Liu","Chenchen Zhang","Linzheng Chai","Ruifeng Yuan","Zhaoxiang Zhang","Jie Fu","Qian Liu","Ge Zhang","Zili Wang","Yuan Qi","Yinghui Xu","Wei Chu"],"pdf_url":"https://arxiv.org/pdf/2411.04905v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06228v1","updated":"2024-11-09T16:17:14Z","published":"2024-11-09T16:17:14Z","title":"An $\\mathbf{L^*}$ Algorithm for Deterministic Weighted Regular Languages","summary":"  Extracting finite state automata (FSAs) from black-box models offers a\npowerful approach to gaining interpretable insights into complex model\nbehaviors. To support this pursuit, we present a weighted variant of Angluin's\n(1987) $\\mathbf{L^*}$ algorithm for learning FSAs. We stay faithful to the\noriginal algorithm, devising a way to exactly learn deterministic weighted FSAs\nwhose weights support division. Furthermore, we formulate the learning process\nin a manner that highlights the connection with FSA minimization, showing how\n$\\mathbf{L^*}$ directly learns a minimal automaton for the target language.\n","authors":["Clemente Pasti","Talu Karag√∂z","Anej Svete","Franz Nowak","Reda Boumasmoud","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.06228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06213v1","updated":"2024-11-09T15:29:04Z","published":"2024-11-09T15:29:04Z","title":"Incorporating Human Explanations for Robust Hate Speech Detection","summary":"  Given the black-box nature and complexity of large transformer language\nmodels (LM), concerns about generalizability and robustness present ethical\nimplications for domains such as hate speech (HS) detection. Using the content\nrich Social Bias Frames dataset, containing human-annotated stereotypes,\nintent, and targeted groups, we develop a three stage analysis to evaluate if\nLMs faithfully assess hate speech. First, we observe the need for modeling\ncontextually grounded stereotype intents to capture implicit semantic meaning.\nNext, we design a new task, Stereotype Intent Entailment (SIE), which\nencourages a model to contextually understand stereotype presence. Finally,\nthrough ablation tests and user studies, we find a SIE objective improves\ncontent understanding, but challenges remain in modeling implicit intent.\n","authors":["Jennifer L. Chen","Faisal Ladhak","Daniel Li","No√©mie Elhadad"],"pdf_url":"https://arxiv.org/pdf/2411.06213v1.pdf","comment":"2021 ACL Unimplicit Workshop"},{"id":"http://arxiv.org/abs/2411.06208v1","updated":"2024-11-09T15:12:43Z","published":"2024-11-09T15:12:43Z","title":"IOPO: Empowering LLMs with Complex Instruction Following via\n  Input-Output Preference Optimization","summary":"  In the realm of large language models (LLMs), the ability of models to\naccurately follow instructions is paramount as more agents and applications\nleverage LLMs for construction, where the complexity of instructions are\nrapidly increasing. However, on the one hand, there is only a certain amount of\ncomplex instruction evaluation data; on the other hand, there are no dedicated\nalgorithms to improve the ability to follow complex instructions. To this end,\nthis paper introduces TRACE, a benchmark for improving and evaluating the\ncomplex instructionfollowing ability, which consists of 120K training data and\n1K evaluation data. Furthermore, we propose IOPO (Input-Output Preference\nOptimization) alignment method which takes both input and output preference\npairs into consideration, where LLMs not only rapidly align with response\npreferences but also meticulously explore the instruction preferences.\nExtensive experiments on both in-domain and outof-domain datasets confirm the\neffectiveness of IOPO, showing 8.15%, 2.18% improvements on in-domain data and\n6.29%, 3.13% on outof-domain data compared to SFT and DPO respectively.\n","authors":["Xinghua Zhang","Haiyang Yu","Cheng Fu","Fei Huang","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2411.06208v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2411.06207v1","updated":"2024-11-09T15:12:28Z","published":"2024-11-09T15:12:28Z","title":"Exploring Knowledge Boundaries in Large Language Models for Retrieval\n  Judgment","summary":"  Large Language Models (LLMs) are increasingly recognized for their practical\napplications. However, these models often encounter challenges in dynamically\nchanging knowledge, as well as in managing unknown static knowledge.\nRetrieval-Augmented Generation (RAG) tackles this challenge and has shown a\nsignificant impact on LLMs. Actually, we find that the impact of RAG on the\nquestion answering capabilities of LLMs can be categorized into three groups:\nbeneficial, neutral, and harmful. By minimizing retrieval requests that yield\nneutral or harmful results, we can effectively reduce both time and\ncomputational costs, while also improving the overall performance of LLMs. This\ninsight motivates us to differentiate between types of questions using certain\nmetrics as indicators, to decrease the retrieval ratio without compromising\nperformance. In our work, we propose a method that is able to identify\ndifferent types of questions from this view by training a Knowledge Boundary\nModel (KBM). Experiments conducted on 11 English and Chinese datasets\nillustrate that the KBM effectively delineates the knowledge boundary,\nsignificantly decreasing the proportion of retrievals required for optimal\nend-to-end performance. Specifically, we evaluate the effectiveness of KBM in\nthree complex scenarios: dynamic knowledge, long-tail static knowledge, and\nmulti-hop problems, as well as its functionality as an external LLM plug-in.\n","authors":["Zhen Zhang","Xinyu Wang","Yong Jiang","Zhuo Chen","Feiteng Mu","Mengting Hu","Pengjun Xie","Fei Huang"],"pdf_url":"https://arxiv.org/pdf/2411.06207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06194v1","updated":"2024-11-09T14:30:58Z","published":"2024-11-09T14:30:58Z","title":"WMT24 Test Suite: Gender Resolution in Speaker-Listener Dialogue Roles","summary":"  We assess the difficulty of gender resolution in literary-style dialogue\nsettings and the influence of gender stereotypes. Instances of the test suite\ncontain spoken dialogue interleaved with external meta-context about the\ncharacters and the manner of speaking. We find that character and manner\nstereotypes outside of the dialogue significantly impact the gender agreement\nof referents within the dialogue.\n","authors":["Hillary Dawkins","Isar Nejadgholi","Chi-kiu Lo"],"pdf_url":"https://arxiv.org/pdf/2411.06194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08803v4","updated":"2024-11-09T13:52:50Z","published":"2023-11-15T09:18:09Z","title":"StrategyLLM: Large Language Models as Strategy Generators, Executors,\n  Optimizers, and Evaluators for Problem Solving","summary":"  Most existing prompting methods suffer from the issues of generalizability\nand consistency, as they often rely on instance-specific solutions that may not\nbe applicable to other instances and lack task-level consistency across the\nselected few-shot examples. To address these limitations, we propose a\ncomprehensive framework, StrategyLLM, allowing LLMs to perform inductive\nreasoning, deriving general strategies from specific task instances, and\ndeductive reasoning, applying these general strategies to particular task\nexamples, for constructing generalizable and consistent few-shot prompts. It\nemploys four LLM-based agents: strategy generator, executor, optimizer, and\nevaluator, working together to generate, evaluate, and select promising\nstrategies for a given task. Experimental results demonstrate that StrategyLLM\noutperforms the competitive baseline CoT-SC that requires human-annotated\nsolutions on 13 datasets across 4 challenging tasks without human involvement,\nincluding math reasoning (34.2\\% $\\rightarrow$ 38.8\\%), commonsense reasoning\n(70.3\\% $\\rightarrow$ 72.5\\%), algorithmic reasoning (73.7\\% $\\rightarrow$\n85.0\\%), and symbolic reasoning (30.0\\% $\\rightarrow$ 79.2\\%). Further analysis\nreveals that StrategyLLM is applicable to various LLMs and demonstrates\nadvantages across numerous scenarios.\n","authors":["Chang Gao","Haiyun Jiang","Deng Cai","Shuming Shi","Wai Lam"],"pdf_url":"https://arxiv.org/pdf/2311.08803v4.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.06176v1","updated":"2024-11-09T13:30:38Z","published":"2024-11-09T13:30:38Z","title":"M-Longdoc: A Benchmark For Multimodal Super-Long Document Understanding\n  And A Retrieval-Aware Tuning Framework","summary":"  The ability to understand and answer questions over documents can be useful\nin many business and practical applications. However, documents often contain\nlengthy and diverse multimodal contents such as texts, figures, and tables,\nwhich are very time-consuming for humans to read thoroughly. Hence, there is an\nurgent need to develop effective and automated methods to aid humans in this\ntask. In this work, we introduce M-LongDoc, a benchmark of 851 samples, and an\nautomated framework to evaluate the performance of large multimodal models. We\nfurther propose a retrieval-aware tuning approach for efficient and effective\nmultimodal document reading. Compared to existing works, our benchmark consists\nof more recent and lengthy documents with hundreds of pages, while also\nrequiring open-ended solutions and not just extractive answers. To our\nknowledge, our training framework is the first to directly address the\nretrieval setting for multimodal long documents. To enable tuning open-source\nmodels, we construct a training corpus in a fully automatic manner for the\nquestion-answering task over such documents. Experiments show that our tuning\napproach achieves a relative improvement of 4.6% for the correctness of model\nresponses, compared to the baseline open-source models. Our data, code, and\nmodels are available at https://multimodal-documents.github.io.\n","authors":["Yew Ken Chia","Liying Cheng","Hou Pong Chan","Chaoqun Liu","Maojia Song","Sharifah Mahani Aljunied","Soujanya Poria","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2411.06176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06175v1","updated":"2024-11-09T13:17:39Z","published":"2024-11-09T13:17:39Z","title":"Clustering Algorithms and RAG Enhancing Semi-Supervised Text\n  Classification with Large LLMs","summary":"  This paper introduces an innovative semi-supervised learning approach for\ntext classification, addressing the challenge of abundant data but limited\nlabeled examples. Our methodology integrates few-shot learning with\nretrieval-augmented generation (RAG) and conventional statistical clustering,\nenabling effective learning from a minimal number of labeled instances while\ngenerating high-quality labeled data. To the best of our knowledge, we are the\nfirst to incorporate RAG alongside clustering in text data generation. Our\nexperiments on the Reuters and Web of Science datasets demonstrate\nstate-of-the-art performance, with few-shot augmented data alone producing\nresults nearly equivalent to those achieved with fully labeled datasets.\nNotably, accuracies of 95.41\\% and 82.43\\% were achieved for complex text\ndocument classification tasks, where the number of categories can exceed 100.\n","authors":["Shan Zhong","Jiahao Zeng","Yongxin Yu","Bohong Lin"],"pdf_url":"https://arxiv.org/pdf/2411.06175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09248v2","updated":"2024-11-09T13:07:39Z","published":"2024-01-17T14:52:26Z","title":"Learning from Implicit User Feedback, Emotions and Demographic\n  Information in Task-Oriented and Document-Grounded Dialogues","summary":"  Implicit user feedback, user emotions and demographic information have shown\nto be promising sources for improving the accuracy and user engagement of\nresponses generated by dialogue systems. However, the influence of such\ninformation on task completion and factual consistency, which are important\ncriteria for task-oriented and document-grounded dialogues, is not yet known.\nTo address this, we introduce FEDI, the first English task-oriented and\ndocument-grounded dialogue dataset annotated with this information. Our\nexperiments with Flan-T5, GPT-2 and Llama 2 show a particularly positive impact\non task completion and factual consistency. Participants in our human\nevaluation reported that the responses generated by the feedback-trained models\nwere more informative (Flan-T5 and GPT-2), relevant and factual consistent\n(Llama 2).\n","authors":["Dominic Petrak","Thy Thy Tran","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2401.09248v2.pdf","comment":"Accepted and published in EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2411.06171v1","updated":"2024-11-09T13:02:36Z","published":"2024-11-09T13:02:36Z","title":"SEEKR: Selective Attention-Guided Knowledge Retention for Continual\n  Learning of Large Language Models","summary":"  Continual learning (CL) is crucial for language models to dynamically adapt\nto the evolving real-world demands. To mitigate the catastrophic forgetting\nproblem in CL, data replay has been proven a simple and effective strategy, and\nthe subsequent data-replay-based distillation can further enhance the\nperformance. However, existing methods fail to fully exploit the knowledge\nembedded in models from previous tasks, resulting in the need for a relatively\nlarge number of replay samples to achieve good results. In this work, we first\nexplore and emphasize the importance of attention weights in knowledge\nretention, and then propose a SElective attEntion-guided Knowledge Retention\nmethod (SEEKR) for data-efficient replay-based continual learning of large\nlanguage models (LLMs). Specifically, SEEKR performs attention distillation on\nthe selected attention heads for finer-grained knowledge retention, where the\nproposed forgettability-based and task-sensitivity-based measures are used to\nidentify the most valuable attention heads. Experimental results on two\ncontinual learning benchmarks for LLMs demonstrate the superiority of SEEKR\nover the existing methods on both performance and efficiency. Explicitly, SEEKR\nachieves comparable or even better performance with only 1/10 of the replayed\ndata used by other methods, and reduces the proportion of replayed data to 1%.\n","authors":["Jinghan He","Haiyun Guo","Kuan Zhu","Zihan Zhao","Ming Tang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2411.06171v1.pdf","comment":"EMNLP2024"},{"id":"http://arxiv.org/abs/2411.04421v2","updated":"2024-11-09T12:30:06Z","published":"2024-11-07T04:17:30Z","title":"Variational Low-Rank Adaptation Using IVON","summary":"  We show that variational learning can significantly improve the accuracy and\ncalibration of Low-Rank Adaptation (LoRA) without a substantial increase in the\ncost. We replace AdamW by the Improved Variational Online Newton (IVON)\nalgorithm to finetune large language models. For Llama-2 with 7 billion\nparameters, IVON improves the accuracy over AdamW by 2.8% and expected\ncalibration error by 4.6%. The accuracy is also better than the other Bayesian\nalternatives, yet the cost is lower and the implementation is easier. Our work\nprovides additional evidence for the effectiveness of IVON for large language\nmodels. The code is available at\nhttps://github.com/team-approx-bayes/ivon-lora.\n","authors":["Bai Cong","Nico Daheim","Yuesong Shen","Daniel Cremers","Rio Yokota","Mohammad Emtiyaz Khan","Thomas M√∂llenhoff"],"pdf_url":"https://arxiv.org/pdf/2411.04421v2.pdf","comment":"Published at 38th Workshop on Fine-Tuning in Machine Learning\n  (NeurIPS 2024). Code available at\n  https://github.com/team-approx-bayes/ivon-lora. In version 2 we fixed a typo\n  in the equation of prior in section 2"},{"id":"http://arxiv.org/abs/2411.01493v2","updated":"2024-11-09T12:22:19Z","published":"2024-11-03T09:18:28Z","title":"Sample-Efficient Alignment for LLMs","summary":"  We study methods for efficiently aligning large language models (LLMs) with\nhuman preferences given budgeted online feedback. We first formulate the LLM\nalignment problem in the frame of contextual dueling bandits. This formulation,\nsubsuming recent paradigms such as online RLHF and online DPO, inherently\nquests for sample-efficient algorithms that incorporate online active\nexploration. Leveraging insights from bandit theory, we introduce a unified\nalgorithm based on Thompson sampling and highlight its applications in two\ndistinct LLM alignment scenarios. The practical agent that efficiently\nimplements this algorithm, named SEA (Sample-Efficient Alignment), is\nempirically validated through extensive experiments across three model scales\n(1B, 2.8B, 6.9B) and three preference learning algorithms (DPO, IPO, SLiC). The\nresults demonstrate that SEA achieves highly sample-efficient alignment with\noracle's preferences, outperforming recent active exploration methods for LLMs.\nAdditionally, we release the implementation of SEA together with an efficient\ncodebase designed for online alignment of LLMs, aiming to accelerate future\nresearch in this field.\n","authors":["Zichen Liu","Changyu Chen","Chao Du","Wee Sun Lee","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2411.01493v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06160v1","updated":"2024-11-09T12:09:26Z","published":"2024-11-09T12:09:26Z","title":"Expansion Quantization Network: An Efficient Micro-emotion Annotation\n  and Detection Framework","summary":"  Text emotion detection constitutes a crucial foundation for advancing\nartificial intelligence from basic comprehension to the exploration of\nemotional reasoning. Most existing emotion detection datasets rely on manual\nannotations, which are associated with high costs, substantial subjectivity,\nand severe label imbalances. This is particularly evident in the inadequate\nannotation of micro-emotions and the absence of emotional intensity\nrepresentation, which fail to capture the rich emotions embedded in sentences\nand adversely affect the quality of downstream task completion. By proposing an\nall-labels and training-set label regression method, we map label values to\nenergy intensity levels, thereby fully leveraging the learning capabilities of\nmachine models and the interdependencies among labels to uncover multiple\nemotions within samples. This led to the establishment of the Emotion\nQuantization Network (EQN) framework for micro-emotion detection and\nannotation. Using five commonly employed sentiment datasets, we conducted\ncomparative experiments with various models, validating the broad applicability\nof our framework within NLP machine learning models. Based on the EQN\nframework, emotion detection and annotation are conducted on the GoEmotions\ndataset. A comprehensive comparison with the results from Google literature\ndemonstrates that the EQN framework possesses a high capability for automatic\ndetection and annotation of micro-emotions. The EQN framework is the first to\nachieve automatic micro-emotion annotation with energy-level scores, providing\nstrong support for further emotion detection analysis and the quantitative\nresearch of emotion computing.\n","authors":["Jingyi Zhou","Senlin Luo","Haofan Chen"],"pdf_url":"https://arxiv.org/pdf/2411.06160v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06159v1","updated":"2024-11-09T12:06:40Z","published":"2024-11-09T12:06:40Z","title":"From References to Insights: Collaborative Knowledge Minigraph Agents\n  for Automating Scholarly Literature Review","summary":"  Literature reviews play a crucial role in scientific research for\nunderstanding the current state of research, identifying gaps, and guiding\nfuture studies on specific topics. However, the process of conducting a\ncomprehensive literature review is yet time-consuming. This paper proposes a\nnovel framework, collaborative knowledge minigraph agents (CKMAs), to automate\nscholarly literature reviews. A novel prompt-based algorithm, the knowledge\nminigraph construction agent (KMCA), is designed to identify relationships\nbetween information pieces from academic literature and automatically\nconstructs knowledge minigraphs. By leveraging the capabilities of large\nlanguage models on constructed knowledge minigraphs, the multiple path\nsummarization agent (MPSA) efficiently organizes information pieces and\nrelationships from different viewpoints to generate literature review\nparagraphs. We evaluate CKMAs on three benchmark datasets. Experimental results\ndemonstrate that the proposed techniques generate informative, complete,\nconsistent, and insightful summaries for different research problems, promoting\nthe use of LLMs in more professional fields.\n","authors":["Zhi Zhang","Yan Liu","Sheng-hua Zhong","Gong Chen","Yu Yang","Jiannong Cao"],"pdf_url":"https://arxiv.org/pdf/2411.06159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06151v1","updated":"2024-11-09T11:37:18Z","published":"2024-11-09T11:37:18Z","title":"Building an Efficient Multilingual Non-Profit IR System for the Islamic\n  Domain Leveraging Multiprocessing Design in Rust","summary":"  The widespread use of large language models (LLMs) has dramatically improved\nmany applications of Natural Language Processing (NLP), including Information\nRetrieval (IR). However, domains that are not driven by commercial interest\noften lag behind in benefiting from AI-powered solutions. One such area is\nreligious and heritage corpora. Alongside similar domains, Islamic literature\nholds significant cultural value and is regularly utilized by scholars and the\ngeneral public. Navigating this extensive amount of text is challenging, and\nthere is currently no unified resource that allows for easy searching of this\ndata using advanced AI tools. This work focuses on the development of a\nmultilingual non-profit IR system for the Islamic domain. This process brings a\nfew major challenges, such as preparing multilingual domain-specific corpora\nwhen data is limited in certain languages, deploying a model on\nresource-constrained devices, and enabling fast search on a limited budget. By\nemploying methods like continued pre-training for domain adaptation and\nlanguage reduction to decrease model size, a lightweight multilingual retrieval\nmodel was prepared, demonstrating superior performance compared to larger\nmodels pre-trained on general domain data. Furthermore, evaluating the proposed\narchitecture that utilizes Rust Language capabilities shows the possibility of\nimplementing efficient semantic search in a low-resource setting.\n","authors":["Vera Pavlova","Mohammed Makhlouf"],"pdf_url":"https://arxiv.org/pdf/2411.06151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06138v1","updated":"2024-11-09T10:23:22Z","published":"2024-11-09T10:23:22Z","title":"StopHC: A Harmful Content Detection and Mitigation Architecture for\n  Social Media Platforms","summary":"  The mental health of social media users has started more and more to be put\nat risk by harmful, hateful, and offensive content. In this paper, we propose\n\\textsc{StopHC}, a harmful content detection and mitigation architecture for\nsocial media platforms. Our aim with \\textsc{StopHC} is to create more secure\nonline environments. Our solution contains two modules, one that employs deep\nneural network architecture for harmful content detection, and one that uses a\nnetwork immunization algorithm to block toxic nodes and stop the spread of\nharmful content. The efficacy of our solution is demonstrated by experiments\nconducted on two real-world datasets.\n","authors":["Ciprian-Octavian TruicƒÉ","Ana-Teodora Constantinescu","Elena-Simona Apostol"],"pdf_url":"https://arxiv.org/pdf/2411.06138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05817v3","updated":"2024-11-09T10:19:02Z","published":"2024-10-08T08:47:11Z","title":"Probing Language Models on Their Knowledge Source","summary":"  Large Language Models (LLMs) often encounter conflicts between their learned,\ninternal (parametric knowledge, PK) and external knowledge provided during\ninference (contextual knowledge, CK). Understanding how LLMs models prioritize\none knowledge source over the other remains a challenge. In this paper, we\npropose a novel probing framework to explore the mechanisms governing the\nselection between PK and CK in LLMs. Using controlled prompts designed to\ncontradict the model's PK, we demonstrate that specific model activations are\nindicative of the knowledge source employed. We evaluate this framework on\nvarious LLMs of different sizes and demonstrate that mid-layer activations,\nparticularly those related to relations in the input, are crucial in predicting\nknowledge source selection, paving the way for more reliable models capable of\nhandling knowledge conflicts effectively.\n","authors":["Zineddine Tighidet","Andrea Mogini","Jiali Mei","Benjamin Piwowarski","Patrick Gallinari"],"pdf_url":"https://arxiv.org/pdf/2410.05817v3.pdf","comment":"Accepted at BlackBoxNLP@EMNLP2024"},{"id":"http://arxiv.org/abs/2410.05915v2","updated":"2024-11-09T08:32:47Z","published":"2024-10-08T11:09:31Z","title":"Give me a hint: Can LLMs take a hint to solve math problems?","summary":"  While state-of-the-art LLMs have shown poor logical and basic mathematical\nreasoning, recent works try to improve their problem-solving abilities using\nprompting techniques. We propose giving \"hints\" to improve the language model's\nperformance on advanced mathematical problems, taking inspiration from how\nhumans approach math pedagogically. We also test robustness to adversarial\nhints and demonstrate their sensitivity to them. We demonstrate the\neffectiveness of our approach by evaluating various diverse LLMs, presenting\nthem with a broad set of problems of different difficulties and topics from the\nMATH dataset and comparing against techniques such as one-shot, few-shot, and\nchain of thought prompting.\n","authors":["Vansh Agrawal","Pratham Singla","Amitoj Singh Miglani","Shivank Garg","Ayush Mangal"],"pdf_url":"https://arxiv.org/pdf/2410.05915v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06101v1","updated":"2024-11-09T07:30:38Z","published":"2024-11-09T07:30:38Z","title":"Detecting Reference Errors in Scientific Literature with Large Language\n  Models","summary":"  Reference errors, such as citation and quotation errors, are common in\nscientific papers. Such errors can result in the propagation of inaccurate\ninformation, but are difficult and time-consuming to detect, posing a\nsignificant challenge to scientific publishing. To support automatic detection\nof reference errors, this work evaluated the ability of large language models\nin OpenAI's GPT family to detect quotation errors. Specifically, we prepared an\nexpert-annotated, general-domain dataset of statement-reference pairs from\njournal articles. Large language models were evaluated in different settings\nwith varying amounts of reference information provided by retrieval\naugmentation. Our results showed that large language models are able to detect\nerroneous citations with limited context and without fine-tuning. This study\ncontributes to the growing literature that seeks to utilize artificial\nintelligence to assist in the writing, reviewing, and publishing of scientific\npapers. Potential avenues for further improvements in this task are also\ndiscussed.\n","authors":["Tianmai M. Zhang","Neil F. Abernethy"],"pdf_url":"https://arxiv.org/pdf/2411.06101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16686v2","updated":"2024-11-09T07:23:42Z","published":"2024-09-25T07:21:51Z","title":"MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for\n  Superior Planning and Decision-Making","summary":"  Long-term memory is significant for agents, in which insights play a crucial\nrole. However, the emergence of irrelevant insight and the lack of general\ninsight can greatly undermine the effectiveness of insight. To solve this\nproblem, in this paper, we introduce Multi-Scale Insight Agent (MSI-Agent), an\nembodied agent designed to improve LLMs' planning and decision-making ability\nby summarizing and utilizing insight effectively across different scales. MSI\nachieves this through the experience selector, insight generator, and insight\nselector. Leveraging a three-part pipeline, MSI can generate task-specific and\nhigh-level insight, store it in a database, and then use relevant insight from\nit to aid in decision-making. Our experiments show that MSI outperforms another\ninsight strategy when planning by GPT3.5. Moreover, We delve into the\nstrategies for selecting seed experience and insight, aiming to provide LLM\nwith more useful and relevant insight for better decision-making. Our\nobservations also indicate that MSI exhibits better robustness when facing\ndomain-shifting scenarios.\n","authors":["Dayuan Fu","Biqing Qi","Yihuai Gao","Che Jiang","Guanting Dong","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.16686v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06096v1","updated":"2024-11-09T07:16:08Z","published":"2024-11-09T07:16:08Z","title":"ZhoBLiMP: a Systematic Assessment of Language Models with Linguistic\n  Minimal Pairs in Chinese","summary":"  Whether and how language models (LMs) acquire the syntax of natural languages\nhas been widely evaluated under the minimal pair paradigm. However, a lack of\nwide-coverage benchmarks in languages other than English has constrained\nsystematic investigations into the issue. Addressing it, we first introduce\nZhoBLiMP, the most comprehensive benchmark of linguistic minimal pairs for\nChinese to date, with 118 paradigms, covering 15 linguistic phenomena. We then\ntrain 20 LMs of different sizes (14M to 1.4B) on Chinese corpora of various\nvolumes (100M to 3B tokens) and evaluate them along with 14 off-the-shelf LLMs\non ZhoBLiMP. The overall results indicate that Chinese grammar can be mostly\nlearned by models with around 500M parameters, trained on 1B tokens with one\nepoch, showing limited benefits for further scaling. Most (N=95) linguistic\nparadigms are of easy or medium difficulty for LMs, while there are still 13\nparadigms that remain challenging even for models with up to 32B parameters. In\nregard to how LMs acquire Chinese grammar, we observe a U-shaped learning\npattern in several phenomena, similar to those observed in child language\nacquisition.\n","authors":["Yikang Liu","Yeting Shen","Hongao Zhu","Lilong Xu","Zhiheng Qian","Siyuan Song","Kejia Zhang","Jialong Tang","Pei Zhang","Baosong Yang","Rui Wang","Hai Hu"],"pdf_url":"https://arxiv.org/pdf/2411.06096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.17443v3","updated":"2024-11-09T06:46:41Z","published":"2024-08-30T17:52:55Z","title":"HERMES: temporal-coHERent long-forM understanding with Episodes and\n  Semantics","summary":"  Existing research often treats long-form videos as extended short videos,\nleading to several limitations: inadequate capture of long-range dependencies,\ninefficient processing of redundant information, and failure to extract\nhigh-level semantic concepts. To address these issues, we propose a novel\napproach that more accurately reflects human cognition. This paper introduces\nHERMES: temporal-coHERent long-forM understanding with Episodes and Semantics,\na model that simulates episodic memory accumulation to capture action sequences\nand reinforces them with semantic knowledge dispersed throughout the video. Our\nwork makes two key contributions: First, we develop an Episodic COmpressor\n(ECO) that efficiently aggregates crucial representations from micro to\nsemi-macro levels, overcoming the challenge of long-range dependencies. Second,\nwe propose a Semantics ReTRiever (SeTR) that enhances these aggregated\nrepresentations with semantic information by focusing on the broader context,\ndramatically reducing feature dimensionality while preserving relevant\nmacro-level information. This addresses the issues of redundancy and lack of\nhigh-level concept extraction. Extensive experiments demonstrate that HERMES\nachieves state-of-the-art performance across multiple long-video understanding\nbenchmarks in both zero-shot and fully-supervised settings.\n","authors":["Gueter Josmy Faure","Jia-Fong Yeh","Min-Hung Chen","Hung-Ting Su","Shang-Hong Lai","Winston H. Hsu"],"pdf_url":"https://arxiv.org/pdf/2408.17443v3.pdf","comment":"This is an improved and expanded version of our EVAL-FoMo Workshop at\n  ECCV'24 (v1 of this paper). Project page:\n  https://joslefaure.github.io/assets/html/hermes.html"},{"id":"http://arxiv.org/abs/2409.02449v4","updated":"2024-11-09T06:37:01Z","published":"2024-09-04T05:08:23Z","title":"What is lost in Normalization? Exploring Pitfalls in Multilingual ASR\n  Model Evaluations","summary":"  This paper explores the pitfalls in evaluating multilingual automatic speech\nrecognition (ASR) models, with a particular focus on Indic language scripts. We\ninvestigate the text normalization routine employed by leading ASR models,\nincluding OpenAI Whisper, Meta's MMS, Seamless, and Assembly AI's Conformer,\nand their unintended consequences on performance metrics. Our research reveals\nthat current text normalization practices, while aiming to standardize ASR\noutputs for fair comparison, by removing inconsistencies such as variations in\nspelling, punctuation, and special characters, are fundamentally flawed when\napplied to Indic scripts. Through empirical analysis using text similarity\nscores and in-depth linguistic examination, we demonstrate that these flaws\nlead to artificially improved performance metrics for Indic languages. We\nconclude by proposing a shift towards developing text normalization routines\nthat leverage native linguistic expertise, ensuring more robust and accurate\nevaluations of multilingual ASR models.\n","authors":["Kavya Manohar","Leena G Pillai","Elizabeth Sherly"],"pdf_url":"https://arxiv.org/pdf/2409.02449v4.pdf","comment":"Accepted to EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2411.06084v1","updated":"2024-11-09T06:30:13Z","published":"2024-11-09T06:30:13Z","title":"Optimizing Large Language Models through Quantization: A Comparative\n  Analysis of PTQ and QAT Techniques","summary":"  This paper presents a comprehensive analysis of quantization techniques for\noptimizing Large Language Models (LLMs), specifically focusing on Post-Training\nQuantization (PTQ) and Quantization-Aware Training (QAT). Through empirical\nevaluation across models ranging from 10M to 1B parameters, we demonstrate that\nquantization can achieve up to 68% reduction in model size while maintaining\nperformance within 6% of full-precision baselines when utilizing our proposed\nscaling factor {\\gamma}. Our experiments show that INT8 quantization delivers a\n40% reduction in computational cost and power consumption, while INT4\nquantization further improves these metrics by 60%. We introduce a novel\ntheoretical framework for mixed-precision quantization, deriving optimal bit\nallocation strategies based on layer sensitivity and weight variance. Hardware\nefficiency evaluations on edge devices reveal that our quantization approach\nenables up to 2.4x throughput improvement for INT8 and 3x for INT4, with 60%\npower reduction compared to full-precision models.\n","authors":["Jahid Hasan"],"pdf_url":"https://arxiv.org/pdf/2411.06084v1.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.06068v1","updated":"2024-11-09T04:57:41Z","published":"2024-11-09T04:57:41Z","title":"Zyda-2: a 5 Trillion Token High-Quality Dataset","summary":"  In this technical report, we present Zyda-2: a five trillion token dataset\nfor language model pretraining. Zyda-2 was used to train our Zamba2 series of\nmodels which are state-of-the-art for their weight class. We build Zyda-2 by\ncollating high-quality open-source tokens such as FineWeb and DCLM, then\ndistilling them to the highest-quality subset via cross-deduplication and\nmodel-based quality filtering. Zyda-2 is released under a permissive open\nlicense, and is available at https://huggingface.co/datasets/Zyphra/Zyda-2\n","authors":["Yury Tokpanov","Paolo Glorioso","Quentin Anthony","Beren Millidge"],"pdf_url":"https://arxiv.org/pdf/2411.06068v1.pdf","comment":"initial upload 11/08/24"},{"id":"http://arxiv.org/abs/2402.13934v2","updated":"2024-11-09T04:25:03Z","published":"2024-02-21T17:00:56Z","title":"Do Efficient Transformers Really Save Computation?","summary":"  As transformer-based language models are trained on increasingly large\ndatasets and with vast numbers of parameters, finding more efficient\nalternatives to the standard Transformer has become very valuable. While many\nefficient Transformers and Transformer alternatives have been proposed, none\nprovide theoretical guarantees that they are a suitable replacement for the\nstandard Transformer. This makes it challenging to identify when to use a\nspecific model and what directions to prioritize for further investigation. In\nthis paper, we aim to understand the capabilities and limitations of efficient\nTransformers, specifically the Sparse Transformer and the Linear Transformer.\nWe focus on their reasoning capability as exhibited by Chain-of-Thought (CoT)\nprompts and follow previous works to model them as Dynamic Programming (DP)\nproblems. Our results show that while these models are expressive enough to\nsolve general DP tasks, contrary to expectations, they require a model size\nthat scales with the problem size. Nonetheless, we identify a class of DP\nproblems for which these models can be more efficient than the standard\nTransformer. We confirm our theoretical results through experiments on\nrepresentative DP tasks, adding to the understanding of efficient Transformers'\npractical strengths and weaknesses.\n","authors":["Kai Yang","Jan Ackermann","Zhenyu He","Guhao Feng","Bohang Zhang","Yunzhen Feng","Qiwei Ye","Di He","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2402.13934v2.pdf","comment":"20 pages, ICML 2024 Camera Ready Version"},{"id":"http://arxiv.org/abs/2404.07234v4","updated":"2024-11-09T04:01:22Z","published":"2024-04-06T06:17:10Z","title":"Goal-guided Generative Prompt Injection Attack on Large Language Models","summary":"  Current large language models (LLMs) provide a strong foundation for\nlarge-scale user-oriented natural language tasks. A large number of users can\neasily inject adversarial text or instructions through the user interface, thus\ncausing LLMs model security challenges. Although there is currently a large\namount of research on prompt injection attacks, most of these black-box attacks\nuse heuristic strategies. It is unclear how these heuristic strategies relate\nto the success rate of attacks and thus effectively improve model robustness.\nTo solve this problem, we redefine the goal of the attack: to maximize the KL\ndivergence between the conditional probabilities of the clean text and the\nadversarial text. Furthermore, we prove that maximizing the KL divergence is\nequivalent to maximizing the Mahalanobis distance between the embedded\nrepresentation $x$ and $x'$ of the clean text and the adversarial text when the\nconditional probability is a Gaussian distribution and gives a quantitative\nrelationship on $x$ and $x'$. Then we designed a simple and effective\ngoal-guided generative prompt injection strategy (G2PIA) to find an injection\ntext that satisfies specific constraints to achieve the optimal attack effect\napproximately. It is particularly noteworthy that our attack method is a\nquery-free black-box attack method with low computational cost. Experimental\nresults on seven LLM models and four datasets show the effectiveness of our\nattack method.\n","authors":["Chong Zhang","Mingyu Jin","Qinkai Yu","Chengzhi Liu","Haochen Xue","Xiaobo Jin"],"pdf_url":"https://arxiv.org/pdf/2404.07234v4.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.23728v2","updated":"2024-11-09T03:27:22Z","published":"2024-10-31T08:30:55Z","title":"GigaCheck: Detecting LLM-generated Content","summary":"  With the increasing quality and spread of LLM-based assistants, the amount of\nLLM-generated content is growing rapidly. In many cases and tasks, such texts\nare already indistinguishable from those written by humans, and the quality of\ngeneration tends to only increase. At the same time, detection methods are\ndeveloping more slowly, making it challenging to prevent misuse of generative\nAI technologies.\n  In this work, we investigate the task of generated text detection by\nproposing the GigaCheck. Our research explores two approaches: (i)\ndistinguishing human-written texts from LLM-generated ones, and (ii) detecting\nLLM-generated intervals in Human-Machine collaborative texts. For the first\ntask, our approach utilizes a general-purpose LLM, leveraging its extensive\nlanguage abilities to fine-tune efficiently for the downstream task of\nLLM-generated text detection, achieving high performance even with limited\ndata. For the second task, we propose a novel approach that combines computer\nvision and natural language processing techniques. Specifically, we use a\nfine-tuned general-purpose LLM in conjunction with a DETR-like detection model,\nadapted from computer vision, to localize AI-generated intervals within text.\n  We evaluate the GigaCheck on five classification datasets with English texts\nand three datasets designed for Human-Machine collaborative text analysis. Our\nresults demonstrate that GigaCheck outperforms previous methods, even in\nout-of-distribution settings, establishing a strong baseline across all\ndatasets.\n","authors":["Irina Tolstykh","Aleksandra Tsybina","Sergey Yakubson","Aleksandr Gordeev","Vladimir Dokholyan","Maksim Kuprashevich"],"pdf_url":"https://arxiv.org/pdf/2410.23728v2.pdf","comment":"11 pages, 1 figure"},{"id":"http://arxiv.org/abs/2401.10471v5","updated":"2024-11-09T03:15:16Z","published":"2024-01-19T03:48:27Z","title":"DeepEdit: Knowledge Editing as Decoding with Constraints","summary":"  How to edit the knowledge in multi-step reasoning has become the major\nchallenge in the knowledge editing (KE) of large language models (LLMs). The\ndifficulty arises because the hallucinations of LLMs during multi-step\nreasoning often lead to incorrect use of new knowledge and incorrect answers.\nTo address this issue, we design decoding constraints to \"regulate\" LLMs'\nreasoning, enhancing logical coherence when incorporating new knowledge. We\npropose a new KE framework: DEEPEDIT (Depth-first Search-based Constrained\nDecoding for Knowledge Editing), which enhances LLMs's ability to generate\ncoherent reasoning chains with new knowledge through depth-first search. Our\nsearch selects the most important knowledge that satisfies our constraints as\nthe reasoning step to efficiently increase the reasoning depth. In addition to\nDEEPEDIT, we propose two new KE benchmarks: MQUAKE-2002 and MQUAKE-HARD, which\nprovide more precise and challenging assessments of KE approaches.\nQualitatively, DEEPEDIT enables LLMs to produce succinct and coherent reasoning\nchains involving new knowledge. Quantitatively, it yields significant\nimprovements on multiple KE benchmarks.\n","authors":["Yiwei Wang","Muhao Chen","Nanyun Peng","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2401.10471v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04579v3","updated":"2024-11-09T03:06:21Z","published":"2024-10-06T18:29:46Z","title":"Upsample or Upweight? Balanced Training on Heavily Imbalanced Datasets","summary":"  Data availability across domains often follows a long-tail distribution: a\nfew domains have abundant data, while most face dat . a scarcity. This\nimbalance poses challenges in training language models uniformly across all\ndomains. In our study, we focus on multilingual settings, where data sizes vary\nsignificantly between high- and low-resource languages. Common strategies to\naddress this include upsampling low-resource languages (Temperature Sampling)\nor upweighting their loss (Scalarization). Although often considered\nequivalent, this assumption has not been proven, which motivates our study.\nThrough both theoretical and empirical analysis, we identify the conditions\nunder which these approaches are equivalent and when they diverge.\nSpecifically, we demonstrate that these two methods are equivalent under full\ngradient descent, but this equivalence breaks down with stochastic gradient\ndescent. Empirically, we observe that Temperature Sampling converges more\nquickly but is prone to overfitting. We argue that this faster convergence is\nlikely due to the lower variance in gradient estimations, as shown\ntheoretically. Based on these insights, we propose Cooldown, a strategy that\nreduces sampling temperature during training, accelerating convergence without\noverfitting to low-resource languages. Our method is competitive with existing\ndata re-weighting and offers computational efficiency.\n","authors":["Tianjian Li","Haoran Xu","Weiting Tan","Kenton Murray","Daniel Khashabi"],"pdf_url":"https://arxiv.org/pdf/2410.04579v3.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2411.06037v1","updated":"2024-11-09T02:13:14Z","published":"2024-11-09T02:13:14Z","title":"Sufficient Context: A New Lens on Retrieval Augmented Generation Systems","summary":"  Augmenting LLMs with context leads to improved performance across many\napplications. Despite much research on Retrieval Augmented Generation (RAG)\nsystems, an open question is whether errors arise because LLMs fail to utilize\nthe context from retrieval or the context itself is insufficient to answer the\nquery. To shed light on this, we develop a new notion of sufficient context,\nalong with a way to classify instances that have enough information to answer\nthe query. We then use sufficient context to analyze several models and\ndatasets. By stratifying errors based on context sufficiency, we find that\nproprietary LLMs (Gemini, GPT, Claude) excel at answering queries when the\ncontext is sufficient, but often output incorrect answers instead of abstaining\nwhen the context is not. On the other hand, open-source LLMs (Llama, Mistral,\nGemma) hallucinate or abstain often, even with sufficient context. We further\ncategorize cases when the context is useful, and improves accuracy, even though\nit does not fully answer the query and the model errs without the context.\nBuilding on our findings, we explore ways to reduce hallucinations in RAG\nsystems, including a new selective generation method that leverages sufficient\ncontext information for guided abstention. Our method improves the fraction of\ncorrect answers among times where the model responds by 2-10% for Gemini, GPT,\nand Gemma.\n","authors":["Hailey Joren","Jianyi Zhang","Chun-Sung Ferng","Da-Cheng Juan","Ankur Taly","Cyrus Rashtchian"],"pdf_url":"https://arxiv.org/pdf/2411.06037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06032v1","updated":"2024-11-09T01:38:55Z","published":"2024-11-09T01:38:55Z","title":"LLM-GLOBE: A Benchmark Evaluating the Cultural Values Embedded in LLM\n  Output","summary":"  Immense effort has been dedicated to minimizing the presence of harmful or\nbiased generative content and better aligning AI output to human intention;\nhowever, research investigating the cultural values of LLMs is still in very\nearly stages. Cultural values underpin how societies operate, providing\nprofound insights into the norms, priorities, and decision making of their\nmembers. In recognition of this need for further research, we draw upon\ncultural psychology theory and the empirically-validated GLOBE framework to\npropose the LLM-GLOBE benchmark for evaluating the cultural value systems of\nLLMs, and we then leverage the benchmark to compare the values of Chinese and\nUS LLMs. Our methodology includes a novel \"LLMs-as-a-Jury\" pipeline which\nautomates the evaluation of open-ended content to enable large-scale analysis\nat a conceptual level. Results clarify similarities and differences that exist\nbetween Eastern and Western cultural value systems and suggest that\nopen-generation tasks represent a more promising direction for evaluation of\ncultural values. We interpret the implications of this research for subsequent\nmodel development, evaluation, and deployment efforts as they relate to LLMs,\nAI cultural alignment more broadly, and the influence of AI cultural value\nsystems on human-AI collaboration outcomes.\n","authors":["Elise Karinshak","Amanda Hu","Kewen Kong","Vishwanatha Rao","Jingren Wang","Jindong Wang","Yi Zeng"],"pdf_url":"https://arxiv.org/pdf/2411.06032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07013v2","updated":"2024-11-09T01:35:32Z","published":"2024-01-13T08:43:32Z","title":"Knowledge Distillation of Black-Box Large Language Models","summary":"  Given the exceptional performance of proprietary large language models (LLMs)\nlike GPT-4, recent research has increasingly focused on boosting the\ncapabilities of smaller models through knowledge distillation (KD) from these\npowerful yet black-box teachers. While leveraging the high-quality outputs of\nthese teachers is advantageous, the inaccessibility of their internal states\noften limits effective knowledge transfer. To overcome this limitation, we\nintroduce Proxy-KD, a novel method that uses a proxy model to facilitate the\nefficient transfer of knowledge from black-box LLMs to smaller models. Our\nexperiments show that Proxy-KD not only enhances the performance of KD from\nblack-box teacher models but also surpasses traditional white-box KD\ntechniques.~This approach presents a compelling new avenue for distilling\nknowledge from advanced LLMs.\n","authors":["Hongzhan Chen","Ruijun Chen","Yuqi Yi","Xiaojun Quan","Chenliang Li","Ming Yan","Ji Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.07013v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08627v3","updated":"2024-11-09T01:25:00Z","published":"2024-06-12T20:20:09Z","title":"Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis","summary":"  Time series data are ubiquitous across a wide range of real-world domains.\nWhile real-world time series analysis (TSA) requires human experts to integrate\nnumerical series data with multimodal domain-specific knowledge, most existing\nTSA models rely solely on numerical data, overlooking the significance of\ninformation beyond numerical series. This oversight is due to the untapped\npotential of textual series data and the absence of a comprehensive,\nhigh-quality multimodal dataset. To overcome this obstacle, we introduce\nTime-MMD, the first multi-domain, multimodal time series dataset covering 9\nprimary data domains. Time-MMD ensures fine-grained modality alignment,\neliminates data contamination, and provides high usability. Additionally, we\ndevelop MM-TSFlib, the first multimodal time-series forecasting (TSF) library,\nseamlessly pipelining multimodal TSF evaluations based on Time-MMD for in-depth\nanalyses. Extensive experiments conducted on Time-MMD through MM-TSFlib\ndemonstrate significant performance enhancements by extending unimodal TSF to\nmultimodality, evidenced by over 15% mean squared error reduction in general,\nand up to 40% in domains with rich textual data. More importantly, our datasets\nand library revolutionize broader applications, impacts, research topics to\nadvance TSA. The dataset and library are available at\nhttps://github.com/AdityaLab/Time-MMD and\nhttps://github.com/AdityaLab/MM-TSFlib.\n","authors":["Haoxin Liu","Shangqing Xu","Zhiyuan Zhao","Lingkai Kong","Harshavardhan Kamarthi","Aditya B. Sasanur","Megha Sharma","Jiaming Cui","Qingsong Wen","Chao Zhang","B. Aditya Prakash"],"pdf_url":"https://arxiv.org/pdf/2406.08627v3.pdf","comment":"Accepted by NeurIPS 2024 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2411.06022v1","updated":"2024-11-09T00:56:02Z","published":"2024-11-09T00:56:02Z","title":"Improved intent classification based on context information using a\n  windows-based approach","summary":"  Conversational systems have a Natural Language Understanding (NLU) module. In\nthis module, there is a task known as an intent classification that aims at\nidentifying what a user is attempting to achieve from an utterance. Previous\nworks use only the current utterance to predict the intent of a given query and\nthey do not consider the role of the context (one or a few previous utterances)\nin the dialog flow for this task. In this work, we propose several approaches\nto investigate the role of contextual information for the intent classification\ntask. Each approach is used to carry out a concatenation between the dialogue\nhistory and the current utterance. Our intent classification method is based on\na convolutional neural network that obtains effective vector representations\nfrom BERT to perform accurate intent classification using an approach\nwindow-based. Our experiments were carried out on a real-world Brazilian\nPortuguese corpus with dialog flows provided by Wavy global company. Our\nresults achieved substantial improvements over the baseline, isolated\nutterances (without context), in three approaches using the user's utterance\nand system's response from previous messages as dialogue context.\n","authors":["Jeanfranco D. Farfan-Escobedo","Julio C. Dos Reis"],"pdf_url":"https://arxiv.org/pdf/2411.06022v1.pdf","comment":"In preparation for Journal Submission"},{"id":"http://arxiv.org/abs/2407.06501v2","updated":"2024-11-09T00:42:46Z","published":"2024-07-09T02:06:30Z","title":"STORYSUMM: Evaluating Faithfulness in Story Summarization","summary":"  Human evaluation has been the gold standard for checking faithfulness in\nabstractive summarization. However, with a challenging source domain like\nnarrative, multiple annotators can agree a summary is faithful, while missing\ndetails that are obvious errors only once pointed out. We therefore introduce a\nnew dataset, STORYSUMM, comprising LLM summaries of short stories with\nlocalized faithfulness labels and error explanations. This benchmark is for\nevaluation methods, testing whether a given method can detect challenging\ninconsistencies. Using this dataset, we first show that any one human\nannotation protocol is likely to miss inconsistencies, and we advocate for\npursuing a range of methods when establishing ground truth for a summarization\ndataset. We finally test recent automatic metrics and find that none of them\nachieve more than 70% balanced accuracy on this task, demonstrating that it is\na challenging benchmark for future work in faithfulness evaluation.\n","authors":["Melanie Subbiah","Faisal Ladhak","Akankshya Mishra","Griffin Adams","Lydia B. Chilton","Kathleen McKeown"],"pdf_url":"https://arxiv.org/pdf/2407.06501v2.pdf","comment":"EMNLP Main 2024"},{"id":"http://arxiv.org/abs/2402.15506v4","updated":"2024-11-09T00:28:26Z","published":"2024-02-23T18:56:26Z","title":"AgentOhana: Design Unified Data and Training Pipeline for Effective\n  Agent Learning","summary":"  Autonomous agents powered by large language models (LLMs) have garnered\nsignificant research attention. However, fully harnessing the potential of LLMs\nfor agent-based tasks presents inherent challenges due to the heterogeneous\nnature of diverse data sources featuring multi-turn trajectories. In this\npaper, we introduce \\textbf{AgentOhana} as a comprehensive solution to address\nthese challenges. \\textit{AgentOhana} aggregates agent trajectories from\ndistinct environments, spanning a wide array of scenarios. It meticulously\nstandardizes and unifies these trajectories into a consistent format,\nstreamlining the creation of a generic data loader optimized for agent\ntraining. Leveraging the data unification, our training pipeline maintains\nequilibrium across different data sources and preserves independent randomness\nacross devices during dataset partitioning and model training. Additionally, we\npresent \\textbf{xLAM-v0.1}, a large action model tailored for AI agents, which\ndemonstrates exceptional performance across various benchmarks. Begin the\nexploration at \\url{https://github.com/SalesforceAIResearch/xLAM}.\n","authors":["Jianguo Zhang","Tian Lan","Rithesh Murthy","Zhiwei Liu","Weiran Yao","Ming Zhu","Juntao Tan","Thai Hoang","Zuxin Liu","Liangwei Yang","Yihao Feng","Shirley Kokane","Tulika Awalgaonkar","Juan Carlos Niebles","Silvio Savarese","Shelby Heinecke","Huan Wang","Caiming Xiong"],"pdf_url":"https://arxiv.org/pdf/2402.15506v4.pdf","comment":"Add GitHub repo link at\n  \\url{https://github.com/SalesforceAIResearch/xLAM} and HuggingFace model link\n  at \\url{https://huggingface.co/Salesforce/xLAM-v0.1-r}"},{"id":"http://arxiv.org/abs/2411.07268v1","updated":"2024-11-09T15:59:59Z","published":"2024-11-09T15:59:59Z","title":"Target-driven Attack for Large Language Models","summary":"  Current large language models (LLM) provide a strong foundation for\nlarge-scale user-oriented natural language tasks. Many users can easily inject\nadversarial text or instructions through the user interface, thus causing LLM\nmodel security challenges like the language model not giving the correct\nanswer. Although there is currently a large amount of research on black-box\nattacks, most of these black-box attacks use random and heuristic strategies.\nIt is unclear how these strategies relate to the success rate of attacks and\nthus effectively improve model robustness. To solve this problem, we propose\nour target-driven black-box attack method to maximize the KL divergence between\nthe conditional probabilities of the clean text and the attack text to redefine\nthe attack's goal. We transform the distance maximization problem into two\nconvex optimization problems based on the attack goal to solve the attack text\nand estimate the covariance. Furthermore, the projected gradient descent\nalgorithm solves the vector corresponding to the attack text. Our target-driven\nblack-box attack approach includes two attack strategies: token manipulation\nand misinformation attack. Experimental results on multiple Large Language\nModels and datasets demonstrate the effectiveness of our attack method.\n","authors":["Chong Zhang","Mingyu Jin","Dong Shu","Taowen Wang","Dongfang Liu","Xiaobo Jin"],"pdf_url":"https://arxiv.org/pdf/2411.07268v1.pdf","comment":"12 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:2404.07234"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.06264v1","updated":"2024-11-09T19:32:26Z","published":"2024-11-09T19:32:26Z","title":"GuidelineGuard: An Agentic Framework for Medical Note Evaluation with\n  Guideline Adherence","summary":"  Although rapid advancements in Large Language Models (LLMs) are facilitating\nthe integration of artificial intelligence-based applications and services in\nhealthcare, limited research has focused on the systematic evaluation of\nmedical notes for guideline adherence. This paper introduces GuidelineGuard, an\nagentic framework powered by LLMs that autonomously analyzes medical notes,\nsuch as hospital discharge and office visit notes, to ensure compliance with\nestablished healthcare guidelines. By identifying deviations from recommended\npractices and providing evidence-based suggestions, GuidelineGuard helps\nclinicians adhere to the latest standards from organizations like the WHO and\nCDC. This framework offers a novel approach to improving documentation quality\nand reducing clinical errors.\n","authors":["MD Ragib Shahriyear"],"pdf_url":"https://arxiv.org/pdf/2411.06264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06256v1","updated":"2024-11-09T19:07:58Z","published":"2024-11-09T19:07:58Z","title":"Annotative Indexing","summary":"  This paper introduces annotative indexing, a novel framework that unifies and\ngeneralizes traditional inverted indexes, column stores, object stores, and\ngraph databases. As a result, annotative indexing can provide the underlying\nindexing framework for databases that support knowledge graphs, entity\nretrieval, semi-structured data, and ranked retrieval. While we primarily focus\non human language data in the form of text, annotative indexing is sufficiently\ngeneral to support a range of other datatypes, and we provide examples of\nSQL-like queries over a JSON store that includes numbers and dates. Taking\nadvantage of the flexibility of annotative indexing, we also demonstrate a\nfully dynamic annotative index incorporating support for ACID properties of\ntransactions with hundreds of multiple concurrent readers and writers.\n","authors":["Charles L. A. Clarke"],"pdf_url":"https://arxiv.org/pdf/2411.06256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06254v1","updated":"2024-11-09T19:03:56Z","published":"2024-11-09T19:03:56Z","title":"KeyB2: Selecting Key Blocks is Also Important for Long Document Ranking\n  with Large Language Models","summary":"  The rapid development of large language models (LLMs) like Llama has\nsignificantly advanced information retrieval (IR) systems. However, using LLMs\nfor long documents, as in RankLLaMA, remains challenging due to computational\ncomplexity, especially concerning input token length. Furthermore, the internal\nmechanisms of LLMs during ranking are still not fully understood. In this\npaper, we first explore the internal workings of LLMs during relevance\njudgement and identify that specific attention heads play a crucial role in\naligning relevant tokens. This observation inspires us to revisit the block\npre-ranking strategy used in KeyB, which remains state-of-the-art (SOTA) on the\nTREC 2019 DL document ranking dataset. Building on these insights, we develop\nKeyB2, an advanced long document IR approach that integrates block pre-ranking\nwith the performance of LLMs. KeyB2 efficiently identifies and processes the\nmost relevant blocks, reducing computational costs and improving ranking\neffectiveness. Additionally, we introduce a new bi-encoder block matching\nstrategy for KeyB2. Comprehensive experiments on long-document datasets,\nincluding TREC 2019 DL, Robust04, and MLDR-zh, show that KeyB2 outperforms\nbaselines like RankLLaMA and KeyB by reducing reranking time and GPU memory\nusage while enhancing retrieval performance, achieving new SOTA results on TREC\n2019 DL with higher NDCG@10 and MAP scores.\n","authors":["Minghan Li","Eric Gaussier","Juntao Li","Guodong Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.06254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10978v2","updated":"2024-11-09T18:46:07Z","published":"2024-03-16T17:21:58Z","title":"Lambda: Learning Matchable Prior For Entity Alignment with Unlabeled\n  Dangling Cases","summary":"  We investigate the entity alignment (EA) problem with unlabeled dangling\ncases, meaning that partial entities have no counterparts in the other\nknowledge graph (KG), and this type of entity remains unlabeled. To address\nthis challenge, we propose the framework \\textit{Lambda} for dangling detection\nand then entity alignment. Lambda features a GNN-based encoder called KEESA\nwith spectral contrastive learning for EA and a positive-unlabeled learning\nalgorithm for dangling detection called iPULE. iPULE offers theoretical\nguarantees of unbiasedness, uniform deviation bounds, and convergence.\nExperimental results demonstrate that each component contributes to overall\nperformances that are superior to baselines, even when baselines additionally\nexploit 30\\% of dangling entities labeled for training.\n","authors":["Hang Yin","Liyao Xiang","Dong Ding","Yuheng He","Yihan Wu","Xinbing Wang","Chenghu Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.10978v2.pdf","comment":"Accepted in NeurIPS 2024 as a poster"},{"id":"http://arxiv.org/abs/2411.06237v1","updated":"2024-11-09T17:38:01Z","published":"2024-11-09T17:38:01Z","title":"Leveraging Retrieval-Augmented Generation for University Knowledge\n  Retrieval","summary":"  This paper introduces an innovative approach using Retrieval-Augmented\nGeneration (RAG) pipelines with Large Language Models (LLMs) to enhance\ninformation retrieval and query response systems for university-related\nquestion answering. By systematically extracting data from the university\nofficial webpage and employing advanced prompt engineering techniques, we\ngenerate accurate, contextually relevant responses to user queries.\n  We developed a comprehensive university benchmark, UniversityQuestionBench\n(UQB), to rigorously evaluate our system performance, based on common key\nmetrics in the filed of RAG pipelines, assessing accuracy and reliability\nthrough various metrics and real-world scenarios. Our experimental results\ndemonstrate significant improvements in the precision and relevance of\ngenerated responses, enhancing user experience and reducing the time required\nto obtain relevant answers. In summary, this paper presents a novel application\nof RAG pipelines and LLMs, supported by a meticulously prepared university\nbenchmark, offering valuable insights into advanced AI techniques for academic\ndata retrieval and setting the stage for future research in this domain.\n","authors":["Arshia Hemmat","Kianoosh Vadaei","Mohammad Hassan Heydari","Afsaneh Fatemi"],"pdf_url":"https://arxiv.org/pdf/2411.06237v1.pdf","comment":"6 pages, 2 figures, 1 table, Submitted to 15th IKT conference"},{"id":"http://arxiv.org/abs/2411.06112v1","updated":"2024-11-09T08:22:31Z","published":"2024-11-09T08:22:31Z","title":"Interpret the Internal States of Recommendation Model with Sparse\n  Autoencoder","summary":"  Explainable recommendation systems are important to enhance transparency,\naccuracy, and fairness. Beyond result-level explanations, model-level\ninterpretations can provide valuable insights that allow developers to optimize\nsystem designs and implement targeted improvements. However, most current\napproaches depend on specialized model designs, which often lack generalization\ncapabilities. Given the various kinds of recommendation models, existing\nmethods have limited ability to effectively interpret them. To address this\nissue, we propose RecSAE, an automatic, generalizable probing method for\ninterpreting the internal states of Recommendation models with Sparse\nAutoEncoder. RecSAE serves as a plug-in module that does not affect original\nmodels during interpretations, while also enabling predictable modifications to\ntheir behaviors based on interpretation results. Firstly, we train an\nautoencoder with sparsity constraints to reconstruct internal activations of\nrecommendation models, making the RecSAE latents more interpretable and\nmonosemantic than the original neuron activations. Secondly, we automated the\nconstruction of concept dictionaries based on the relationship between latent\nactivations and input item sequences. Thirdly, RecSAE validates these\ninterpretations by predicting latent activations on new item sequences using\nthe concept dictionary and deriving interpretation confidence scores from\nprecision and recall. We demonstrate RecSAE's effectiveness on two datasets,\nidentifying hundreds of highly interpretable concepts from pure ID-based\nmodels. Latent ablation studies further confirm that manipulating latent\nconcepts produces corresponding changes in model output behavior, underscoring\nRecSAE's utility for both understanding and targeted tuning recommendation\nmodels. Code and data are publicly available at\nhttps://github.com/Alice1998/RecSAE.\n","authors":["Jiayin Wang","Xiaoyu Zhang","Weizhi Ma","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06064v1","updated":"2024-11-09T04:23:58Z","published":"2024-11-09T04:23:58Z","title":"Snippet-based Conversational Recommender System","summary":"  Conversational Recommender Systems (CRS) engage users in interactive\ndialogues to gather preferences and provide personalized recommendations.\nTraditionally, CRS rely on pre-defined attributes or expensive, domain-specific\nannotated datasets to guide conversations, which limits flexibility and\nadaptability across domains. In this work, we introduce SnipRec, a novel CRS\nthat enhances dialogues and recommendations by extracting diverse expressions\nand preferences from user-generated content (UGC) like customer reviews. Using\nlarge language models, SnipRec maps user responses and UGC to concise snippets,\nwhich are used to generate clarification questions and retrieve relevant items.\nOur approach eliminates the need for domain-specific training, making it\nadaptable to new domains and effective without prior knowledge of user\npreferences. Extensive experiments on the Yelp dataset demonstrate the\neffectiveness of snippet-based representations against document and\nsentence-based representations. Additionally, SnipRec is able to improve\nHits@10 by 0.25 over the course of five conversational turns, underscoring the\nefficiency of SnipRec in capturing user preferences through multi-turn\nconversations.\n","authors":["Haibo Sun","Naoki Otani","Hannah Kim","Dan Zhang","Nikita Bhutani"],"pdf_url":"https://arxiv.org/pdf/2411.06064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.05975v5","updated":"2024-11-09T02:41:43Z","published":"2024-01-11T15:22:55Z","title":"End-to-end Learnable Clustering for Intent Learning in Recommendation","summary":"  Intent learning, which aims to learn users' intents for user understanding\nand item recommendation, has become a hot research spot in recent years.\nHowever, existing methods suffer from complex and cumbersome alternating\noptimization, limiting performance and scalability. To this end, we propose a\nnovel intent learning method termed \\underline{ELCRec}, by unifying behavior\nrepresentation learning into an \\underline{E}nd-to-end \\underline{L}earnable\n\\underline{C}lustering framework, for effective and efficient\n\\underline{Rec}ommendation. Concretely, we encode user behavior sequences and\ninitialize the cluster centers (latent intents) as learnable neurons. Then, we\ndesign a novel learnable clustering module to separate different cluster\ncenters, thus decoupling users' complex intents. Meanwhile, it guides the\nnetwork to learn intents from behaviors by forcing behavior embeddings close to\ncluster centers. This allows simultaneous optimization of recommendation and\nclustering via mini-batch data. Moreover, we propose intent-assisted\ncontrastive learning by using cluster centers as self-supervision signals,\nfurther enhancing mutual promotion. Both experimental results and theoretical\nanalyses demonstrate the superiority of ELCRec from six perspectives. Compared\nto the runner-up, ELCRec improves NDCG@5 by 8.9\\% and reduces computational\ncosts by 22.5\\% on the Beauty dataset. Furthermore, due to the scalability and\nuniversal applicability, we deploy this method on the industrial recommendation\nsystem with 130 million page views and achieve promising results. The codes are\navailable on GitHub (https://github.com/yueliu1999/ELCRec). A collection\n(papers, codes, datasets) of deep group recommendation/intent learning methods\nis available on GitHub\n(https://github.com/yueliu1999/Awesome-Deep-Group-Recommendation).\n","authors":["Yue Liu","Shihao Zhu","Jun Xia","Yingwei Ma","Jian Ma","Xinwang Liu","Shengju Yu","Kejun Zhang","Wenliang Zhong"],"pdf_url":"https://arxiv.org/pdf/2401.05975v5.pdf","comment":"37 pages"}]},"2024-11-12T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2411.08019v1","updated":"2024-11-12T18:50:35Z","published":"2024-11-12T18:50:35Z","title":"Language Models as Causal Effect Generators","summary":"  We present a framework for large language model (LLM) based data generation\nwith controllable causal structure. In particular, we define a procedure for\nturning any language model and any directed acyclic graph (DAG) into a\nsequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM\nis a causal model with user-defined structure and LLM-defined structural\nequations. We characterize how an SD-SCM allows sampling from observational,\ninterventional, and counterfactual distributions according to the desired\ncausal structure. We then leverage this procedure to propose a new type of\nbenchmark for causal inference methods, generating individual-level\ncounterfactual data without needing to manually specify functional\nrelationships between variables. We create an example benchmark consisting of\nthousands of datasets, and test a suite of popular estimation methods on these\ndatasets for average, conditional average, and individual treatment effect\nestimation, both with and without hidden confounding. Apart from generating\ndata, the same procedure also allows us to test for the presence of a causal\neffect that might be encoded in an LLM. This procedure can underpin auditing\nLLMs for misinformation, discrimination, or otherwise undesirable behavior. We\nbelieve SD-SCMs can serve as a useful tool in any application that would\nbenefit from sequential data with controllable causal structure.\n","authors":["Lucius E. J. Bynum","Kyunghyun Cho"],"pdf_url":"https://arxiv.org/pdf/2411.08019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08010v1","updated":"2024-11-12T18:35:28Z","published":"2024-11-12T18:35:28Z","title":"ExpressivityArena: Can LLMs Express Information Implicitly?","summary":"  While Large Language Models (LLMs) have demonstrated remarkable performance\nin certain dimensions, their ability to express implicit language cues that\nhuman use for effective communication remains unclear. This paper presents\nExpressivityArena, a Python library for measuring the implicit communication\nabilities of LLMs. We provide a comprehensive framework to evaluate\nexpressivity of arbitrary LLMs and explore its practical implications. To this\nend, we refine the definition and measurements of ``expressivity,'' and use our\nframework in a set of small experiments. These experiments test LLMs in\ncreative and logical tasks such as poetry, coding, and emotion-based responses.\nThey are then evaluated by an automated grader, through ExpressivityArena,\nwhich we verify to be the most pragmatic for testing expressivity. Building on\nthese experiments, we deepen our understanding of the expressivity of LLMs by\nassessing their ability to remain expressive in conversations. Our findings\nindicate that LLMs are capable of generating and understanding expressive\ncontent, however, with some limitations. These insights will inform the future\ndevelopment and deployment of expressive LLMs. We provide the code for\nExpressivityArena alongside our paper.\n","authors":["Joshua Tint","Som Sagar","Aditya Taparia","Kelly Raines","Bimsara Pathiraja","Caleb Liu","Ransalu Senanayake"],"pdf_url":"https://arxiv.org/pdf/2411.08010v1.pdf","comment":"8 pages, 22 figures"},{"id":"http://arxiv.org/abs/2411.08003v1","updated":"2024-11-12T18:28:57Z","published":"2024-11-12T18:28:57Z","title":"Can adversarial attacks by large language models be attributed?","summary":"  Attributing outputs from Large Language Models (LLMs) in adversarial\nsettings-such as cyberattacks and disinformation-presents significant\nchallenges that are likely to grow in importance. We investigate this\nattribution problem using formal language theory, specifically language\nidentification in the limit as introduced by Gold and extended by Angluin. By\nmodeling LLM outputs as formal languages, we analyze whether finite text\nsamples can uniquely pinpoint the originating model. Our results show that due\nto the non-identifiability of certain language classes, under some mild\nassumptions about overlapping outputs from fine-tuned models it is\ntheoretically impossible to attribute outputs to specific LLMs with certainty.\nThis holds also when accounting for expressivity limitations of Transformer\narchitectures. Even with direct model access or comprehensive monitoring,\nsignificant computational hurdles impede attribution efforts. These findings\nhighlight an urgent need for proactive measures to mitigate risks posed by\nadversarial LLM use as their influence continues to expand.\n","authors":["Manuel Cebrian","Jan Arne Telle"],"pdf_url":"https://arxiv.org/pdf/2411.08003v1.pdf","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2411.07990v1","updated":"2024-11-12T18:15:19Z","published":"2024-11-12T18:15:19Z","title":"Derivational Morphology Reveals Analogical Generalization in Large\n  Language Models","summary":"  What mechanisms underlie linguistic generalization in large language models\n(LLMs)? This question has attracted considerable attention, with most studies\nanalyzing the extent to which the language skills of LLMs resemble rules. As of\nyet, it is not known whether linguistic generalization in LLMs could equally\nwell be explained as the result of analogical processes, which can be\nformalized as similarity operations on stored exemplars. A key shortcoming of\nprior research is its focus on linguistic phenomena with a high degree of\nregularity, for which rule-based and analogical approaches make the same\npredictions. Here, we instead examine derivational morphology, specifically\nEnglish adjective nominalization, which displays notable variability. We\nintroduce a new method for investigating linguistic generalization in LLMs:\nfocusing on GPT-J, we fit cognitive models that instantiate rule-based and\nanalogical learning to the LLM training data and compare their predictions on a\nset of nonce adjectives with those of the LLM, allowing us to draw direct\nconclusions regarding underlying mechanisms. As expected, rule-based and\nanalogical models explain the predictions of GPT-J equally well for adjectives\nwith regular nominalization patterns. However, for adjectives with variable\nnominalization patterns, the analogical model provides a much better match.\nFurthermore, GPT-J's behavior is sensitive to the individual word frequencies,\neven for regular forms, a behavior that is consistent with an analogical\naccount of regular forms but not a rule-based one. These findings refute the\nhypothesis that GPT-J's linguistic generalization on adjective nominalization\ninvolves rules, suggesting similarity operations on stored exemplars as the\nunderlying mechanism. Overall, our study suggests that analogical processes\nplay a bigger role in the linguistic generalization of LLMs than previously\nthought.\n","authors":["Valentin Hofmann","Leonie Weissweiler","David Mortensen","Hinrich Sch√ºtze","Janet Pierrehumbert"],"pdf_url":"https://arxiv.org/pdf/2411.07990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07975v1","updated":"2024-11-12T17:55:10Z","published":"2024-11-12T17:55:10Z","title":"JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified\n  Multimodal Understanding and Generation","summary":"  We present JanusFlow, a powerful framework that unifies image understanding\nand generation in a single model. JanusFlow introduces a minimalist\narchitecture that integrates autoregressive language models with rectified\nflow, a state-of-the-art method in generative modeling. Our key finding\ndemonstrates that rectified flow can be straightforwardly trained within the\nlarge language model framework, eliminating the need for complex architectural\nmodifications. To further improve the performance of our unified model, we\nadopt two key strategies: (i) decoupling the understanding and generation\nencoders, and (ii) aligning their representations during unified training.\nExtensive experiments show that JanusFlow achieves comparable or superior\nperformance to specialized models in their respective domains, while\nsignificantly outperforming existing unified approaches across standard\nbenchmarks. This work represents a step toward more efficient and versatile\nvision-language models.\n","authors":["Yiyang Ma","Xingchao Liu","Xiaokang Chen","Wen Liu","Chengyue Wu","Zhiyu Wu","Zizheng Pan","Zhenda Xie","Haowei Zhang","Xingkai yu","Liang Zhao","Yisong Wang","Jiaying Liu","Chong Ruan"],"pdf_url":"https://arxiv.org/pdf/2411.07975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07965v1","updated":"2024-11-12T17:41:16Z","published":"2024-11-12T17:41:16Z","title":"From General to Specific: Utilizing General Hallucation to Automatically\n  Measure the Role Relationship Fidelity for Specific Role-Play Agents","summary":"  The advanced role-playing capabilities of Large Language Models (LLMs) have\npaved the way for developing Role-Playing Agents (RPAs). However, existing\nbenchmarks, such as HPD, which incorporates manually scored character\nrelationships into the context for LLMs to sort coherence, and SocialBench,\nwhich uses specific profiles generated by LLMs in the context of\nmultiple-choice tasks to assess character preferences, face limitations like\npoor generalizability, implicit and inaccurate judgments, and excessive context\nlength. To address the above issues, we propose an automatic, scalable, and\ngeneralizable paradigm. Specifically, we construct a benchmark by extracting\nrelations from a general knowledge graph and leverage RPA's inherent\nhallucination properties to prompt it to interact across roles, employing\nChatGPT for stance detection and defining relationship hallucination along with\nthree related metrics. Extensive experiments validate the effectiveness and\nstability of our metrics. Our findings further explore factors influencing\nthese metrics and discuss the trade-off between relationship hallucination and\nfactuality.\n","authors":["Chuyi Kong","Ziyang Luo","Hongzhan Lin","Zhiyuan Fan","Yaxin Fan","Yuxi Sun","Jing Ma"],"pdf_url":"https://arxiv.org/pdf/2411.07965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08479v5","updated":"2024-11-12T17:38:29Z","published":"2024-02-13T14:12:32Z","title":"Plausible Extractive Rationalization through Semi-Supervised Entailment\n  Signal","summary":"  The increasing use of complex and opaque black box models requires the\nadoption of interpretable measures, one such option is extractive rationalizing\nmodels, which serve as a more interpretable alternative. These models, also\nknown as Explain-Then-Predict models, employ an explainer model to extract\nrationales and subsequently condition the predictor with the extracted\ninformation. Their primary objective is to provide precise and faithful\nexplanations, represented by the extracted rationales. In this paper, we take a\nsemi-supervised approach to optimize for the plausibility of extracted\nrationales. We adopt a pre-trained natural language inference (NLI) model and\nfurther fine-tune it on a small set of supervised rationales ($10\\%$). The NLI\npredictor is leveraged as a source of supervisory signals to the explainer via\nentailment alignment. We show that, by enforcing the alignment agreement\nbetween the explanation and answer in a question-answering task, the\nperformance can be improved without access to ground truth labels. We evaluate\nour approach on the ERASER dataset and show that our approach achieves\ncomparable results with supervised extractive models and outperforms\nunsupervised approaches by $> 100\\%$.\n","authors":["Wei Jie Yeo","Ranjan Satapathy","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2402.08479v5.pdf","comment":"ACL Findings 2024"},{"id":"http://arxiv.org/abs/2406.11275v2","updated":"2024-11-12T17:37:10Z","published":"2024-06-17T07:25:09Z","title":"Self-training Large Language Models through Knowledge Detection","summary":"  Large language models (LLMs) often necessitate extensive labeled datasets and\ntraining compute to achieve impressive performance across downstream tasks.\nThis paper explores a self-training paradigm, where the LLM autonomously\ncurates its own labels and selectively trains on unknown data samples\nidentified through a reference-free consistency method. Empirical evaluations\ndemonstrate significant improvements in reducing hallucination in generation\nacross multiple subjects. Furthermore, the selective training framework\nmitigates catastrophic forgetting in out-of-distribution benchmarks, addressing\na critical limitation in training LLMs. Our findings suggest that such an\napproach can substantially reduce the dependency on large labeled datasets,\npaving the way for more scalable and cost-effective language model training.\n","authors":["Wei Jie Yeo","Teddy Ferdinan","Przemyslaw Kazienko","Ranjan Satapathy","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2406.11275v2.pdf","comment":"EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2411.07917v1","updated":"2024-11-12T16:49:51Z","published":"2024-11-12T16:49:51Z","title":"CryptoLLM: Unleashing the Power of Prompted LLMs for SmartQnA and\n  Classification of Crypto Posts","summary":"  The rapid growth of social media has resulted in an large volume of\nuser-generated content, particularly in niche domains such as cryptocurrency.\nThis task focuses on developing robust classification models to accurately\ncategorize cryptocurrency-related social media posts into predefined classes,\nincluding but not limited to objective, positive, negative, etc. Additionally,\nthe task requires participants to identify the most relevant answers from a set\nof posts in response to specific questions. By leveraging advanced LLMs, this\nresearch aims to enhance the understanding and filtering of cryptocurrency\ndiscourse, thereby facilitating more informed decision-making in this volatile\nsector. We have used a prompt-based technique to solve the classification task\nfor reddit posts and twitter posts. Also, we have used 64-shot technique along\nwith prompts on GPT-4-Turbo model to determine whether a answer is relevant to\na question or not.\n","authors":["Aniket Deroy","Subhankar Maity"],"pdf_url":"https://arxiv.org/pdf/2411.07917v1.pdf","comment":"Accepted at FIRE 2024 (Track: Opinion Extraction and Question\n  Answering from CryptoCurrency-Related Tweets and Reddit posts (CryptOQA))"},{"id":"http://arxiv.org/abs/2406.13230v2","updated":"2024-11-12T16:47:49Z","published":"2024-06-19T05:33:34Z","title":"Enhancing Language Model Factuality via Activation-Based Confidence\n  Calibration and Guided Decoding","summary":"  Calibrating language models (LMs) aligns their generation confidence with the\nactual likelihood of answer correctness, which can inform users about LMs'\nreliability and mitigate hallucinated content. However, prior calibration\nmethods, such as self-consistency-based and logit-based approaches, are either\nlimited in inference-time efficiency or fall short of providing informative\nsignals. Moreover, simply filtering out low-confidence responses reduces the\nLM's helpfulness when the answers are correct. Therefore, effectively using\ncalibration techniques to enhance an LM's factuality remains an unsolved\nchallenge. In this paper, we first propose an activation-based calibration\nmethod, ActCab, which trains a linear layer on top of the LM's last-layer\nactivations that can better capture the representations of knowledge. Built on\ntop of ActCab, we further propose CoDec, a confidence-guided decoding strategy\nto elicit truthful answers with high confidence from LMs. By evaluating on five\npopular QA benchmarks, ActCab achieves superior calibration performance than\nall competitive baselines, e.g., by reducing the average expected calibration\nerror (ECE) score by up to 39%. Further experiments on CoDec show consistent\nimprovements in several LMs' factuality on challenging QA datasets, such as\nTruthfulQA, highlighting the value of confidence signals in enhancing\nfactuality.\n","authors":["Xin Liu","Farima Fatahi Bayat","Lu Wang"],"pdf_url":"https://arxiv.org/pdf/2406.13230v2.pdf","comment":"EMNLP 2024 Camera Ready"},{"id":"http://arxiv.org/abs/2310.10429v2","updated":"2024-11-12T16:39:55Z","published":"2023-10-16T14:13:38Z","title":"Exploiting User Comments for Early Detection of Fake News Prior to\n  Users' Commenting","summary":"  Both accuracy and timeliness are key factors in detecting fake news on social\nmedia. However, most existing methods encounter an accuracy-timeliness dilemma:\nContent-only methods guarantee timeliness but perform moderately because of\nlimited available information, while social con-text-based ones generally\nperform better but inevitably lead to latency because of social context\naccumulation needs. To break such a dilemma, a feasible but not well-studied\nsolution is to leverage social contexts (e.g., comments) from historical news\nfor training a detection model and apply it to newly emerging news without\nsocial contexts. This requires the model to (1) sufficiently learn helpful\nknowledge from social contexts, and (2) be well compatible with situations that\nsocial contexts are available or not. To achieve this goal, we propose to\nabsorb and parameterize useful knowledge from comments in historical news and\nthen inject it into a content-only detection model. Specifically, we design the\nComments ASsisted FakE News Detection method (CAS-FEND), which transfers useful\nknowledge from a comment-aware teacher model to a content-only student model\nand detects newly emerging news with the student model. Experiments show that\nthe CAS-FEND student model outperforms all content-only methods and even\ncomment-aware ones with 1/4 comments as inputs, demonstrating its superiority\nfor early detection.\n","authors":["Qiong Nan","Qiang Sheng","Juan Cao","Yongchun Zhu","Danding Wang","Guang Yang","Jintao Li"],"pdf_url":"https://arxiv.org/pdf/2310.10429v2.pdf","comment":"19 pages, 6 figures, 7 tables. The article has been accepted by\n  Frontiers of Computer Science (FCS), with the DOI:\n  {10.1007/s11704-024-40674-6}"},{"id":"http://arxiv.org/abs/2406.11813v3","updated":"2024-11-12T16:38:37Z","published":"2024-06-17T17:54:40Z","title":"How Do Large Language Models Acquire Factual Knowledge During\n  Pretraining?","summary":"  Despite the recent observation that large language models (LLMs) can store\nsubstantial factual knowledge, there is a limited understanding of the\nmechanisms of how they acquire factual knowledge through pretraining. This work\naddresses this gap by studying how LLMs acquire factual knowledge during\npretraining. The findings reveal several important insights into the dynamics\nof factual knowledge acquisition during pretraining. First, counterintuitively,\nwe observe that pretraining on more data shows no significant improvement in\nthe model's capability to acquire and maintain factual knowledge. Next, there\nis a power-law relationship between training steps and forgetting of\nmemorization and generalization of factual knowledge, and LLMs trained with\nduplicated training data exhibit faster forgetting. Third, training LLMs with\nlarger batch sizes can enhance the models' robustness to forgetting. Overall,\nour observations suggest that factual knowledge acquisition in LLM pretraining\noccurs by progressively increasing the probability of factual knowledge\npresented in the pretraining data at each step. However, this increase is\ndiluted by subsequent forgetting. Based on this interpretation, we demonstrate\nthat we can provide plausible explanations for recently observed behaviors of\nLLMs, such as the poor performance of LLMs on long-tail knowledge and the\nbenefits of deduplicating the pretraining corpus.\n","authors":["Hoyeon Chang","Jinho Park","Seonghyeon Ye","Sohee Yang","Youngkyung Seo","Du-Seong Chang","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2406.11813v3.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.06855v2","updated":"2024-11-12T16:03:24Z","published":"2024-11-11T10:37:11Z","title":"A Unified Multi-Task Learning Architecture for Hate Detection Leveraging\n  User-Based Information","summary":"  Hate speech, offensive language, aggression, racism, sexism, and other\nabusive language are common phenomena in social media. There is a need for\nArtificial Intelligence(AI)based intervention which can filter hate content at\nscale. Most existing hate speech detection solutions have utilized the features\nby treating each post as an isolated input instance for the classification.\nThis paper addresses this issue by introducing a unique model that improves\nhate speech identification for the English language by utilising intra-user and\ninter-user-based information. The experiment is conducted over single-task\nlearning (STL) and multi-task learning (MTL) paradigms that use deep neural\nnetworks, such as convolutional neural networks (CNN), gated recurrent unit\n(GRU), bidirectional encoder representations from the transformer (BERT), and A\nLite BERT (ALBERT). We use three benchmark datasets and conclude that combining\ncertain user features with textual features gives significant improvements in\nmacro-F1 and weighted-F1.\n","authors":["Prashant Kapil","Asif Ekbal"],"pdf_url":"https://arxiv.org/pdf/2411.06855v2.pdf","comment":"7 pages, 1 figure, and two tables. Accepted at the 20th International\n  Conference on Natural Language Processing (ICON) 2023.\n  https://aclanthology.org/2023.icon-1.53"},{"id":"http://arxiv.org/abs/2411.07892v1","updated":"2024-11-12T15:56:48Z","published":"2024-11-12T15:56:48Z","title":"Mapping the Podcast Ecosystem with the Structured Podcast Research\n  Corpus","summary":"  Podcasts provide highly diverse content to a massive listener base through a\nunique on-demand modality. However, limited data has prevented large-scale\ncomputational analysis of the podcast ecosystem. To fill this gap, we introduce\na massive dataset of over 1.1M podcast transcripts that is largely\ncomprehensive of all English language podcasts available through public RSS\nfeeds from May and June of 2020. This data is not limited to text, but rather\nincludes audio features and speaker turns for a subset of 370K episodes, and\nspeaker role inferences and other metadata for all 1.1M episodes. Using this\ndata, we also conduct a foundational investigation into the content, structure,\nand responsiveness of this ecosystem. Together, our data and analyses open the\ndoor to continued computational research of this popular and impactful medium.\n","authors":["Benjamin Litterer","David Jurgens","Dallas Card"],"pdf_url":"https://arxiv.org/pdf/2411.07892v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.05508v2","updated":"2024-11-12T15:36:04Z","published":"2024-11-08T12:08:17Z","title":"An Early FIRST Reproduction and Improvements to Single-Token Decoding\n  for Fast Listwise Reranking","summary":"  Recent advances have demonstrated that large language models (LLMs) excel as\nlistwise rerankers, but their high computational demands remain a barrier to\nwidespread adoption. Further, the traditional language modeling (LM) objective\nis not ideally suited for reranking tasks. FIRST is a novel approach that\naddresses these challenges by integrating a learning-to-rank objective and\nleveraging the logits of only the first generated token, thereby significantly\nreducing inference latency compared to traditional LLM rerankers. In this\nstudy, we extend the evaluation of FIRST to the TREC Deep Learning datasets\n(DL19-22), validating its robustness across diverse domains. We investigate the\ninfluence of different first-stage retrievers on FIRST rerankers, observing\ndiminishing returns and patterns consistent with traditional LLM rerankers.\nThrough applying the FIRST objective to a broader range of backbone models, we\nachieve effectiveness surpassing the original implementation. Our experiments\nconfirm that fast reranking with single-token logits does not compromise\nout-of-domain reranking quality. To better quantify the computational savings\nin the original study, we measure and compare latency to find a 21%-42% gain\nacross various models and benchmarks. Moreover, while LM training implicitly\nimproves zero-shot single-token reranking, our experiments also raise questions\nabout whether LM pre-training may hinder subsequent fine-tuning with the FIRST\nobjective. These findings pave the way for more efficient and effective\nlistwise reranking in future applications.\n","authors":["Zijian Chen","Ronak Pradeep","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05508v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07870v1","updated":"2024-11-12T15:26:17Z","published":"2024-11-12T15:26:17Z","title":"Trustful LLMs: Customizing and Grounding Text Generation with Knowledge\n  Bases and Dual Decoders","summary":"  Although people are impressed by the content generation skills of large\nlanguage models, the use of LLMs, such as ChatGPT, is limited by the domain\ngrounding of the content. The correctness and groundedness of the generated\ncontent need to be based on a verified context, such as results from\nRetrieval-Augmented Generation (RAG). One important issue when adapting LLMs to\na customized domain is that the generated responses are often incomplete, or\nthe additions are not verified and may even be hallucinated. Prior studies on\nhallucination detection have focused on evaluation metrics, which are not\neasily adaptable to dynamic domains and can be vulnerable to attacks like\njail-breaking. In this work, we propose 1) a post-processing algorithm that\nleverages knowledge triplets in RAG context to correct hallucinations and 2) a\ndual-decoder model that fuses RAG context to guide the generation process.\n","authors":["Xiaofeng Zhu","Jaya Krishna Mandivarapu"],"pdf_url":"https://arxiv.org/pdf/2411.07870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07858v1","updated":"2024-11-12T15:15:20Z","published":"2024-11-12T15:15:20Z","title":"Verbosity $\\neq$ Veracity: Demystify Verbosity Compensation Behavior of\n  Large Language Models","summary":"  When unsure about an answer, humans often respond with more words than\nnecessary, hoping that part of the response will be correct. We observe a\nsimilar behavior in large language models (LLMs), which we term \"Verbosity\nCompensation\" (VC). VC is harmful because it confuses the user understanding,\nleading to low efficiency, and influences the LLM services by increasing the\nlatency and cost of generating useless tokens. In this paper, we present the\nfirst work that defines and analyzes Verbosity Compensation, explores its\ncauses, and proposes a simple mitigating approach. We define Verbosity\nCompensation as the behavior of generating responses that can be compressed\nwithout information loss when prompted to write concisely. Our experiments,\nconducted on five datasets of knowledge and reasoning-based QA tasks with 14\nnewly developed LLMs, reveal three conclusions. 1) We reveal a pervasive\npresence of verbosity compensation across all models and all datasets. Notably,\nGPT-4 exhibits a VC frequency of 50.40%. 2) We reveal the large performance gap\nbetween verbose and concise responses, with a notable difference of 27.61% on\nthe Qasper dataset. We also demonstrate that this difference does not naturally\ndiminish as LLM capability increases. Both 1) and 2) highlight the urgent need\nto mitigate the frequency of VC behavior and disentangle verbosity with\nveracity. We propose a simple yet effective cascade algorithm that replaces the\nverbose responses with the other model-generated responses. The results show\nthat our approach effectively alleviates the VC of the Mistral model from\n63.81% to 16.16% on the Qasper dataset. 3) We also find that verbose responses\nexhibit higher uncertainty across all five datasets, suggesting a strong\nconnection between verbosity and model uncertainty. Our dataset and code are\navailable at https://github.com/psunlpgroup/VerbosityLLM.\n","authors":["Yusen Zhang","Sarkar Snigdha Sarathi Das","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07858v1.pdf","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.07854v1","updated":"2024-11-12T15:06:06Z","published":"2024-11-12T15:06:06Z","title":"Tucano: Advancing Neural Text Generation for Portuguese","summary":"  Significant advances have been made in natural language processing in recent\nyears. However, our current deep learning approach to language modeling\nrequires substantial resources in terms of data and computation. One of the\nside effects of this data-hungry paradigm is the current schism between\nlanguages, separating those considered high-resource, where most of the\ndevelopment happens and resources are available, and the low-resource ones,\nwhich struggle to attain the same level of performance and autonomy. This study\naims to introduce a new set of resources to stimulate the future development of\nneural text generation in Portuguese. In this work, we document the development\nof GigaVerbo, a concatenation of deduplicated Portuguese text corpora amounting\nto 200 billion tokens. Via this corpus, we trained a series of\ndecoder-transformers named Tucano. Our models perform equal or superior to\nother Portuguese and multilingual language models of similar size in several\nPortuguese benchmarks. The evaluation of our models also reveals that model\nperformance on many currently available benchmarks used by the Portuguese NLP\ncommunity has little to no correlation with the scaling of token ingestion\nduring training, highlighting the limitations of such evaluations when it comes\nto the assessment of Portuguese generative language models. All derivatives of\nour study are openly released on GitHub and Hugging Face. See\nhttps://nkluge-correa.github.io/Tucano/\n","authors":["Nicholas Kluge Corr√™a","Aniket Sen","Sophia Falk","Shiza Fatimah"],"pdf_url":"https://arxiv.org/pdf/2411.07854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07850v1","updated":"2024-11-12T15:01:47Z","published":"2024-11-12T15:01:47Z","title":"IAE: Irony-based Adversarial Examples for Sentiment Analysis Systems","summary":"  Adversarial examples, which are inputs deliberately perturbed with\nimperceptible changes to induce model errors, have raised serious concerns for\nthe reliability and security of deep neural networks (DNNs). While adversarial\nattacks have been extensively studied in continuous data domains such as\nimages, the discrete nature of text presents unique challenges. In this paper,\nwe propose Irony-based Adversarial Examples (IAE), a method that transforms\nstraightforward sentences into ironic ones to create adversarial text. This\napproach exploits the rhetorical device of irony, where the intended meaning is\nopposite to the literal interpretation, requiring a deeper understanding of\ncontext to detect. The IAE method is particularly challenging due to the need\nto accurately locate evaluation words, substitute them with appropriate\ncollocations, and expand the text with suitable ironic elements while\nmaintaining semantic coherence. Our research makes the following key\ncontributions: (1) We introduce IAE, a strategy for generating textual\nadversarial examples using irony. This method does not rely on pre-existing\nirony corpora, making it a versatile tool for creating adversarial text in\nvarious NLP tasks. (2) We demonstrate that the performance of several\nstate-of-the-art deep learning models on sentiment analysis tasks significantly\ndeteriorates when subjected to IAE attacks. This finding underscores the\nsusceptibility of current NLP systems to adversarial manipulation through\nirony. (3) We compare the impact of IAE on human judgment versus NLP systems,\nrevealing that humans are less susceptible to the effects of irony in text.\n","authors":["Xiaoyin Yi","Jiacheng Huang"],"pdf_url":"https://arxiv.org/pdf/2411.07850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07845v1","updated":"2024-11-12T14:53:12Z","published":"2024-11-12T14:53:12Z","title":"Ethical Concern Identification in NLP: A Corpus of ACL Anthology Ethics\n  Statements","summary":"  What ethical concerns, if any, do LLM researchers have? We introduce EthiCon,\na corpus of 1,580 ethical concern statements extracted from scientific papers\npublished in the ACL Anthology. We extract ethical concern keywords from the\nstatements and show promising results in automating the concern identification\nprocess. Through a survey, we compare the ethical concerns of the corpus to the\nconcerns listed by the general public and professionals in the field. Finally,\nwe compare our retrieved ethical concerns with existing taxonomies pointing to\ngaps and future research directions.\n","authors":["Antonia Karamolegkou","Sandrine Schiller Hansen","Ariadni Christopoulou","Filippos Stamatiou","Anne Lauscher","Anders S√∏gaard"],"pdf_url":"https://arxiv.org/pdf/2411.07845v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07843v1","updated":"2024-11-12T14:51:41Z","published":"2024-11-12T14:51:41Z","title":"Chain Association-based Attacking and Shielding Natural Language\n  Processing Systems","summary":"  Association as a gift enables people do not have to mention something in\ncompletely straightforward words and allows others to understand what they\nintend to refer to. In this paper, we propose a chain association-based\nadversarial attack against natural language processing systems, utilizing the\ncomprehension gap between humans and machines. We first generate a chain\nassociation graph for Chinese characters based on the association paradigm for\nbuilding search space of potential adversarial examples. Then, we introduce an\ndiscrete particle swarm optimization algorithm to search for the optimal\nadversarial examples. We conduct comprehensive experiments and show that\nadvanced natural language processing models and applications, including large\nlanguage models, are vulnerable to our attack, while humans appear good at\nunderstanding the perturbed text. We also explore two methods, including\nadversarial training and associative graph-based recovery, to shield systems\nfrom chain association-based attack. Since a few examples that use some\nderogatory terms, this paper contains materials that may be offensive or\nupsetting to some people.\n","authors":["Jiacheng Huang","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07843v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20178v2","updated":"2024-11-12T14:45:18Z","published":"2024-10-26T13:19:57Z","title":"LLMs Can Evolve Continually on Modality for X-Modal Reasoning","summary":"  Multimodal Large Language Models (MLLMs) have gained significant attention\ndue to their impressive capabilities in multimodal understanding. However,\nexisting methods rely heavily on extensive modal-specific pretraining and\njoint-modal tuning, leading to significant computational burdens when expanding\nto new modalities. In this paper, we propose PathWeave, a flexible and scalable\nframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs\nto continually EVolve on modalities for $\\mathbb{X}$-modal reasoning. We\nleverage the concept of Continual Learning and develop an incremental training\nstrategy atop pre-trained MLLMs, enabling their expansion to new modalities\nusing uni-modal data, without executing joint-modal pretraining. In detail, a\nnovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and\ncross-modal adapters are seamlessly integrated to facilitate efficient modality\nalignment and collaboration. Additionally, an MoE-based gating module is\napplied between two types of adapters to further enhance the multimodal\ninteraction. To investigate the proposed method, we establish a challenging\nbenchmark called Continual Learning of Modality (MCL), which consists of\nhigh-quality QA data from five distinct modalities: image, video, audio, depth\nand point cloud. Extensive experiments demonstrate the effectiveness of the\nproposed AnA framework on learning plasticity and memory stability during\ncontinual learning. Furthermore, PathWeave performs comparably to\nstate-of-the-art MLLMs while concurrently reducing parameter training burdens\nby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave\n","authors":["Jiazuo Yu","Haomiao Xiong","Lu Zhang","Haiwen Diao","Yunzhi Zhuge","Lanqing Hong","Dong Wang","Huchuan Lu","You He","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2410.20178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06008v2","updated":"2024-11-12T14:30:28Z","published":"2024-11-08T23:02:59Z","title":"The Dark Patterns of Personalized Persuasion in Large Language Models:\n  Exposing Persuasive Linguistic Features for Big Five Personality Traits in\n  LLMs Responses","summary":"  This study explores how the Large Language Models (LLMs) adjust linguistic\nfeatures to create personalized persuasive outputs. While research showed that\nLLMs personalize outputs, a gap remains in understanding the linguistic\nfeatures of their persuasive capabilities. We identified 13 linguistic features\ncrucial for influencing personalities across different levels of the Big Five\nmodel of personality. We analyzed how prompts with personality trait\ninformation influenced the output of 19 LLMs across five model families. The\nfindings show that models use more anxiety-related words for neuroticism,\nincrease achievement-related words for conscientiousness, and employ fewer\ncognitive processes words for openness to experience. Some model families excel\nat adapting language for openness to experience, others for conscientiousness,\nwhile only one model adapts language for neuroticism. Our findings show how\nLLMs tailor responses based on personality cues in prompts, indicating their\npotential to create persuasive content affecting the mind and well-being of the\nrecipients.\n","authors":["Wiktoria Mieleszczenko-Kowszewicz","Dawid P≈Çudowski","Filip Ko≈Çodziejczyk","Jakub ≈öwistak","Julian Sienkiewicz","Przemys≈Çaw Biecek"],"pdf_url":"https://arxiv.org/pdf/2411.06008v2.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2411.07820v1","updated":"2024-11-12T14:12:45Z","published":"2024-11-12T14:12:45Z","title":"Query Optimization for Parametric Knowledge Refinement in\n  Retrieval-Augmented Large Language Models","summary":"  We introduce the \\textit{Extract-Refine-Retrieve-Read} (ERRR) framework, a\nnovel approach designed to bridge the pre-retrieval information gap in\nRetrieval-Augmented Generation (RAG) systems through query optimization\ntailored to meet the specific knowledge requirements of Large Language Models\n(LLMs). Unlike conventional query optimization techniques used in RAG, the ERRR\nframework begins by extracting parametric knowledge from LLMs, followed by\nusing a specialized query optimizer for refining these queries. This process\nensures the retrieval of only the most pertinent information essential for\ngenerating accurate responses. Moreover, to enhance flexibility and reduce\ncomputational costs, we propose a trainable scheme for our pipeline that\nutilizes a smaller, tunable model as the query optimizer, which is refined\nthrough knowledge distillation from a larger teacher model. Our evaluations on\nvarious question-answering (QA) datasets and with different retrieval systems\nshow that ERRR consistently outperforms existing baselines, proving to be a\nversatile and cost-effective module for improving the utility and accuracy of\nRAG systems.\n","authors":["Youan Cong","Cheng Wang","Pritom Saha Akash","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2411.07820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.05894v3","updated":"2024-11-12T14:06:49Z","published":"2024-05-09T16:45:27Z","title":"Efficient LLM Comparative Assessment: a Product of Experts Framework for\n  Pairwise Comparisons","summary":"  LLM-as-a-judge approaches are a practical and effective way of assessing a\nrange of text tasks. However, when using pairwise comparisons to rank a set of\ncandidates, the computational cost scales quadratically with the number of\ncandidates, which has practical limitations. This paper introduces a Product of\nExpert (PoE) framework for efficient LLM Comparative Assessment. Here\nindividual comparisons are considered experts that provide information on a\npair's score difference. The PoE framework combines the information from these\nexperts to yield an expression that can be maximized with respect to the\nunderlying set of candidates, and is highly flexible where any form of expert\ncan be assumed. When Gaussian experts are used one can derive simple\nclosed-form solutions for the optimal candidate ranking, and expressions for\nselecting which comparisons should be made to maximize the probability of this\nranking. Our approach enables efficient comparative assessment, where by using\nonly a small subset of the possible comparisons, one can generate score\npredictions that correlate well with human judgements. We evaluate the approach\non multiple NLG tasks and demonstrate that our framework can yield considerable\ncomputational savings when performing pairwise comparative assessment. With\nmany candidate texts, using as few as 2% of comparisons the PoE solution can\nachieve similar performance to when all comparisons are used.\n","authors":["Adian Liusie","Vatsal Raina","Yassir Fathullah","Mark Gales"],"pdf_url":"https://arxiv.org/pdf/2405.05894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12186v3","updated":"2024-11-12T13:24:25Z","published":"2024-09-18T17:57:57Z","title":"Qwen2.5-Coder Technical Report","summary":"  In this report, we introduce the Qwen2.5-Coder series, a significant upgrade\nfrom its predecessor, CodeQwen1.5. This series includes six models:\nQwen2.5-Coder-(0.5B/1.5B/3B/7B/14B/32B). As a code-specific model,\nQwen2.5-Coder is built upon the Qwen2.5 architecture and continues pretrained\non a vast corpus of over 5.5 trillion tokens. Through meticulous data cleaning,\nscalable synthetic data generation, and balanced data mixing, Qwen2.5-Coder\ndemonstrates impressive code generation capabilities while retaining general\nand math skills. These models have been evaluated on a wide range of\ncode-related tasks, achieving state-of-the-art (SOTA) performance across more\nthan 10 benchmarks, including code generation, completion, reasoning, and\nrepair, consistently outperforming larger models of the same model size. We\nbelieve that the release of the Qwen2.5-Coder series will advance research in\ncode intelligence and, with its permissive licensing, support wider adoption by\ndevelopers in real-world applications.\n","authors":["Binyuan Hui","Jian Yang","Zeyu Cui","Jiaxi Yang","Dayiheng Liu","Lei Zhang","Tianyu Liu","Jiajun Zhang","Bowen Yu","Keming Lu","Kai Dang","Yang Fan","Yichang Zhang","An Yang","Rui Men","Fei Huang","Bo Zheng","Yibo Miao","Shanghaoran Quan","Yunlong Feng","Xingzhang Ren","Xuancheng Ren","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2409.12186v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07773v1","updated":"2024-11-12T13:14:09Z","published":"2024-11-12T13:14:09Z","title":"Likelihood as a Performance Gauge for Retrieval-Augmented Generation","summary":"  Recent work finds that retrieval-augmented generation with large language\nmodels is prone to be influenced by the order of retrieved documents in the\ncontext. However, the lack of in-depth analysis limits the use of this\nphenomenon for prompt engineering in practice. In this study, we posit that\nlikelihoods serve as an effective gauge for language model performance. Through\nexperiments on two question-answering datasets with a variety of\nstate-of-the-art language models, we reveal correlations between answer\naccuracy and the likelihood of the question at both the corpus level and the\ninstance level. In addition, we find that question likelihood can also indicate\nthe position of the task-relevant information in the context. Based on these\nfindings, we propose two methods that use question likelihood as a gauge for\nselecting and constructing prompts that lead to better performance. We\ndemonstrate their effectiveness with experiments. In addition, our\nlikelihood-based methods are efficient, as they only need to compute the\nlikelihood of the input, requiring much fewer language model passes than\nheuristic prompt engineering methods that require generating responses. Our\nanalysis deepens our understanding of how input prompts affect model\nperformance and provides a promising direction for efficient prompt\noptimization.\n","authors":["Tianyu Liu","Jirui Qi","Paul He","Arianna Bisazza","Mrinmaya Sachan","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07773v1.pdf","comment":"Under review at NAACL 2025. Code is available at\n  https://github.com/lyutyuh/poptimizer"},{"id":"http://arxiv.org/abs/2411.07772v1","updated":"2024-11-12T13:13:20Z","published":"2024-11-12T13:13:20Z","title":"Automatic Album Sequencing","summary":"  Album sequencing is a critical part of the album production process.\nRecently, a data-driven approach was proposed that sequences general\ncollections of independent media by extracting the narrative essence of the\nitems in the collections. While this approach implies an album sequencing\ntechnique, it is not widely accessible to a less technical audience, requiring\nadvanced knowledge of machine learning techniques to use. To address this, we\nintroduce a new user-friendly web-based tool that allows a less technical\naudience to upload music tracks, execute this technique in one click, and\nsubsequently presents the result in a clean visualization to the user. To both\nincrease the number of templates available to the user and address shortcomings\nof previous work, we also introduce a new direct transformer-based album\nsequencing method. We find that our more direct method outperforms a random\nbaseline but does not reach the same performance as the narrative essence\napproach. Both methods are included in our web-based user interface, and this\n-- alongside a full copy of our implementation -- is publicly available at\nhttps://github.com/dylanashley/automatic-album-sequencing\n","authors":["Vincent Herrmann","Dylan R. Ashley","J√ºrgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2411.07772v1.pdf","comment":"presented as a late breaking demo in the 25th International Society\n  for Music Information Retrieval Conference; 3 pages in main text, 3 figures\n  in main text; source code available at\n  https://github.com/dylanashley/automatic-album-sequencing"},{"id":"http://arxiv.org/abs/2411.04799v2","updated":"2024-11-12T12:57:58Z","published":"2024-11-07T15:38:25Z","title":"Kwai-STaR: Transform LLMs into State-Transition Reasoners","summary":"  Mathematical reasoning presents a significant challenge to the cognitive\ncapabilities of LLMs. Various methods have been proposed to enhance the\nmathematical ability of LLMs. However, few recognize the value of state\ntransition for LLM reasoning. In this work, we define mathematical\nproblem-solving as a process of transiting from an initial unsolved state to\nthe final resolved state, and propose Kwai-STaR framework, which transforms\nLLMs into State-Transition Reasoners to improve their intuitive reasoning\ncapabilities. Our approach comprises three main steps: (1) Define the state\nspace tailored to the mathematical reasoning. (2) Generate state-transition\ndata based on the state space. (3) Convert original LLMs into State-Transition\nReasoners via a curricular training strategy. Our experiments validate the\neffectiveness of Kwai-STaR in enhancing mathematical reasoning: After training\non the small-scale Kwai-STaR dataset, general LLMs, including Mistral-7B and\nLLaMA-3, achieve considerable performance gain on the GSM8K and GSM-Hard\ndataset. Additionally, the state transition-based design endows Kwai-STaR with\nremarkable training and inference efficiency. Further experiments are underway\nto establish the generality of Kwai-STaR.\n","authors":["Xingyu Lu","Yuhang Hu","Changyi Liu","Tianke Zhang","Zhenyu Yang","Zhixiang Ding","Shengsheng Qian","Meng Du","Ruiwen Kang","Kaiyu Tang","Fan Yang","Tingting Gao","Di Zhang","Hai-Tao Zheng","Bin Wen"],"pdf_url":"https://arxiv.org/pdf/2411.04799v2.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.07763v1","updated":"2024-11-12T12:52:17Z","published":"2024-11-12T12:52:17Z","title":"Spider 2.0: Evaluating Language Models on Real-World Enterprise\n  Text-to-SQL Workflows","summary":"  Real-world enterprise text-to-SQL workflows often involve complex cloud or\nlocal data across various database systems, multiple SQL queries in various\ndialects, and diverse operations from data transformation to analytics. We\nintroduce Spider 2.0, an evaluation framework comprising 632 real-world\ntext-to-SQL workflow problems derived from enterprise-level database use cases.\nThe databases in Spider 2.0 are sourced from real data applications, often\ncontaining over 1,000 columns and stored in local or cloud database systems\nsuch as BigQuery and Snowflake. We show that solving problems in Spider 2.0\nfrequently requires understanding and searching through database metadata,\ndialect documentation, and even project-level codebases. This challenge calls\nfor models to interact with complex SQL workflow environments, process\nextremely long contexts, perform intricate reasoning, and generate multiple SQL\nqueries with diverse operations, often exceeding 100 lines, which goes far\nbeyond traditional text-to-SQL challenges. Our evaluations indicate that based\non o1-preview, our code agent framework successfully solves only 17.0% of the\ntasks, compared with 91.2% on Spider 1.0 and 73.0% on BIRD. Our results on\nSpider 2.0 show that while language models have demonstrated remarkable\nperformance in code generation -- especially in prior text-to-SQL benchmarks --\nthey require significant improvement in order to achieve adequate performance\nfor real-world enterprise usage. Progress on Spider 2.0 represents crucial\nsteps towards developing intelligent, autonomous, code agents for real-world\nenterprise settings. Our code, baseline models, and data are available at\nhttps://spider2-sql.github.io.\n","authors":["Fangyu Lei","Jixuan Chen","Yuxiao Ye","Ruisheng Cao","Dongchan Shin","Hongjin Su","Zhaoqing Suo","Hongcheng Gao","Wenjing Hu","Pengcheng Yin","Victor Zhong","Caiming Xiong","Ruoxi Sun","Qian Liu","Sida Wang","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2411.07763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00722v2","updated":"2024-11-12T11:49:33Z","published":"2024-04-26T11:57:21Z","title":"LLMs for Generating and Evaluating Counterfactuals: A Comprehensive\n  Study","summary":"  As NLP models become more complex, understanding their decisions becomes more\ncrucial. Counterfactuals (CFs), where minimal changes to inputs flip a model's\nprediction, offer a way to explain these models. While Large Language Models\n(LLMs) have shown remarkable performance in NLP tasks, their efficacy in\ngenerating high-quality CFs remains uncertain. This work fills this gap by\ninvestigating how well LLMs generate CFs for two NLU tasks. We conduct a\ncomprehensive comparison of several common LLMs, and evaluate their CFs,\nassessing both intrinsic metrics, and the impact of these CFs on data\naugmentation. Moreover, we analyze differences between human and LLM-generated\nCFs, providing insights for future research directions. Our results show that\nLLMs generate fluent CFs, but struggle to keep the induced changes minimal.\nGenerating CFs for Sentiment Analysis (SA) is less challenging than NLI where\nLLMs show weaknesses in generating CFs that flip the original label. This also\nreflects on the data augmentation performance, where we observe a large gap\nbetween augmenting with human and LLMs CFs. Furthermore, we evaluate LLMs'\nability to assess CFs in a mislabelled data setting, and show that they have a\nstrong bias towards agreeing with the provided labels. GPT4 is more robust\nagainst this bias and its scores correlate well with automatic metrics. Our\nfindings reveal several limitations and point to potential future work\ndirections.\n","authors":["Van Bach Nguyen","Paul Youssef","Christin Seifert","J√∂rg Schl√∂tterer"],"pdf_url":"https://arxiv.org/pdf/2405.00722v2.pdf","comment":"Accepted to EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2405.07863v3","updated":"2024-11-12T11:18:43Z","published":"2024-05-13T15:50:39Z","title":"RLHF Workflow: From Reward Modeling to Online RLHF","summary":"  We present the workflow of Online Iterative Reinforcement Learning from Human\nFeedback (RLHF) in this technical report, which is widely reported to\noutperform its offline counterpart by a large margin in the recent large\nlanguage model (LLM) literature. However, existing open-source RLHF projects\nare still largely confined to the offline learning setting. In this technical\nreport, we aim to fill in this gap and provide a detailed recipe that is easy\nto reproduce for online iterative RLHF. In particular, since online human\nfeedback is usually infeasible for open-source communities with limited\nresources, we start by constructing preference models using a diverse set of\nopen-source datasets and use the constructed proxy preference model to\napproximate human feedback. Then, we discuss the theoretical insights and\nalgorithmic principles behind online iterative RLHF, followed by a detailed\npractical implementation. Our trained LLM achieves impressive performance on\nLLM chatbot benchmarks, including AlpacaEval-2, Arena-Hard, and MT-Bench, as\nwell as other academic benchmarks such as HumanEval and TruthfulQA. We have\nshown that supervised fine-tuning (SFT) and iterative RLHF can obtain\nstate-of-the-art performance with fully open-source datasets. Further, we have\nmade our models, curated datasets, and comprehensive step-by-step code\nguidebooks publicly available. Please refer to\nhttps://github.com/RLHFlow/RLHF-Reward-Modeling and\nhttps://github.com/RLHFlow/Online-RLHF for more detailed information.\n","authors":["Hanze Dong","Wei Xiong","Bo Pang","Haoxiang Wang","Han Zhao","Yingbo Zhou","Nan Jiang","Doyen Sahoo","Caiming Xiong","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.07863v3.pdf","comment":"Published in Transactions on Machine Learning Research (09/2024)"},{"id":"http://arxiv.org/abs/2407.14192v2","updated":"2024-11-12T11:09:35Z","published":"2024-07-19T10:40:10Z","title":"LeKUBE: A Legal Knowledge Update BEnchmark","summary":"  Recent advances in Large Language Models (LLMs) have significantly shaped the\napplications of AI in multiple fields, including the studies of legal\nintelligence. Trained on extensive legal texts, including statutes and legal\ndocuments, the legal LLMs can capture important legal knowledge/concepts\neffectively and provide important support for downstream legal applications\nsuch as legal consultancy. Yet, the dynamic nature of legal statutes and\ninterpretations also poses new challenges to the use of LLMs in legal\napplications. Particularly, how to update the legal knowledge of LLMs\neffectively and efficiently has become an important research problem in\npractice. Existing benchmarks for evaluating knowledge update methods are\nmostly designed for the open domain and cannot address the specific challenges\nof the legal domain, such as the nuanced application of new legal knowledge,\nthe complexity and lengthiness of legal regulations, and the intricate nature\nof legal reasoning. To address this gap, we introduce the Legal Knowledge\nUpdate BEnchmark, i.e. LeKUBE, which evaluates knowledge update methods for\nlegal LLMs across five dimensions. Specifically, we categorize the needs of\nknowledge updates in the legal domain with the help of legal professionals, and\nthen hire annotators from law schools to create synthetic updates to the\nChinese Criminal and Civil Code as well as sets of questions of which the\nanswers would change after the updates. Through a comprehensive evaluation of\nstate-of-the-art knowledge update methods, we reveal a notable gap between\nexisting knowledge update methods and the unique needs of the legal domain,\nemphasizing the need for further research and development of knowledge update\nmechanisms tailored for legal LLMs.\n","authors":["Changyue Wang","Weihang Su","Hu Yiran","Qingyao Ai","Yueyue Wu","Cheng Luo","Yiqun Liu","Min Zhang","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2407.14192v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12036v2","updated":"2024-11-12T10:12:49Z","published":"2024-07-01T05:37:17Z","title":"Exploring Advanced Large Language Models with LLMsuite","summary":"  This tutorial explores the advancements and challenges in the development of\nLarge Language Models (LLMs) such as ChatGPT and Gemini. It addresses inherent\nlimitations like temporal knowledge cutoffs, mathematical inaccuracies, and the\ngeneration of incorrect information, proposing solutions like Retrieval\nAugmented Generation (RAG), Program-Aided Language Models (PAL), and frameworks\nsuch as ReAct and LangChain. The integration of these techniques enhances LLM\nperformance and reliability, especially in multi-step reasoning and complex\ntask execution. The paper also covers fine-tuning strategies, including\ninstruction fine-tuning, parameter-efficient methods like LoRA, and\nReinforcement Learning from Human Feedback (RLHF) as well as Reinforced\nSelf-Training (ReST). Additionally, it provides a comprehensive survey of\ntransformer architectures and training techniques for LLMs. The source code can\nbe accessed by contacting the author via email for a request.\n","authors":["Giorgio Roffo"],"pdf_url":"https://arxiv.org/pdf/2407.12036v2.pdf","comment":"Keywords: Language Model Benchmarking, Pre-Trained LLM Comparison,\n  LLM Performance Analysis, NLP Model Evaluation Tools, Public Dataset\n  Inference for LLMs, BLEU and ROUGE Metrics for LLM, Open Source LLM Testing\n  Tools, Large Language Model Evaluation Software, NLP Benchmarking Suite,\n  Comprehensive LLM Evaluation Toolkit"},{"id":"http://arxiv.org/abs/2406.16620v3","updated":"2024-11-12T10:02:12Z","published":"2024-06-24T13:05:39Z","title":"OmAgent: A Multi-modal Agent Framework for Complex Video Understanding\n  with Task Divide-and-Conquer","summary":"  Recent advancements in Large Language Models (LLMs) have expanded their\ncapabilities to multimodal contexts, including comprehensive video\nunderstanding. However, processing extensive videos such as 24-hour CCTV\nfootage or full-length films presents significant challenges due to the vast\ndata and processing demands. Traditional methods, like extracting key frames or\nconverting frames to text, often result in substantial information loss. To\naddress these shortcomings, we develop OmAgent, efficiently stores and\nretrieves relevant video frames for specific queries, preserving the detailed\ncontent of videos. Additionally, it features an Divide-and-Conquer Loop capable\nof autonomous reasoning, dynamically invoking APIs and tools to enhance query\nprocessing and accuracy. This approach ensures robust video understanding,\nsignificantly reducing information loss. Experimental results affirm OmAgent's\nefficacy in handling various types of videos and complex tasks. Moreover, we\nhave endowed it with greater autonomy and a robust tool-calling system,\nenabling it to accomplish even more intricate tasks.\n","authors":["Lu Zhang","Tiancheng Zhao","Heting Ying","Yibo Ma","Kyusong Lee"],"pdf_url":"https://arxiv.org/pdf/2406.16620v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07656v1","updated":"2024-11-12T09:14:16Z","published":"2024-11-12T09:14:16Z","title":"Mitigating Bias in Queer Representation within Large Language Models: A\n  Collaborative Agent Approach","summary":"  Large Language Models (LLMs) often perpetuate biases in pronoun usage,\nleading to misrepresentation or exclusion of queer individuals. This paper\naddresses the specific problem of biased pronoun usage in LLM outputs,\nparticularly the inappropriate use of traditionally gendered pronouns (\"he,\"\n\"she\") when inclusive language is needed to accurately represent all\nidentities. We introduce a collaborative agent pipeline designed to mitigate\nthese biases by analyzing and optimizing pronoun usage for inclusivity. Our\nmulti-agent framework includes specialized agents for both bias detection and\ncorrection. Experimental evaluations using the Tango dataset-a benchmark\nfocused on gender pronoun usage-demonstrate that our approach significantly\nimproves inclusive pronoun classification, achieving a 32.6 percentage point\nincrease over GPT-4o in correctly disagreeing with inappropriate traditionally\ngendered pronouns $(\\chi^2 = 38.57, p < 0.0001)$. These results accentuate the\npotential of agent-driven frameworks in enhancing fairness and inclusivity in\nAI-generated content, demonstrating their efficacy in reducing biases and\npromoting socially responsible AI.\n","authors":["Tianyi Huang","Arya Somasundaram"],"pdf_url":"https://arxiv.org/pdf/2411.07656v1.pdf","comment":"NeurIPS 2024 Queer in AI Workshop"},{"id":"http://arxiv.org/abs/2409.18412v3","updated":"2024-11-12T09:11:37Z","published":"2024-09-27T03:00:29Z","title":"SciDFM: A Large Language Model with Mixture-of-Experts for Science","summary":"  Recently, there has been a significant upsurge of interest in leveraging\nlarge language models (LLMs) to assist scientific discovery. However, most LLMs\nonly focus on general science, while they lack domain-specific knowledge, such\nas chemical molecules and amino acid sequences. To bridge these gaps, we\nintroduce SciDFM, a mixture-of-experts LLM, which is trained from scratch and\nis able to conduct college-level scientific reasoning and understand molecules\nand amino acid sequences. We collect a large-scale training corpus containing\nnumerous scientific papers and books from different disciplines as well as data\nfrom domain-specific databases. We further fine-tune the pre-trained model on\nlots of instruction data to improve performances on downstream benchmarks. From\nexperiment results, we show that SciDFM achieves strong performance on general\nscientific benchmarks such as SciEval and SciQ, and it reaches a SOTA\nperformance on domain-specific benchmarks among models of similar size. We\nfurther analyze the expert layers and show that the results of expert selection\nvary with data from different disciplines. To benefit the broader research\ncommunity, we open-source SciDFM at\nhttps://huggingface.co/OpenDFM/SciDFM-MoE-A5.6B-v1.0.\n","authors":["Liangtai Sun","Danyu Luo","Da Ma","Zihan Zhao","Baocai Chen","Zhennan Shen","Su Zhu","Lu Chen","Xin Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2409.18412v3.pdf","comment":"12 pages, 1 figure, 9 tables. Technical Report, accepted by NeurIPS\n  2024 Workshop FM4Science"},{"id":"http://arxiv.org/abs/2404.12866v2","updated":"2024-11-12T08:59:30Z","published":"2024-04-19T13:05:37Z","title":"How Does the Textual Information Affect the Retrieval of Multimodal\n  In-Context Learning?","summary":"  The increase in parameter size of multimodal large language models (MLLMs)\nintroduces significant capabilities, particularly in-context learning, where\nMLLMs enhance task performance without updating pre-trained parameters. This\neffectiveness, however, hinges on the appropriate selection of in-context\nexamples, a process that is currently biased towards visual data, overlooking\ntextual information. Furthermore, the area of supervised retrievers for MLLMs,\ncrucial for optimal in-context example selection, continues to be\nuninvestigated. Our study offers an in-depth evaluation of the impact of\ntextual information on the unsupervised selection of in-context examples in\nmultimodal contexts, uncovering a notable sensitivity of retriever performance\nto the employed modalities. Responding to this, we introduce a novel supervised\nMLLM-retriever MSIER that employs a neural network to select examples that\nenhance multimodal in-context learning efficiency. This approach is validated\nthrough extensive testing across three distinct tasks, demonstrating the\nmethod's effectiveness. Additionally, we investigate the influence of\nmodalities on our supervised retrieval method's training and pinpoint factors\ncontributing to our model's success. This exploration paves the way for future\nadvancements, highlighting the potential for refined in-context learning in\nMLLMs through the strategic use of multimodal data.\n","authors":["Yang Luo","Zangwei Zheng","Zirui Zhu","Yang You"],"pdf_url":"https://arxiv.org/pdf/2404.12866v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2311.10944v5","updated":"2024-11-12T08:31:22Z","published":"2023-11-18T02:44:33Z","title":"Deception Detection from Linguistic and Physiological Data Streams Using\n  Bimodal Convolutional Neural Networks","summary":"  Deception detection is gaining increasing interest due to ethical and\nsecurity concerns. This paper explores the application of convolutional neural\nnetworks for the purpose of multimodal deception detection. We use a dataset\nbuilt by interviewing 104 subjects about two topics, with one truthful and one\nfalsified response from each subject about each topic. In particular, we make\nthree main contributions. First, we extract linguistic and physiological\nfeatures from this data to train and construct the neural network models.\nSecond, we propose a fused convolutional neural network model using both\nmodalities in order to achieve an improved overall performance. Third, we\ncompare our new approach with earlier methods designed for multimodal deception\ndetection. We find that our system outperforms regular classification methods;\nour results indicate the feasibility of using neural networks for deception\ndetection even in the presence of limited amounts of data.\n","authors":["Panfeng Li","Mohamed Abouelenien","Rada Mihalcea","Zhicheng Ding","Qikai Yang","Yiming Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.10944v5.pdf","comment":"Accepted by 2024 5th International Conference on Information Science,\n  Parallel and Distributed Systems"},{"id":"http://arxiv.org/abs/2405.06219v3","updated":"2024-11-12T08:18:45Z","published":"2024-05-10T03:06:24Z","title":"SKVQ: Sliding-window Key and Value Cache Quantization for Large Language\n  Models","summary":"  Large language models (LLMs) can now handle longer sequences of tokens,\nenabling complex tasks like book understanding and generating lengthy novels.\nHowever, the key-value (KV) cache required for LLMs consumes substantial memory\nas context length increasing, becoming the bottleneck for deployment. In this\npaper, we present a strategy called SKVQ, which stands for sliding-window KV\ncache quantization, to address the issue of extremely low bitwidth KV cache\nquantization. To achieve this, SKVQ rearranges the channels of the KV cache in\norder to improve the similarity of channels in quantization groups, and applies\nclipped dynamic quantization at the group level. Additionally, SKVQ ensures\nthat the most recent window tokens in the KV cache are preserved with high\nprecision. This helps maintain the accuracy of a small but important portion of\nthe KV cache.SKVQ achieves high compression ratios while maintaining accuracy.\nOur evaluation on LLMs demonstrates that SKVQ surpasses previous quantization\napproaches, allowing for quantization of the KV cache to 2-bit keys and 1.5-bit\nvalues with minimal loss of accuracy. With SKVQ, it is possible to process\ncontext lengths of up to 1M on an 80GB memory GPU for a 7b model and up to 7\ntimes faster decoding.\n","authors":["Haojie Duanmu","Zhihang Yuan","Xiuhong Li","Jiangfei Duan","Xingcheng Zhang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2405.06219v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07623v1","updated":"2024-11-12T08:10:54Z","published":"2024-11-12T08:10:54Z","title":"Annotating Constructions with UD: the experience of the Italian\n  Constructicon","summary":"  The paper descirbes a first attempt of linking the Italian constructicon to\nUD resources\n","authors":["Ludovica Pannitto","Beatrice Bernasconi","Lucia Busso","Flavio Pisciotta","Giulia Rambelli","Francesca Masini"],"pdf_url":"https://arxiv.org/pdf/2411.07623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07618v1","updated":"2024-11-12T07:54:13Z","published":"2024-11-12T07:54:13Z","title":"Direct Preference Optimization Using Sparse Feature-Level Constraints","summary":"  The alignment of large language models (LLMs) with human preferences remains\na key challenge. While post-training techniques like Reinforcement Learning\nfrom Human Feedback (RLHF) and Direct Preference Optimization (DPO) have\nachieved notable success, they often introduce computational inefficiencies and\ntraining instability. In this paper, we propose Feature-level constrained\nPreference Optimization (FPO), a novel method designed to simplify the\nalignment process while ensuring stability. FPO leverages pre-trained Sparse\nAutoencoders (SAEs) and introduces feature-level constraints, allowing for\nefficient, sparsity-enforced alignment. Our approach enjoys efficiency by using\nsparse features activated in a well-trained sparse autoencoder and the quality\nof sequential KL divergence by using the feature-level offline reference.\nExperimental results on benchmark datasets demonstrate that FPO achieves a\n5.08% absolute improvement in win rate with much lower computational cost\ncompared to state-of-the-art baselines, making it a promising solution for\nefficient and controllable LLM alignments.\n","authors":["Qingyu Yin","Chak Tou Leong","Hongbo Zhang","Minjun Zhu","Hanqi Yan","Qiang Zhang","Yulan He","Wenjie Li","Jun Wang","Yue Zhang","Linyi Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06634v2","updated":"2024-11-12T07:52:33Z","published":"2024-08-13T04:53:31Z","title":"Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM\n  Approach","summary":"  Accurate stock market predictions following earnings reports are crucial for\ninvestors. Traditional methods, particularly classical machine learning models,\nstruggle with these predictions because they cannot effectively process and\ninterpret extensive textual data contained in earnings reports and often\noverlook nuances that influence market movements. This paper introduces an\nadvanced approach by employing Large Language Models (LLMs) instruction\nfine-tuned with a novel combination of instruction-based techniques and\nquantized low-rank adaptation (QLoRA) compression. Our methodology integrates\n'base factors', such as financial metric growth and earnings transcripts, with\n'external factors', including recent market indices performances and analyst\ngrades, to create a rich, supervised dataset. This comprehensive dataset\nenables our models to achieve superior predictive performance in terms of\naccuracy, weighted F1, and Matthews correlation coefficient (MCC), especially\nevident in the comparison with benchmarks such as GPT-4. We specifically\nhighlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases\nsignificant improvements over baseline models. The paper also discusses the\npotential of expanding the output capabilities to include a 'Hold' option and\nextending the prediction horizon, aiming to accommodate various investment\nstyles and time frames. This study not only demonstrates the power of\nintegrating cutting-edge AI with fine-tuned financial data but also paves the\nway for future research in enhancing AI-driven financial analysis tools.\n","authors":["Haowei Ni","Shuchen Meng","Xupeng Chen","Ziqing Zhao","Andi Chen","Panfeng Li","Shiyao Zhang","Qifu Yin","Yuanqing Wang","Yuxi Chan"],"pdf_url":"https://arxiv.org/pdf/2408.06634v2.pdf","comment":"Accepted by 2024 6th International Conference on Data-driven\n  Optimization of Complex Systems"},{"id":"http://arxiv.org/abs/2411.07611v1","updated":"2024-11-12T07:34:56Z","published":"2024-11-12T07:34:56Z","title":"Multimodal Clinical Reasoning through Knowledge-augmented Rationale\n  Generation","summary":"  Clinical rationales play a pivotal role in accurate disease diagnosis;\nhowever, many models predominantly use discriminative methods and overlook the\nimportance of generating supportive rationales. Rationale distillation is a\nprocess that transfers knowledge from large language models (LLMs) to smaller\nlanguage models (SLMs), thereby enhancing the latter's ability to break down\ncomplex tasks. Despite its benefits, rationale distillation alone is inadequate\nfor addressing domain knowledge limitations in tasks requiring specialized\nexpertise, such as disease diagnosis. Effectively embedding domain knowledge in\nSLMs poses a significant challenge. While current LLMs are primarily geared\ntoward processing textual data, multimodal LLMs that incorporate time series\ndata, especially electronic health records (EHRs), are still evolving. To\ntackle these limitations, we introduce ClinRaGen, an SLM optimized for\nmultimodal rationale generation in disease diagnosis. ClinRaGen incorporates a\nunique knowledge-augmented attention mechanism to merge domain knowledge with\ntime series EHR data, utilizing a stepwise rationale distillation strategy to\nproduce both textual and time series-based clinical rationales. Our evaluations\nshow that ClinRaGen markedly improves the SLM's capability to interpret\nmultimodal EHR data and generate accurate clinical rationales, supporting more\nreliable disease diagnosis, advancing LLM applications in healthcare, and\nnarrowing the performance divide between LLMs and SLMs.\n","authors":["Shuai Niu","Jing Ma","Liang Bai","Zhihua Wang","Yida Xu","Yunya Song","Xian Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07611v1.pdf","comment":"11 pages. 4 figures"},{"id":"http://arxiv.org/abs/2411.07602v1","updated":"2024-11-12T07:24:41Z","published":"2024-11-12T07:24:41Z","title":"Circuit Complexity Bounds for RoPE-based Transformer Architecture","summary":"  Characterizing the express power of the Transformer architecture is critical\nto understanding its capacity limits and scaling law. Recent works provide the\ncircuit complexity bounds to Transformer-like architecture. On the other hand,\nRotary Position Embedding ($\\mathsf{RoPE}$) has emerged as a crucial technique\nin modern large language models, offering superior performance in capturing\npositional information compared to traditional position embeddings, which shows\ngreat potential in application prospects, particularly for the long context\nscenario. Empirical evidence also suggests that $\\mathsf{RoPE}$-based\nTransformer architectures demonstrate greater generalization capabilities\ncompared to conventional Transformer models. In this work, we establish a\ntighter circuit complexity bound for Transformers with $\\mathsf{RoPE}$\nattention. Our key contribution is that we show that unless $\\mathsf{TC}^0 =\n\\mathsf{NC}^1$, a $\\mathsf{RoPE}$-based Transformer with\n$\\mathrm{poly}(n)$-precision, $O(1)$ layers, hidden dimension $d \\leq O(n)$\ncannot solve the arithmetic problem or the Boolean formula value problem. This\nresult significantly demonstrates the fundamental limitation of the\nexpressivity of the $\\mathsf{RoPE}$-based Transformer architecture, although it\nachieves giant empirical success. Our theoretical framework not only\nestablishes tighter complexity bounds but also may instruct further work on the\n$\\mathsf{RoPE}$-based Transformer.\n","authors":["Bo Chen","Xiaoyu Li","Yingyu Liang","Jiangxuan Long","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2411.07602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12196v2","updated":"2024-11-12T07:22:21Z","published":"2024-07-16T21:43:47Z","title":"MASIVE: Open-Ended Affective State Identification in English and Spanish","summary":"  In the field of emotion analysis, much NLP research focuses on identifying a\nlimited number of discrete emotion categories, often applied across languages.\nThese basic sets, however, are rarely designed with textual data in mind, and\nculture, language, and dialect can influence how particular emotions are\ninterpreted. In this work, we broaden our scope to a practically unbounded set\nof \\textit{affective states}, which includes any terms that humans use to\ndescribe their experiences of feeling. We collect and publish MASIVE, a dataset\nof Reddit posts in English and Spanish containing over 1,000 unique affective\nstates each. We then define the new problem of \\textit{affective state\nidentification} for language generation models framed as a masked span\nprediction task. On this task, we find that smaller finetuned multilingual\nmodels outperform much larger LLMs, even on region-specific Spanish affective\nstates. Additionally, we show that pretraining on MASIVE improves model\nperformance on existing emotion benchmarks. Finally, through machine\ntranslation experiments, we find that native speaker-written data is vital to\ngood performance on this task.\n","authors":["Nicholas Deas","Elsbeth Turcan","Iv√°n P√©rez Mej√≠a","Kathleen McKeown"],"pdf_url":"https://arxiv.org/pdf/2407.12196v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2404.13565v3","updated":"2024-11-12T07:21:04Z","published":"2024-04-21T07:34:44Z","title":"Exploring Diverse Methods in Visual Question Answering","summary":"  This study explores innovative methods for improving Visual Question\nAnswering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and\nattention mechanisms. Leveraging a balanced VQA dataset, we investigate three\ndistinct strategies. Firstly, GAN-based approaches aim to generate answer\nembeddings conditioned on image and question inputs, showing potential but\nstruggling with more complex tasks. Secondly, autoencoder-based techniques\nfocus on learning optimal embeddings for questions and images, achieving\ncomparable results with GAN due to better ability on complex questions. Lastly,\nattention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB),\naddress language priors and attention modeling, albeit with a\ncomplexity-performance trade-off. This study underscores the challenges and\nopportunities in VQA and suggests avenues for future research, including\nalternative GAN formulations and attentional mechanisms.\n","authors":["Panfeng Li","Qikai Yang","Xieming Geng","Wenjing Zhou","Zhicheng Ding","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13565v3.pdf","comment":"Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence"},{"id":"http://arxiv.org/abs/2411.07598v1","updated":"2024-11-12T07:16:51Z","published":"2024-11-12T07:16:51Z","title":"Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring\n  Conversations","summary":"  Many open-ended conversations (e.g., tutoring lessons or business meetings)\nrevolve around pre-defined reference materials, like worksheets or meeting\nbullets. To provide a framework for studying such conversation structure, we\nintroduce Problem-Oriented Segmentation & Retrieval (POSR), the task of jointly\nbreaking down conversations into segments and linking each segment to the\nrelevant reference item. As a case study, we apply POSR to education where\neffectively structuring lessons around problems is critical yet difficult. We\npresent LessonLink, the first dataset of real-world tutoring lessons, featuring\n3,500 segments, spanning 24,300 minutes of instruction and linked to 116 SAT\nmath problems. We define and evaluate several joint and independent approaches\nfor POSR, including segmentation (e.g., TextTiling), retrieval (e.g., ColBERT),\nand large language models (LLMs) methods. Our results highlight that modeling\nPOSR as one joint task is essential: POSR methods outperform independent\nsegmentation and retrieval pipelines by up to +76% on joint metrics and surpass\ntraditional segmentation methods by up to +78% on segmentation metrics. We\ndemonstrate POSR's practical impact on downstream education applications,\nderiving new insights on the language and time use in real-world lesson\nstructures.\n","authors":["Rose E. Wang","Pawan Wirawarn","Kenny Lam","Omar Khattab","Dorottya Demszky"],"pdf_url":"https://arxiv.org/pdf/2411.07598v1.pdf","comment":"EMNLP 2024 Findings. Our code and dataset are open-sourced at\n  https://github.com/rosewang2008/posr"},{"id":"http://arxiv.org/abs/2411.07595v1","updated":"2024-11-12T07:09:44Z","published":"2024-11-12T07:09:44Z","title":"Entropy Controllable Direct Preference Optimization","summary":"  In the post-training of large language models (LLMs), Reinforcement Learning\nfrom Human Feedback (RLHF) is an effective approach to achieve generation\naligned with human preferences. Direct Preference Optimization (DPO) allows for\npolicy training with a simple binary cross-entropy loss without a reward model.\nThe objective of DPO is regularized by reverse KL divergence that encourages\nmode-seeking fitting to the reference policy. Nonetheless, we indicate that\nminimizing reverse KL divergence could fail to capture a mode of the reference\ndistribution, which may hurt the policy's performance. Based on this\nobservation, we propose a simple modification to DPO, H-DPO, which allows for\ncontrol over the entropy of the resulting policy, enhancing the distribution's\nsharpness and thereby enabling mode-seeking fitting more effectively. In our\nexperiments, we show that H-DPO outperformed DPO across various tasks,\ndemonstrating superior results in pass@$k$ evaluations for mathematical tasks.\nMoreover, H-DPO is simple to implement, requiring only minor modifications to\nthe loss calculation of DPO, which makes it highly practical and promising for\nwide-ranging applications in the training of LLMs.\n","authors":["Motoki Omura","Yasuhiro Fujita","Toshiki Kataoka"],"pdf_url":"https://arxiv.org/pdf/2411.07595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09059v2","updated":"2024-11-12T06:15:50Z","published":"2024-03-14T02:56:38Z","title":"LAMP: A Language Model on the Map","summary":"  Large Language Models (LLMs) are poised to play an increasingly important\nrole in our lives, providing assistance across a wide array of tasks. In the\ngeospatial domain, LLMs have demonstrated the ability to answer generic\nquestions, such as identifying a country's capital; nonetheless, their utility\nis hindered when it comes to answering fine-grained questions about specific\nplaces, such as grocery stores or restaurants, which constitute essential\naspects of people's everyday lives. This is mainly because the places in our\ncities haven't been systematically fed into LLMs, so as to understand and\nmemorize them. This study introduces a novel framework for fine-tuning a\npre-trained model on city-specific data, to enable it to provide accurate\nrecommendations, while minimizing hallucinations. We share our model, LAMP, and\nthe data used to train it. We conduct experiments to analyze its ability to\ncorrectly retrieving spatial objects, and compare it to well-known open- and\nclosed- source language models, such as GPT-4. Finally, we explore its emerging\ncapabilities through a case study on day planning.\n","authors":["Pasquale Balsebre","Weiming Huang","Gao Cong"],"pdf_url":"https://arxiv.org/pdf/2403.09059v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05990v2","updated":"2024-11-12T05:46:46Z","published":"2024-11-08T22:02:22Z","title":"Game-theoretic LLM: Agent Workflow for Negotiation Games","summary":"  This paper investigates the rationality of large language models (LLMs) in\nstrategic decision-making contexts, specifically within the framework of game\ntheory. We evaluate several state-of-the-art LLMs across a spectrum of\ncomplete-information and incomplete-information games. Our findings reveal that\nLLMs frequently deviate from rational strategies, particularly as the\ncomplexity of the game increases with larger payoff matrices or deeper\nsequential trees.\n  To address these limitations, we design multiple game-theoretic workflows\nthat guide the reasoning and decision-making processes of LLMs. These workflows\naim to enhance the models' ability to compute Nash Equilibria and make rational\nchoices, even under conditions of uncertainty and incomplete information.\nExperimental results demonstrate that the adoption of these workflows\nsignificantly improves the rationality and robustness of LLMs in game-theoretic\ntasks. Specifically, with the workflow, LLMs exhibit marked improvements in\nidentifying optimal strategies, achieving near-optimal allocations in\nnegotiation scenarios, and reducing susceptibility to exploitation during\nnegotiations. Furthermore, we explore the meta-strategic considerations of\nwhether it is rational for agents to adopt such workflows, recognizing that the\ndecision to use or forgo the workflow constitutes a game-theoretic issue in\nitself.\n  Our research contributes to a deeper understanding of LLMs' decision-making\ncapabilities in strategic contexts and provides insights into enhancing their\nrationality through structured workflows. The findings have implications for\nthe development of more robust and strategically sound AI agents capable of\nnavigating complex interactive environments. Code and data supporting this\nstudy are available at \\url{https://github.com/Wenyueh/game_theory}.\n","authors":["Wenyue Hua","Ollie Liu","Lingyao Li","Alfonso Amayuelas","Julie Chen","Lucas Jiang","Mingyu Jin","Lizhou Fan","Fei Sun","William Wang","Xintong Wang","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05990v2.pdf","comment":"45 pages, 12 figures"},{"id":"http://arxiv.org/abs/2408.11856v2","updated":"2024-11-12T05:37:15Z","published":"2024-08-15T19:13:38Z","title":"Dynamic Adaptive Optimization for Effective Sentiment Analysis\n  Fine-Tuning on Large Language Models","summary":"  Sentiment analysis plays a crucial role in various domains, such as business\nintelligence and financial forecasting. Large language models (LLMs) have\nbecome a popular paradigm for sentiment analysis, leveraging multi-task\nlearning to address specific tasks concurrently. However, LLMs with fine-tuning\nfor sentiment analysis often underperforms due to the inherent challenges in\nmanaging diverse task complexities. Moreover, constant-weight approaches in\nmulti-task learning struggle to adapt to variations in data characteristics,\nfurther complicating model effectiveness. To address these issues, we propose a\nnovel multi-task learning framework with a dynamic adaptive optimization (DAO)\nmodule. This module is designed as a plug-and-play component that can be\nseamlessly integrated into existing models, providing an effective and flexible\nsolution for multi-task learning. The key component of the DAO module is\ndynamic adaptive loss, which dynamically adjusts the weights assigned to\ndifferent tasks based on their relative importance and data characteristics\nduring training. Sentiment analyses on a standard and customized financial text\ndataset demonstrate that the proposed framework achieves superior performance.\nSpecifically, this work improves the Mean Squared Error (MSE) and Accuracy\n(ACC) by 15.58% and 1.24% respectively, compared with previous work.\n","authors":["Hongcheng Ding","Xuanze Zhao","Shamsul Nahar Abdullah","Deshinta Arrova Dewi","Zixiao Jiang","Xiangyu Shi"],"pdf_url":"https://arxiv.org/pdf/2408.11856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10839v3","updated":"2024-11-12T05:33:05Z","published":"2024-06-16T08:20:12Z","title":"Reminding Multimodal Large Language Models of Object-aware Knowledge\n  with Retrieved Tags","summary":"  Despite recent advances in the general visual instruction-following ability\nof Multimodal Large Language Models (MLLMs), they still struggle with critical\nproblems when required to provide a precise and detailed response to a visual\ninstruction: (1) failure to identify novel objects or entities, (2) mention of\nnon-existent objects, and (3) neglect of object's attributed details. Intuitive\nsolutions include improving the size and quality of data or using larger\nfoundation models. They show effectiveness in mitigating these issues, but at\nan expensive cost of collecting a vast amount of new data and introducing a\nsignificantly larger model. Standing at the intersection of these approaches,\nwe examine the three object-oriented problems from the perspective of the\nimage-to-text mapping process by the multimodal connector. In this paper, we\nfirst identify the limitations of multimodal connectors stemming from\ninsufficient training data. Driven by this, we propose to enhance the mapping\nwith retrieval-augmented tag tokens, which contain rich object-aware\ninformation such as object names and attributes. With our Tag-grounded visual\ninstruction tuning with retrieval Augmentation (TUNA), we outperform baselines\nthat share the same language model and training data on 12 benchmarks.\nFurthermore, we show the zero-shot capability of TUNA when provided with\nspecific datastores.\n","authors":["Daiqing Qi","Handong Zhao","Zijun Wei","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.10839v3.pdf","comment":"Main Conference at EMNLP 2024"},{"id":"http://arxiv.org/abs/2401.12585v6","updated":"2024-11-12T05:09:34Z","published":"2024-01-23T09:33:31Z","title":"SLANG: New Concept Comprehension of Large Language Models","summary":"  The dynamic nature of language, particularly evident in the realm of slang\nand memes on the Internet, poses serious challenges to the adaptability of\nlarge language models (LLMs). Traditionally anchored to static datasets, these\nmodels often struggle to keep up with the rapid linguistic evolution\ncharacteristic of online communities. This research aims to bridge this gap by\nenhancing LLMs' comprehension of the evolving new concepts on the Internet,\nwithout the high cost of continual retraining. In pursuit of this goal, we\nintroduce $\\textbf{SLANG}$, a benchmark designed to autonomously integrate\nnovel data and assess LLMs' ability to comprehend emerging concepts, alongside\n$\\textbf{FOCUS}$, an approach uses causal inference to enhance LLMs to\nunderstand new phrases and their colloquial context. Our benchmark and approach\ninvolves understanding real-world instances of linguistic shifts, serving as\ncontextual beacons, to form more precise and contextually relevant connections\nbetween newly emerging expressions and their meanings. The empirical analysis\nshows that our causal inference-based approach outperforms the baseline methods\nin terms of precision and relevance in the comprehension of Internet slang and\nmemes.\n","authors":["Lingrui Mei","Shenghua Liu","Yiwei Wang","Baolong Bi","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2401.12585v6.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2411.07546v1","updated":"2024-11-12T04:50:10Z","published":"2024-11-12T04:50:10Z","title":"Contrastive Language Prompting to Ease False Positives in Medical\n  Anomaly Detection","summary":"  A pre-trained visual-language model, contrastive language-image pre-training\n(CLIP), successfully accomplishes various downstream tasks with text prompts,\nsuch as finding images or localizing regions within the image. Despite CLIP's\nstrong multi-modal data capabilities, it remains limited in specialized\nenvironments, such as medical applications. For this purpose, many CLIP\nvariants-i.e., BioMedCLIP, and MedCLIP-SAMv2-have emerged, but false positives\nrelated to normal regions persist. Thus, we aim to present a simple yet\nimportant goal of reducing false positives in medical anomaly detection. We\nintroduce a Contrastive LAnguage Prompting (CLAP) method that leverages both\npositive and negative text prompts. This straightforward approach identifies\npotential lesion regions by visual attention to the positive prompts in the\ngiven image. To reduce false positives, we attenuate attention on normal\nregions using negative prompts. Extensive experiments with the BMAD dataset,\nincluding six biomedical benchmarks, demonstrate that CLAP method enhances\nanomaly detection performance. Our future plans include developing an automated\nfine prompting method for more practical usage.\n","authors":["YeongHyeon Park","Myung Jin Kim","Hyeong Seok Kim"],"pdf_url":"https://arxiv.org/pdf/2411.07546v1.pdf","comment":"4 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2407.01523v3","updated":"2024-11-12T04:37:44Z","published":"2024-07-01T17:59:26Z","title":"MMLongBench-Doc: Benchmarking Long-context Document Understanding with\n  Visualizations","summary":"  Understanding documents with rich layouts and multi-modal components is a\nlong-standing and practical task. Recent Large Vision-Language Models (LVLMs)\nhave made remarkable strides in various tasks, particularly in single-page\ndocument understanding (DU). However, their abilities on long-context DU remain\nan open problem. This work presents MMLongBench-Doc, a long-context,\nmulti-modal benchmark comprising 1,062 expert-annotated questions. Distinct\nfrom previous datasets, it is constructed upon 130 lengthy PDF-formatted\ndocuments with an average of 49.4 pages and 20,971 textual tokens. Towards\ncomprehensive evaluation, answers to these questions rely on pieces of evidence\nfrom (1) different sources (text, image, chart, table, and layout structure)\nand (2) various locations (i.e. page number). Moreover, 33.2% of the questions\nare cross-page questions requiring evidence across multiple pages. 22.8% of the\nquestions are designed to be unanswerable for detecting potential\nhallucinations. Experiments on 14 LVLMs demonstrate that long-context DU\ngreatly challenges current models. Notably, the best-performing model, GPT-4o,\nachieves an F1 score of only 42.7%, while the second-best, GPT-4V, scores\n31.4%. Furthermore, 12 LVLMs (all except GPT-4o and GPT-4V) even present worse\nperformance than their LLM counterparts which are fed with lossy-parsed OCR\ndocuments. These results validate the necessity of future research toward more\ncapable long-context LVLMs. Project Page:\nhttps://mayubo2333.github.io/MMLongBench-Doc\n","authors":["Yubo Ma","Yuhang Zang","Liangyu Chen","Meiqi Chen","Yizhu Jiao","Xinze Li","Xinyuan Lu","Ziyu Liu","Yan Ma","Xiaoyi Dong","Pan Zhang","Liangming Pan","Yu-Gang Jiang","Jiaqi Wang","Yixin Cao","Aixin Sun"],"pdf_url":"https://arxiv.org/pdf/2407.01523v3.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Spotlight)"},{"id":"http://arxiv.org/abs/2410.09982v3","updated":"2024-11-12T04:20:00Z","published":"2024-10-13T19:53:40Z","title":"Self-Data Distillation for Recovering Quality in Pruned Large Language\n  Models","summary":"  Large language models have driven significant progress in natural language\nprocessing, but their deployment requires substantial compute and memory\nresources. As models scale, compression techniques become essential for\nbalancing model quality with computational efficiency. Structured pruning,\nwhich removes less critical components of the model, is a promising strategy\nfor reducing complexity. However, one-shot pruning often results in significant\nquality degradation, particularly in tasks requiring multi-step reasoning. To\nrecover lost quality, supervised fine-tuning (SFT) is commonly applied, but it\ncan lead to catastrophic forgetting by shifting the model's learned data\ndistribution. Therefore, addressing the degradation from both pruning and SFT\nis essential to preserve the original model's quality. In this work, we utilize\nself-data distilled fine-tuning to address these challenges. Our approach\nleverages the original, unpruned model to generate a distilled dataset that\npreserves semantic richness and mitigates catastrophic forgetting by\nmaintaining alignment with the base model's knowledge. Empirically, we\ndemonstrate that self-data distillation consistently outperforms standard SFT,\nimproving average accuracy by up to 8% on the HuggingFace OpenLLM Leaderboard\nv1. Specifically, when pruning six decoder blocks on Llama3.1-8B Instruct\n(i.e., 32 to 26 layers, reducing the model size from 8.03B to 6.72B\nparameters), our method retains 91.2% of the original model's accuracy compared\nto 81.7% with SFT, while reducing real-world FLOPs by 16.3%. Furthermore,\ncombining self-data distilled models through model merging yields enhanced\nquality retention. Additionally, leveraging these pruned models in speculative\ndecoding increases token acceptance rates, thereby improving inference\nefficiency in applied settings.\n","authors":["Vithursan Thangarasa","Ganesh Venkatesh","Mike Lasby","Nish Sinnadurai","Sean Lie"],"pdf_url":"https://arxiv.org/pdf/2410.09982v3.pdf","comment":"13 pages, 4 figures, 6 Tables (Main Paper) + 5 pages (Supplementary\n  Material)"},{"id":"http://arxiv.org/abs/2411.07533v1","updated":"2024-11-12T04:16:44Z","published":"2024-11-12T04:16:44Z","title":"Large Language Models as Neurolinguistic Subjects: Identifying Internal\n  Representations for Form and Meaning","summary":"  This study investigates the linguistic understanding of Large Language Models\n(LLMs) regarding signifier (form) and signified (meaning) by distinguishing two\nLLM evaluation paradigms: psycholinguistic and neurolinguistic. Traditional\npsycholinguistic evaluations often reflect statistical biases that may\nmisrepresent LLMs' true linguistic capabilities. We introduce a neurolinguistic\napproach, utilizing a novel method that combines minimal pair and diagnostic\nprobing to analyze activation patterns across model layers. This method allows\nfor a detailed examination of how LLMs represent form and meaning, and whether\nthese representations are consistent across languages. Our contributions are\nthree-fold: (1) We compare neurolinguistic and psycholinguistic methods,\nrevealing distinct patterns in LLM assessment; (2) We demonstrate that LLMs\nexhibit higher competence in form compared to meaning, with the latter largely\ncorrelated to the former; (3) We present new conceptual minimal pair datasets\nfor Chinese (COMPS-ZH) and German (COMPS-DE), complementing existing English\ndatasets.\n","authors":["Linyang He","Ercong Nie","Helmut Schmid","Hinrich Sch√ºtze","Nima Mesgarani","Jonathan Brennan"],"pdf_url":"https://arxiv.org/pdf/2411.07533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07070v2","updated":"2024-11-12T04:12:32Z","published":"2024-11-11T15:46:07Z","title":"On Active Privacy Auditing in Supervised Fine-tuning for White-Box\n  Language Models","summary":"  The pretraining and fine-tuning approach has become the leading technique for\nvarious NLP applications. However, recent studies reveal that fine-tuning data,\ndue to their sensitive nature, domain-specific characteristics, and\nidentifiability, pose significant privacy concerns. To help develop more\nprivacy-resilient fine-tuning models, we introduce a novel active privacy\nauditing framework, dubbed Parsing, designed to identify and quantify privacy\nleakage risks during the supervised fine-tuning (SFT) of language models (LMs).\nThe framework leverages improved white-box membership inference attacks (MIAs)\nas the core technology, utilizing novel learning objectives and a two-stage\npipeline to monitor the privacy of the LMs' fine-tuning process, maximizing the\nexposure of privacy risks. Additionally, we have improved the effectiveness of\nMIAs on large LMs including GPT-2, Llama2, and certain variants of them. Our\nresearch aims to provide the SFT community of LMs with a reliable, ready-to-use\nprivacy auditing tool, and to offer valuable insights into safeguarding privacy\nduring the fine-tuning process. Experimental results confirm the framework's\nefficiency across various models and tasks, emphasizing notable privacy\nconcerns in the fine-tuning process. Project code available for\nhttps://anonymous.4open.science/r/PARSING-4817/.\n","authors":["Qian Sun","Hanpeng Wu","Xi Sheryl Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07133v2","updated":"2024-11-12T04:05:54Z","published":"2024-11-11T17:06:48Z","title":"Stronger Models are NOT Stronger Teachers for Instruction Tuning","summary":"  Instruction tuning has been widely adopted to ensure large language models\n(LLMs) follow user instructions effectively. The resulting\ninstruction-following capabilities of LLMs heavily rely on the instruction\ndatasets used for tuning. Recently, synthetic instruction datasets have emerged\nas an economically viable solution to provide LLMs diverse and high-quality\ninstructions. However, existing approaches typically assume that larger or\nstronger models are stronger teachers for instruction tuning, and hence simply\nadopt these models as response generators to the synthetic instructions. In\nthis paper, we challenge this commonly-adopted assumption. Our extensive\nexperiments across five base models and twenty response generators reveal that\nlarger and stronger models are not necessarily stronger teachers of smaller\nmodels. We refer to this phenomenon as the Larger Models' Paradox. We observe\nthat existing metrics cannot precisely predict the effectiveness of response\ngenerators since they ignore the compatibility between teachers and base models\nbeing fine-tuned. We thus develop a novel metric, named as\nCompatibility-Adjusted Reward (CAR) to measure the effectiveness of response\ngenerators. Our experiments across five base models demonstrate that CAR\noutperforms almost all baselines.\n","authors":["Zhangchen Xu","Fengqing Jiang","Luyao Niu","Bill Yuchen Lin","Radha Poovendran"],"pdf_url":"https://arxiv.org/pdf/2411.07133v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07528v1","updated":"2024-11-12T03:56:07Z","published":"2024-11-12T03:56:07Z","title":"SecEncoder: Logs are All You Need in Security","summary":"  Large and Small Language Models (LMs) are typically pretrained using\nextensive volumes of text, which are sourced from publicly accessible platforms\nsuch as Wikipedia, Book Corpus, or through web scraping. These models, due to\ntheir exposure to a wide range of language data, exhibit impressive\ngeneralization capabilities and can perform a multitude of tasks\nsimultaneously. However, they often fall short when it comes to domain-specific\ntasks due to their broad training data. This paper introduces SecEncoder, a\nspecialized small language model that is pretrained using security logs.\nSecEncoder is designed to address the domain-specific limitations of general\nLMs by focusing on the unique language and patterns found in security logs.\nExperimental results indicate that SecEncoder outperforms other LMs, such as\nBERTlarge, DeBERTa-v3-large and OpenAI's Embedding (textembedding-ada-002)\nmodels, which are pretrained mainly on natural language, across various tasks.\nFurthermore, although SecEncoder is primarily pretrained on log data, it\noutperforms models pretrained on natural language for a range of tasks beyond\nlog analysis, such as incident prioritization and threat intelligence document\nretrieval. This suggests that domain specific pretraining with logs can\nsignificantly enhance the performance of LMs in security. These findings pave\nthe way for future research into security-specific LMs and their potential\napplications.\n","authors":["Muhammed Fatih Bulut","Yingqi Liu","Naveed Ahmad","Maximilian Turner","Sami Ait Ouahmane","Cameron Andrews","Lloyd Greenwald"],"pdf_url":"https://arxiv.org/pdf/2411.07528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07527v1","updated":"2024-11-12T03:55:27Z","published":"2024-11-12T03:55:27Z","title":"Prompt-enhanced Network for Hateful Meme Classification","summary":"  The dynamic expansion of social media has led to an inundation of hateful\nmemes on media platforms, accentuating the growing need for efficient\nidentification and removal. Acknowledging the constraints of conventional\nmultimodal hateful meme classification, which heavily depends on external\nknowledge and poses the risk of including irrelevant or redundant content, we\ndeveloped Pen -- a prompt-enhanced network framework based on the prompt\nlearning approach. Specifically, after constructing the sequence through the\nprompt method and encoding it with a language model, we performed region\ninformation global extraction on the encoded sequence for multi-view\nperception. By capturing global information about inference instances and\ndemonstrations, Pen facilitates category selection by fully leveraging sequence\ninformation. This approach significantly improves model classification\naccuracy. Additionally, to bolster the model's reasoning capabilities in the\nfeature space, we introduced prompt-aware contrastive learning into the\nframework to improve the quality of sample feature distributions. Through\nextensive ablation experiments on two public datasets, we evaluate the\neffectiveness of the Pen framework, concurrently comparing it with\nstate-of-the-art model baselines. Our research findings highlight that Pen\nsurpasses manual prompt methods, showcasing superior generalization and\nclassification accuracy in hateful meme classification tasks. Our code is\navailable at https://github.com/juszzi/Pen.\n","authors":["Junxi Liu","Yanyan Feng","Jiehai Chen","Yun Xue","Fenghuan Li"],"pdf_url":"https://arxiv.org/pdf/2411.07527v1.pdf","comment":"Published in Proceedings of the Thirty-Third International Joint\n  Conference on Artificial Intelligence Main Track. Pages 6397-6405"},{"id":"http://arxiv.org/abs/2411.07521v1","updated":"2024-11-12T03:37:53Z","published":"2024-11-12T03:37:53Z","title":"Fair Summarization: Bridging Quality and Diversity in Extractive\n  Summaries","summary":"  Fairness in multi-document summarization of user-generated content remains a\ncritical challenge in natural language processing (NLP). Existing summarization\nmethods often fail to ensure equitable representation across different social\ngroups, leading to biased outputs. In this paper, we introduce two novel\nmethods for fair extractive summarization: FairExtract, a clustering-based\napproach, and FairGPT, which leverages GPT-3.5-turbo with fairness constraints.\nWe evaluate these methods using Divsumm summarization dataset of White-aligned,\nHispanic, and African-American dialect tweets and compare them against relevant\nbaselines. The results obtained using a comprehensive set of summarization\nquality metrics such as SUPERT, BLANC, SummaQA, BARTScore, and UniEval, as well\nas a fairness metric F, demonstrate that FairExtract and FairGPT achieve\nsuperior fairness while maintaining competitive summarization quality.\nAdditionally, we introduce composite metrics (e.g., SUPERT+F, BLANC+F) that\nintegrate quality and fairness into a single evaluation framework, offering a\nmore nuanced understanding of the trade-offs between these objectives. This\nwork highlights the importance of fairness in summarization and sets a\nbenchmark for future research in fairness-aware NLP models.\n","authors":["Sina Bagheri Nezhad","Sayan Bandyapadhyay","Ameeta Agrawal"],"pdf_url":"https://arxiv.org/pdf/2411.07521v1.pdf","comment":"Accepted at Algorithmic Fairness through the Lens of Metrics and\n  Evaluation Workshop @ NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07516v1","updated":"2024-11-12T03:25:33Z","published":"2024-11-12T03:25:33Z","title":"SparrowVQE: Visual Question Explanation for Course Content Understanding","summary":"  Visual Question Answering (VQA) research seeks to create AI systems to answer\nnatural language questions in images, yet VQA methods often yield overly\nsimplistic and short answers. This paper aims to advance the field by\nintroducing Visual Question Explanation (VQE), which enhances the ability of\nVQA to provide detailed explanations rather than brief responses and address\nthe need for more complex interaction with visual content. We first created an\nMLVQE dataset from a 14-week streamed video machine learning course, including\n885 slide images, 110,407 words of transcripts, and 9,416 designed\nquestion-answer (QA) pairs. Next, we proposed a novel SparrowVQE, a small 3\nbillion parameters multimodal model. We trained our model with a three-stage\ntraining mechanism consisting of multimodal pre-training (slide images and\ntranscripts feature alignment), instruction tuning (tuning the pre-trained\nmodel with transcripts and QA pairs), and domain fine-tuning (fine-tuning slide\nimage and QA pairs). Eventually, our SparrowVQE can understand and connect\nvisual information using the SigLIP model with transcripts using the Phi-2\nlanguage model with an MLP adapter. Experimental results demonstrate that our\nSparrowVQE achieves better performance in our developed MLVQE dataset and\noutperforms state-of-the-art methods in the other five benchmark VQA datasets.\nThe source code is available at\n\\url{https://github.com/YoushanZhang/SparrowVQE}.\n","authors":["Jialu Li","Manish Kumar Thota","Ruslan Gokhman","Radek Holik","Youshan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07494v1","updated":"2024-11-12T02:44:49Z","published":"2024-11-12T02:44:49Z","title":"Rapid Response: Mitigating LLM Jailbreaks with a Few Examples","summary":"  As large language models (LLMs) grow more powerful, ensuring their safety\nagainst misuse becomes crucial. While researchers have focused on developing\nrobust defenses, no method has yet achieved complete invulnerability to\nattacks. We propose an alternative approach: instead of seeking perfect\nadversarial robustness, we develop rapid response techniques to look to block\nwhole classes of jailbreaks after observing only a handful of attacks. To study\nthis setting, we develop RapidResponseBench, a benchmark that measures a\ndefense's robustness against various jailbreak strategies after adapting to a\nfew observed examples. We evaluate five rapid response methods, all of which\nuse jailbreak proliferation, where we automatically generate additional\njailbreaks similar to the examples observed. Our strongest method, which\nfine-tunes an input classifier to block proliferated jailbreaks, reduces attack\nsuccess rate by a factor greater than 240 on an in-distribution set of\njailbreaks and a factor greater than 15 on an out-of-distribution set, having\nobserved just one example of each jailbreaking strategy. Moreover, further\nstudies suggest that the quality of proliferation model and number of\nproliferated examples play an key role in the effectiveness of this defense.\nOverall, our results highlight the potential of responding rapidly to novel\njailbreaks to limit LLM misuse.\n","authors":["Alwin Peng","Julian Michael","Henry Sleight","Ethan Perez","Mrinank Sharma"],"pdf_url":"https://arxiv.org/pdf/2411.07494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00774v2","updated":"2024-11-12T02:18:38Z","published":"2024-11-01T17:59:51Z","title":"Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model\n  with Frozen LLM","summary":"  Rapidly developing large language models (LLMs) have brought tremendous\nintelligent applications. GPT-4o's excellent duplex speech interaction ability\nhas recently brought impressive experience to users. Researchers have recently\nproposed several multi-modal LLMs in this direction that can achieve\nspeech-to-speech dialogue. This paper proposes a novel speech-text multimodal\nLLM architecture called Freeze-Omni. Our main contribution is that the speech\ninput and output modalities can be easily connected to a textual LLM while\nkeeping the LLM's parameters frozen throughout the training process. We\ndesigned 3-stage training strategies both for the modeling of speech input and\noutput, enabling Freeze-Omni to obtain speech-to-speech dialogue ability using\ntext-speech paired data (such as ASR and TTS data) and only 60,000 multi-round\ntext Q&A data on 8 GPUs. Moreover, we can effectively ensure that the\nintelligence of the Freeze-Omni in the speech modality is at the same level\ncompared with that in the text modality of its backbone LLM, while the\nend-to-end latency of the spoken response achieves a low level. In addition, we\nalso designed a method to achieve duplex dialogue ability through multi-task\ntraining, making Freeze-Omni have a more natural style of dialogue ability\nbetween the users. Freeze-Omni mainly provides a possibility for researchers to\nconduct multimodal LLM under the condition of a frozen LLM, avoiding various\nimpacts caused by the catastrophic forgetting of LLM caused by fewer data and\ntraining resources.\n","authors":["Xiong Wang","Yangze Li","Chaoyou Fu","Yunhang Shen","Lei Xie","Ke Li","Xing Sun","Long Ma"],"pdf_url":"https://arxiv.org/pdf/2411.00774v2.pdf","comment":"Project Page: https://freeze-omni.github.io/"},{"id":"http://arxiv.org/abs/2409.13755v2","updated":"2024-11-12T02:01:37Z","published":"2024-09-15T10:50:51Z","title":"Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation\n  Extraction in Long Sentences","summary":"  Relation extraction as an important natural Language processing (NLP) task is\nto identify relations between named entities in text. Recently, graph\nconvolutional networks over dependency trees have been widely used to capture\nsyntactic features and achieved attractive performance. However, most existing\ndependency-based approaches ignore the positive influence of the words outside\nthe dependency trees, sometimes conveying rich and useful information on\nrelation extraction. In this paper, we propose a novel model, Entity-aware\nSelf-attention Contextualized GCN (ESC-GCN), which efficiently incorporates\nsyntactic structure of input sentences and semantic context of sequences. To be\nspecific, relative position self-attention obtains the overall semantic\npairwise correlation related to word position, and contextualized graph\nconvolutional networks capture rich intra-sentence dependencies between words\nby adequately pruning operations. Furthermore, entity-aware attention layer\ndynamically selects which token is more decisive to make final relation\nprediction. In this way, our proposed model not only reduces the noisy impact\nfrom dependency trees, but also obtains easily-ignored entity-related semantic\nrepresentation. Extensive experiments on various tasks demonstrate that our\nmodel achieves encouraging performance as compared to existing dependency-based\nand sequence-based models. Specially, our model excels in extracting relations\nbetween entities of long sentences.\n","authors":["Xin Wang","Xinyi Bai"],"pdf_url":"https://arxiv.org/pdf/2409.13755v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.00625v2","updated":"2024-11-12T01:47:40Z","published":"2024-09-01T05:59:54Z","title":"Entity-Aware Biaffine Attention Model for Improved Constituent Parsing\n  with Reduced Entity Violations","summary":"  Constituency parsing involves analyzing a sentence by breaking it into\nsub-phrases, or constituents. While many deep neural models have achieved\nstate-of-the-art performance in this task, they often overlook the\nentity-violating issue, where an entity fails to form a complete sub-tree in\nthe resultant parsing tree. To address this, we propose an entity-aware\nbiaffine attention model for constituent parsing. This model incorporates\nentity information into the biaffine attention mechanism by using additional\nentity role vectors for potential phrases, which enhances the parsing accuracy.\nWe introduce a new metric, the Entity Violating Rate (EVR), to quantify the\nextent of entity violations in parsing results. Experiments on three popular\ndatasets-ONTONOTES, PTB, and CTB-demonstrate that our model achieves the lowest\nEVR while maintaining high precision, recall, and F1-scores comparable to\nexisting models. Further evaluation in downstream tasks, such as sentence\nsentiment analysis, highlights the effectiveness of our model and the validity\nof the proposed EVR metric.\n","authors":["Xinyi Bai"],"pdf_url":"https://arxiv.org/pdf/2409.00625v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07474v1","updated":"2024-11-12T01:26:41Z","published":"2024-11-12T01:26:41Z","title":"Controlled Evaluation of Syntactic Knowledge in Multilingual Language\n  Models","summary":"  Language models (LMs) are capable of acquiring elements of human-like\nsyntactic knowledge. Targeted syntactic evaluation tests have been employed to\nmeasure how well they form generalizations about syntactic phenomena in\nhigh-resource languages such as English. However, we still lack a thorough\nunderstanding of LMs' capacity for syntactic generalizations in low-resource\nlanguages, which are responsible for much of the diversity of syntactic\npatterns worldwide. In this study, we develop targeted syntactic evaluation\ntests for three low-resource languages (Basque, Hindi, and Swahili) and use\nthem to evaluate five families of open-access multilingual Transformer LMs. We\nfind that some syntactic tasks prove relatively easy for LMs while others\n(agreement in sentences containing indirect objects in Basque, agreement across\na prepositional phrase in Swahili) are challenging. We additionally uncover\nissues with publicly available Transformers, including a bias toward the\nhabitual aspect in Hindi in multilingual BERT and underperformance compared to\nsimilar-sized models in XGLM-4.5B.\n","authors":["Daria Kryvosheieva","Roger Levy"],"pdf_url":"https://arxiv.org/pdf/2411.07474v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.01332v3","updated":"2024-11-12T01:06:22Z","published":"2024-03-29T22:49:43Z","title":"Explaining Large Language Models Decisions Using Shapley Values","summary":"  The emergence of large language models (LLMs) has opened up exciting\npossibilities for simulating human behavior and cognitive processes, with\npotential applications in various domains, including marketing research and\nconsumer behavior analysis. However, the validity of utilizing LLMs as\nstand-ins for human subjects remains uncertain due to glaring divergences that\nsuggest fundamentally different underlying processes at play and the\nsensitivity of LLM responses to prompt variations. This paper presents a novel\napproach based on Shapley values from cooperative game theory to interpret LLM\nbehavior and quantify the relative contribution of each prompt component to the\nmodel's output. Through two applications - a discrete choice experiment and an\ninvestigation of cognitive biases - we demonstrate how the Shapley value method\ncan uncover what we term \"token noise\" effects, a phenomenon where LLM\ndecisions are disproportionately influenced by tokens providing minimal\ninformative content. This phenomenon raises concerns about the robustness and\ngeneralizability of insights obtained from LLMs in the context of human\nbehavior simulation. Our model-agnostic approach extends its utility to\nproprietary LLMs, providing a valuable tool for practitioners and researchers\nto strategically optimize prompts and mitigate apparent cognitive biases. Our\nfindings underscore the need for a more nuanced understanding of the factors\ndriving LLM responses before relying on them as substitutes for human subjects\nin survey settings. We emphasize the importance of researchers reporting\nresults conditioned on specific prompt templates and exercising caution when\ndrawing parallels between human behavior and LLMs.\n","authors":["Behnam Mohammadi"],"pdf_url":"https://arxiv.org/pdf/2404.01332v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07466v1","updated":"2024-11-12T01:05:55Z","published":"2024-11-12T01:05:55Z","title":"IdentifyMe: A Challenging Long-Context Mention Resolution Benchmark","summary":"  Recent evaluations of LLMs on coreference resolution have revealed that\ntraditional output formats and evaluation metrics do not fully capture the\nmodels' referential understanding. To address this, we introduce IdentifyMe, a\nnew benchmark for mention resolution presented in a multiple-choice question\n(MCQ) format, commonly used for evaluating LLMs. IdentifyMe features long\nnarratives and employs heuristics to exclude easily identifiable mentions,\ncreating a more challenging task. The benchmark also consists of a curated\nmixture of different mention types and corresponding entities, allowing for a\nfine-grained analysis of model performance. We evaluate both closed- and open\nsource LLMs on IdentifyMe and observe a significant performance gap (20-30%)\nbetween the state-of-the-art sub-10B open models vs. closed ones. We observe\nthat pronominal mentions, which have limited surface information, are typically\nmuch harder for models to resolve than nominal mentions. Additionally, we find\nthat LLMs often confuse entities when their mentions overlap in nested\nstructures. The highest-scoring model, GPT-4o, achieves 81.9% accuracy,\nhighlighting the strong referential capabilities of state-of-the-art LLMs while\nalso indicating room for further improvement.\n","authors":["Kawshik Manikantan","Makarand Tapaswi","Vineet Gandhi","Shubham Toshniwal"],"pdf_url":"https://arxiv.org/pdf/2411.07466v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.04916v4","updated":"2024-11-12T01:01:32Z","published":"2023-11-02T04:01:04Z","title":"Explainable Identification of Hate Speech towards Islam using Graph\n  Neural Networks","summary":"  Islamophobic language on online platforms fosters intolerance, making\ndetection and elimination crucial for promoting harmony. Traditional hate\nspeech detection models rely on NLP techniques like tokenization,\npart-of-speech tagging, and encoder-decoder models. However, Graph Neural\nNetworks (GNNs), with their ability to utilize relationships between data\npoints, offer more effective detection and greater explainability. In this\nwork, we represent speeches as nodes and connect them with edges based on their\ncontext and similarity to develop the graph. This study introduces a novel\nparadigm using GNNs to identify and explain hate speech towards Islam. Our\nmodel leverages GNNs to understand the context and patterns of hate speech by\nconnecting texts via pretrained NLP-generated word embeddings, achieving\nstate-of-the-art performance and enhancing detection accuracy while providing\nvaluable explanations. This highlights the potential of GNNs in combating\nonline hate speech and fostering a safer, more inclusive online environment.\n","authors":["Azmine Toushik Wasi"],"pdf_url":"https://arxiv.org/pdf/2311.04916v4.pdf","comment":"Accepted in: (i) NeurIPS 2023 : Muslims in ML Workshop (Non-archival)\n  (https://www.musiml.org/schedule/#:~:text=Azmine%20Toushik%20Wasi) (ii) EMNLP\n  2024 : NLP for Positive Impact Workshop (Archival; ACL Anthology:\n  https://aclanthology.org/2024.nlp4pi-1.23/)"},{"id":"http://arxiv.org/abs/2407.02885v5","updated":"2024-11-12T01:00:53Z","published":"2024-07-03T07:59:52Z","title":"CogErgLLM: Exploring Large Language Model Systems Design Perspective\n  Using Cognitive Ergonomics","summary":"  Integrating cognitive ergonomics with LLMs is crucial for improving safety,\nreliability, and user satisfaction in human-AI interactions. Current LLM\ndesigns often lack this integration, resulting in systems that may not fully\nalign with human cognitive capabilities and limitations. This oversight\nexacerbates biases in LLM outputs and leads to suboptimal user experiences due\nto inconsistent application of user-centered design principles. Researchers are\nincreasingly leveraging NLP, particularly LLMs, to model and understand human\nbehavior across social sciences, psychology, psychiatry, health, and\nneuroscience. Our position paper explores the need to integrate cognitive\nergonomics into LLM design, providing a comprehensive framework and practical\nguidelines for ethical development. By addressing these challenges, we aim to\nadvance safer, more reliable, and ethically sound human-AI interactions.\n","authors":["Azmine Toushik Wasi","Mst Rafia Islam"],"pdf_url":"https://arxiv.org/pdf/2407.02885v5.pdf","comment":"10 Page, 3 Figures. Accepted in: (i) ICML'24: LLMs & Cognition\n  Workshop (Non-archival; OpenReview:\n  https://openreview.net/forum?id=63C9YSc77p) (ii) EMNLP'24 : NLP for Science\n  Workshop (Archival; ACL Anthology:\n  https://aclanthology.org/2024.nlp4science-1.22/)"},{"id":"http://arxiv.org/abs/2411.07464v1","updated":"2024-11-12T00:57:30Z","published":"2024-11-12T00:57:30Z","title":"BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating\n  Machine Learning Tasks","summary":"  Large Language Models (LLMs) excel in diverse applications including\ngeneration of code snippets, but often struggle with generating code for\ncomplex Machine Learning (ML) tasks. Although existing LLM single-agent based\nsystems give varying performance depending on the task complexity, they purely\nrely on larger and expensive models such as GPT-4. Our investigation reveals\nthat no-cost and low-cost models such as Gemini-Pro, Mixtral and CodeLlama\nperform far worse than GPT-4 in a single-agent setting. With the motivation of\ndeveloping a cost-efficient LLM based solution for solving ML tasks, we propose\nan LLM Multi-Agent based system which leverages combination of experts using\nprofiling, efficient retrieval of past observations, LLM cascades, and\nask-the-expert calls. Through empirical analysis on ML engineering tasks in the\nMLAgentBench benchmark, we demonstrate the effectiveness of our system, using\nno-cost models, namely Gemini as the base LLM, paired with GPT-4 in cascade and\nexpert to serve occasional ask-the-expert calls for planning. With 94.2\\%\nreduction in the cost (from \\$0.931 per run cost averaged over all tasks for\nGPT-4 single agent system to \\$0.054), our system is able to yield better\naverage success rate of 32.95\\% as compared to GPT-4 single-agent system\nyielding 22.72\\% success rate averaged over all the tasks of MLAgentBench.\n","authors":["Shubham Gandhi","Manasi Patwardhan","Lovekesh Vig","Gautam Shroff"],"pdf_url":"https://arxiv.org/pdf/2411.07464v1.pdf","comment":"Presented at AIMLSystems '24"},{"id":"http://arxiv.org/abs/2411.07457v1","updated":"2024-11-12T00:48:01Z","published":"2024-11-12T00:48:01Z","title":"DecoPrompt : Decoding Prompts Reduces Hallucinations when Large Language\n  Models Meet False Premises","summary":"  While large language models (LLMs) have demonstrated increasing power, they\nhave also called upon studies on their hallucinated outputs that deviate from\nfactually correct statements. In this paper, we focus on one important scenario\nof false premises, where LLMs are distracted by misaligned claims although the\nmodel possesses the required factual knowledge to answer original questions\naccurately. Inspired by the observation that entropy of the false-premise\nprompt is closely related to its likelihood to elicit hallucination generation,\nwe propose a new prompting algorithm, named DecoPrompt, to mitigate\nhallucination. DecoPrompt leverages LLMs to \"decode\" the false-premise prompts\nwithout really eliciting hallucination output from LLMs. We perform experiments\non two datasets, demonstrating that DecoPrompt can reduce hallucinations\neffectively on outputs from different LLMs. Moreover, DecoPrompt exhibits\ncross-model transferability, which facilitates its applications to scenarios\nsuch as LLMs of large sizes or unavailable model logits.\n","authors":["Nan Xu","Xuezhe Ma"],"pdf_url":"https://arxiv.org/pdf/2411.07457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07446v1","updated":"2024-11-12T00:07:29Z","published":"2024-11-12T00:07:29Z","title":"Efficient and Accurate Prompt Optimization: the Benefit of Memory in\n  Exemplar-Guided Reflection","summary":"  Automatic prompt engineering aims to enhance the generation quality of large\nlanguage models (LLMs). Recent works utilize feedbacks generated from erroneous\ncases to guide the prompt optimization. During inference, they may further\nretrieve several semantically-related exemplars and concatenate them to the\noptimized prompts to improve the performance. However, those works only utilize\nthe feedback at the current step, ignoring historical and unseleccted feedbacks\nwhich are potentially beneficial. Moreover, the selection of exemplars only\nconsiders the general semantic relationship and may not be optimal in terms of\ntask performance and matching with the optimized prompt. In this work, we\npropose an Exemplar-Guided Reflection with Memory mechanism (ERM) to realize\nmore efficient and accurate prompt optimization. Specifically, we design an\nexemplar-guided reflection mechanism where the feedback generation is\nadditionally guided by the generated exemplars. We further build two kinds of\nmemory to fully utilize the historical feedback information and support more\neffective exemplar retrieval. Empirical evaluations show our method surpasses\nprevious state-of-the-arts with less optimization steps, i.e., improving F1\nscore by 10.1 on LIAR dataset, and reducing half of the optimization steps on\nProTeGi.\n","authors":["Cilin Yan","Jingyun Wang","Lin Zhang","Ruihui Zhao","Xiaopu Wu","Kai Xiong","Qingsong Liu","Guoliang Kang","Yangyang Kang"],"pdf_url":"https://arxiv.org/pdf/2411.07446v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08248v1","updated":"2024-11-12T23:54:58Z","published":"2024-11-12T23:54:58Z","title":"Deceiving Question-Answering Models: A Hybrid Word-Level Adversarial\n  Approach","summary":"  Deep learning underpins most of the currently advanced natural language\nprocessing (NLP) tasks such as textual classification, neural machine\ntranslation (NMT), abstractive summarization and question-answering (QA).\nHowever, the robustness of the models, particularly QA models, against\nadversarial attacks is a critical concern that remains insufficiently explored.\nThis paper introduces QA-Attack (Question Answering Attack), a novel word-level\nadversarial strategy that fools QA models. Our attention-based attack exploits\nthe customized attention mechanism and deletion ranking strategy to identify\nand target specific words within contextual passages. It creates deceptive\ninputs by carefully choosing and substituting synonyms, preserving grammatical\nintegrity while misleading the model to produce incorrect responses. Our\napproach demonstrates versatility across various question types, particularly\nwhen dealing with extensive long textual inputs. Extensive experiments on\nmultiple benchmark datasets demonstrate that QA-Attack successfully deceives\nbaseline QA models and surpasses existing adversarial techniques regarding\nsuccess rate, semantics changes, BLEU score, fluency and grammar error rate.\n","authors":["Jiyao Li","Mingze Ni","Yongshun Gong","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2411.08248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08243v1","updated":"2024-11-12T23:43:20Z","published":"2024-11-12T23:43:20Z","title":"Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset","summary":"  In an effort to mitigate the harms of large language models (LLMs), learning\nfrom human feedback (LHF) has been used to steer LLMs towards outputs that are\nintended to be both less harmful and more helpful. Despite the widespread\nadoption of LHF in practice, the quality of this feedback and its effectiveness\nas a safety mitigation technique remain unclear. This study addresses these\nissues by auditing the widely-used Helpful and Harmless (HH) dataset by\nAnthropic. Our work includes: (1) a thorough investigation of the dataset's\ncontent through both manual and automated evaluation; (2) experiments\ndemonstrating the dataset's impact on models' safety; and (3) an analysis of\nthe 100 most influential papers citing this dataset. Through our audit, we\nshowcase how conceptualization failures and quality issues identified in the HH\ndataset can create additional harms by leading to disparate safety behaviors\nacross demographic groups. Our findings highlight the need for more nuanced,\ncontext-sensitive approaches to safety mitigation in LLMs.\n","authors":["Khaoula Chehbouni","Jonathan Cola√ßo-Carr","Yash More","Jackie CK Cheung","Golnoosh Farnadi"],"pdf_url":"https://arxiv.org/pdf/2411.08243v1.pdf","comment":"Prepared for conference submission"},{"id":"http://arxiv.org/abs/2403.06399v3","updated":"2024-11-12T22:17:46Z","published":"2024-03-11T03:21:15Z","title":"GlossLM: A Massively Multilingual Corpus and Pretrained Model for\n  Interlinear Glossed Text","summary":"  Language documentation projects often involve the creation of annotated text\nin a format such as interlinear glossed text (IGT), which captures fine-grained\nmorphosyntactic analyses in a morpheme-by-morpheme format. However, there are\nfew existing resources providing large amounts of standardized, easily\naccessible IGT data, limiting their applicability to linguistic research, and\nmaking it difficult to use such data in NLP modeling.\n  We compile the largest existing corpus of IGT data from a variety of sources,\ncovering over 450k examples across 1.8k languages, to enable research on\ncrosslingual transfer and IGT generation. We normalize much of our data to\nfollow a standard set of labels across languages.\n  Furthermore, we explore the task of automatically generating IGT in order to\naid documentation projects. As many languages lack sufficient monolingual data,\nwe pretrain a large multilingual model on our corpus. We demonstrate the\nutility of this model by finetuning it on monolingual corpora, outperforming\nSOTA models by up to 6.6\\%. Our pretrained model and dataset are available on\nHugging Face.\n","authors":["Michael Ginn","Lindia Tjuatja","Taiqi He","Enora Rice","Graham Neubig","Alexis Palmer","Lori Levin"],"pdf_url":"https://arxiv.org/pdf/2403.06399v3.pdf","comment":"EMNLP 2024. First two authors are equal contribution"},{"id":"http://arxiv.org/abs/2408.07832v6","updated":"2024-11-12T20:51:07Z","published":"2024-07-31T14:49:35Z","title":"LADDER: Language Driven Slice Discovery and Error Rectification","summary":"  Error slice discovery associates structured patterns with model errors.\nExisting methods discover error slices by clustering the error-prone samples\nwith similar patterns or assigning discrete attributes to each sample for\npost-hoc analysis. While these methods aim for interpretability and easier\nmitigation through reweighting or rebalancing, they may not capture the full\ncomplexity of error patterns due to incomplete or missing attributes. Contrary\nto the existing approach, this paper utilizes the reasoning capabilities of the\nLarge Language Model (LLM) to analyze complex error patterns and generate\ntestable hypotheses. This paper proposes LADDER: Language Driven slice\nDiscovery and Error Rectification. It first projects the model's representation\ninto a language-aligned feature space (eg CLIP) to preserve semantics in the\noriginal model feature space. This ensures the accurate retrieval of sentences\nthat highlight the model's errors. Next, the LLM utilizes the sentences and\ngenerates hypotheses to discover error slices. Finally, we mitigate the error\nby fine-tuning the classification head by creating a group-balanced dataset\nusing the hypotheses. Our entire method does not require any attribute\nannotation, either explicitly or through external tagging models. We validate\nour method with \\textbf{five} image classification datasets.\n","authors":["Shantanu Ghosh","Rayan Syed","Chenyu Wang","Clare B. Poynton","Shyam Visweswaran","Kayhan Batmanghelich"],"pdf_url":"https://arxiv.org/pdf/2408.07832v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08165v1","updated":"2024-11-12T20:15:58Z","published":"2024-11-12T20:15:58Z","title":"Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for\n  Knowledge Graph Completion","summary":"  The Knowledge Graph Completion~(KGC) task aims to infer the missing entity\nfrom an incomplete triple. Existing embedding-based methods rely solely on\ntriples in the KG, which is vulnerable to specious relation patterns and\nlong-tail entities. On the other hand, text-based methods struggle with the\nsemantic gap between KG triples and natural language. Apart from triples,\nentity contexts (e.g., labels, descriptions, aliases) also play a significant\nrole in augmenting KGs. To address these limitations, we propose KGR3, a\ncontext-enriched framework for KGC. KGR3 is composed of three modules. Firstly,\nthe Retrieval module gathers supporting triples from the KG, collects plausible\ncandidate answers from a base embedding model, and retrieves context for each\nrelated entity. Then, the Reasoning module employs a large language model to\ngenerate potential answers for each query triple. Finally, the Re-ranking\nmodule combines candidate answers from the two modules mentioned above, and\nfine-tunes an LLM to provide the best answer. Extensive experiments on widely\nused datasets demonstrate that KGR3 consistently improves various KGC methods.\nSpecifically, the best variant of KGR3 achieves absolute Hits@1 improvements of\n12.3% and 5.6% on the FB15k237 and WN18RR datasets.\n","authors":["Muzhi Li","Cehao Yang","Chengjin Xu","Xuhui Jiang","Yiyan Qi","Jian Guo","Ho-fung Leung","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2411.08165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04427v2","updated":"2024-11-12T20:11:58Z","published":"2024-11-07T04:38:58Z","title":"One fish, two fish, but not the whole sea: Alignment reduces language\n  models' conceptual diversity","summary":"  Researchers in social science and psychology have recently proposed using\nlarge language models (LLMs) as replacements for humans in behavioral research.\nIn addition to arguments about whether LLMs accurately capture population-level\npatterns, this has raised questions about whether LLMs capture human-like\nconceptual diversity. Separately, it is debated whether post-training alignment\n(RLHF or RLAIF) affects models' internal diversity. Inspired by human studies,\nwe use a new way of measuring the conceptual diversity of\nsynthetically-generated LLM \"populations\" by relating the internal variability\nof simulated individuals to the population-level variability. We use this\napproach to evaluate non-aligned and aligned LLMs on two domains with rich\nhuman behavioral data. While no model reaches human-like diversity, aligned\nmodels generally display less diversity than their instruction fine-tuned\ncounterparts. Our findings highlight potential trade-offs between increasing\nmodels' value alignment and decreasing the diversity of their conceptual\nrepresentations.\n","authors":["Sonia K. Murthy","Tomer Ullman","Jennifer Hu"],"pdf_url":"https://arxiv.org/pdf/2411.04427v2.pdf","comment":"17 pages, 10 figures; corrected figure version"},{"id":"http://arxiv.org/abs/2411.08147v1","updated":"2024-11-12T19:53:00Z","published":"2024-11-12T19:53:00Z","title":"Large Language Models Can Self-Improve in Long-context Reasoning","summary":"  Large language models (LLMs) have achieved substantial progress in processing\nlong contexts but still struggle with long-context reasoning. Existing\napproaches typically involve fine-tuning LLMs with synthetic data, which\ndepends on annotations from human experts or advanced models like GPT-4, thus\nrestricting further advancements. To address this issue, we investigate the\npotential for LLMs to self-improve in long-context reasoning and propose \\ours,\nan approach specifically designed for this purpose. This approach is\nstraightforward: we sample multiple outputs for each question, score them with\nMinimum Bayes Risk, and then apply supervised fine-tuning or preference\noptimization based on these outputs. Extensive experiments on several leading\nLLMs demonstrate the effectiveness of \\ours, with an absolute improvement of\n$4.2$ points for Llama-3.1-8B-Instruct. Furthermore, \\ours achieves superior\nperformance compared to prior approaches that depend on data produced by human\nexperts or advanced models. We anticipate that this work will open new avenues\nfor self-improvement techniques in long-context scenarios, which are essential\nfor the continual advancement of LLMs.\n","authors":["Siheng Li","Cheng Yang","Zesen Cheng","Lemao Liu","Mo Yu","Yujiu Yang","Wai Lam"],"pdf_url":"https://arxiv.org/pdf/2411.08147v1.pdf","comment":"Project Page: https://github.com/SihengLi99/SEALONG"},{"id":"http://arxiv.org/abs/2411.04329v2","updated":"2024-11-12T19:37:20Z","published":"2024-11-07T00:09:54Z","title":"CodeTree: Agent-guided Tree Search for Code Generation with Large\n  Language Models","summary":"  Pre-trained on massive amounts of code and text data, large language models\n(LLMs) have demonstrated remarkable achievements in performing code generation\ntasks. With additional execution-based feedback, these models can act as agents\nwith capabilities to self-refine and improve generated code autonomously.\nHowever, on challenging coding tasks with extremely large search space, current\nagentic approaches still struggle with multi-stage planning, generating, and\ndebugging. To address this problem, we propose CodeTree, a framework for LLM\nagents to efficiently explore the search space in different stages of the code\ngeneration process. Specifically, we adopted a unified tree structure to\nexplicitly explore different coding strategies, generate corresponding coding\nsolutions, and subsequently refine the solutions. In each stage, critical\ndecision-making (ranking, termination, expanding) of the exploration process is\nguided by both the environmental execution-based feedback and\nLLM-agent-generated feedback. We comprehensively evaluated CodeTree on 7 code\ngeneration benchmarks and demonstrated the significant performance gains of\nCodeTree against strong baselines. Using GPT-4o as the base model, we\nconsistently achieved top results of 95.1 on HumanEval, 98.7 on MBPP, and 43.0\non CodeContests. On the challenging SWEBench benchmark, our approach led to\nsignificant performance gains.\n","authors":["Jierui Li","Hung Le","Yingbo Zhou","Caiming Xiong","Silvio Savarese","Doyen Sahoo"],"pdf_url":"https://arxiv.org/pdf/2411.04329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16803v2","updated":"2024-11-12T19:28:34Z","published":"2024-10-22T08:28:05Z","title":"Context-aware Inductive Knowledge Graph Completion with Latent Type\n  Constraints and Subgraph Reasoning","summary":"  Inductive knowledge graph completion (KGC) aims to predict missing triples\nwith unseen entities. Recent works focus on modeling reasoning paths between\nthe head and tail entity as direct supporting evidence. However, these methods\ndepend heavily on the existence and quality of reasoning paths, which limits\ntheir general applicability in different scenarios. In addition, we observe\nthat latent type constraints and neighboring facts inherent in KGs are also\nvital in inferring missing triples. To effectively utilize all useful\ninformation in KGs, we introduce CATS, a novel context-aware inductive KGC\nsolution. With sufficient guidance from proper prompts and supervised\nfine-tuning, CATS activates the strong semantic understanding and reasoning\ncapabilities of large language models to assess the existence of query triples,\nwhich consist of two modules. First, the type-aware reasoning module evaluates\nwhether the candidate entity matches the latent entity type as required by the\nquery relation. Then, the subgraph reasoning module selects relevant reasoning\npaths and neighboring facts, and evaluates their correlation to the query\ntriple. Experiment results on three widely used datasets demonstrate that CATS\nsignificantly outperforms state-of-the-art methods in 16 out of 18\ntransductive, inductive, and few-shot settings with an average absolute MRR\nimprovement of 7.2%.\n","authors":["Muzhi Li","Cehao Yang","Chengjin Xu","Zixing Song","Xuhui Jiang","Jian Guo","Ho-fung Leung","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2410.16803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08135v1","updated":"2024-11-12T19:26:43Z","published":"2024-11-12T19:26:43Z","title":"On the Role of Speech Data in Reducing Toxicity Detection Bias","summary":"  Text toxicity detection systems exhibit significant biases, producing\ndisproportionate rates of false positives on samples mentioning demographic\ngroups. But what about toxicity detection in speech? To investigate the extent\nto which text-based biases are mitigated by speech-based systems, we produce a\nset of high-quality group annotations for the multilingual MuTox dataset, and\nthen leverage these annotations to systematically compare speech- and\ntext-based toxicity classifiers. Our findings indicate that access to speech\ndata during inference supports reduced bias against group mentions,\nparticularly for ambiguous and disagreement-inducing samples. Our results also\nsuggest that improving classifiers, rather than transcription pipelines, is\nmore helpful for reducing group bias. We publicly release our annotations and\nprovide recommendations for future toxicity dataset construction.\n","authors":["Samuel J. Bell","Mariano Coria Meglioli","Megan Richards","Eduardo S√°nchez","Christophe Ropers","Skyler Wang","Adina Williams","Levent Sagun","Marta R. Costa-juss√†"],"pdf_url":"https://arxiv.org/pdf/2411.08135v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2304.04918v2","updated":"2024-11-12T15:42:42Z","published":"2023-04-11T01:10:49Z","title":"Explicit and Implicit Semantic Ranking Framework","summary":"  The core challenge in numerous real-world applications is to match an inquiry\nto the best document from a mutable and finite set of candidates. Existing\nindustry solutions, especially latency-constrained services, often rely on\nsimilarity algorithms that sacrifice quality for speed. In this paper we\nintroduce a generic semantic learning-to-rank framework, Self-training Semantic\nCross-attention Ranking (sRank). This transformer-based framework uses linear\npairwise loss with mutable training batch sizes and achieves quality gains and\nhigh efficiency, and has been applied effectively to show gains on two industry\ntasks at Microsoft over real-world large-scale data sets: Smart Reply (SR) and\nAmbient Clinical Intelligence (ACI). In Smart Reply, sRank assists live\ncustomers with technical support by selecting the best reply from predefined\nsolutions based on consumer and support agent messages. It achieves 11.7% gain\nin offline top-one accuracy on the SR task over the previous system, and has\nenabled 38.7% time reduction in composing messages in telemetry recorded since\nits general release in January 2021. In the ACI task, sRank selects relevant\nhistorical physician templates that serve as guidance for a text summarization\nmodel to generate higher quality medical notes. It achieves 35.5% top-one\naccuracy gain, along with 46% relative ROUGE-L gain in generated medical notes.\n","authors":["Xiaofeng Zhu","Thomas Lin","Vishal Anand","Matthew Calderwood","Eric Clausen-Brown","Gord Lueck","Wen-wai Yim","Cheng Wu"],"pdf_url":"https://arxiv.org/pdf/2304.04918v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05508v2","updated":"2024-11-12T15:36:04Z","published":"2024-11-08T12:08:17Z","title":"An Early FIRST Reproduction and Improvements to Single-Token Decoding\n  for Fast Listwise Reranking","summary":"  Recent advances have demonstrated that large language models (LLMs) excel as\nlistwise rerankers, but their high computational demands remain a barrier to\nwidespread adoption. Further, the traditional language modeling (LM) objective\nis not ideally suited for reranking tasks. FIRST is a novel approach that\naddresses these challenges by integrating a learning-to-rank objective and\nleveraging the logits of only the first generated token, thereby significantly\nreducing inference latency compared to traditional LLM rerankers. In this\nstudy, we extend the evaluation of FIRST to the TREC Deep Learning datasets\n(DL19-22), validating its robustness across diverse domains. We investigate the\ninfluence of different first-stage retrievers on FIRST rerankers, observing\ndiminishing returns and patterns consistent with traditional LLM rerankers.\nThrough applying the FIRST objective to a broader range of backbone models, we\nachieve effectiveness surpassing the original implementation. Our experiments\nconfirm that fast reranking with single-token logits does not compromise\nout-of-domain reranking quality. To better quantify the computational savings\nin the original study, we measure and compare latency to find a 21%-42% gain\nacross various models and benchmarks. Moreover, while LM training implicitly\nimproves zero-shot single-token reranking, our experiments also raise questions\nabout whether LM pre-training may hinder subsequent fine-tuning with the FIRST\nobjective. These findings pave the way for more efficient and effective\nlistwise reranking in future applications.\n","authors":["Zijian Chen","Ronak Pradeep","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05508v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07820v1","updated":"2024-11-12T14:12:45Z","published":"2024-11-12T14:12:45Z","title":"Query Optimization for Parametric Knowledge Refinement in\n  Retrieval-Augmented Large Language Models","summary":"  We introduce the \\textit{Extract-Refine-Retrieve-Read} (ERRR) framework, a\nnovel approach designed to bridge the pre-retrieval information gap in\nRetrieval-Augmented Generation (RAG) systems through query optimization\ntailored to meet the specific knowledge requirements of Large Language Models\n(LLMs). Unlike conventional query optimization techniques used in RAG, the ERRR\nframework begins by extracting parametric knowledge from LLMs, followed by\nusing a specialized query optimizer for refining these queries. This process\nensures the retrieval of only the most pertinent information essential for\ngenerating accurate responses. Moreover, to enhance flexibility and reduce\ncomputational costs, we propose a trainable scheme for our pipeline that\nutilizes a smaller, tunable model as the query optimizer, which is refined\nthrough knowledge distillation from a larger teacher model. Our evaluations on\nvarious question-answering (QA) datasets and with different retrieval systems\nshow that ERRR consistently outperforms existing baselines, proving to be a\nversatile and cost-effective module for improving the utility and accuracy of\nRAG systems.\n","authors":["Youan Cong","Cheng Wang","Pritom Saha Akash","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2411.07820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18480v2","updated":"2024-11-12T13:54:25Z","published":"2024-03-27T11:49:58Z","title":"Content-Based Collaborative Generation for Recommender Systems","summary":"  Generative models have emerged as a promising utility to enhance recommender\nsystems. It is essential to model both item content and user-item collaborative\ninteractions in a unified generative framework for better recommendation.\nAlthough some existing large language model (LLM)-based methods contribute to\nfusing content information and collaborative signals, they fundamentally rely\non textual language generation, which is not fully aligned with the\nrecommendation task. How to integrate content knowledge and collaborative\ninteraction signals in a generative framework tailored for item recommendation\nis still an open research challenge.\n  In this paper, we propose content-based collaborative generation for\nrecommender systems, namely ColaRec. ColaRec is a sequence-to-sequence\nframework which is tailored for directly generating the recommended item\nidentifier. Precisely, the input sequence comprises data pertaining to the\nuser's interacted items, and the output sequence represents the generative\nidentifier (GID) for the suggested item. To model collaborative signals, the\nGIDs are constructed from a pretrained collaborative filtering model, and the\nuser is represented as the content aggregation of interacted items. To this\nend, ColaRec captures both collaborative signals and content information in a\nunified framework. Then an item indexing task is proposed to conduct the\nalignment between the content-based semantic space and the interaction-based\ncollaborative space. Besides, a contrastive loss is further introduced to\nensure that items with similar collaborative GIDs have similar content\nrepresentations. To verify the effectiveness of ColaRec, we conduct experiments\non four benchmark datasets. Empirical results demonstrate the superior\nperformance of ColaRec.\n","authors":["Yidan Wang","Zhaochun Ren","Weiwei Sun","Jiyuan Yang","Zhixiang Liang","Xin Chen","Ruobing Xie","Su Yan","Xu Zhang","Pengjie Ren","Zhumin Chen","Xin Xin"],"pdf_url":"https://arxiv.org/pdf/2403.18480v2.pdf","comment":"Accepted by CIKM 2024; GitHub:\n  https://github.com/Junewang0614/ColaRec"},{"id":"http://arxiv.org/abs/2411.07770v1","updated":"2024-11-12T13:06:16Z","published":"2024-11-12T13:06:16Z","title":"A Theoretical Analysis of Recommendation Loss Functions under Negative\n  Sampling","summary":"  Recommender Systems (RSs) are pivotal in diverse domains such as e-commerce,\nmusic streaming, and social media. This paper conducts a comparative analysis\nof prevalent loss functions in RSs: Binary Cross-Entropy (BCE), Categorical\nCross-Entropy (CCE), and Bayesian Personalized Ranking (BPR). Exploring the\nbehaviour of these loss functions across varying negative sampling settings, we\nreveal that BPR and CCE are equivalent when one negative sample is used.\nAdditionally, we demonstrate that all losses share a common global minimum.\nEvaluation of RSs mainly relies on ranking metrics known as Normalized\nDiscounted Cumulative Gain (NDCG) and Mean Reciprocal Rank (MRR). We produce\nbounds of the different losses for negative sampling settings to establish a\nprobabilistic lower bound for NDCG. We show that the BPR bound on NDCG is\nweaker than that of BCE, contradicting the common assumption that BPR is\nsuperior to BCE in RSs training. Experiments on five datasets and four models\nempirically support these theoretical findings. Our code is available at\n\\url{https://anonymous.4open.science/r/recsys_losses} .\n","authors":["Giulia Di Teodoro","Federico Siciliano","Nicola Tonellotto","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2411.07770v1.pdf","comment":"main paper 8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.07739v1","updated":"2024-11-12T12:03:57Z","published":"2024-11-12T12:03:57Z","title":"Unlocking Legal Knowledge with Multi-Layered Embedding-Based Retrieval","summary":"  This work addresses the challenge of capturing the complexities of legal\nknowledge by proposing a multi-layered embedding-based retrieval method for\nlegal and legislative texts. Creating embeddings not only for individual\narticles but also for their components (paragraphs, clauses) and structural\ngroupings (books, titles, chapters, etc), we seek to capture the subtleties of\nlegal information through the use of dense vectors of embeddings, representing\nit at varying levels of granularity. Our method meets various information needs\nby allowing the Retrieval Augmented Generation system to provide accurate\nresponses, whether for specific segments or entire sections, tailored to the\nuser's query. We explore the concepts of aboutness, semantic chunking, and\ninherent hierarchy within legal texts, arguing that this method enhances the\nlegal information retrieval. Despite the focus being on Brazil's legislative\nmethods and the Brazilian Constitution, which follow a civil law tradition, our\nfindings should in principle be applicable across different legal systems,\nincluding those adhering to common law traditions. Furthermore, the principles\nof the proposed method extend beyond the legal domain, offering valuable\ninsights for organizing and retrieving information in any field characterized\nby information encoded in hierarchical text.\n","authors":["Jo√£o Alberto de Oliveira Lima"],"pdf_url":"https://arxiv.org/pdf/2411.07739v1.pdf","comment":"27 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.07658v1","updated":"2024-11-12T09:19:32Z","published":"2024-11-12T09:19:32Z","title":"Advancing Sustainability via Recommender Systems: A Survey","summary":"  Human behavioral patterns and consumption paradigms have emerged as pivotal\ndeterminants in environmental degradation and climate change, with quotidian\ndecisions pertaining to transportation, energy utilization, and resource\nconsumption collectively precipitating substantial ecological impacts.\nRecommender systems, which generate personalized suggestions based on user\npreferences and historical interaction data, exert considerable influence on\nindividual behavioral trajectories. However, conventional recommender systems\npredominantly optimize for user engagement and economic metrics, inadvertently\nneglecting the environmental and societal ramifications of their\nrecommendations, potentially catalyzing over-consumption and reinforcing\nunsustainable behavioral patterns. Given their instrumental role in shaping\nuser decisions, there exists an imperative need for sustainable recommender\nsystems that incorporate sustainability principles to foster eco-conscious and\nsocially responsible choices. This comprehensive survey addresses this critical\nresearch gap by presenting a systematic analysis of sustainable recommender\nsystems. As these systems can simultaneously advance multiple sustainability\nobjectives--including resource conservation, sustainable consumer behavior, and\nsocial impact enhancement--examining their implementations across distinct\napplication domains provides a more rigorous analytical framework. Through a\nmethodological analysis of domain-specific implementations encompassing\ntransportation, food, buildings, and auxiliary sectors, we can better elucidate\nhow these systems holistically advance sustainability objectives while\naddressing sector-specific constraints and opportunities. Moreover, we\ndelineate future research directions for evolving recommender systems beyond\nsustainability advocacy toward fostering environmental resilience and social\nconsciousness in society.\n","authors":["Xin Zhou","Lei Zhang","Honglei Zhang","Yixin Zhang","Xiaoxiong Zhang","Jie Zhang","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2411.07658v1.pdf","comment":"20pages, 10 figures. Working paper: https://github.com/enoche/SusRec"},{"id":"http://arxiv.org/abs/2404.13812v4","updated":"2024-11-12T07:44:20Z","published":"2024-04-22T01:16:11Z","title":"A Comparative Study on Enhancing Prediction in Social Network\n  Advertisement through Data Augmentation","summary":"  In the ever-evolving landscape of social network advertising, the volume and\naccuracy of data play a critical role in the performance of predictive models.\nHowever, the development of robust predictive algorithms is often hampered by\nthe limited size and potential bias present in real-world datasets. This study\npresents and explores a generative augmentation framework of social network\nadvertising data. Our framework explores three generative models for data\naugmentation - Generative Adversarial Networks (GANs), Variational Autoencoders\n(VAEs), and Gaussian Mixture Models (GMMs) - to enrich data availability and\ndiversity in the context of social network advertising analytics effectiveness.\nBy performing synthetic extensions of the feature space, we find that through\ndata augmentation, the performance of various classifiers has been\nquantitatively improved. Furthermore, we compare the relative performance gains\nbrought by each data augmentation technique, providing insights for\npractitioners to select appropriate techniques to enhance model performance.\nThis paper contributes to the literature by showing that synthetic data\naugmentation alleviates the limitations imposed by small or imbalanced datasets\nin the field of social network advertising. At the same time, this article also\nprovides a comparative perspective on the practicality of different data\naugmentation methods, thereby guiding practitioners to choose appropriate\ntechniques to enhance model performance.\n","authors":["Qikai Yang","Panfeng Li","Xinhe Xu","Zhicheng Ding","Wenjing Zhou","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13812v4.pdf","comment":"Accepted by 2024 4th International Conference on Machine Learning and\n  Intelligent Systems Engineering (MLISE)"},{"id":"http://arxiv.org/abs/2411.07589v1","updated":"2024-11-12T06:58:03Z","published":"2024-11-12T06:58:03Z","title":"Overhead-free User-side Recommender Systems","summary":"  Traditionally, recommendation algorithms have been designed for service\ndevelopers. But recently, a new paradigm called user-side recommender systems\nhas been proposed. User-side recommender systems are built and used by end\nusers, in sharp contrast to traditional provider-side recommender systems. Even\nif the official recommender system offered by the provider is not fair, end\nusers can create and enjoy their own user-side recommender systems by\nthemselves. Although the concept of user-side recommender systems is\nattractive, the problem is they require tremendous communication costs between\nthe user and the official system. Even the most efficient user-side recommender\nsystems require about 5 times more costs than provider-side recommender\nsystems. Such high costs hinder the adoption of user-side recommender systems.\nIn this paper, we propose overhead-free user-side recommender systems,\nRecCycle, which realizes user-side recommender systems without any\ncommunication overhead. The main idea of RecCycle is to recycle past\nrecommendation results offered by the provider's recommender systems. The\ningredients of RecCycle can be retrieved ``for free,'' and it greatly reduces\nthe cost of user-side recommendations. In the experiments, we confirm that\nRecCycle performs as well as state-of-the-art user-side recommendation\nalgorithms while RecCycle reduces costs significantly.\n","authors":["Ryoma Sato"],"pdf_url":"https://arxiv.org/pdf/2411.07589v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2208.09864,\n  arXiv:2403.15757"},{"id":"http://arxiv.org/abs/2411.07569v1","updated":"2024-11-12T06:03:47Z","published":"2024-11-12T06:03:47Z","title":"Towards Automated Model Design on Recommender Systems","summary":"  The increasing popularity of deep learning models has created new\nopportunities for developing AI-based recommender systems. Designing\nrecommender systems using deep neural networks requires careful architecture\ndesign, and further optimization demands extensive co-design efforts on jointly\noptimizing model architecture and hardware. Design automation, such as\nAutomated Machine Learning (AutoML), is necessary to fully exploit the\npotential of recommender model design, including model choices and\nmodel-hardware co-design strategies. We introduce a novel paradigm that\nutilizes weight sharing to explore abundant solution spaces. Our paradigm\ncreates a large supernet to search for optimal architectures and co-design\nstrategies to address the challenges of data multi-modality and heterogeneity\nin the recommendation domain. From a model perspective, the supernet includes a\nvariety of operators, dense connectivity, and dimension search options. From a\nco-design perspective, it encompasses versatile Processing-In-Memory (PIM)\nconfigurations to produce hardware-efficient models. Our solution space's\nscale, heterogeneity, and complexity pose several challenges, which we address\nby proposing various techniques for training and evaluating the supernet. Our\ncrafted models show promising results on three Click-Through Rates (CTR)\nprediction benchmarks, outperforming both manually designed and AutoML-crafted\nmodels with state-of-the-art performance when focusing solely on architecture\nsearch. From a co-design perspective, we achieve 2x FLOPs efficiency, 1.8x\nenergy efficiency, and 1.5x performance improvements in recommender models.\n","authors":["Tunhou Zhang","Dehua Cheng","Yuchen He","Zhengxing Chen","Xiaoliang Dai","Liang Xiong","Yudong Liu","Feng Cheng","Yufan Cao","Feng Yan","Hai Li","Yiran Chen","Wei Wen"],"pdf_url":"https://arxiv.org/pdf/2411.07569v1.pdf","comment":"Accepted in ACM Transactions on Recommender Systems. arXiv admin\n  note: substantial text overlap with arXiv:2207.07187"},{"id":"http://arxiv.org/abs/2411.07508v1","updated":"2024-11-12T03:05:03Z","published":"2024-11-12T03:05:03Z","title":"Feature Interaction Fusion Self-Distillation Network For CTR Prediction","summary":"  Click-Through Rate (CTR) prediction plays a vital role in recommender\nsystems, online advertising, and search engines. Most of the current approaches\nmodel feature interactions through stacked or parallel structures, with some\nemploying knowledge distillation for model compression. However, we observe\nsome limitations with these approaches: (1) In parallel structure models, the\nexplicit and implicit components are executed independently and simultaneously,\nwhich leads to insufficient information sharing within the feature set. (2) The\nintroduction of knowledge distillation technology brings about the problems of\ncomplex teacher-student framework design and low knowledge transfer efficiency.\n(3) The dataset and the process of constructing high-order feature interactions\ncontain significant noise, which limits the model's effectiveness. To address\nthese limitations, we propose FSDNet, a CTR prediction framework incorporating\na plug-and-play fusion self-distillation module. Specifically, FSDNet forms\nconnections between explicit and implicit feature interactions at each layer,\nenhancing the sharing of information between different features. The deepest\nfused layer is then used as the teacher model, utilizing self-distillation to\nguide the training of shallow layers. Empirical evaluation across four\nbenchmark datasets validates the framework's efficacy and generalization\ncapabilities. The code is available on https://github.com/coder-qiu/FSDNet.\n","authors":["Lei Sang","Qiuze Ru","Honghao Li","Yiwen Zhang","Xindong Wu"],"pdf_url":"https://arxiv.org/pdf/2411.07508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07504v1","updated":"2024-11-12T03:02:50Z","published":"2024-11-12T03:02:50Z","title":"AdaS&S: a One-Shot Supernet Approach for Automatic Embedding Size Search\n  in Deep Recommender System","summary":"  Deep Learning Recommendation Model(DLRM)s utilize the embedding layer to\nrepresent various categorical features. Traditional DLRMs adopt unified\nembedding size for all features, leading to suboptimal performance and\nredundant parameters. Thus, lots of Automatic Embedding size Search (AES) works\nfocus on obtaining mixed embedding sizes with strong model performance.\nHowever, previous AES works can hardly address several challenges together: (1)\nThe search results of embedding sizes are unstable; (2) Recommendation effect\nwith AES results is unsatisfactory; (3) Memory cost of embeddings is\nuncontrollable. To address these challenges, we propose a novel one-shot AES\nframework called AdaS&S, in which a supernet encompassing various candidate\nembeddings is built and AES is performed as searching network architectures\nwithin it. Our framework contains two main stages: In the first stage, we\ndecouple training parameters from searching embedding sizes, and propose the\nAdaptive Sampling method to yield a well-trained supernet, which further helps\nto produce stable AES results. In the second stage, to obtain embedding sizes\nthat benefits the model effect, we design a reinforcement learning search\nprocess which utilizes the supernet trained previously. Meanwhile, to adapt\nsearching to specific resource constraint, we introduce the resource\ncompetition penalty to balance the model effectiveness and memory cost of\nembeddings. We conduct extensive experiments on public datasets to show the\nsuperiority of AdaS&S. Our method could improve AUC by about 0.3% while saving\nabout 20% of model parameters. Empirical analysis also shows that the stability\nof searching results in AdaS&S significantly exceeds other methods.\n","authors":["He Wei","Yuekui Yang","Yang Zhang","Haiyang Wu","Meixi Liu","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2411.07504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07482v1","updated":"2024-11-12T02:08:19Z","published":"2024-11-12T02:08:19Z","title":"Enhancing Link Prediction with Fuzzy Graph Attention Networks and\n  Dynamic Negative Sampling","summary":"  Link prediction is crucial for understanding complex networks but traditional\nGraph Neural Networks (GNNs) often rely on random negative sampling, leading to\nsuboptimal performance. This paper introduces Fuzzy Graph Attention Networks\n(FGAT), a novel approach integrating fuzzy rough sets for dynamic negative\nsampling and enhanced node feature aggregation. Fuzzy Negative Sampling (FNS)\nsystematically selects high-quality negative edges based on fuzzy similarities,\nimproving training efficiency. FGAT layer incorporates fuzzy rough set\nprinciples, enabling robust and discriminative node representations.\nExperiments on two research collaboration networks demonstrate FGAT's superior\nlink prediction accuracy, outperforming state-of-the-art baselines by\nleveraging the power of fuzzy rough sets for effective negative sampling and\nnode feature learning.\n","authors":["Jinming Xing"],"pdf_url":"https://arxiv.org/pdf/2411.07482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04916v4","updated":"2024-11-12T01:01:32Z","published":"2023-11-02T04:01:04Z","title":"Explainable Identification of Hate Speech towards Islam using Graph\n  Neural Networks","summary":"  Islamophobic language on online platforms fosters intolerance, making\ndetection and elimination crucial for promoting harmony. Traditional hate\nspeech detection models rely on NLP techniques like tokenization,\npart-of-speech tagging, and encoder-decoder models. However, Graph Neural\nNetworks (GNNs), with their ability to utilize relationships between data\npoints, offer more effective detection and greater explainability. In this\nwork, we represent speeches as nodes and connect them with edges based on their\ncontext and similarity to develop the graph. This study introduces a novel\nparadigm using GNNs to identify and explain hate speech towards Islam. Our\nmodel leverages GNNs to understand the context and patterns of hate speech by\nconnecting texts via pretrained NLP-generated word embeddings, achieving\nstate-of-the-art performance and enhancing detection accuracy while providing\nvaluable explanations. This highlights the potential of GNNs in combating\nonline hate speech and fostering a safer, more inclusive online environment.\n","authors":["Azmine Toushik Wasi"],"pdf_url":"https://arxiv.org/pdf/2311.04916v4.pdf","comment":"Accepted in: (i) NeurIPS 2023 : Muslims in ML Workshop (Non-archival)\n  (https://www.musiml.org/schedule/#:~:text=Azmine%20Toushik%20Wasi) (ii) EMNLP\n  2024 : NLP for Positive Impact Workshop (Archival; ACL Anthology:\n  https://aclanthology.org/2024.nlp4pi-1.23/)"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.08027v1","updated":"2024-11-12T18:56:58Z","published":"2024-11-12T18:56:58Z","title":"LLMPhy: Complex Physical Reasoning Using Large Language Models and World\n  Models","summary":"  Physical reasoning is an important skill needed for robotic agents when\noperating in the real world. However, solving such reasoning problems often\ninvolves hypothesizing and reflecting over complex multi-body interactions\nunder the effect of a multitude of physical forces and thus learning all such\ninteractions poses a significant hurdle for state-of-the-art machine learning\nframeworks, including large language models (LLMs). To study this problem, we\npropose a new physical reasoning task and a dataset, dubbed TraySim. Our task\ninvolves predicting the dynamics of several objects on a tray that is given an\nexternal impact -- the domino effect of the ensued object interactions and\ntheir dynamics thus offering a challenging yet controlled setup, with the goal\nof reasoning being to infer the stability of the objects after the impact. To\nsolve this complex physical reasoning task, we present LLMPhy, a zero-shot\nblack-box optimization framework that leverages the physics knowledge and\nprogram synthesis abilities of LLMs, and synergizes these abilities with the\nworld models built into modern physics engines. Specifically, LLMPhy uses an\nLLM to generate code to iteratively estimate the physical hyperparameters of\nthe system (friction, damping, layout, etc.) via an implicit\nanalysis-by-synthesis approach using a (non-differentiable) simulator in the\nloop and uses the inferred parameters to imagine the dynamics of the scene\ntowards solving the reasoning task. To show the effectiveness of LLMPhy, we\npresent experiments on our TraySim dataset to predict the steady-state poses of\nthe objects. Our results show that the combination of the LLM and the physics\nengine leads to state-of-the-art zero-shot physical reasoning performance,\nwhile demonstrating superior convergence against standard black-box\noptimization methods and better estimation of the physical parameters.\n","authors":["Anoop Cherian","Radu Corcodel","Siddarth Jain","Diego Romeres"],"pdf_url":"https://arxiv.org/pdf/2411.08027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08024v1","updated":"2024-11-12T18:54:55Z","published":"2024-11-12T18:54:55Z","title":"Leonardo vindicated: Pythagorean trees for minimal reconstruction of the\n  natural branching structures","summary":"  Trees continue to fascinate with their natural beauty and as engineering\nmasterpieces optimal with respect to several independent criteria. Pythagorean\ntree is a well-known fractal design that realistically mimics the natural tree\nbranching structures. We study various types of Pythagorean-like fractal trees\nwith different shapes of the base, branching angles and relaxed scales in an\nattempt to identify and explain which variants are the closest match to the\nbranching structures commonly observed in the natural world. Pursuing\nsimultaneously the realism and minimalism of the fractal tree model, we have\ndeveloped a flexibly parameterised and fast algorithm to grow and visually\nexamine deep Pythagorean-inspired fractal trees with the capability to orderly\nover- or underestimate the Leonardo da Vinci's tree branching rule as well as\ncontrol various imbalances and branching angles. We tested the realism of the\ngenerated fractal tree images by means of the classification accuracy of\ndetecting natural tree with the transfer-trained deep Convolutional Neural\nNetworks (CNNs). Having empirically established the parameters of the fractal\ntrees that maximize the CNN's natural tree class classification accuracy we\nhave translated them back to the scales and angles of branches and came to the\ninteresting conclusions that support the da Vinci branching rule and golden\nratio based scaling for both the shape of the branch and imbalance between the\nchild branches, and claim the flexibly parameterized fractal trees can be used\nto generate artificial examples to train robust detectors of different species\nof trees.\n","authors":["Dymitr Ruta","Corrado Mio","Ernesto Damiani"],"pdf_url":"https://arxiv.org/pdf/2411.08024v1.pdf","comment":"22 pages, lots of hi res figures I had to reduce quality of,\n  submitting as a requirement to the Theory of Computing Journal"},{"id":"http://arxiv.org/abs/2411.08019v1","updated":"2024-11-12T18:50:35Z","published":"2024-11-12T18:50:35Z","title":"Language Models as Causal Effect Generators","summary":"  We present a framework for large language model (LLM) based data generation\nwith controllable causal structure. In particular, we define a procedure for\nturning any language model and any directed acyclic graph (DAG) into a\nsequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM\nis a causal model with user-defined structure and LLM-defined structural\nequations. We characterize how an SD-SCM allows sampling from observational,\ninterventional, and counterfactual distributions according to the desired\ncausal structure. We then leverage this procedure to propose a new type of\nbenchmark for causal inference methods, generating individual-level\ncounterfactual data without needing to manually specify functional\nrelationships between variables. We create an example benchmark consisting of\nthousands of datasets, and test a suite of popular estimation methods on these\ndatasets for average, conditional average, and individual treatment effect\nestimation, both with and without hidden confounding. Apart from generating\ndata, the same procedure also allows us to test for the presence of a causal\neffect that might be encoded in an LLM. This procedure can underpin auditing\nLLMs for misinformation, discrimination, or otherwise undesirable behavior. We\nbelieve SD-SCMs can serve as a useful tool in any application that would\nbenefit from sequential data with controllable causal structure.\n","authors":["Lucius E. J. Bynum","Kyunghyun Cho"],"pdf_url":"https://arxiv.org/pdf/2411.08019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08017v1","updated":"2024-11-12T18:49:06Z","published":"2024-11-12T18:49:06Z","title":"Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model\n  with Compact Wavelet Encodings","summary":"  Large-scale 3D generative models require substantial computational resources\nyet often fall short in capturing fine details and complex geometries at high\nresolutions. We attribute this limitation to the inefficiency of current\nrepresentations, which lack the compactness required to model the generative\nmodels effectively. To address this, we introduce a novel approach called\nWavelet Latent Diffusion, or WaLa, that encodes 3D shapes into wavelet-based,\ncompact latent encodings. Specifically, we compress a $256^3$ signed distance\nfield into a $12^3 \\times 4$ latent grid, achieving an impressive 2427x\ncompression ratio with minimal loss of detail. This high level of compression\nallows our method to efficiently train large-scale generative networks without\nincreasing the inference time. Our models, both conditional and unconditional,\ncontain approximately one billion parameters and successfully generate\nhigh-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapid\ninference, producing shapes within two to four seconds depending on the\ncondition, despite the model's scale. We demonstrate state-of-the-art\nperformance across multiple datasets, with significant improvements in\ngeneration quality, diversity, and computational efficiency. We open-source our\ncode and, to the best of our knowledge, release the largest pretrained 3D\ngenerative models across different modalities.\n","authors":["Aditya Sanghi","Aliasghar Khani","Pradyumna Reddy","Arianna Rampini","Derek Cheung","Kamal Rahimi Malekshan","Kanika Madan","Hooman Shayani"],"pdf_url":"https://arxiv.org/pdf/2411.08017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08013v1","updated":"2024-11-12T18:43:27Z","published":"2024-11-12T18:43:27Z","title":"Investigating the Effectiveness of Explainability Methods in Parkinson's\n  Detection from Speech","summary":"  Speech impairments in Parkinson's disease (PD) provide significant early\nindicators for diagnosis. While models for speech-based PD detection have shown\nstrong performance, their interpretability remains underexplored. This study\nsystematically evaluates several explainability methods to identify PD-specific\nspeech features, aiming to support the development of accurate, interpretable\nmodels for clinical decision-making in PD diagnosis and monitoring. Our\nmethodology involves (i) obtaining attributions and saliency maps using\nmainstream interpretability techniques, (ii) quantitatively evaluating the\nfaithfulness of these maps and their combinations obtained via union and\nintersection through a range of established metrics, and (iii) assessing the\ninformation conveyed by the saliency maps for PD detection from an auxiliary\nclassifier. Our results reveal that, while explanations are aligned with the\nclassifier, they often fail to provide valuable information for domain experts.\n","authors":["Eleonora Mancini","Francesco Paissan","Paolo Torroni","Cem Subakan","Mirco Ravanelli"],"pdf_url":"https://arxiv.org/pdf/2411.08013v1.pdf","comment":"The first two authors contributed equally to this research: author\n  order is alphabetical"},{"id":"http://arxiv.org/abs/2401.11555v2","updated":"2024-11-12T18:18:43Z","published":"2024-01-21T18:00:15Z","title":"VQC-Based Reinforcement Learning with Data Re-uploading: Performance and\n  Trainability","summary":"  Reinforcement Learning (RL) consists of designing agents that make\nintelligent decisions without human supervision. When used alongside function\napproximators such as Neural Networks (NNs), RL is capable of solving extremely\ncomplex problems. Deep Q-Learning, a RL algorithm that uses Deep NNs, achieved\nsuper-human performance in some specific tasks. Nonetheless, it is also\npossible to use Variational Quantum Circuits (VQCs) as function approximators\nin RL algorithms. This work empirically studies the performance and\ntrainability of such VQC-based Deep Q-Learning models in classic control\nbenchmark environments. More specifically, we research how data re-uploading\naffects both these metrics. We show that the magnitude and the variance of the\ngradients of these models remain substantial throughout training due to the\nmoving targets of Deep Q-Learning. Moreover, we empirically show that\nincreasing the number of qubits does not lead to an exponential vanishing\nbehavior of the magnitude and variance of the gradients for a PQC approximating\na 2-design, unlike what was expected due to the Barren Plateau Phenomenon. This\nhints at the possibility of VQCs being specially adequate for being used as\nfunction approximators in such a context.\n","authors":["Rodrigo Coelho","Andr√© Sequeira","Lu√≠s Paulo Santos"],"pdf_url":"https://arxiv.org/pdf/2401.11555v2.pdf","comment":"26 pages, 11 figures"},{"id":"http://arxiv.org/abs/2411.07990v1","updated":"2024-11-12T18:15:19Z","published":"2024-11-12T18:15:19Z","title":"Derivational Morphology Reveals Analogical Generalization in Large\n  Language Models","summary":"  What mechanisms underlie linguistic generalization in large language models\n(LLMs)? This question has attracted considerable attention, with most studies\nanalyzing the extent to which the language skills of LLMs resemble rules. As of\nyet, it is not known whether linguistic generalization in LLMs could equally\nwell be explained as the result of analogical processes, which can be\nformalized as similarity operations on stored exemplars. A key shortcoming of\nprior research is its focus on linguistic phenomena with a high degree of\nregularity, for which rule-based and analogical approaches make the same\npredictions. Here, we instead examine derivational morphology, specifically\nEnglish adjective nominalization, which displays notable variability. We\nintroduce a new method for investigating linguistic generalization in LLMs:\nfocusing on GPT-J, we fit cognitive models that instantiate rule-based and\nanalogical learning to the LLM training data and compare their predictions on a\nset of nonce adjectives with those of the LLM, allowing us to draw direct\nconclusions regarding underlying mechanisms. As expected, rule-based and\nanalogical models explain the predictions of GPT-J equally well for adjectives\nwith regular nominalization patterns. However, for adjectives with variable\nnominalization patterns, the analogical model provides a much better match.\nFurthermore, GPT-J's behavior is sensitive to the individual word frequencies,\neven for regular forms, a behavior that is consistent with an analogical\naccount of regular forms but not a rule-based one. These findings refute the\nhypothesis that GPT-J's linguistic generalization on adjective nominalization\ninvolves rules, suggesting similarity operations on stored exemplars as the\nunderlying mechanism. Overall, our study suggests that analogical processes\nplay a bigger role in the linguistic generalization of LLMs than previously\nthought.\n","authors":["Valentin Hofmann","Leonie Weissweiler","David Mortensen","Hinrich Sch√ºtze","Janet Pierrehumbert"],"pdf_url":"https://arxiv.org/pdf/2411.07990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02271v2","updated":"2024-11-12T18:11:30Z","published":"2024-11-04T17:03:52Z","title":"On the Utilization of Unique Node Identifiers in Graph Neural Networks","summary":"  Graph Neural Networks have inherent representational limitations due to their\nmessage-passing structure. Recent work has suggested that these limitations can\nbe overcome by using unique node identifiers (UIDs). Here we argue that despite\nthe advantages of UIDs, one of their disadvantages is that they lose the\ndesirable property of permutation-equivariance. We thus propose to focus on UID\nmodels that are permutation-equivariant, and present theoretical arguments for\ntheir advantages. Motivated by this, we propose a method to regularize UID\nmodels towards permutation equivariance, via a contrastive loss. We empirically\ndemonstrate that our approach improves generalization and extrapolation\nabilities while providing faster training convergence. On the recent BREC\nexpressiveness benchmark, our proposed method achieves state-of-the-art\nperformance compared to other random-based approaches.\n","authors":["Maya Bechler-Speicher","Moshe Eliasof","Carola-Bibiane Sch√∂nlieb","Ran Gilad-Bachrach","Amir Globerson"],"pdf_url":"https://arxiv.org/pdf/2411.02271v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07979v1","updated":"2024-11-12T17:58:40Z","published":"2024-11-12T17:58:40Z","title":"Exact, Tractable Gauss-Newton Optimization in Deep Reversible\n  Architectures Reveal Poor Generalization","summary":"  Second-order optimization has been shown to accelerate the training of deep\nneural networks in many applications, often yielding faster progress per\niteration on the training loss compared to first-order optimizers.However, the\ngeneralization properties of second-order methods are still being debated.\nTheoretical investigations have proved difficult to carry out outside the\ntractable settings of heavily simplified model classes -- thus, the relevance\nof existing theories to practical deep learning applications remains unclear.\nSimilarly, empirical studies in large-scale models and real datasets are\nsignificantly confounded by the necessity to approximate second-order updates\nin practice. It is often unclear whether the observed generalization behaviour\narises specifically from the second-order nature of the parameter updates, or\ninstead reflects the specific structured (e.g.\\ Kronecker) approximations used\nor any damping-based interpolation towards first-order updates. Here, we show\nfor the first time that exact Gauss-Newton (GN) updates take on a tractable\nform in a class of deep reversible architectures that are sufficiently\nexpressive to be meaningfully applied to common benchmark datasets. We exploit\nthis novel setting to study the training and generalization properties of the\nGN optimizer. We find that exact GN generalizes poorly. In the mini-batch\ntraining setting, this manifests as rapidly saturating progress even on the\n\\emph{training} loss, with parameter updates found to overfit each\nmini-batchatch without producing the features that would support generalization\nto other mini-batches. We show that our experiments run in the ``lazy'' regime,\nin which the neural tangent kernel (NTK) changes very little during the course\nof training. This behaviour is associated with having no significant changes in\nneural representations, explaining the lack of generalization.\n","authors":["Davide Buffelli","Jamie McGowan","Wangkun Xu","Alexandru Cioba","Da-shan Shiu","Guillaume Hennequin","Alberto Bernacchia"],"pdf_url":"https://arxiv.org/pdf/2411.07979v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07978v1","updated":"2024-11-12T17:58:34Z","published":"2024-11-12T17:58:34Z","title":"Doubly Robust Regression Discontinuity Designs","summary":"  This study introduces a doubly robust (DR) estimator for regression\ndiscontinuity (RD) designs. In RD designs, treatment effects are estimated in a\nquasi-experimental setting where treatment assignment depends on whether a\nrunning variable surpasses a predefined cutoff. A common approach in RD\nestimation is to apply nonparametric regression methods, such as local linear\nregression. In such an approach, the validity relies heavily on the consistency\nof nonparametric estimators and is limited by the nonparametric convergence\nrate, thereby preventing $\\sqrt{n}$-consistency. To address these issues, we\npropose the DR-RD estimator, which combines two distinct estimators for the\nconditional expected outcomes. If either of these estimators is consistent, the\ntreatment effect estimator remains consistent. Furthermore, due to the\ndebiasing effect, our proposed estimator achieves $\\sqrt{n}$-consistency if\nboth regression estimators satisfy certain mild conditions, which also\nsimplifies statistical inference.\n","authors":["Masahiro Kato"],"pdf_url":"https://arxiv.org/pdf/2411.07978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07971v1","updated":"2024-11-12T17:51:45Z","published":"2024-11-12T17:51:45Z","title":"Optimal Control of Mechanical Ventilators with Learned Respiratory\n  Dynamics","summary":"  Deciding on appropriate mechanical ventilator management strategies\nsignificantly impacts the health outcomes for patients with respiratory\ndiseases. Acute Respiratory Distress Syndrome (ARDS) is one such disease that\nrequires careful ventilator operation to be effectively treated. In this work,\nwe frame the management of ventilators for patients with ARDS as a sequential\ndecision making problem using the Markov decision process framework. We\nimplement and compare controllers based on clinical guidelines contained in the\nARDSnet protocol, optimal control theory, and learned latent dynamics\nrepresented as neural networks. The Pulse Physiology Engine's respiratory\ndynamics simulator is used to establish a repeatable benchmark, gather\nsimulated data, and quantitatively compare these controllers. We score\nperformance in terms of measured improvement in established ARDS health markers\n(pertaining to improved respiratory rate, oxygenation, and vital signs). Our\nresults demonstrate that techniques leveraging neural networks and optimal\ncontrol can automatically discover effective ventilation management strategies\nwithout access to explicit ventilator management procedures or guidelines (such\nas those defined in the ARDSnet protocol).\n","authors":["Isaac Ronald Ward","Dylan M. Asmar","Mansur Arief","Jana Krystofova Mike","Mykel J. Kochenderfer"],"pdf_url":"https://arxiv.org/pdf/2411.07971v1.pdf","comment":"2024 IEEE 37th International Symposium on Computer-Based Medical\n  Systems (CBMS), 7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.09434v2","updated":"2024-11-12T17:49:12Z","published":"2024-07-12T17:09:47Z","title":"Foundation Models for the Electric Power Grid","summary":"  Foundation models (FMs) currently dominate news headlines. They employ\nadvanced deep learning architectures to extract structural information\nautonomously from vast datasets through self-supervision. The resulting rich\nrepresentations of complex systems and dynamics can be applied to many\ndownstream applications. Therefore, FMs can find uses in electric power grids,\nchallenged by the energy transition and climate change. In this paper, we call\nfor the development of, and state why we believe in, the potential of FMs for\nelectric grids. We highlight their strengths and weaknesses amidst the\nchallenges of a changing grid. We argue that an FM learning from diverse grid\ndata and topologies could unlock transformative capabilities, pioneering a new\napproach in leveraging AI to redefine how we manage complexity and uncertainty\nin the electric grid. Finally, we discuss a power grid FM concept, namely\nGridFM, based on graph neural networks and show how different downstream tasks\nbenefit.\n","authors":["Hendrik F. Hamann","Thomas Brunschwiler","Blazhe Gjorgiev","Leonardo S. A. Martins","Alban Puech","Anna Varbella","Jonas Weiss","Juan Bernabe-Moreno","Alexandre Blondin Mass√©","Seong Choi","Ian Foster","Bri-Mathias Hodge","Rishabh Jain","Kibaek Kim","Vincent Mai","Fran√ßois Mirall√®s","Martin De Montigny","Octavio Ramos-Lea√±os","Hussein Supr√™me","Le Xie","El-Nasser S. Youssef","Arnaud Zinflou","Alexander J. Belyi","Ricardo J. Bessa","Bishnu Prasad Bhattarai","Johannes Schmude","Stanislav Sobolevsky"],"pdf_url":"https://arxiv.org/pdf/2407.09434v2.pdf","comment":"Major equal contributors: H.F.H., T.B., B.G., L.S.A.M., A.P., A.V.,\n  J.W.; Significant equal contributors: J.B., A.B.M., S.C., I.F., B.H., R.J.,\n  K.K., V.M., F.M., M.D.M., O.R., H.S., L.X., E.S.Y., A.Z.; Other equal\n  contributors: A.J.B., R.J.B., B.P.B., J.S., S.S; Lead contact: H.F.H"},{"id":"http://arxiv.org/abs/2411.07964v1","updated":"2024-11-12T17:41:16Z","published":"2024-11-12T17:41:16Z","title":"Sleep Staging from Airflow Signals Using Fourier Approximations of\n  Persistence Curves","summary":"  Sleep staging is a challenging task, typically manually performed by sleep\ntechnologists based on electroencephalogram and other biosignals of patients\ntaken during overnight sleep studies. Recent work aims to leverage automated\nalgorithms to perform sleep staging not based on electroencephalogram signals,\nbut rather based on the airflow signals of subjects. Prior work uses ideas from\ntopological data analysis (TDA), specifically Hermite function expansions of\npersistence curves (HEPC) to featurize airflow signals. However, finite order\nHEPC captures only partial information. In this work, we propose Fourier\napproximations of persistence curves (FAPC), and use this technique to perform\nsleep staging based on airflow signals. We analyze performance using an XGBoost\nmodel on 1155 pediatric sleep studies taken from the Nationwide Children's\nHospital Sleep DataBank (NCHSDB), and find that FAPC methods provide\ncomplimentary information to HEPC methods alone, leading to a 4.9% increase in\nperformance over baseline methods.\n","authors":["Shashank Manjunath","Hau-Tieng Wu","Aarti Sathyanarayana"],"pdf_url":"https://arxiv.org/pdf/2411.07964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07959v1","updated":"2024-11-12T17:36:20Z","published":"2024-11-12T17:36:20Z","title":"On the Convergence of Continual Federated Learning Using Incrementally\n  Aggregated Gradients","summary":"  The holy grail of machine learning is to enable Continual Federated Learning\n(CFL) to enhance the efficiency, privacy, and scalability of AI systems while\nlearning from streaming data. The primary challenge of a CFL system is to\novercome global catastrophic forgetting, wherein the accuracy of the global\nmodel trained on new tasks declines on the old tasks. In this work, we propose\nContinual Federated Learning with Aggregated Gradients (C-FLAG), a novel\nreplay-memory based federated strategy consisting of edge-based gradient\nupdates on memory and aggregated gradients on the current data. We provide\nconvergence analysis of the C-FLAG approach which addresses forgetting and bias\nwhile converging at a rate of $O(1/\\sqrt{T})$ over $T$ communication rounds. We\nformulate an optimization sub-problem that minimizes catastrophic forgetting,\ntranslating CFL into an iterative algorithm with adaptive learning rates that\nensure seamless learning across tasks. We empirically show that C-FLAG\noutperforms several state-of-the-art baselines on both task and\nclass-incremental settings with respect to metrics such as accuracy and\nforgetting.\n","authors":["Satish Kumar Keshri","Nazreen Shah","Ranjitha Prasad"],"pdf_url":"https://arxiv.org/pdf/2411.07959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07957v1","updated":"2024-11-12T17:34:38Z","published":"2024-11-12T17:34:38Z","title":"Tukey g-and-h neural network regression for non-Gaussian data","summary":"  This paper addresses non-Gaussian regression with neural networks via the use\nof the Tukey g-and-h distribution.The Tukey g-and-h transform is a flexible\nparametric transform with two parameters $g$ and $h$ which, when applied to a\nstandard normal random variable, introduces both skewness and kurtosis,\nresulting in a distribution commonly called the Tukey g-and-h distribution.\nSpecific values of $g$ and $h$ produce good approximations to other families of\ndistributions, such as the Cauchy and student-t distributions. The flexibility\nof the Tukey g-and-h distribution has driven its popularity in the statistical\ncommunity, in applied sciences and finance. In this work we consider the\ntraining of a neural network to predict the parameters of a Tukey g-and-h\ndistribution in a regression framework via the minimization of the\ncorresponding negative log-likelihood, despite the latter having no closed-form\nexpression. We demonstrate the efficiency of our procedure in simulated\nexamples and apply our method to a real-world dataset of global crop yield for\nseveral types of crops. Finally, we show how we can carry out a goodness-of-fit\nanalysis between the predicted distributions and the test data. A Pytorch\nimplementation is made available on Github and as a Pypi package.\n","authors":["Arthur P. Guillaumin","Natalia Efremova"],"pdf_url":"https://arxiv.org/pdf/2411.07957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07954v1","updated":"2024-11-12T17:30:31Z","published":"2024-11-12T17:30:31Z","title":"Learning Memory Mechanisms for Decision Making through Demonstrations","summary":"  In Partially Observable Markov Decision Processes, integrating an agent's\nhistory into memory poses a significant challenge for decision-making.\nTraditional imitation learning, relying on observation-action pairs for expert\ndemonstrations, fails to capture the expert's memory mechanisms used in\ndecision-making. To capture memory processes as demonstrations, we introduce\nthe concept of \\textbf{memory dependency pairs} $(p, q)$ indicating that events\nat time $p$ are recalled for decision-making at time $q$. We introduce\n\\textbf{AttentionTuner} to leverage memory dependency pairs in Transformers and\nfind significant improvements across several tasks compared to standard\nTransformers when evaluated on Memory Gym and the Long-term Memory Benchmark.\nCode is available at https://github.com/WilliamYue37/AttentionTuner .\n","authors":["William Yue","Bo Liu","Peter Stone"],"pdf_url":"https://arxiv.org/pdf/2411.07954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07942v1","updated":"2024-11-12T17:11:46Z","published":"2024-11-12T17:11:46Z","title":"Towards Low-bit Communication for Tensor Parallel LLM Inference","summary":"  Tensor parallelism provides an effective way to increase server large\nlanguage model (LLM) inference efficiency despite adding an additional\ncommunication cost. However, as server LLMs continue to scale in size, they\nwill need to be distributed across more devices, magnifying the communication\ncost. One way to approach this problem is with quantization, but current\nmethods for LLMs tend to avoid quantizing the features that tensor parallelism\nneeds to communicate. Taking advantage of consistent outliers in communicated\nfeatures, we introduce a quantization method that reduces communicated values\non average from 16 bits to 4.2 bits while preserving nearly all of the original\nperformance. For instance, our method maintains around 98.0% and 99.5% of Gemma\n2 27B's and Llama 2 13B's original performance, respectively, averaged across\nall tasks we evaluated on.\n","authors":["Harry Dong","Tyler Johnson","Minsik Cho","Emad Soroush"],"pdf_url":"https://arxiv.org/pdf/2411.07942v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07934v1","updated":"2024-11-12T17:04:56Z","published":"2024-11-12T17:04:56Z","title":"Doubly Mild Generalization for Offline Reinforcement Learning","summary":"  Offline Reinforcement Learning (RL) suffers from the extrapolation error and\nvalue overestimation. From a generalization perspective, this issue can be\nattributed to the over-generalization of value functions or policies towards\nout-of-distribution (OOD) actions. Significant efforts have been devoted to\nmitigating such generalization, and recent in-sample learning approaches have\nfurther succeeded in entirely eschewing it. Nevertheless, we show that mild\ngeneralization beyond the dataset can be trusted and leveraged to improve\nperformance under certain conditions. To appropriately exploit generalization\nin offline RL, we propose Doubly Mild Generalization (DMG), comprising (i) mild\naction generalization and (ii) mild generalization propagation. The former\nrefers to selecting actions in a close neighborhood of the dataset to maximize\nthe Q values. Even so, the potential erroneous generalization can still be\npropagated, accumulated, and exacerbated by bootstrapping. In light of this,\nthe latter concept is introduced to mitigate the generalization propagation\nwithout impeding the propagation of RL learning signals. Theoretically, DMG\nguarantees better performance than the in-sample optimal policy in the oracle\ngeneralization scenario. Even under worst-case generalization, DMG can still\ncontrol value overestimation at a certain level and lower bound the\nperformance. Empirically, DMG achieves state-of-the-art performance across\nGym-MuJoCo locomotion tasks and challenging AntMaze tasks. Moreover, benefiting\nfrom its flexibility in both generalization aspects, DMG enjoys a seamless\ntransition from offline to online learning and attains strong online\nfine-tuning performance.\n","authors":["Yixiu Mao","Qi Wang","Yun Qu","Yuhang Jiang","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2411.07934v1.pdf","comment":"Accepted to NeurIPS 2024. arXiv admin note: substantial text overlap\n  with arXiv:2410.19400"},{"id":"http://arxiv.org/abs/2411.07933v1","updated":"2024-11-12T17:04:12Z","published":"2024-11-12T17:04:12Z","title":"Prediction of Acoustic Communication Performance for AUVs using Gaussian\n  Process Classification","summary":"  Cooperating autonomous underwater vehicles (AUVs) often rely on acoustic\ncommunication to coordinate their actions effectively. However, the reliability\nof underwater acoustic communication decreases as the communication range\nbetween vehicles increases. Consequently, teams of cooperating AUVs typically\nmake conservative assumptions about the maximum range at which they can\ncommunicate reliably. To address this limitation, we propose a novel approach\nthat involves learning a map representing the probability of successful\ncommunication based on the locations of the transmitting and receiving\nvehicles. This probabilistic communication map accounts for factors such as the\nrange between vehicles, environmental noise, and multi-path effects at a given\nlocation. In pursuit of this goal, we investigate the application of Gaussian\nprocess binary classification to generate the desired communication map. We\nspecialize existing results to this specific binary classification problem and\nexplore methods to incorporate uncertainty in vehicle location into the mapping\nprocess. Furthermore, we compare the prediction performance of the probability\ncommunication map generated using binary classification with that of a\nsignal-to-noise ratio (SNR) communication map generated using Gaussian process\nregression. Our approach is experimentally validated using communication and\nnavigation data collected during trials with a pair of Virginia Tech 690 AUVs.\n","authors":["Yifei Gao","Harun Yetkin","McMahon James","Daniel J. Stilwell"],"pdf_url":"https://arxiv.org/pdf/2411.07933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01897v2","updated":"2024-11-12T16:48:29Z","published":"2024-11-04T09:04:11Z","title":"LE-PDE++: Mamba for accelerating PDEs Simulations","summary":"  Partial Differential Equations are foundational in modeling science and\nnatural systems such as fluid dynamics and weather forecasting. The Latent\nEvolution of PDEs method is designed to address the computational intensity of\nclassical and deep learning-based PDE solvers by proposing a scalable and\nefficient alternative. To enhance the efficiency and accuracy of LE-PDE, we\nincorporate the Mamba model, an advanced machine learning model known for its\npredictive efficiency and robustness in handling complex dynamic systems with a\nprogressive learning strategy. The LE-PDE was tested on several benchmark\nproblems. The method demonstrated a marked reduction in computational time\ncompared to traditional solvers and standalone deep learning models while\nmaintaining high accuracy in predicting system behavior over time. Our method\ndoubles the inference speed compared to the LE-PDE while retaining the same\nlevel of parameter efficiency, making it well-suited for scenarios requiring\nlong-term predictions.\n","authors":["Aoming Liang","Zhaoyang Mu","Qi liu","Ruipeng Li","Mingming Ge","Dixia Fan"],"pdf_url":"https://arxiv.org/pdf/2411.01897v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03497v2","updated":"2024-11-12T16:44:24Z","published":"2024-08-07T01:37:10Z","title":"Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and\n  Tabnet with SMOTEENN","summary":"  Bank credit risk is a significant challenge in modern financial transactions,\nand the ability to identify qualified credit card holders among a large number\nof applicants is crucial for the profitability of a bank'sbank's credit card\nbusiness. In the past, screening applicants'applicants' conditions often\nrequired a significant amount of manual labor, which was time-consuming and\nlabor-intensive. Although the accuracy and reliability of previously used ML\nmodels have been continuously improving, the pursuit of more reliable and\npowerful AI intelligent models is undoubtedly the unremitting pursuit by major\nbanks in the financial industry. In this study, we used a dataset of over\n40,000 records provided by a commercial bank as the research object. We\ncompared various dimensionality reduction techniques such as PCA and T-SNE for\npreprocessing high-dimensional datasets and performed in-depth adaptation and\ntuning of distributed models such as LightGBM and XGBoost, as well as deep\nmodels like Tabnet. After a series of research and processing, we obtained\nexcellent research results by combining SMOTEENN with these techniques. The\nexperiments demonstrated that LightGBM combined with PCA and SMOTEENN\ntechniques can assist banks in accurately predicting potential high-quality\ncustomers, showing relatively outstanding performance compared to other models.\n","authors":["Chang Yu","Yixin Jin","Qianwen Xing","Ye Zhang","Shaobo Guo","Shuchen Meng"],"pdf_url":"https://arxiv.org/pdf/2408.03497v2.pdf","comment":"8 pagess on IEEE ICPICS"},{"id":"http://arxiv.org/abs/2406.04658v3","updated":"2024-11-12T16:44:20Z","published":"2024-06-07T05:56:43Z","title":"Advanced Payment Security System:XGBoost, LightGBM and SMOTE Integrated","summary":"  With the rise of various online and mobile payment systems, transaction fraud\nhas become a significant threat to financial security. This study explores the\napplication of advanced machine learning models, specifically based on XGBoost\nand LightGBM, for developing a more accurate and robust Payment Security\nProtection Model. To enhance data reliability, we meticulously processed the\ndata sources and applied SMOTE (Synthetic Minority Over-sampling Technique) to\naddress class imbalance and improve data representation. By selecting highly\ncorrelated features, we aimed to strengthen the training process and boost\nmodel performance. We conducted thorough performance evaluations of our\nproposed models, comparing them against traditional methods including Random\nForest, Neural Network, and Logistic Regression. Using metrics such as\nPrecision, Recall, and F1 Score, we rigorously assessed their effectiveness.\nOur detailed analyses and comparisons reveal that the combination of SMOTE with\nXGBoost and LightGBM offers a highly efficient and powerful mechanism for\npayment security protection. Moreover, the integration of XGBoost and LightGBM\nin a Local Ensemble model further demonstrated outstanding performance. After\nincorporating SMOTE, the new combined model achieved a significant improvement\nof nearly 6\\% over traditional models and around 5\\% over its sub-models,\nshowcasing remarkable results.\n","authors":["Qi Zheng","Chang Yu","Jin Cao","Yongshun Xu","Qianwen Xing","Yinxin Jin"],"pdf_url":"https://arxiv.org/pdf/2406.04658v3.pdf","comment":"This paper is received by https://ieee-metacom.org"},{"id":"http://arxiv.org/abs/2406.03733v4","updated":"2024-11-12T16:44:14Z","published":"2024-06-06T04:12:57Z","title":"Credit Card Fraud Detection Using Advanced Transformer Model","summary":"  With the proliferation of various online and mobile payment systems, credit\ncard fraud has emerged as a significant threat to financial security. This\nstudy focuses on innovative applications of the latest Transformer models for\nmore robust and precise fraud detection. To ensure the reliability of the data,\nwe meticulously processed the data sources, balancing the dataset to address\nthe issue of data sparsity significantly. We also selected highly correlated\nvectors to strengthen the training process.To guarantee the reliability and\npracticality of the new Transformer model, we conducted performance comparisons\nwith several widely adopted models, including Support Vector Machine (SVM),\nRandom Forest, Neural Network, and Logistic Regression. We rigorously compared\nthese models using metrics such as Precision, Recall, and F1 Score. Through\nthese detailed analyses and comparisons, we present to the readers a highly\nefficient and powerful anti-fraud mechanism with promising prospects. The\nresults demonstrate that the Transformer model not only excels in traditional\napplications but also shows great potential in niche areas like fraud\ndetection, offering a substantial advancement in the field.\n","authors":["Chang Yu","Yongshun Xu","Jin Cao","Ye Zhang","Yinxin Jin","Mengran Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.03733v4.pdf","comment":"This paper have been received by https://ieee-metacom.org/"},{"id":"http://arxiv.org/abs/2410.00256v2","updated":"2024-11-12T16:43:41Z","published":"2024-09-30T21:56:16Z","title":"Enhanced Credit Score Prediction Using Ensemble Deep Learning Model","summary":"  In contemporary economic society, credit scores are crucial for every\nparticipant. A robust credit evaluation system is essential for the\nprofitability of core businesses such as credit cards, loans, and investments\nfor commercial banks and the financial sector. This paper combines\nhigh-performance models like XGBoost and LightGBM, already widely used in\nmodern banking systems, with the powerful TabNet model. We have developed a\npotent model capable of accurately determining credit score levels by\nintegrating Random Forest, XGBoost, and TabNet, and through the stacking\ntechnique in ensemble modeling. This approach surpasses the limitations of\nsingle models and significantly advances the precise credit score prediction.\nIn the following sections, we will explain the techniques we used and\nthoroughly validate our approach by comprehensively comparing a series of\nmetrics such as Precision, Recall, F1, and AUC. By integrating Random Forest,\nXGBoost, and with the TabNet deep learning architecture, these models\ncomplement each other, demonstrating exceptionally strong overall performance.\n","authors":["Qianwen Xing","Chang Yu","Sining Huang","Qi Zheng","Xingyu Mu","Mengying Sun"],"pdf_url":"https://arxiv.org/pdf/2410.00256v2.pdf","comment":"This paper have been accepted by sci of AI Journal"},{"id":"http://arxiv.org/abs/2305.16945v3","updated":"2024-11-12T16:23:50Z","published":"2023-05-26T14:00:12Z","title":"Levin Tree Search with Context Models","summary":"  Levin Tree Search (LTS) is a search algorithm that makes use of a policy (a\nprobability distribution over actions) and comes with a theoretical guarantee\non the number of expansions before reaching a goal node, depending on the\nquality of the policy. This guarantee can be used as a loss function, which we\ncall the LTS loss, to optimize neural networks representing the policy\n(LTS+NN). In this work we show that the neural network can be substituted with\nparameterized context models originating from the online compression literature\n(LTS+CM). We show that the LTS loss is convex under this new model, which\nallows for using standard convex optimization tools, and obtain convergence\nguarantees to the optimal parameters in an online setting for a given set of\nsolution trajectories -- guarantees that cannot be provided for neural\nnetworks. The new LTS+CM algorithm compares favorably against LTS+NN on several\nbenchmarks: Sokoban (Boxoban), The Witness, and the 24-Sliding Tile puzzle\n(STP). The difference is particularly large on STP, where LTS+NN fails to solve\nmost of the test instances while LTS+CM solves each test instance in a fraction\nof a second. Furthermore, we show that LTS+CM is able to learn a policy that\nsolves the Rubik's cube in only a few hundred expansions, which considerably\nimproves upon previous machine learning techniques.\n","authors":["Laurent Orseau","Marcus Hutter","Levi H. S. Lelis"],"pdf_url":"https://arxiv.org/pdf/2305.16945v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.18438v3","updated":"2024-11-12T15:57:13Z","published":"2023-11-30T10:39:47Z","title":"Piecewise Linearity of Min-Norm Solution Map of a Nonconvexly\n  Regularized Convex Sparse Model","summary":"  It is well known that the minimum $\\ell_2$-norm solution of the convex LASSO\nmodel, say $\\mathbf{x}_{\\star}$, is a continuous piecewise linear function of\nthe regularization parameter $\\lambda$, and its signed sparsity pattern is\nconstant within each linear piece. The current study is an extension of this\nclassic result, proving that the aforementioned properties extend to the\nmin-norm solution map $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, where\n$\\mathbf{y}$ is the observed signal, for a generalization of LASSO termed the\nscaled generalized minimax concave (sGMC) model. The sGMC model adopts a\nnonconvex debiased variant of the $\\ell_1$-norm as sparse regularizer, but its\nobjective function is overall-convex. Based on the geometric properties of\n$\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, we propose an extension of the least\nangle regression (LARS) algorithm, which iteratively computes the closed-form\nexpression of $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$ in each linear zone.\nUnder suitable conditions, the proposed algorithm provably obtains the whole\nsolution map $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$ within finite iterations.\nNotably, our proof techniques for establishing continuity and piecewise\nlinearity of $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$ are novel, and they lead\nto two side contributions: (a) our proofs establish continuity of the sGMC\nsolution set as a set-valued mapping of $(\\mathbf{y},\\lambda)$; (b) to prove\npiecewise linearity and piecewise constant sparsity pattern of\n$\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, we do not require any assumption that\nprevious work relies on (whereas to prove some additional properties of\n$\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, we use a different set of assumptions\nfrom previous work).\n","authors":["Yi Zhang","Isao Yamada"],"pdf_url":"https://arxiv.org/pdf/2311.18438v3.pdf","comment":"40 pages. Submitted to journal"},{"id":"http://arxiv.org/abs/2403.00043v2","updated":"2024-11-12T15:54:29Z","published":"2024-02-29T14:50:58Z","title":"RiNALMo: General-Purpose RNA Language Models Can Generalize Well on\n  Structure Prediction Tasks","summary":"  While RNA has recently been recognized as an interesting small-molecule drug\ntarget, many challenges remain to be addressed before we take full advantage of\nit. This emphasizes the necessity to improve our understanding of its\nstructures and functions. Over the years, sequencing technologies have produced\nan enormous amount of unlabeled RNA data, which hides a huge potential.\nMotivated by the successes of protein language models, we introduce RiboNucleic\nAcid Language Model (RiNALMo) to unveil the hidden code of RNA. RiNALMo is the\nlargest RNA language model to date, with 650M parameters pre-trained on 36M\nnon-coding RNA sequences from several databases. It can extract hidden\nknowledge and capture the underlying structure information implicitly embedded\nwithin the RNA sequences. RiNALMo achieves state-of-the-art results on several\ndownstream tasks. Notably, we show that its generalization capabilities\novercome the inability of other deep learning methods for secondary structure\nprediction to generalize on unseen RNA families.\n","authors":["Rafael Josip Peniƒá","Tin Vla≈°iƒá","Roland G. Huber","Yue Wan","Mile ≈†ikiƒá"],"pdf_url":"https://arxiv.org/pdf/2403.00043v2.pdf","comment":"31 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.07889v1","updated":"2024-11-12T15:51:35Z","published":"2024-11-12T15:51:35Z","title":"A Stochastic Optimization Framework for Private and Fair Learning From\n  Decentralized Data","summary":"  Machine learning models are often trained on sensitive data (e.g., medical\nrecords and race/gender) that is distributed across different \"silos\" (e.g.,\nhospitals). These federated learning models may then be used to make\nconsequential decisions, such as allocating healthcare resources. Two key\nchallenges emerge in this setting: (i) maintaining the privacy of each person's\ndata, even if other silos or an adversary with access to the central server\ntries to infer this data; (ii) ensuring that decisions are fair to different\ndemographic groups (e.g., race/gender). In this paper, we develop a novel\nalgorithm for private and fair federated learning (FL). Our algorithm satisfies\ninter-silo record-level differential privacy (ISRL-DP), a strong notion of\nprivate FL requiring that silo i's sent messages satisfy record-level\ndifferential privacy for all i. Our framework can be used to promote different\nfairness notions, including demographic parity and equalized odds. We prove\nthat our algorithm converges under mild smoothness assumptions on the loss\nfunction, whereas prior work required strong convexity for convergence. As a\nbyproduct of our analysis, we obtain the first convergence guarantee for\nISRL-DP nonconvex-strongly concave min-max FL. Experiments demonstrate the\nstate-of-the-art fairness-accuracy tradeoffs of our algorithm across different\nprivacy levels.\n","authors":["Devansh Gupta","A. S. Poornash","Andrew Lowy","Meisam Razaviyayn"],"pdf_url":"https://arxiv.org/pdf/2411.07889v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07885v1","updated":"2024-11-12T15:47:17Z","published":"2024-11-12T15:47:17Z","title":"INTRABENCH: Interactive Radiological Benchmark","summary":"  Current interactive segmentation approaches, inspired by the success of\nMETA's Segment Anything model, have achieved notable advancements, however,\nthey come with substantial limitations that hinder their practical application\nin real clinical scenarios. These include unrealistic human interaction\nrequirements, such as slice-by-slice operations for 2D models on 3D data, a\nlack of iterative refinement, and insufficient evaluation experiments. These\nshortcomings prevent accurate assessment of model performance and lead to\ninconsistent outcomes across studies. IntRaBench overcomes these challenges by\noffering a comprehensive and reproducible framework for evaluating interactive\nsegmentation methods in realistic, clinically relevant scenarios. It includes\ndiverse datasets, target structures, and segmentation models, and provides a\nflexible codebase that allows seamless integration of new models and prompting\nstrategies. Additionally, we introduce advanced techniques to minimize\nclinician interaction, ensuring fair comparisons between 2D and 3D models. By\nopen-sourcing IntRaBench, we invite the research community to integrate their\nmodels and prompting techniques, ensuring continuous and transparent evaluation\nof interactive segmentation models in 3D medical imaging.\n","authors":["Constantin Ulrich","Tassilo Wald","Emily Tempus","Maximilian Rokuss","Paul F. Jaeger","Klaus Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2411.07885v1.pdf","comment":"Undergoing Peer-Review"},{"id":"http://arxiv.org/abs/2310.05327v2","updated":"2024-11-12T15:34:57Z","published":"2023-10-09T01:18:07Z","title":"Provable Compositional Generalization for Object-Centric Learning","summary":"  Learning representations that generalize to novel compositions of known\nconcepts is crucial for bridging the gap between human and machine perception.\nOne prominent effort is learning object-centric representations, which are\nwidely conjectured to enable compositional generalization. Yet, it remains\nunclear when this conjecture will be true, as a principled theoretical or\nempirical understanding of compositional generalization is lacking. In this\nwork, we investigate when compositional generalization is guaranteed for\nobject-centric representations through the lens of identifiability theory. We\nshow that autoencoders that satisfy structural assumptions on the decoder and\nenforce encoder-decoder consistency will learn object-centric representations\nthat provably generalize compositionally. We validate our theoretical result\nand highlight the practical relevance of our assumptions through experiments on\nsynthetic image data.\n","authors":["Thadd√§us Wiedemer","Jack Brady","Alexander Panfilov","Attila Juhos","Matthias Bethge","Wieland Brendel"],"pdf_url":"https://arxiv.org/pdf/2310.05327v2.pdf","comment":"Oral at ICLR 2024. The first four authors contributed equally"},{"id":"http://arxiv.org/abs/2306.10084v3","updated":"2024-11-12T15:32:40Z","published":"2023-06-16T11:57:11Z","title":"Convolutional and Deep Learning based techniques for Time Series Ordinal\n  Classification","summary":"  Time Series Classification (TSC) covers the supervised learning problem where\ninput data is provided in the form of series of values observed through\nrepeated measurements over time, and whose objective is to predict the category\nto which they belong. When the class values are ordinal, classifiers that take\nthis into account can perform better than nominal classifiers. Time Series\nOrdinal Classification (TSOC) is the field covering this gap, yet unexplored in\nthe literature. There are a wide range of time series problems showing an\nordered label structure, and TSC techniques that ignore the order relationship\ndiscard useful information. Hence, this paper presents a first benchmarking of\nTSOC methodologies, exploiting the ordering of the target labels to boost the\nperformance of current TSC state-of-the-art. Both convolutional- and deep\nlearning-based methodologies (among the best performing alternatives for\nnominal TSC) are adapted for TSOC. For the experiments, a selection of 29\nordinal problems from two well-known archives has been made. In this way, this\npaper contributes to the establishment of the state-of-the-art in TSOC. The\nresults obtained by ordinal versions are found to be significantly better than\ncurrent nominal TSC techniques in terms of ordinal performance metrics,\noutlining the importance of considering the ordering of the labels when dealing\nwith this kind of problems.\n","authors":["Rafael Ayll√≥n-Gavil√°n","David Guijo-Rubio","Pedro Antonio Guti√©rrez","Anthony Bagnall","C√©sar Herv√°s-Mart√≠nez"],"pdf_url":"https://arxiv.org/pdf/2306.10084v3.pdf","comment":"13 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.00171v2","updated":"2024-11-12T15:30:15Z","published":"2024-09-30T19:18:34Z","title":"Basis-to-Basis Operator Learning Using Function Encoders","summary":"  We present Basis-to-Basis (B2B) operator learning, a novel approach for\nlearning operators on Hilbert spaces of functions based on the foundational\nideas of function encoders. We decompose the task of learning operators into\ntwo parts: learning sets of basis functions for both the input and output\nspaces and learning a potentially nonlinear mapping between the coefficients of\nthe basis functions. B2B operator learning circumvents many challenges of prior\nworks, such as requiring data to be at fixed locations, by leveraging classic\ntechniques such as least squares to compute the coefficients. It is especially\npotent for linear operators, where we compute a mapping between bases as a\nsingle matrix transformation with a closed-form solution. Furthermore, with\nminimal modifications and using the deep theoretical connections between\nfunction encoders and functional analysis, we derive operator learning\nalgorithms that are directly analogous to eigen-decomposition and singular\nvalue decomposition. We empirically validate B2B operator learning on seven\nbenchmark operator learning tasks and show that it demonstrates a\ntwo-orders-of-magnitude improvement in accuracy over existing approaches on\nseveral benchmark tasks.\n","authors":["Tyler Ingebrand","Adam J. Thorpe","Somdatta Goswami","Krishna Kumar","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2410.00171v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07873v1","updated":"2024-11-12T15:29:50Z","published":"2024-11-12T15:29:50Z","title":"Diverse capability and scaling of diffusion and auto-regressive models\n  when learning abstract rules","summary":"  Humans excel at discovering regular structures from limited samples and\napplying inferred rules to novel settings. We investigate whether modern\ngenerative models can similarly learn underlying rules from finite samples and\nperform reasoning through conditional sampling. Inspired by Raven's Progressive\nMatrices task, we designed GenRAVEN dataset, where each sample consists of\nthree rows, and one of 40 relational rules governing the object position,\nnumber, or attributes applies to all rows. We trained generative models to\nlearn the data distribution, where samples are encoded as integer arrays to\nfocus on rule learning. We compared two generative model families: diffusion\n(EDM, DiT, SiT) and autoregressive models (GPT2, Mamba). We evaluated their\nability to generate structurally consistent samples and perform panel\ncompletion via unconditional and conditional sampling. We found diffusion\nmodels excel at unconditional generation, producing more novel and consistent\nsamples from scratch and memorizing less, but performing less well in panel\ncompletion, even with advanced conditional sampling methods. Conversely,\nautoregressive models excel at completing missing panels in a rule-consistent\nmanner but generate less consistent samples unconditionally. We observe diverse\ndata scaling behaviors: for both model families, rule learning emerges at a\ncertain dataset size - around 1000s examples per rule. With more training data,\ndiffusion models improve both their unconditional and conditional generation\ncapabilities. However, for autoregressive models, while panel completion\nimproves with more training data, unconditional generation consistency\ndeclines. Our findings highlight complementary capabilities and limitations of\ndiffusion and autoregressive models in rule learning and reasoning tasks,\nsuggesting avenues for further research into their mechanisms and potential for\nhuman-like reasoning.\n","authors":["Binxu Wang","Jiaqi Shang","Haim Sompolinsky"],"pdf_url":"https://arxiv.org/pdf/2411.07873v1.pdf","comment":"12 pages, 5 figures. Accepted to NeurIPS2024 Workshop on System 2\n  Reasoning At Scale as long paper"},{"id":"http://arxiv.org/abs/2411.07863v1","updated":"2024-11-12T15:22:14Z","published":"2024-11-12T15:22:14Z","title":"CDXFormer: Boosting Remote Sensing Change Detection with Extended Long\n  Short-Term Memory","summary":"  In complex scenes and varied conditions, effectively integrating\nspatial-temporal context is crucial for accurately identifying changes.\nHowever, current RS-CD methods lack a balanced consideration of performance and\nefficiency. CNNs lack global context, Transformers have quadratic computational\ncomplexity, and Mambas are restricted by CUDA acceleration. In this paper, we\npropose CDXFormer, with a core component that is a powerful XLSTM-based feature\nenhancement layer, integrating the advantages of linear computational\ncomplexity, global context perception, and strong interpret-ability.\nSpecifically, we introduce a scale-specific Feature Enhancer layer,\nincorporating a Cross-Temporal Global Perceptron customized for\nsemantic-accurate deep features, and a Cross-Temporal Spatial Refiner\ncustomized for detail-rich shallow features. Additionally, we propose a\nCross-Scale Interactive Fusion module to progressively interact global change\nrepresentations with spatial responses. Extensive experimental results\ndemonstrate that CDXFormer achieves state-of-the-art performance across three\nbenchmark datasets, offering a compelling balance between efficiency and\naccuracy. Code is available at https://github.com/xwmaxwma/rschange.\n","authors":["Zhenkai Wu","Xiaowen Ma","Rongrong Lian","Zhentao Lin","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04492v4","updated":"2024-11-12T15:16:36Z","published":"2024-10-06T14:11:39Z","title":"Interpret Your Decision: Logical Reasoning Regularization for\n  Generalization in Visual Classification","summary":"  Vision models excel in image classification but struggle to generalize to\nunseen data, such as classifying images from unseen domains or discovering\nnovel categories. In this paper, we explore the relationship between logical\nreasoning and deep learning generalization in visual classification. A logical\nregularization termed L-Reg is derived which bridges a logical analysis\nframework to image classification. Our work reveals that L-Reg reduces the\ncomplexity of the model in terms of the feature distribution and classifier\nweights. Specifically, we unveil the interpretability brought by L-Reg, as it\nenables the model to extract the salient features, such as faces to persons,\nfor classification. Theoretical analysis and experiments demonstrate that L-Reg\nenhances generalization across various scenarios, including multi-domain\ngeneralization and generalized category discovery. In complex real-world\nscenarios where images span unknown classes and unseen domains, L-Reg\nconsistently improves generalization, highlighting its practical efficacy.\n","authors":["Zhaorui Tan","Xi Yang","Qiufeng Wang","Anh Nguyen","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.04492v4.pdf","comment":"Accepted by NeurIPS2024 as Spotlight"},{"id":"http://arxiv.org/abs/2411.07854v1","updated":"2024-11-12T15:06:06Z","published":"2024-11-12T15:06:06Z","title":"Tucano: Advancing Neural Text Generation for Portuguese","summary":"  Significant advances have been made in natural language processing in recent\nyears. However, our current deep learning approach to language modeling\nrequires substantial resources in terms of data and computation. One of the\nside effects of this data-hungry paradigm is the current schism between\nlanguages, separating those considered high-resource, where most of the\ndevelopment happens and resources are available, and the low-resource ones,\nwhich struggle to attain the same level of performance and autonomy. This study\naims to introduce a new set of resources to stimulate the future development of\nneural text generation in Portuguese. In this work, we document the development\nof GigaVerbo, a concatenation of deduplicated Portuguese text corpora amounting\nto 200 billion tokens. Via this corpus, we trained a series of\ndecoder-transformers named Tucano. Our models perform equal or superior to\nother Portuguese and multilingual language models of similar size in several\nPortuguese benchmarks. The evaluation of our models also reveals that model\nperformance on many currently available benchmarks used by the Portuguese NLP\ncommunity has little to no correlation with the scaling of token ingestion\nduring training, highlighting the limitations of such evaluations when it comes\nto the assessment of Portuguese generative language models. All derivatives of\nour study are openly released on GitHub and Hugging Face. See\nhttps://nkluge-correa.github.io/Tucano/\n","authors":["Nicholas Kluge Corr√™a","Aniket Sen","Sophia Falk","Shiza Fatimah"],"pdf_url":"https://arxiv.org/pdf/2411.07854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07853v1","updated":"2024-11-12T15:06:04Z","published":"2024-11-12T15:06:04Z","title":"Evidential time-to-event prediction model with well-calibrated\n  uncertainty estimation","summary":"  Time-to-event analysis, or Survival analysis, provides valuable insights into\nclinical prognosis and treatment recommendations. However, this task is\ntypically more challenging than other regression tasks due to the censored\nobservations. Moreover, concerns regarding the reliability of predictions\npersist among clinicians, mainly attributed to the absence of confidence\nassessment, robustness, and calibration of prediction. To address those\nchallenges, we introduce an evidential regression model designed especially for\ntime-to-event prediction tasks, with which the most plausible event time, is\ndirectly quantified by aggregated Gaussian random fuzzy numbers (GRFNs). The\nGRFNs are a newly introduced family of random fuzzy subsets of the real line\nthat generalizes both Gaussian random variables and Gaussian possibility\ndistributions. Different from conventional methods that construct models based\non strict data distribution, e.g., proportional hazard function, our model only\nassumes the event time is encoded in a real line GFRN without any strict\ndistribution assumption, therefore offering more flexibility in complex data\nscenarios. Furthermore, the epistemic and aleatory uncertainty regarding the\nevent time is quantified within the aggregated GRFN as well. Our model can,\ntherefore, provide more detailed clinical decision-making guidance with two\nmore degrees of information. The model is fit by minimizing a generalized\nnegative log-likelihood function that accounts for data censoring based on\nuncertainty evidence reasoning. Experimental results on simulated datasets with\nvarying data distributions and censoring scenarios, as well as on real-world\ndatasets across diverse clinical settings and tasks, demonstrate that our model\nachieves both accurate and reliable performance, outperforming state-of-the-art\nmethods.\n","authors":["Ling Huang","Yucheng Xing","Swapnil Mishra","Thierry Denoeux","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2411.07853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05225v5","updated":"2024-11-12T15:05:00Z","published":"2024-06-07T19:25:02Z","title":"A Manifold Perspective on the Statistical Generalization of Graph Neural\n  Networks","summary":"  Graph Neural Networks (GNNs) extend convolutional neural networks to operate\non graphs. Despite their impressive performances in various graph learning\ntasks, the theoretical understanding of their generalization capability is\nstill lacking. Previous GNN generalization bounds ignore the underlying graph\nstructures, often leading to bounds that increase with the number of nodes -- a\nbehavior contrary to the one experienced in practice. In this paper, we take a\nmanifold perspective to establish the statistical generalization theory of GNNs\non graphs sampled from a manifold in the spectral domain. As demonstrated\nempirically, we prove that the generalization bounds of GNNs decrease linearly\nwith the size of the graphs in the logarithmic scale, and increase linearly\nwith the spectral continuity constants of the filter functions. Notably, our\ntheory explains both node-level and graph-level tasks. Our result has two\nimplications: i) guaranteeing the generalization of GNNs to unseen data over\nmanifolds; ii) providing insights into the practical design of GNNs, i.e.,\nrestrictions on the discriminability of GNNs are necessary to obtain a better\ngeneralization performance. We demonstrate our generalization bounds of GNNs\nusing synthetic and multiple real-world datasets.\n","authors":["Zhiyang Wang","Juan Cervino","Alejandro Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2406.05225v5.pdf","comment":"37 pages,25 figures, 10 tables"},{"id":"http://arxiv.org/abs/2402.11658v3","updated":"2024-11-12T15:03:48Z","published":"2024-02-18T17:32:53Z","title":"Dynamic planning in hierarchical active inference","summary":"  By dynamic planning, we refer to the ability of the human brain to infer and\nimpose motor trajectories related to cognitive decisions. A recent paradigm,\nactive inference, brings fundamental insights into the adaptation of biological\norganisms, constantly striving to minimize prediction errors to restrict\nthemselves to life-compatible states. Over the past years, many studies have\nshown how human and animal behaviors could be explained in terms of active\ninference - either as discrete decision-making or continuous motor control -\ninspiring innovative solutions in robotics and artificial intelligence. Still,\nthe literature lacks a comprehensive outlook on effectively planning realistic\nactions in changing environments. Setting ourselves the goal of modeling\ncomplex tasks such as tool use, we delve into the topic of dynamic planning in\nactive inference, keeping in mind two crucial aspects of biological behavior:\nthe capacity to understand and exploit affordances for object manipulation, and\nto learn the hierarchical interactions between the self and the environment,\nincluding other agents. We start from a simple unit and gradually describe more\nadvanced structures, comparing recently proposed design choices and providing\nbasic examples. This study distances itself from traditional views centered on\nneural networks and reinforcement learning, and points toward a yet unexplored\ndirection in active inference: hybrid representations in hierarchical models.\n","authors":["Matteo Priorelli","Ivilin Peev Stoianov"],"pdf_url":"https://arxiv.org/pdf/2402.11658v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12203v3","updated":"2024-11-12T15:00:37Z","published":"2024-03-18T19:25:57Z","title":"Bootstrapping Reinforcement Learning with Imitation for Vision-Based\n  Agile Flight","summary":"  Learning visuomotor policies for agile quadrotor flight presents significant\ndifficulties, primarily from inefficient policy exploration caused by\nhigh-dimensional visual inputs and the need for precise and low-latency\ncontrol. To address these challenges, we propose a novel approach that combines\nthe performance of Reinforcement Learning (RL) and the sample efficiency of\nImitation Learning (IL) in the task of vision-based autonomous drone racing.\nWhile RL provides a framework for learning high-performance controllers through\ntrial and error, it faces challenges with sample efficiency and computational\ndemands due to the high dimensionality of visual inputs. Conversely, IL\nefficiently learns from visual expert demonstrations, but it remains limited by\nthe expert's performance and state distribution. To overcome these limitations,\nour policy learning framework integrates the strengths of both approaches. Our\nframework contains three phases: training a teacher policy using RL with\nprivileged state information, distilling it into a student policy via IL, and\nadaptive fine-tuning via RL. Testing in both simulated and real-world scenarios\nshows our approach can not only learn in scenarios where RL from scratch fails\nbut also outperforms existing IL methods in both robustness and performance,\nsuccessfully navigating a quadrotor through a race course using only visual\ninformation. Videos of the experiments are available at\nhttps://rpg.ifi.uzh.ch/bootstrap-rl-with-il/index.html.\n","authors":["Jiaxu Xing","Angel Romero","Leonard Bauersfeld","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.12203v3.pdf","comment":"8th Annual Conference on Robot Learning (CoRL)"},{"id":"http://arxiv.org/abs/2402.14585v2","updated":"2024-11-12T14:58:48Z","published":"2024-02-22T14:38:52Z","title":"Bandits with Abstention under Expert Advice","summary":"  We study the classic problem of prediction with expert advice under bandit\nfeedback. Our model assumes that one action, corresponding to the learner's\nabstention from play, has no reward or loss on every trial. We propose the CBA\nalgorithm, which exploits this assumption to obtain reward bounds that can\nsignificantly improve those of the classical Exp4 algorithm. We can view our\nproblem as the aggregation of confidence-rated predictors when the learner has\nthe option of abstention from play. Importantly, we are the first to achieve\nbounds on the expected cumulative reward for general confidence-rated\npredictors. In the special case of specialists we achieve a novel reward bound,\nsignificantly improving previous bounds of SpecialistExp (treating abstention\nas another action). As an example application, we discuss learning unions of\nballs in a finite metric space. In this contextual setting, we devise an\nefficient implementation of CBA, reducing the runtime from quadratic to almost\nlinear in the number of contexts. Preliminary experiments show that CBA\nimproves over existing bandit algorithms.\n","authors":["Stephen Pasteris","Alberto Rumi","Maximilian Thiessen","Shota Saito","Atsushi Miyauchi","Fabio Vitale","Mark Herbster"],"pdf_url":"https://arxiv.org/pdf/2402.14585v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14803v3","updated":"2024-11-12T14:57:08Z","published":"2024-10-18T18:19:56Z","title":"DistRL: An Asynchronous Distributed Reinforcement Learning Framework for\n  On-Device Control Agents","summary":"  On-device control agents, especially on mobile devices, are responsible for\noperating mobile devices to fulfill users' requests, enabling seamless and\nintuitive interactions. Integrating Multimodal Large Language Models (MLLMs)\ninto these agents enhances their ability to understand and execute complex\ncommands, thereby improving user experience. However, fine-tuning MLLMs for\non-device control presents significant challenges due to limited data\navailability and inefficient online training processes. This paper introduces\nDistRL, a novel framework designed to enhance the efficiency of online RL\nfine-tuning for mobile device control agents. DistRL employs centralized\ntraining and decentralized data acquisition to ensure efficient fine-tuning in\nthe context of dynamic online interactions. Additionally, the framework is\nbacked by our tailor-made RL algorithm, which effectively balances exploration\nwith the prioritized utilization of collected data to ensure stable and robust\ntraining. Our experiments show that, on average, DistRL delivers a 3X\nimprovement in training efficiency and enables training data collection 2.4X\nfaster than the leading synchronous multi-machine methods. Notably, after\ntraining, DistRL achieves a 20% relative improvement in success rate compared\nto state-of-the-art methods on general Android tasks from an open benchmark,\nsignificantly outperforming existing approaches while maintaining the same\ntraining time. These results validate DistRL as a scalable and efficient\nsolution, offering substantial improvements in both training efficiency and\nagent performance for real-world, in-the-wild device control tasks.\n","authors":["Taiyi Wang","Zhihao Wu","Jianheng Liu","Jianye Hao","Jun Wang","Kun Shao"],"pdf_url":"https://arxiv.org/pdf/2410.14803v3.pdf","comment":"Paper and Appendix, 25 pages"},{"id":"http://arxiv.org/abs/2410.20178v2","updated":"2024-11-12T14:45:18Z","published":"2024-10-26T13:19:57Z","title":"LLMs Can Evolve Continually on Modality for X-Modal Reasoning","summary":"  Multimodal Large Language Models (MLLMs) have gained significant attention\ndue to their impressive capabilities in multimodal understanding. However,\nexisting methods rely heavily on extensive modal-specific pretraining and\njoint-modal tuning, leading to significant computational burdens when expanding\nto new modalities. In this paper, we propose PathWeave, a flexible and scalable\nframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs\nto continually EVolve on modalities for $\\mathbb{X}$-modal reasoning. We\nleverage the concept of Continual Learning and develop an incremental training\nstrategy atop pre-trained MLLMs, enabling their expansion to new modalities\nusing uni-modal data, without executing joint-modal pretraining. In detail, a\nnovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and\ncross-modal adapters are seamlessly integrated to facilitate efficient modality\nalignment and collaboration. Additionally, an MoE-based gating module is\napplied between two types of adapters to further enhance the multimodal\ninteraction. To investigate the proposed method, we establish a challenging\nbenchmark called Continual Learning of Modality (MCL), which consists of\nhigh-quality QA data from five distinct modalities: image, video, audio, depth\nand point cloud. Extensive experiments demonstrate the effectiveness of the\nproposed AnA framework on learning plasticity and memory stability during\ncontinual learning. Furthermore, PathWeave performs comparably to\nstate-of-the-art MLLMs while concurrently reducing parameter training burdens\nby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave\n","authors":["Jiazuo Yu","Haomiao Xiong","Lu Zhang","Haiwen Diao","Yunzhi Zhuge","Lanqing Hong","Dong Wang","Huchuan Lu","You He","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2410.20178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07837v1","updated":"2024-11-12T14:41:07Z","published":"2024-11-12T14:41:07Z","title":"FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for\n  Scalable Training","summary":"  With the increase in the number of parameters in large language models, the\nprocess of pre-training and fine-tuning increasingly demands larger volumes of\nGPU memory. A significant portion of this memory is typically consumed by the\noptimizer state. To overcome this challenge, recent approaches such as low-rank\nadaptation (LoRA (Hu et al., 2021)), low-rank gradient projection (GaLore (Zhao\net al., 2024)), and blockwise optimization (BAdam (Luo et al., 2024)) have been\nproposed. However, in all these algorithms, the $\\textit{effective rank of the\nweight updates remains low-rank}$, which can lead to a substantial loss of\ninformation from the gradient. This loss can be critically important,\nespecially during the pre-training stage. In this paper, we introduce\n$\\texttt{FRUGAL}$ ($\\textbf{F}$ull-$\\textbf{R}$ank $\\textbf{U}$pdates with\n$\\textbf{G}$r$\\textbf{A}$dient sp$\\textbf{L}$itting), a new memory-efficient\noptimization framework. $\\texttt{FRUGAL}$ leverages gradient splitting to\nperform low-dimensional updates using advanced algorithms (such as Adam), while\nupdates along the remaining directions are executed via state-free methods like\nSGD or signSGD (Bernstein et al., 2018). Our framework can be integrated with\nvarious low-rank update selection techniques, including GaLore and BAdam. We\nprovide theoretical convergence guarantees for our framework when using SGDM\nfor low-dimensional updates and SGD for state-free updates. Additionally, our\nmethod consistently outperforms concurrent approaches across various fixed\nmemory budgets, achieving state-of-the-art results in pre-training and\nfine-tuning tasks while balancing memory efficiency and performance metrics.\n","authors":["Philip Zmushko","Aleksandr Beznosikov","Martin Tak√°ƒç","Samuel Horv√°th"],"pdf_url":"https://arxiv.org/pdf/2411.07837v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12550v2","updated":"2024-11-12T14:39:29Z","published":"2024-07-17T13:31:13Z","title":"UniTE: A Survey and Unified Pipeline for Pre-training Spatiotemporal\n  Trajectory Embeddings","summary":"  Spatiotemporal trajectories are sequences of timestamped locations, which\nenable a variety of analyses that in turn enable important real-world\napplications. It is common to map trajectories to vectors, called embeddings,\nbefore subsequent analyses. Thus, the qualities of embeddings are very\nimportant. Methods for pre-training embeddings, which leverage unlabeled\ntrajectories for training universal embeddings, have shown promising\napplicability across different tasks, thus attracting considerable interest.\nHowever, research progress on this topic faces two key challenges: a lack of a\ncomprehensive overview of existing methods, resulting in several related\nmethods not being well-recognized, and the absence of a unified pipeline,\ncomplicating the development of new methods and the analysis of methods.\n  We present UniTE, a survey and a unified pipeline for this domain. In doing\nso, we present a comprehensive list of existing methods for pre-training\ntrajectory embeddings, which includes methods that either explicitly or\nimplicitly employ pre-training techniques. Further, we present a unified and\nmodular pipeline with publicly available underlying code, simplifying the\nprocess of constructing and evaluating methods for pre-training trajectory\nembeddings. Additionally, we contribute a selection of experimental results\nusing the proposed pipeline on real-world datasets. Implementation of the\npipeline is publicly available at https://github.com/Logan-Lin/UniTE.\n","authors":["Yan Lin","Zeyu Zhou","Yicheng Liu","Haochen Lv","Haomin Wen","Tianyi Li","Yushuai Li","Christian S. Jensen","Shengnan Guo","Youfang Lin","Huaiyu Wan"],"pdf_url":"https://arxiv.org/pdf/2407.12550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07832v1","updated":"2024-11-12T14:27:45Z","published":"2024-11-12T14:27:45Z","title":"Dynamical-VAE-based Hindsight to Learn the Causal Dynamics of\n  Factored-POMDPs","summary":"  Learning representations of underlying environmental dynamics from partial\nobservations is a critical challenge in machine learning. In the context of\nPartially Observable Markov Decision Processes (POMDPs), state representations\nare often inferred from the history of past observations and actions. We\ndemonstrate that incorporating future information is essential to accurately\ncapture causal dynamics and enhance state representations. To address this, we\nintroduce a Dynamical Variational Auto-Encoder (DVAE) designed to learn causal\nMarkovian dynamics from offline trajectories in a POMDP. Our method employs an\nextended hindsight framework that integrates past, current, and multi-step\nfuture information within a factored-POMDP setting. Empirical results reveal\nthat this approach uncovers the causal graph governing hidden state transitions\nmore effectively than history-based and typical hindsight-based models.\n","authors":["Chao Han","Debabrota Basu","Michael Mangan","Eleni Vasilaki","Aditya Gilra"],"pdf_url":"https://arxiv.org/pdf/2411.07832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07828v1","updated":"2024-11-12T14:23:52Z","published":"2024-11-12T14:23:52Z","title":"Suite-IN: Aggregating Motion Features from Apple Suite for Robust\n  Inertial Navigation","summary":"  With the rapid development of wearable technology, devices like smartphones,\nsmartwatches, and headphones equipped with IMUs have become essential for\napplications such as pedestrian positioning. However, traditional pedestrian\ndead reckoning (PDR) methods struggle with diverse motion patterns, while\nrecent data-driven approaches, though improving accuracy, often lack robustness\ndue to reliance on a single device.In our work, we attempt to enhance the\npositioning performance using the low-cost commodity IMUs embedded in the\nwearable devices. We propose a multi-device deep learning framework named\nSuite-IN, aggregating motion data from Apple Suite for inertial navigation.\nMotion data captured by sensors on different body parts contains both local and\nglobal motion information, making it essential to reduce the negative effects\nof localized movements and extract global motion representations from multiple\ndevices.\n","authors":["Lan Sun","Songpengcheng Xia","Junyuan Deng","Jiarui Yang","Zengyuan Lai","Qi Wu","Ling Pei"],"pdf_url":"https://arxiv.org/pdf/2411.07828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07826v1","updated":"2024-11-12T14:22:16Z","published":"2024-11-12T14:22:16Z","title":"Efficient Federated Finetuning of Tiny Transformers with\n  Resource-Constrained Devices","summary":"  In recent years, Large Language Models (LLMs) through Transformer structures\nhave dominated many machine learning tasks, especially text processing.\nHowever, these models require massive amounts of data for training and induce\nhigh resource requirements, particularly in terms of the large number of\nFloating Point Operations (FLOPs) and the high amounts of memory needed. To\nfine-tune such a model in a parameter-efficient way, techniques like Adapter or\nLoRA have been developed. However, we observe that the application of LoRA,\nwhen used in federated learning (FL), while still being parameter-efficient, is\nmemory and FLOP inefficient. Based on that observation, we develop a novel\nlayer finetuning scheme that allows devices in cross-device FL to make use of\npretrained neural networks (NNs) while adhering to given resource constraints.\nWe show that our presented scheme outperforms the current state of the art when\ndealing with homogeneous or heterogeneous computation and memory constraints\nand is on par with LoRA regarding limited communication, thereby achieving\nsignificantly higher accuracies in FL training.\n","authors":["Kilian Pfeiffer","Mohamed Aboelenien Ahmed","Ramin Khalili","J√∂rg Henkel"],"pdf_url":"https://arxiv.org/pdf/2411.07826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03163v2","updated":"2024-11-12T14:18:51Z","published":"2024-11-05T15:07:20Z","title":"Efficient Hamiltonian, structure and trace distance learning of Gaussian\n  states","summary":"  In this work, we initiate the study of Hamiltonian learning for positive\ntemperature bosonic Gaussian states, the quantum generalization of the widely\nstudied problem of learning Gaussian graphical models. We obtain efficient\nprotocols, both in sample and computational complexity, for the task of\ninferring the parameters of their underlying quadratic Hamiltonian under the\nassumption of bounded temperature, squeezing, displacement and maximal degree\nof the interaction graph. Our protocol only requires heterodyne measurements,\nwhich are often experimentally feasible, and has a sample complexity that\nscales logarithmically with the number of modes. Furthermore, we show that it\nis possible to learn the underlying interaction graph in a similar setting and\nsample complexity. Taken together, our results put the status of the quantum\nHamiltonian learning problem for continuous variable systems in a much more\nadvanced state when compared to spins, where state-of-the-art results are\neither unavailable or quantitatively inferior to ours. In addition, we use our\ntechniques to obtain the first results on learning Gaussian states in trace\ndistance with a quadratic scaling in precision and polynomial in the number of\nmodes, albeit imposing certain restrictions on the Gaussian states. Our main\ntechnical innovations are several continuity bounds for the covariance and\nHamiltonian matrix of a Gaussian state, which are of independent interest,\ncombined with what we call the local inversion technique. In essence, the local\ninversion technique allows us to reliably infer the Hamiltonian of a Gaussian\nstate by only estimating in parallel submatrices of the covariance matrix whose\nsize scales with the desired precision, but not the number of modes. This way\nwe bypass the need to obtain precise global estimates of the covariance matrix,\ncontrolling the sample complexity.\n","authors":["Marco Fanizza","Cambyse Rouz√©","Daniel Stilck Fran√ßa"],"pdf_url":"https://arxiv.org/pdf/2411.03163v2.pdf","comment":"43 pages, 1 figure. Corrections to Lemma 4.1. Main results are\n  unchanged"},{"id":"http://arxiv.org/abs/2411.07816v1","updated":"2024-11-12T14:09:16Z","published":"2024-11-12T14:09:16Z","title":"Dual-Criterion Model Aggregation in Federated Learning: Balancing Data\n  Quantity and Quality","summary":"  Federated learning (FL) has become one of the key methods for\nprivacy-preserving collaborative learning, as it enables the transfer of models\nwithout requiring local data exchange. Within the FL framework, an aggregation\nalgorithm is recognized as one of the most crucial components for ensuring the\nefficacy and security of the system. Existing average aggregation algorithms\ntypically assume that all client-trained data holds equal value or that weights\nare based solely on the quantity of data contributed by each client. In\ncontrast, alternative approaches involve training the model locally after\naggregation to enhance adaptability. However, these approaches fundamentally\nignore the inherent heterogeneity between different clients' data and the\ncomplexity of variations in data at the aggregation stage, which may lead to a\nsuboptimal global model.\n  To address these issues, this study proposes a novel dual-criterion weighted\naggregation algorithm involving the quantity and quality of data from the\nclient node. Specifically, we quantify the data used for training and perform\nmultiple rounds of local model inference accuracy evaluation on a specialized\ndataset to assess the data quality of each client. These two factors are\nutilized as weights within the aggregation process, applied through a\ndynamically weighted summation of these two factors. This approach allows the\nalgorithm to adaptively adjust the weights, ensuring that every client can\ncontribute to the global model, regardless of their data's size or initial\nquality. Our experiments show that the proposed algorithm outperforms several\nexisting state-of-the-art aggregation approaches on both a general-purpose\nopen-source dataset, CIFAR-10, and a dataset specific to visual obstacle\navoidance.\n","authors":["Haizhou Zhang","Xianjia Yu","Tomi Westerlund"],"pdf_url":"https://arxiv.org/pdf/2411.07816v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2411.07806v1","updated":"2024-11-12T14:01:08Z","published":"2024-11-12T14:01:08Z","title":"Federated Low-Rank Adaptation with Differential Privacy over Wireless\n  Networks","summary":"  Fine-tuning large pre-trained foundation models (FMs) on distributed edge\ndevices presents considerable computational and privacy challenges. Federated\nfine-tuning (FedFT) mitigates some privacy issues by facilitating collaborative\nmodel training without the need to share raw data. To lessen the computational\nburden on resource-limited devices, combining low-rank adaptation (LoRA) with\nfederated learning enables parameter-efficient fine-tuning. Additionally, the\nsplit FedFT architecture partitions an FM between edge devices and a central\nserver, reducing the necessity for complete model deployment on individual\ndevices. However, the risk of privacy eavesdropping attacks in FedFT remains a\nconcern, particularly in sensitive areas such as healthcare and finance. In\nthis paper, we propose a split FedFT framework with differential privacy (DP)\nover wireless networks, where the inherent wireless channel noise in the uplink\ntransmission is utilized to achieve DP guarantees without adding an extra\nartificial noise. We shall investigate the impact of the wireless noise on\nconvergence performance of the proposed framework. We will also show that by\nupdating only one of the low-rank matrices in the split FedFT with DP, the\nproposed method can mitigate the noise amplification effect. Simulation results\nwill demonstrate that the proposed framework achieves higher accuracy under\nstrict privacy budgets compared to baseline methods.\n","authors":["Tianqu Kang","Zixin Wang","Hengtao He","Jun Zhang","Shenghui Song","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2411.07806v1.pdf","comment":"6 pages, 3 figures, submitted to IEEE ICC 2025"},{"id":"http://arxiv.org/abs/2408.12970v2","updated":"2024-11-12T13:56:33Z","published":"2024-08-23T10:36:08Z","title":"SUMO: Search-Based Uncertainty Estimation for Model-Based Offline\n  Reinforcement Learning","summary":"  The performance of offline reinforcement learning (RL) suffers from the\nlimited size and quality of static datasets. Model-based offline RL addresses\nthis issue by generating synthetic samples through a dynamics model to enhance\noverall performance. To evaluate the reliability of the generated samples,\nuncertainty estimation methods are often employed. However, model ensemble, the\nmost commonly used uncertainty estimation method, is not always the best\nchoice. In this paper, we propose a \\textbf{S}earch-based \\textbf{U}ncertainty\nestimation method for \\textbf{M}odel-based \\textbf{O}ffline RL (SUMO) as an\nalternative. SUMO characterizes the uncertainty of synthetic samples by\nmeasuring their cross entropy against the in-distribution dataset samples, and\nuses an efficient search-based method for implementation. In this way, SUMO can\nachieve trustworthy uncertainty estimation. We integrate SUMO into several\nmodel-based offline RL algorithms including MOPO and Adapted MOReL (AMOReL),\nand provide theoretical analysis for them. Extensive experimental results on\nD4RL datasets demonstrate that SUMO can provide more accurate uncertainty\nestimation and boost the performance of base algorithms. These indicate that\nSUMO could be a better uncertainty estimator for model-based offline RL when\nused in either reward penalty or trajectory truncation. Our code is available\nand will be open-source for further research and development.\n","authors":["Zhongjian Qiao","Jiafei Lyu","Kechen Jiao","Qi Liu","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2408.12970v2.pdf","comment":"Submitted to AAAI2025"},{"id":"http://arxiv.org/abs/2411.07800v1","updated":"2024-11-12T13:54:13Z","published":"2024-11-12T13:54:13Z","title":"Kernel-based retrieval models for hyperspectral image data optimized\n  with Kernel Flows","summary":"  Kernel-based statistical methods are efficient, but their performance depends\nheavily on the selection of kernel parameters. In literature, the optimization\nstudies on kernel-based chemometric methods is limited and often reduced to\ngrid searching. Previously, the authors introduced Kernel Flows (KF) to learn\nkernel parameters for Kernel Partial Least-Squares (K-PLS) regression. KF is\neasy to implement and helps minimize overfitting. In cases of high collinearity\nbetween spectra and biogeophysical quantities in spectroscopy, simpler methods\nlike Principal Component Regression (PCR) may be more suitable. In this study,\nwe propose a new KF-type approach to optimize Kernel Principal Component\nRegression (K-PCR) and test it alongside KF-PLS. Both methods are benchmarked\nagainst non-linear regression techniques using two hyperspectral remote sensing\ndatasets.\n","authors":["Zina-Sabrina Duma","Tuomas Sihvonen","Jouni Susiluoto","Otto Lamminp√§√§","Heikki Haario","Satu-Pia Reinikainen"],"pdf_url":"https://arxiv.org/pdf/2411.07800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08770v3","updated":"2024-11-12T13:50:05Z","published":"2024-08-16T14:25:20Z","title":"Pessimistic Iterative Planning for Robust POMDPs","summary":"  Robust POMDPs extend classical POMDPs to handle model uncertainty.\nSpecifically, robust POMDPs exhibit so-called uncertainty sets on the\ntransition and observation models, effectively defining ranges of\nprobabilities. Policies for robust POMDPs must be (1) memory-based to account\nfor partial observability and (2) robust against model uncertainty to account\nfor the worst-case instances from the uncertainty sets. To compute such robust\nmemory-based policies, we propose the pessimistic iterative planning (PIP)\nframework, which alternates between two main steps: (1) selecting a pessimistic\n(non-robust) POMDP via worst-case probability instances from the uncertainty\nsets; and (2) computing a finite-state controller (FSC) for this pessimistic\nPOMDP. We evaluate the performance of this FSC on the original robust POMDP and\nuse this evaluation in step (1) to select the next pessimistic POMDP. Within\nPIP, we propose the rFSCNet algorithm. In each iteration, rFSCNet finds an FSC\nthrough a recurrent neural network by using supervision policies optimized for\nthe pessimistic POMDP. The empirical evaluation in four benchmark environments\nshowcases improved robustness against several baseline methods and competitive\nperformance compared to a state-of-the-art robust POMDP solver.\n","authors":["Maris F. L. Galesloot","Marnix Suilen","Thiago D. Sim√£o","Steven Carr","Matthijs T. J. Spaan","Ufuk Topcu","Nils Jansen"],"pdf_url":"https://arxiv.org/pdf/2408.08770v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07796v1","updated":"2024-11-12T13:46:58Z","published":"2024-11-12T13:46:58Z","title":"PatchCTG: Patch Cardiotocography Transformer for Antepartum Fetal Health\n  Monitoring","summary":"  Antepartum Cardiotocography (CTG) is vital for fetal health monitoring, but\ntraditional methods like the Dawes-Redman system are often limited by high\ninter-observer variability, leading to inconsistent interpretations and\npotential misdiagnoses. This paper introduces PatchCTG, a transformer-based\nmodel specifically designed for CTG analysis, employing patch-based\ntokenisation, instance normalisation and channel-independent processing to\ncapture essential local and global temporal dependencies within CTG signals.\nPatchCTG was evaluated on the Oxford Maternity (OXMAT) dataset, comprising over\n20,000 CTG traces across diverse clinical outcomes after applying the inclusion\nand exclusion criteria. With extensive hyperparameter optimisation, PatchCTG\nachieved an AUC of 77%, with specificity of 88% and sensitivity of 57% at\nYouden's index threshold, demonstrating adaptability to various clinical needs.\nTesting across varying temporal thresholds showed robust predictive\nperformance, particularly with finetuning on data closer to delivery, achieving\na sensitivity of 52% and specificity of 88% for near-delivery cases. These\nfindings suggest the potential of PatchCTG to enhance clinical decision-making\nin antepartum care by providing a reliable, objective tool for fetal health\nassessment. The source code is available at\nhttps://github.com/jaleedkhan/PatchCTG.\n","authors":["M. Jaleed Khan","Manu Vatish","Gabriel Davis Jones"],"pdf_url":"https://arxiv.org/pdf/2411.07796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00426v2","updated":"2024-11-12T13:41:47Z","published":"2024-08-01T09:57:48Z","title":"A Cross-Domain Benchmark for Active Learning","summary":"  Active Learning (AL) deals with identifying the most informative samples for\nlabeling to reduce data annotation costs for supervised learning tasks. AL\nresearch suffers from the fact that lifts from literature generalize poorly and\nthat only a small number of repetitions of experiments are conducted. To\novercome these obstacles, we propose CDALBench, the first active learning\nbenchmark which includes tasks in computer vision, natural language processing\nand tabular learning. Furthermore, by providing an efficient, greedy oracle,\nCDALBench can be evaluated with 50 runs for each experiment. We show, that both\nthe cross-domain character and a large amount of repetitions are crucial for\nsophisticated evaluation of AL research. Concretely, we show that the\nsuperiority of specific methods varies over the different domains, making it\nimportant to evaluate Active Learning with a cross-domain benchmark.\nAdditionally, we show that having a large amount of runs is crucial. With only\nconducting three runs as often done in the literature, the superiority of\nspecific methods can strongly vary with the specific runs. This effect is so\nstrong, that, depending on the seed, even a well-established method's\nperformance can be significantly better and significantly worse than random for\nthe same dataset.\n","authors":["Thorben Werner","Johannes Burchert","Maximilian Stubbemann","Lars Schmidt-Thieme"],"pdf_url":"https://arxiv.org/pdf/2408.00426v2.pdf","comment":"Accepted at NeurIPS 24 in the Benchmarks and Datasets Track. Updated\n  version of paper \"Toward Comparable Active Learning\" (arXiv:2311.18356).\n  \"Toward Comparable Active Learning\" is deprecated, please use this version.\n  arXiv admin note: text overlap with arXiv:2311.18356; text overlap with\n  arXiv:2301.10625 by other authors"},{"id":"http://arxiv.org/abs/2310.04361v4","updated":"2024-11-12T13:35:37Z","published":"2023-10-06T16:34:51Z","title":"Exploiting Activation Sparsity with Dense to Dynamic-k\n  Mixture-of-Experts Conversion","summary":"  Transformer models can face practical limitations due to their high\ncomputational requirements. At the same time, such models exhibit significant\nactivation sparsity, which can be leveraged to reduce the inference cost by\nconverting parts of the network into equivalent Mixture-of-Experts (MoE)\nlayers. Despite the crucial role played by activation sparsity, its impact on\nthis process remains unexplored. We demonstrate that the efficiency of the\nconversion can be significantly enhanced by a proper regularization of the\nactivation sparsity of the base model. Moreover, motivated by the high variance\nof the number of activated neurons for different inputs, we introduce a more\neffective dynamic-$k$ expert selection rule that adjusts the number of executed\nexperts on a per-token basis. To achieve further savings, we extend this\napproach to multi-head attention projections. Finally, we develop an efficient\nimplementation that translates these computational savings into actual\nwall-clock speedup. The proposed method, Dense to Dynamic-$k$\nMixture-of-Experts (D2DMoE), outperforms existing approaches on common NLP and\nvision tasks, reducing inference cost by up to 60% without significantly\nimpacting performance.\n","authors":["Filip Szatkowski","Bartosz W√≥jcik","Miko≈Çaj Pi√≥rczy≈Ñski","Simone Scardapane"],"pdf_url":"https://arxiv.org/pdf/2310.04361v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07784v1","updated":"2024-11-12T13:33:26Z","published":"2024-11-12T13:33:26Z","title":"Interaction Asymmetry: A General Principle for Learning Composable\n  Abstractions","summary":"  Learning disentangled representations of concepts and re-composing them in\nunseen ways is crucial for generalizing to out-of-domain situations. However,\nthe underlying properties of concepts that enable such disentanglement and\ncompositional generalization remain poorly understood. In this work, we propose\nthe principle of interaction asymmetry which states: \"Parts of the same concept\nhave more complex interactions than parts of different concepts\". We formalize\nthis via block diagonality conditions on the $(n+1)$th order derivatives of the\ngenerator mapping concepts to observed data, where different orders of\n\"complexity\" correspond to different $n$. Using this formalism, we prove that\ninteraction asymmetry enables both disentanglement and compositional\ngeneralization. Our results unify recent theoretical results for learning\nconcepts of objects, which we show are recovered as special cases with\n$n\\!=\\!0$ or $1$. We provide results for up to $n\\!=\\!2$, thus extending these\nprior works to more flexible generator functions, and conjecture that the same\nproof strategies generalize to larger $n$. Practically, our theory suggests\nthat, to disentangle concepts, an autoencoder should penalize its latent\ncapacity and the interactions between concepts during decoding. We propose an\nimplementation of these criteria using a flexible Transformer-based VAE, with a\nnovel regularizer on the attention weights of the decoder. On synthetic image\ndatasets consisting of objects, we provide evidence that this model can achieve\ncomparable object disentanglement to existing models that use more explicit\nobject-centric priors.\n","authors":["Jack Brady","Julius von K√ºgelgen","S√©bastien Lachapelle","Simon Buchholz","Thomas Kipf","Wieland Brendel"],"pdf_url":"https://arxiv.org/pdf/2411.07784v1.pdf","comment":"Preprint, under review"},{"id":"http://arxiv.org/abs/2408.08074v2","updated":"2024-11-12T13:26:39Z","published":"2024-08-15T11:01:35Z","title":"A Survey on Integrated Sensing, Communication, and Computation","summary":"  The forthcoming generation of wireless technology, 6G, aims to usher in an\nera of ubiquitous intelligent services, where everything is interconnected and\nintelligent. This vision requires the seamless integration of three fundamental\nmodules: Sensing for information acquisition, communication for information\nsharing, and computation for information processing and decision-making. These\nmodules are intricately linked, especially in complex tasks such as edge\nlearning and inference. However, the performance of these modules is\ninterdependent, creating a resource competition for time, energy, and\nbandwidth. Existing techniques like integrated communication and computation\n(ICC), integrated sensing and computation (ISC), and integrated sensing and\ncommunication (ISAC) have made partial strides in addressing this challenge,\nbut they fall short of meeting the extreme performance requirements. To\novercome these limitations, it is essential to develop new techniques that\ncomprehensively integrate sensing, communication, and computation. This\nintegrated approach, known as Integrated Sensing, Communication, and\nComputation (ISCC), offers a systematic perspective for enhancing task\nperformance. This paper begins with a comprehensive survey of historic and\nrelated techniques such as ICC, ISC, and ISAC, highlighting their strengths and\nlimitations. It then discusses the benefits, functions, and challenges of ISCC.\nSubsequently, the state-of-the-art signal designs for ISCC, along with network\nresource management strategies specifically tailored for ISCC are explored.\nFurthermore, this paper discusses the exciting research opportunities that lie\nahead for implementing ISCC in future advanced networks, and the unresolved\nissues requiring further investigation. ISCC is expected to unlock the full\npotential of intelligent connectivity, paving the way for groundbreaking\napplications and services.\n","authors":["Dingzhu Wen","Yong Zhou","Xiaoyang Li","Yuanming Shi","Kaibin Huang","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2408.08074v2.pdf","comment":"In this version, a series of discussions have been added.The\n  benefits, functions, and challenges of ISCC are investigated using a new\n  section. Moreover, the unresolved issues of ISCC have been discussed"},{"id":"http://arxiv.org/abs/2411.07773v1","updated":"2024-11-12T13:14:09Z","published":"2024-11-12T13:14:09Z","title":"Likelihood as a Performance Gauge for Retrieval-Augmented Generation","summary":"  Recent work finds that retrieval-augmented generation with large language\nmodels is prone to be influenced by the order of retrieved documents in the\ncontext. However, the lack of in-depth analysis limits the use of this\nphenomenon for prompt engineering in practice. In this study, we posit that\nlikelihoods serve as an effective gauge for language model performance. Through\nexperiments on two question-answering datasets with a variety of\nstate-of-the-art language models, we reveal correlations between answer\naccuracy and the likelihood of the question at both the corpus level and the\ninstance level. In addition, we find that question likelihood can also indicate\nthe position of the task-relevant information in the context. Based on these\nfindings, we propose two methods that use question likelihood as a gauge for\nselecting and constructing prompts that lead to better performance. We\ndemonstrate their effectiveness with experiments. In addition, our\nlikelihood-based methods are efficient, as they only need to compute the\nlikelihood of the input, requiring much fewer language model passes than\nheuristic prompt engineering methods that require generating responses. Our\nanalysis deepens our understanding of how input prompts affect model\nperformance and provides a promising direction for efficient prompt\noptimization.\n","authors":["Tianyu Liu","Jirui Qi","Paul He","Arianna Bisazza","Mrinmaya Sachan","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07773v1.pdf","comment":"Under review at NAACL 2025. Code is available at\n  https://github.com/lyutyuh/poptimizer"},{"id":"http://arxiv.org/abs/2411.07772v1","updated":"2024-11-12T13:13:20Z","published":"2024-11-12T13:13:20Z","title":"Automatic Album Sequencing","summary":"  Album sequencing is a critical part of the album production process.\nRecently, a data-driven approach was proposed that sequences general\ncollections of independent media by extracting the narrative essence of the\nitems in the collections. While this approach implies an album sequencing\ntechnique, it is not widely accessible to a less technical audience, requiring\nadvanced knowledge of machine learning techniques to use. To address this, we\nintroduce a new user-friendly web-based tool that allows a less technical\naudience to upload music tracks, execute this technique in one click, and\nsubsequently presents the result in a clean visualization to the user. To both\nincrease the number of templates available to the user and address shortcomings\nof previous work, we also introduce a new direct transformer-based album\nsequencing method. We find that our more direct method outperforms a random\nbaseline but does not reach the same performance as the narrative essence\napproach. Both methods are included in our web-based user interface, and this\n-- alongside a full copy of our implementation -- is publicly available at\nhttps://github.com/dylanashley/automatic-album-sequencing\n","authors":["Vincent Herrmann","Dylan R. Ashley","J√ºrgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2411.07772v1.pdf","comment":"presented as a late breaking demo in the 25th International Society\n  for Music Information Retrieval Conference; 3 pages in main text, 3 figures\n  in main text; source code available at\n  https://github.com/dylanashley/automatic-album-sequencing"},{"id":"http://arxiv.org/abs/2411.07762v1","updated":"2024-11-12T12:52:04Z","published":"2024-11-12T12:52:04Z","title":"ASER: Activation Smoothing and Error Reconstruction for Large Language\n  Model Quantization","summary":"  Quantization stands as a pivotal technique for large language model (LLM)\nserving, yet it poses significant challenges particularly in achieving\neffective low-bit quantization. The limited numerical mapping makes the\nquantized model produce a non-trivial error, bringing out intolerable\nperformance degration. This paper is anchored in the basic idea of model\ncompression objectives, and delves into the layer-wise error distribution of\nLLMs during post-training quantization. Subsequently, we introduce ASER, an\nalgorithm consisting of (1) Error Reconstruction: low-rank compensation for\nquantization error with LoRA-style matrices constructed by whitening SVD; (2)\nActivation Smoothing: outlier extraction to gain smooth activation and better\nerror compensation. ASER is capable of quantizing typical LLMs to low-bit ones,\nparticularly preserving accuracy even in W4A8 per-channel setup. Experimental\nresults show that ASER is competitive among the state-of-the-art quantization\nalgorithms, showing potential to activation quantization, with minor overhead.\n","authors":["Weibo Zhao","Yubin Shi","Xinyu Lyu","Wanchen Sui","Shen Li","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2411.07762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07760v1","updated":"2024-11-12T12:49:41Z","published":"2024-11-12T12:49:41Z","title":"Navigation with QPHIL: Quantizing Planner for Hierarchical Implicit\n  Q-Learning","summary":"  Offline Reinforcement Learning (RL) has emerged as a powerful alternative to\nimitation learning for behavior modeling in various domains, particularly in\ncomplex navigation tasks. An existing challenge with Offline RL is the\nsignal-to-noise ratio, i.e. how to mitigate incorrect policy updates due to\nerrors in value estimates. Towards this, multiple works have demonstrated the\nadvantage of hierarchical offline RL methods, which decouples high-level path\nplanning from low-level path following. In this work, we present a novel\nhierarchical transformer-based approach leveraging a learned quantizer of the\nspace. This quantization enables the training of a simpler zone-conditioned\nlow-level policy and simplifies planning, which is reduced to discrete\nautoregressive prediction. Among other benefits, zone-level reasoning in\nplanning enables explicit trajectory stitching rather than implicit stitching\nbased on noisy value function estimates. By combining this transformer-based\nplanner with recent advancements in offline RL, our proposed approach achieves\nstate-of-the-art results in complex long-distance navigation environments.\n","authors":["Alexi Canesse","Mathieu Petitbois","Ludovic Denoyer","Sylvain Lamprier","R√©my Portelas"],"pdf_url":"https://arxiv.org/pdf/2411.07760v1.pdf","comment":"Under review. Code will be released upon acceptance"},{"id":"http://arxiv.org/abs/2411.02199v4","updated":"2024-11-12T12:44:02Z","published":"2024-11-04T15:54:32Z","title":"Provably Transformers Harness Multi-Concept Word Semantics for Efficient\n  In-Context Learning","summary":"  Transformer-based large language models (LLMs) have displayed remarkable\ncreative prowess and emergence capabilities. Existing empirical studies have\nrevealed a strong connection between these LLMs' impressive emergence abilities\nand their in-context learning (ICL) capacity, allowing them to solve new tasks\nusing only task-specific prompts without further fine-tuning. On the other\nhand, existing empirical and theoretical studies also show that there is a\nlinear regularity of the multi-concept encoded semantic representation behind\ntransformer-based LLMs. However, existing theoretical work fail to build up an\nunderstanding of the connection between this regularity and the innovative\npower of ICL. Additionally, prior work often focuses on simplified, unrealistic\nscenarios involving linear transformers or unrealistic loss functions, and they\nachieve only linear or sub-linear convergence rates. In contrast, this work\nprovides a fine-grained mathematical analysis to show how transformers leverage\nthe multi-concept semantics of words to enable powerful ICL and excellent\nout-of-distribution ICL abilities, offering insights into how transformers\ninnovate solutions for certain unseen tasks encoded with multiple cross-concept\nsemantics. Inspired by empirical studies on the linear latent geometry of LLMs,\nthe analysis is based on a concept-based low-noise sparse coding prompt model.\nLeveraging advanced techniques, this work showcases the exponential 0-1 loss\nconvergence over the highly non-convex training dynamics, which pioneeringly\nincorporates the challenges of softmax self-attention, ReLU-activated MLPs, and\ncross-entropy loss. Empirical simulations corroborate the theoretical findings.\n","authors":["Dake Bu","Wei Huang","Andi Han","Atsushi Nitanda","Taiji Suzuki","Qingfu Zhang","Hau-San Wong"],"pdf_url":"https://arxiv.org/pdf/2411.02199v4.pdf","comment":"Accepted by the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2404.19664v4","updated":"2024-11-12T12:43:42Z","published":"2024-04-30T15:57:41Z","title":"Towards Generalist Robot Learning from Internet Video: A Survey","summary":"  Scaling deep learning to massive, diverse internet data has yielded\nremarkably general capabilities in visual and natural language understanding\nand generation. However, data has remained scarce and challenging to collect in\nrobotics, seeing robot learning struggle to obtain similarly general\ncapabilities. Promising Learning from Videos (LfV) methods aim to address the\nrobotics data bottleneck by augmenting traditional robot data with large-scale\ninternet video data. This video data offers broad foundational information\nregarding physical behaviour and the underlying physics of the world, and thus\ncan be highly informative for a generalist robot.\n  In this survey, we present a thorough overview of the emerging field of LfV.\nWe outline fundamental concepts, including the benefits and challenges of LfV.\nWe provide a comprehensive review of current methods for extracting knowledge\nfrom large-scale internet video, addressing key challenges in LfV, and boosting\ndownstream robot and reinforcement learning via the use of video data. The\nsurvey concludes with a critical discussion of challenges and opportunities in\nLfV. Here, we advocate for scalable foundation model approaches that can\nleverage the full range of available internet video to improve the learning of\nrobot policies and dynamics models. We hope this survey can inform and catalyse\nfurther LfV research, driving progress towards the development of\ngeneral-purpose robots.\n","authors":["Robert McCarthy","Daniel C. H. Tan","Dominik Schmidt","Fernando Acero","Nathan Herr","Yilun Du","Thomas G. Thuruthel","Zhibin Li"],"pdf_url":"https://arxiv.org/pdf/2404.19664v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07753v1","updated":"2024-11-12T12:24:48Z","published":"2024-11-12T12:24:48Z","title":"Spatially Regularized Graph Attention Autoencoder Framework for\n  Detecting Rainfall Extremes","summary":"  We introduce a novel Graph Attention Autoencoder (GAE) with spatial\nregularization to address the challenge of scalable anomaly detection in\nspatiotemporal rainfall data across India from 1990 to 2015. Our model\nleverages a Graph Attention Network (GAT) to capture spatial dependencies and\ntemporal dynamics in the data, further enhanced by a spatial regularization\nterm ensuring geographic coherence. We construct two graph datasets employing\nrainfall, pressure, and temperature attributes from the Indian Meteorological\nDepartment and ERA5 Reanalysis on Single Levels, respectively. Our network\noperates on graph representations of the data, where nodes represent geographic\nlocations, and edges, inferred through event synchronization, denote\nsignificant co-occurrences of rainfall events. Through extensive experiments,\nwe demonstrate that our GAE effectively identifies anomalous rainfall patterns\nacross the Indian landscape. Our work paves the way for sophisticated\nspatiotemporal anomaly detection methodologies in climate science, contributing\nto better climate change preparedness and response strategies.\n","authors":["Mihir Agarwal","Progyan Das","Udit Bhatia"],"pdf_url":"https://arxiv.org/pdf/2411.07753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06911v2","updated":"2024-11-12T12:07:00Z","published":"2024-11-11T12:13:58Z","title":"Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI","summary":"  Segmentation of cardiac magnetic resonance images (MRI) is crucial for the\nanalysis and assessment of cardiac function, helping to diagnose and treat\nvarious cardiovascular diseases. Most recent techniques rely on deep learning\nand usually require an extensive amount of labeled data. To overcome this\nproblem, few-shot learning has the capability of reducing data dependency on\nlabeled data. In this work, we introduce a new method that merges few-shot\nlearning with a U-Net architecture and Gaussian Process Emulators (GPEs),\nenhancing data integration from a support set for improved performance. GPEs\nare trained to learn the relation between the support images and the\ncorresponding masks in latent space, facilitating the segmentation of unseen\nquery images given only a small labeled support set at inference. We test our\nmodel with the M&Ms-2 public dataset to assess its ability to segment the heart\nin cardiac magnetic resonance imaging from different orientations, and compare\nit with state-of-the-art unsupervised and few-shot methods. Our architecture\nshows higher DICE coefficients compared to these methods, especially in the\nmore challenging setups where the size of the support set is considerably\nsmall.\n","authors":["Bruno Viti","Franz Thaler","Kathrin Lisa Kapper","Martin Urschler","Martin Holler","Elias Karabelas"],"pdf_url":"https://arxiv.org/pdf/2411.06911v2.pdf","comment":"Accepted at Statistical Atlases and Computational Modeling of the\n  Heart (STACOM) Workshop 2024"},{"id":"http://arxiv.org/abs/2411.07087v2","updated":"2024-11-12T12:03:07Z","published":"2024-11-11T16:04:49Z","title":"OCMDP: Observation-Constrained Markov Decision Process","summary":"  In many practical applications, decision-making processes must balance the\ncosts of acquiring information with the benefits it provides. Traditional\ncontrol systems often assume full observability, an unrealistic assumption when\nobservations are expensive. We tackle the challenge of simultaneously learning\nobservation and control strategies in such cost-sensitive environments by\nintroducing the Observation-Constrained Markov Decision Process (OCMDP), where\nthe policy influences the observability of the true state. To manage the\ncomplexity arising from the combined observation and control actions, we\ndevelop an iterative, model-free deep reinforcement learning algorithm that\nseparates the sensing and control components of the policy. This decomposition\nenables efficient learning in the expanded action space by focusing on when and\nwhat to observe, as well as determining optimal control actions, without\nrequiring knowledge of the environment's dynamics. We validate our approach on\na simulated diagnostic task and a realistic healthcare environment using\nHeartPole. Given both scenarios, the experimental results demonstrate that our\nmodel achieves a substantial reduction in observation costs on average,\nsignificantly outperforming baseline methods by a notable margin in efficiency.\n","authors":["Taiyi Wang","Jianheng Liu","Bryan Lee","Zhihao Wu","Yu Wu"],"pdf_url":"https://arxiv.org/pdf/2411.07087v2.pdf","comment":"Full paper, 14 Pages"},{"id":"http://arxiv.org/abs/2408.12308v3","updated":"2024-11-12T11:45:35Z","published":"2024-08-22T11:34:34Z","title":"Deep Learning with CNNs: A Compact Holistic Tutorial with Focus on\n  Supervised Regression (Preprint)","summary":"  In this tutorial, we present a compact and holistic discussion of Deep\nLearning with a focus on Convolutional Neural Networks (CNNs) and supervised\nregression. While there are numerous books and articles on the individual\ntopics we cover, comprehensive and detailed tutorials that address Deep\nLearning from a foundational yet rigorous and accessible perspective are rare.\nMost resources on CNNs are either too advanced, focusing on cutting-edge\narchitectures, or too narrow, addressing only specific applications like image\nclassification.This tutorial not only summarizes the most relevant concepts but\nalso provides an in-depth exploration of each, offering a complete yet agile\nset of ideas. Moreover, we highlight the powerful synergy between learning\ntheory, statistic, and machine learning, which together underpin the Deep\nLearning and CNN frameworks. We aim for this tutorial to serve as an optimal\nresource for students, professors, and anyone interested in understanding the\nfoundations of Deep Learning. Upon acceptance we will provide an accompanying\nrepository under\n\\href{https://github.com/neoglez/deep-learning-tutorial}{https://github.com/neoglez/deep-learning-tutorial}\n  Keywords: Tutorial, Deep Learning, Convolutional Neural Networks, Machine\nLearning.\n","authors":["Yansel Gonzalez Tejeda","Helmut A. Mayer"],"pdf_url":"https://arxiv.org/pdf/2408.12308v3.pdf","comment":"Submitted to the journal Machine Learning and Knowledge Extraction"},{"id":"http://arxiv.org/abs/2411.07729v1","updated":"2024-11-12T11:41:38Z","published":"2024-11-12T11:41:38Z","title":"Exploring the loss landscape of regularized neural networks via convex\n  duality","summary":"  We discuss several aspects of the loss landscape of regularized neural\nnetworks: the structure of stationary points, connectivity of optimal\nsolutions, path with nonincreasing loss to arbitrary global optimum, and the\nnonuniqueness of optimal solutions, by casting the problem into an equivalent\nconvex problem and considering its dual. Starting from two-layer neural\nnetworks with scalar output, we first characterize the solution set of the\nconvex problem using its dual and further characterize all stationary points.\nWith the characterization, we show that the topology of the global optima goes\nthrough a phase transition as the width of the network changes, and construct\ncounterexamples where the problem may have a continuum of optimal solutions.\nFinally, we show that the solution set characterization and connectivity\nresults can be extended to different architectures, including two-layer\nvector-valued neural networks and parallel three-layer neural networks.\n","authors":["Sungyoon Kim","Aaron Mishkin","Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2411.07729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07724v1","updated":"2024-11-12T11:30:53Z","published":"2024-11-12T11:30:53Z","title":"Convergence Rate Analysis of LION","summary":"  The LION (evoLved sIgn mOmeNtum) optimizer for deep neural network training\nwas found by Google via program search, with the simple sign update yet showing\nimpressive performance in training large scale networks. Although previous\nstudies have investigated its convergence properties, a comprehensive analysis,\nespecially the convergence rate, is still desirable. Recognizing that LION can\nbe regarded as solving a specific constrained problem, this paper focuses on\ndemonstrating its convergence to the Karush-Kuhn-Tucker (KKT) point at the rate\nof $\\cal O(\\sqrt{d}K^{-1/4})$ measured by gradient $\\ell_1$ norm, where $d$ is\nthe problem dimension and $K$ is the number of iteration steps. Step further,\nwe remove the constraint and establish that LION converges to the critical\npoint of the general unconstrained problem at the same rate. This rate not only\ndelivers the currently optimal dependence on the problem dimension $d$ but also\ntightly matches the theoretical lower bound for nonconvex stochastic\noptimization algorithms, which is typically measured using the gradient\n$\\ell_2$ norm, with respect to the number of iterations $K$. Through extensive\nexperiments, we not only demonstrate that LION achieves lower loss and higher\nperformance compared to standard SGD, but also empirically confirm that the\ngradient $\\ell_1/\\ell_2$ norm ratio aligns with $\\Theta(\\sqrt{d})$, thus\nproving that our convergence rate matches the theoretical lower bound with\nrespect to $d$ in the empirical sense.\n","authors":["Yiming Dong","Huan Li","Zhouchen Lin"],"pdf_url":"https://arxiv.org/pdf/2411.07724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07719v1","updated":"2024-11-12T11:24:18Z","published":"2024-11-12T11:24:18Z","title":"EMPERROR: A Flexible Generative Perception Error Model for Probing\n  Self-Driving Planners","summary":"  To handle the complexities of real-world traffic, learning planners for\nself-driving from data is a promising direction. While recent approaches have\nshown great progress, they typically assume a setting in which the ground-truth\nworld state is available as input. However, when deployed, planning needs to be\nrobust to the long-tail of errors incurred by a noisy perception system, which\nis often neglected in evaluation. To address this, previous work has proposed\ndrawing adversarial samples from a perception error model (PEM) mimicking the\nnoise characteristics of a target object detector. However, these methods use\nsimple PEMs that fail to accurately capture all failure modes of detection. In\nthis paper, we present EMPERROR, a novel transformer-based generative PEM,\napply it to stress-test an imitation learning (IL)-based planner and show that\nit imitates modern detectors more faithfully than previous work. Furthermore,\nit is able to produce realistic noisy inputs that increase the planner's\ncollision rate by up to 85%, demonstrating its utility as a valuable tool for a\nmore complete evaluation of self-driving planners.\n","authors":["Niklas Hanselmann","Simon Doll","Marius Cordts","Hendrik P. A. Lensch","Andreas Geiger"],"pdf_url":"https://arxiv.org/pdf/2411.07719v1.pdf","comment":"Project page: https://lasnik.github.io/emperror/"},{"id":"http://arxiv.org/abs/2405.07863v3","updated":"2024-11-12T11:18:43Z","published":"2024-05-13T15:50:39Z","title":"RLHF Workflow: From Reward Modeling to Online RLHF","summary":"  We present the workflow of Online Iterative Reinforcement Learning from Human\nFeedback (RLHF) in this technical report, which is widely reported to\noutperform its offline counterpart by a large margin in the recent large\nlanguage model (LLM) literature. However, existing open-source RLHF projects\nare still largely confined to the offline learning setting. In this technical\nreport, we aim to fill in this gap and provide a detailed recipe that is easy\nto reproduce for online iterative RLHF. In particular, since online human\nfeedback is usually infeasible for open-source communities with limited\nresources, we start by constructing preference models using a diverse set of\nopen-source datasets and use the constructed proxy preference model to\napproximate human feedback. Then, we discuss the theoretical insights and\nalgorithmic principles behind online iterative RLHF, followed by a detailed\npractical implementation. Our trained LLM achieves impressive performance on\nLLM chatbot benchmarks, including AlpacaEval-2, Arena-Hard, and MT-Bench, as\nwell as other academic benchmarks such as HumanEval and TruthfulQA. We have\nshown that supervised fine-tuning (SFT) and iterative RLHF can obtain\nstate-of-the-art performance with fully open-source datasets. Further, we have\nmade our models, curated datasets, and comprehensive step-by-step code\nguidebooks publicly available. Please refer to\nhttps://github.com/RLHFlow/RLHF-Reward-Modeling and\nhttps://github.com/RLHFlow/Online-RLHF for more detailed information.\n","authors":["Hanze Dong","Wei Xiong","Bo Pang","Haoxiang Wang","Han Zhao","Yingbo Zhou","Nan Jiang","Doyen Sahoo","Caiming Xiong","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.07863v3.pdf","comment":"Published in Transactions on Machine Learning Research (09/2024)"},{"id":"http://arxiv.org/abs/2201.07395v4","updated":"2024-11-12T11:12:46Z","published":"2022-01-19T03:08:33Z","title":"Overview frequency principle/spectral bias in deep learning","summary":"  Understanding deep learning is increasingly emergent as it penetrates more\nand more into industry and science. In recent years, a research line from\nFourier analysis sheds lights on this magical \"black box\" by showing a\nFrequency Principle (F-Principle or spectral bias) of the training behavior of\ndeep neural networks (DNNs) -- DNNs often fit functions from low to high\nfrequency during the training. The F-Principle is first demonstrated by\nonedimensional synthetic data followed by the verification in high-dimensional\nreal datasets. A series of works subsequently enhance the validity of the\nF-Principle. This low-frequency implicit bias reveals the strength of neural\nnetwork in learning low-frequency functions as well as its deficiency in\nlearning high-frequency functions. Such understanding inspires the design of\nDNN-based algorithms in practical problems, explains experimental phenomena\nemerging in various scenarios, and further advances the study of deep learning\nfrom the frequency perspective. Although incomplete, we provide an overview of\nF-Principle and propose some open problems for future research.\n","authors":["Zhi-Qin John Xu","Yaoyu Zhang","Tao Luo"],"pdf_url":"https://arxiv.org/pdf/2201.07395v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06736v2","updated":"2024-11-12T11:09:18Z","published":"2024-11-11T06:04:53Z","title":"Mr.Steve: Instruction-Following Agents in Minecraft with What-Where-When\n  Memory","summary":"  Significant advances have been made in developing general-purpose embodied AI\nin environments like Minecraft through the adoption of LLM-augmented\nhierarchical approaches. While these approaches, which combine high-level\nplanners with low-level controllers, show promise, low-level controllers\nfrequently become performance bottlenecks due to repeated failures. In this\npaper, we argue that the primary cause of failure in many low-level controllers\nis the absence of an episodic memory system. To address this, we introduce Mr.\nSteve (Memory Recall Steve-1), a novel low-level controller equipped with Place\nEvent Memory (PEM), a form of episodic memory that captures what, where, and\nwhen information from episodes. This directly addresses the main limitation of\nthe popular low-level controller, Steve-1. Unlike previous models that rely on\nshort-term memory, PEM organizes spatial and event-based data, enabling\nefficient recall and navigation in long-horizon tasks. Additionally, we propose\nan Exploration Strategy and a Memory-Augmented Task Solving Framework, allowing\nagents to alternate between exploration and task-solving based on recalled\nevents. Our approach significantly improves task-solving and exploration\nefficiency compared to existing methods. We will release our code and demos on\nthe project page: https://sites.google.com/view/mr-steve.\n","authors":["Junyeong Park","Junmo Cho","Sungjin Ahn"],"pdf_url":"https://arxiv.org/pdf/2411.06736v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.08364v3","updated":"2024-11-12T10:56:38Z","published":"2024-07-11T10:18:54Z","title":"Scalar Function Topology Divergence: Comparing Topology of 3D Objects","summary":"  We propose a new topological tool for computer vision - Scalar Function\nTopology Divergence (SFTD), which measures the dissimilarity of multi-scale\ntopology between sublevel sets of two functions having a common domain.\nFunctions can be defined on an undirected graph or Euclidean space of any\ndimensionality. Most of the existing methods for comparing topology are based\non Wasserstein distance between persistence barcodes and they don't take into\naccount the localization of topological features. The minimization of SFTD\nensures that the corresponding topological features of scalar functions are\nlocated in the same places. The proposed tool provides useful visualizations\ndepicting areas where functions have topological dissimilarities. We provide\napplications of the proposed method to 3D computer vision. In particular,\nexperiments demonstrate that SFTD as an additional loss improves the\nreconstruction of cellular 3D shapes from 2D fluorescence microscopy images,\nand helps to identify topological errors in 3D segmentation. Additionally, we\nshow that SFTD outperforms Betti matching loss in 2D segmentation problems.\n","authors":["Ilya Trofimov","Daria Voronkova","Eduard Tulchinskii","Evgeny Burnaev","Serguei Barannikov"],"pdf_url":"https://arxiv.org/pdf/2407.08364v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07711v1","updated":"2024-11-12T10:55:30Z","published":"2024-11-12T10:55:30Z","title":"OWLed: Outlier-weighed Layerwise Pruning for Efficient Autonomous\n  Driving Framework","summary":"  The integration of Large Language Models (LLMs) into autonomous driving\nsystems offers promising enhancements in environmental understanding and\ndecision-making. However, the substantial computational demands of deploying\nLLMs locally on vehicles render this approach unfeasible for real-world\nautomotive applications. To address this challenge, we introduce OWLed, the\nOutlier-Weighed Layerwise Pruning for Efficient Autonomous Driving Framework\nthat leverages outlier-weighted layerwise sparsity for model compression. Our\nmethod assigns non-uniform sparsity ratios to different layers based on the\ndistribution of outlier features, significantly reducing the model size without\nthe need for fine-tuning. To ensure the compressed model adapts well to\nautonomous driving tasks, we incorporate driving environment data into both the\ncalibration and pruning processes. Our empirical studies reveal that the\nencoder component is more sensitive to pruning than the LLM, highlighting its\ncritical role in the system. Experimental results demonstrate that OWLed\noutperforms existing methods in perception, action prediction, and language\nunderstanding while substantially lowering computational requirements. These\nfindings underscore the potential of combining advanced pruning techniques with\nLLMs to develop efficient and robust autonomous driving systems capable of\nhandling complex scenarios. Code will be made publicly available.\n","authors":["Jiaxi Li","Lu Yin","Xilu Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07711v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2411.07700v1","updated":"2024-11-12T10:26:44Z","published":"2024-11-12T10:26:44Z","title":"Test Where Decisions Matter: Importance-driven Testing for Deep\n  Reinforcement Learning","summary":"  In many Deep Reinforcement Learning (RL) problems, decisions in a trained\npolicy vary in significance for the expected safety and performance of the\npolicy. Since RL policies are very complex, testing efforts should concentrate\non states in which the agent's decisions have the highest impact on the\nexpected outcome. In this paper, we propose a novel model-based method to\nrigorously compute a ranking of state importance across the entire state space.\nWe then focus our testing efforts on the highest-ranked states. In this paper,\nwe focus on testing for safety. However, the proposed methods can be easily\nadapted to test for performance. In each iteration, our testing framework\ncomputes optimistic and pessimistic safety estimates. These estimates provide\nlower and upper bounds on the expected outcomes of the policy execution across\nall modeled states in the state space. Our approach divides the state space\ninto safe and unsafe regions upon convergence, providing clear insights into\nthe policy's weaknesses. Two important properties characterize our approach.\n(1) Optimal Test-Case Selection: At any time in the testing process, our\napproach evaluates the policy in the states that are most critical for safety.\n(2) Guaranteed Safety: Our approach can provide formal verification guarantees\nover the entire state space by sampling only a fraction of the policy. Any\nsafety properties assured by the pessimistic estimate are formally proven to\nhold for the policy. We provide a detailed evaluation of our framework on\nseveral examples, showing that our method discovers unsafe policy behavior with\nlow testing effort.\n","authors":["Stefan Pranger","Hana Chockler","Martin Tappler","Bettina K√∂nighofer"],"pdf_url":"https://arxiv.org/pdf/2411.07700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02487v2","updated":"2024-11-12T10:03:37Z","published":"2024-08-05T14:09:30Z","title":"LiCoEval: Evaluating LLMs on License Compliance in Code Generation","summary":"  Recent advances in Large Language Models (LLMs) have revolutionized code\ngeneration, leading to widespread adoption of AI coding tools by developers.\nHowever, LLMs can generate license-protected code without providing the\nnecessary license information, leading to potential intellectual property\nviolations during software production. This paper addresses the critical, yet\nunderexplored, issue of license compliance in LLM-generated code by\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\nlicense information for their generated code. To establish this benchmark, we\nconduct an empirical study to identify a reasonable standard for \"striking\nsimilarity\" that excludes the possibility of independent creation, indicating a\ncopy relationship between the LLM output and certain open-source code. Based on\nthis standard, we propose LiCoEval, to evaluate the license compliance\ncapabilities of LLMs, i.e., the ability to provide accurate license or\ncopyright information when they generate code with striking similarity to\nalready existing copyrighted code. Using LiCoEval, we evaluate 14 popular LLMs,\nfinding that even top-performing LLMs produce a non-negligible proportion\n(0.88% to 2.01%) of code strikingly similar to existing open-source\nimplementations. Notably, most LLMs fail to provide accurate license\ninformation, particularly for code under copyleft licenses. These findings\nunderscore the urgent need to enhance LLM compliance capabilities in code\ngeneration tasks. Our study provides a foundation for future research and\ndevelopment to improve license compliance in AI-assisted software development,\ncontributing to both the protection of open-source software copyrights and the\nmitigation of legal risks for LLM users.\n","authors":["Weiwei Xu","Kai Gao","Hao He","Minghui Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.02487v2.pdf","comment":"The 47th International Conference on Software Engineering(ICSE 2025)"},{"id":"http://arxiv.org/abs/2405.17544v2","updated":"2024-11-12T09:57:28Z","published":"2024-05-27T18:00:00Z","title":"Towards Human-AI Complementarity with Prediction Sets","summary":"  Decision support systems based on prediction sets have proven to be effective\nat helping human experts solve classification tasks. Rather than providing\nsingle-label predictions, these systems provide sets of label predictions\nconstructed using conformal prediction, namely prediction sets, and ask human\nexperts to predict label values from these sets. In this paper, we first show\nthat the prediction sets constructed using conformal prediction are, in\ngeneral, suboptimal in terms of average accuracy. Then, we show that the\nproblem of finding the optimal prediction sets under which the human experts\nachieve the highest average accuracy is NP-hard. More strongly, unless P = NP,\nwe show that the problem is hard to approximate to any factor less than the\nsize of the label set. However, we introduce a simple and efficient greedy\nalgorithm that, for a large class of expert models and non-conformity scores,\nis guaranteed to find prediction sets that provably offer equal or greater\nperformance than those constructed using conformal prediction. Further, using a\nsimulation study with both synthetic and real expert predictions, we\ndemonstrate that, in practice, our greedy algorithm finds near-optimal\nprediction sets offering greater performance than conformal prediction.\n","authors":["Giovanni De Toni","Nastaran Okati","Suhas Thejaswi","Eleni Straitouri","Manuel Gomez-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2405.17544v2.pdf","comment":"Published in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2407.19872v3","updated":"2024-11-12T09:57:00Z","published":"2024-07-29T10:43:15Z","title":"OpenUAS: Embeddings of Cities in Japan with Anchor Data for Cross-city\n  Analysis of Area Usage Patterns","summary":"  We publicly release OpenUAS, a dataset of area embeddings based on urban\nusage patterns, including embeddings for over 1.3 million 50-meter square\nmeshes covering a total area of 3,300 square kilometers. This dataset is\nvaluable for analyzing area functions in fields such as market analysis, urban\nplanning, transportation infrastructure, and infection prediction. It captures\nthe characteristics of each area in the city, such as office districts and\nresidential areas, by employing an area embedding technique that utilizes\nlocation information typically obtained by GPS. Numerous area embedding\ntechniques have been proposed, and while the public release of such embedding\ndatasets is technically feasible, it has not been realized. One reason for this\nis that previous methods could not embed areas from different cities and\nperiods into the same embedding space without sharing raw location data. We\naddress this issue by developing an anchoring method that establishes anchors\nwithin a shared embedding space. We publicly release this anchor dataset along\nwith area embedding datasets from several periods in eight major Japanese\ncities.\n","authors":["Naoki Tamura","Kazuyuki Shoji","Shin Katayama","Kenta Urano","Takuro Yonezawa","Nobuo Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2407.19872v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06797v2","updated":"2024-11-12T09:54:07Z","published":"2023-07-13T15:08:44Z","title":"Fast and Functional Structured Data Generators Rooted in\n  Out-of-Equilibrium Physics","summary":"  In this study, we address the challenge of using energy-based models to\nproduce high-quality, label-specific data in complex structured datasets, such\nas population genetics, RNA or protein sequences data. Traditional training\nmethods encounter difficulties due to inefficient Markov chain Monte Carlo\nmixing, which affects the diversity of synthetic data and increases generation\ntimes. To address these issues, we use a novel training algorithm that exploits\nnon-equilibrium effects. This approach, applied on the Restricted Boltzmann\nMachine, improves the model's ability to correctly classify samples and\ngenerate high-quality synthetic data in only a few sampling steps. The\neffectiveness of this method is demonstrated by its successful application to\nfour different types of data: handwritten digits, mutations of human genomes\nclassified by continental origin, functionally characterized sequences of an\nenzyme protein family, and homologous RNA sequences from specific taxonomies.\n","authors":["Alessandra Carbone","Aur√©lien Decelle","Lorenzo Rosset","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2307.06797v2.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2411.07681v1","updated":"2024-11-12T09:52:40Z","published":"2024-11-12T09:52:40Z","title":"What Do Learning Dynamics Reveal About Generalization in LLM Reasoning?","summary":"  Despite the remarkable capabilities of modern large language models (LLMs),\nthe mechanisms behind their problem-solving abilities remain elusive. In this\nwork, we aim to better understand how the learning dynamics of LLM finetuning\nshapes downstream generalization. Our analysis focuses on reasoning tasks,\nwhose problem structure allows us to distinguish between memorization (the\nexact replication of reasoning steps from the training data) and performance\n(the correctness of the final solution). We find that a model's generalization\nbehavior can be effectively characterized by a training metric we call\npre-memorization train accuracy: the accuracy of model samples on training\nqueries before they begin to copy the exact reasoning steps from the training\nset. On the dataset level, this metric is able to reliably predict test\naccuracy, achieving $R^2$ of around or exceeding 0.9 across various models\n(Llama3 8, Gemma2 9B), datasets (GSM8k, MATH), and training configurations. On\na per-example level, this metric is also indicative of whether individual model\npredictions are robust to perturbations in the training query. By connecting a\nmodel's learning behavior to its generalization, pre-memorization train\naccuracy can guide targeted improvements to training strategies. We focus on\ndata curation as an example, and show that prioritizing examples with low\npre-memorization accuracy leads to 1.5-2x improvements in data efficiency\ncompared to i.i.d. data scaling, and outperforms other standard data curation\ntechniques.\n","authors":["Katie Kang","Amrith Setlur","Dibya Ghosh","Jacob Steinhardt","Claire Tomlin","Sergey Levine","Aviral Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02066v4","updated":"2024-11-12T09:50:15Z","published":"2024-09-03T17:13:55Z","title":"Robust Clustering on High-Dimensional Data with Stochastic Quantization","summary":"  This paper addresses the limitations of conventional vector quantization\nalgorithms, particularly K-Means and its variant K-Means++, and investigates\nthe Stochastic Quantization (SQ) algorithm as a scalable alternative for\nhigh-dimensional unsupervised and semi-supervised learning tasks. Traditional\nclustering algorithms often suffer from inefficient memory utilization during\ncomputation, necessitating the loading of all data samples into memory, which\nbecomes impractical for large-scale datasets. While variants such as Mini-Batch\nK-Means partially mitigate this issue by reducing memory usage, they lack\nrobust theoretical convergence guarantees due to the non-convex nature of\nclustering problems. In contrast, the Stochastic Quantization algorithm\nprovides strong theoretical convergence guarantees, making it a robust\nalternative for clustering tasks. We demonstrate the computational efficiency\nand rapid convergence of the algorithm on an image classification problem with\npartially labeled data, comparing model accuracy across various ratios of\nlabeled to unlabeled data. To address the challenge of high dimensionality, we\nemploy a Triplet Network to encode images into low-dimensional representations\nin a latent space, which serve as a basis for comparing the efficiency of both\nthe Stochastic Quantization algorithm and traditional quantization algorithms.\nFurthermore, we enhance the algorithm's convergence speed by introducing\nmodifications with an adaptive learning rate.\n","authors":["Anton Kozyriev","Vladimir Norkin"],"pdf_url":"https://arxiv.org/pdf/2409.02066v4.pdf","comment":"22 pages, 5 figures, to be published in the International Scientific\n  Technical Journal \"Problems of Control and Informatics\""},{"id":"http://arxiv.org/abs/2411.07679v1","updated":"2024-11-12T09:49:16Z","published":"2024-11-12T09:49:16Z","title":"Safe Exploitative Play with Untrusted Type Beliefs","summary":"  The combination of the Bayesian game and learning has a rich history, with\nthe idea of controlling a single agent in a system composed of multiple agents\nwith unknown behaviors given a set of types, each specifying a possible\nbehavior for the other agents. The idea is to plan an agent's own actions with\nrespect to those types which it believes are most likely to maximize the\npayoff. However, the type beliefs are often learned from past actions and\nlikely to be incorrect. With this perspective in mind, we consider an agent in\na game with type predictions of other components, and investigate the impact of\nincorrect beliefs to the agent's payoff. In particular, we formally define a\ntradeoff between risk and opportunity by comparing the payoff obtained against\nthe optimal payoff, which is represented by a gap caused by trusting or\ndistrusting the learned beliefs. Our main results characterize the tradeoff by\nestablishing upper and lower bounds on the Pareto front for both normal-form\nand stochastic Bayesian games, with numerical results provided.\n","authors":["Tongxin Li","Tinashe Handina","Shaolei Ren","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2411.07679v1.pdf","comment":"26 pages, NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.17351v2","updated":"2024-11-12T09:46:25Z","published":"2024-03-26T03:29:42Z","title":"Learn from Heterophily: Heterophilous Information-enhanced Graph Neural\n  Network","summary":"  Under circumstances of heterophily, where nodes with different labels tend to\nbe connected based on semantic meanings, Graph Neural Networks (GNNs) often\nexhibit suboptimal performance. Current studies on graph heterophily mainly\nfocus on aggregation calibration or neighbor extension and address the\nheterophily issue by utilizing node features or structural information to\nimprove GNN representations. In this paper, we propose and demonstrate that the\nvaluable semantic information inherent in heterophily can be utilized\neffectively in graph learning by investigating the distribution of neighbors\nfor each individual node within the graph. The theoretical analysis is carried\nout to demonstrate the efficacy of the idea in enhancing graph learning. Based\non this analysis, we propose HiGNN, an innovative approach that constructs an\nadditional new graph structure, that integrates heterophilous information by\nleveraging node distribution to enhance connectivity between nodes that share\nsimilar semantic characteristics. We conduct empirical assessments on node\nclassification tasks using both homophilous and heterophilous benchmark\ndatasets and compare HiGNN to popular GNN baselines and SoTA methods,\nconfirming the effectiveness in improving graph representations. In addition,\nby incorporating heterophilous information, we demonstrate a notable\nenhancement in existing GNN-based approaches, and the homophily degree across\nreal-world datasets, thus affirming the efficacy of our approach.\n","authors":["Yilun Zheng","Jiahao Xu","Lihui Chen"],"pdf_url":"https://arxiv.org/pdf/2403.17351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19178v2","updated":"2024-11-12T09:42:13Z","published":"2024-05-29T15:18:39Z","title":"Model-independent cosmological inference post DESI DR1 BAO measurements","summary":"  In this work, we implement Gaussian process regression to reconstruct the\nexpansion history of the universe in a model-agnostic manner, using the\nPantheon-Plus SN-Ia compilation in combination with two different BAO\nmeasurements (SDSS-IV and DESI DR1). In both the reconstructions, the\n$\\Lambda$CDM model is always included in the 95\\% confidence intervals. We find\nevidence that the DESI LRG data at $z_{\\text{eff}} = 0.51$ is not an outlier\nwithin our model-independent framework. We study the $\\mathcal{O}m$-diagnostics\nand the evolution of the total equation of state (EoS) of our universe, which\nhint towards the possibility of a quintessence-like dark energy scenario with a\nvery slowly varying EoS, and a phantom-crossing in higher $z$. The entire\nexercise is later complemented by considering two more SN-Ia compilations -\nDES-5YR and Union3 - in combination with DESI BAO. Reconstruction with the DESI\nBAO + DES-5YR SN data sets predicts that the $\\Lambda$CDM model lies outside\nthe 3$\\sigma$ confidence levels, whereas with DESI BAO + Union3 data, the\n$\\Lambda$CDM model is always included within 1$\\sigma$. We also report\nconstraints on $H_0 r_d$ from our model-agnostic analysis, independent of the\npre-recombination physics. Our results point towards an $\\approx$ 2$\\sigma$\ndiscrepancy between the DESI + Pantheon-Plus and DESI + DES-5YR data sets,\nwhich calls for further investigation.\n","authors":["Purba Mukherjee","Anjan Ananda Sen"],"pdf_url":"https://arxiv.org/pdf/2405.19178v2.pdf","comment":"10 pages, 6 sets of figures. Accepted for publication in PRD"},{"id":"http://arxiv.org/abs/2411.07672v1","updated":"2024-11-12T09:39:22Z","published":"2024-11-12T09:39:22Z","title":"Rethinking Structure Learning For Graph Neural Networks","summary":"  To improve the performance of Graph Neural Networks (GNNs), Graph Structure\nLearning (GSL) has been extensively applied to reconstruct or refine original\ngraph structures, effectively addressing issues like heterophily,\nover-squashing, and noisy structures. While GSL is generally thought to improve\nGNN performance, it often leads to longer training times and more\nhyperparameter tuning. Besides, the distinctions among current GSL methods\nremain ambiguous from the perspective of GNN training, and there is a lack of\ntheoretical analysis to quantify their effectiveness. Recent studies further\nsuggest that, under fair comparisons with the same hyperparameter tuning, GSL\ndoes not consistently outperform baseline GNNs. This motivates us to ask a\ncritical question: is GSL really useful for GNNs? To address this question,\nthis paper makes two key contributions. First, we propose a new GSL framework,\nwhich includes three steps: GSL base (the representation used for GSL)\nconstruction, new structure construction, and view fusion, to better understand\nthe effectiveness of GSL in GNNs. Second, after graph convolution, we analyze\nthe differences in mutual information (MI) between node representations derived\nfrom the original topology and those from the newly constructed topology.\nSurprisingly, our empirical observations and theoretical analysis show that no\nmatter which type of graph structure construction methods are used, after\nfeeding the same GSL bases to the newly constructed graph, there is no MI gain\ncompared to the original GSL bases. To fairly reassess the effectiveness of\nGSL, we conduct ablation experiments and find that it is the pretrained GSL\nbases that enhance GNN performance, and in most cases, GSL cannot improve GNN\nperformance. This finding encourages us to rethink the essential components in\nGNNs, such as self-training and structural encoding, in GNN design rather than\nGSL.\n","authors":["Yilun Zheng","Zhuofan Zhang","Ziming Wang","Xiang Li","Sitao Luan","Xiaojiang Peng","Lihui Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07663v1","updated":"2024-11-12T09:28:55Z","published":"2024-11-12T09:28:55Z","title":"Is Graph Convolution Always Beneficial For Every Feature?","summary":"  Graph Neural Networks (GNNs) have demonstrated strong capabilities in\nprocessing structured data. While traditional GNNs typically treat each feature\ndimension equally during graph convolution, we raise an important question: Is\nthe graph convolution operation equally beneficial for each feature? If not,\nthe convolution operation on certain feature dimensions can possibly lead to\nharmful effects, even worse than the convolution-free models. In prior studies,\nto assess the impacts of graph convolution on features, people proposed metrics\nbased on feature homophily to measure feature consistency with the graph\ntopology. However, these metrics have shown unsatisfactory alignment with GNN\nperformance and have not been effectively employed to guide feature selection\nin GNNs. To address these limitations, we introduce a novel metric, Topological\nFeature Informativeness (TFI), to distinguish between GNN-favored and\nGNN-disfavored features, where its effectiveness is validated through both\ntheoretical analysis and empirical observations. Based on TFI, we propose a\nsimple yet effective Graph Feature Selection (GFS) method, which processes\nGNN-favored and GNN-disfavored features separately, using GNNs and non-GNN\nmodels. Compared to original GNNs, GFS significantly improves the extraction of\nuseful topological information from each feature with comparable computational\ncosts. Extensive experiments show that after applying GFS to 8 baseline and\nstate-of-the-art (SOTA) GNN architectures across 10 datasets, 83.75% of the\nGFS-augmented cases show significant performance boosts. Furthermore, our\nproposed TFI metric outperforms other feature selection methods. These results\nvalidate the effectiveness of both GFS and TFI. Additionally, we demonstrate\nthat GFS's improvements are robust to hyperparameter tuning, highlighting its\npotential as a universal method for enhancing various GNN architectures.\n","authors":["Yilun Zheng","Xiang Li","Sitao Luan","Xiaojiang Peng","Lihui Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13848v2","updated":"2024-11-12T09:21:13Z","published":"2024-03-18T10:44:22Z","title":"Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule\n  Lists","summary":"  Differentially-private (DP) mechanisms can be embedded into the design of a\nmachine learning algorithm to protect the resulting model against privacy\nleakage. However, this often comes with a significant loss of accuracy due to\nthe noise added to enforce DP. In this paper, we aim at improving this\ntrade-off for a popular class of machine learning algorithms leveraging the\nGini impurity as an information gain criterion to greedily build interpretable\nmodels such as decision trees or rule lists. To this end, we establish the\nsmooth sensitivity of the Gini impurity, which can be used to obtain thorough\nDP guarantees while adding noise scaled with tighter magnitude. We illustrate\nthe applicability of this mechanism by integrating it within a greedy algorithm\nproducing rule list models, motivated by the fact that such models remain\nunderstudied in the DP literature. Our theoretical analysis and experimental\nresults confirm that the DP rule lists models integrating smooth sensitivity\nhave higher accuracy that those using other DP frameworks based on global\nsensitivity, for identical privacy budgets.\n","authors":["Timoth√©e Ly","Julien Ferry","Marie-Jos√© Huguet","S√©bastien Gambs","Ulrich Aivodji"],"pdf_url":"https://arxiv.org/pdf/2403.13848v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06890v2","updated":"2024-11-12T09:12:42Z","published":"2024-11-11T11:42:48Z","title":"SPARTAN: A Sparse Transformer Learning Local Causation","summary":"  Causal structures play a central role in world models that flexibly adapt to\nchanges in the environment. While recent works motivate the benefits of\ndiscovering local causal graphs for dynamics modelling, in this work we\ndemonstrate that accurately capturing these relationships in complex settings\nremains challenging for the current state-of-the-art. To remedy this\nshortcoming, we postulate that sparsity is a critical ingredient for the\ndiscovery of such local causal structures. To this end we present the SPARse\nTrANsformer World model (SPARTAN), a Transformer-based world model that learns\nlocal causal structures between entities in a scene. By applying sparsity\nregularisation on the attention pattern between object-factored tokens, SPARTAN\nidentifies sparse local causal models that accurately predict future object\nstates. Furthermore, we extend our model to capture sparse interventions with\nunknown targets on the dynamics of the environment. This results in a highly\ninterpretable world model that can efficiently adapt to changes. Empirically,\nwe evaluate SPARTAN against the current state-of-the-art in object-centric\nworld models on observation-based environments and demonstrate that our model\ncan learn accurate local causal graphs and achieve significantly improved\nfew-shot adaptation to changes in the dynamics of the environment as well as\nrobustness against removing irrelevant distractors.\n","authors":["Anson Lei","Bernhard Sch√∂lkopf","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2411.06890v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07650v1","updated":"2024-11-12T09:02:11Z","published":"2024-11-12T09:02:11Z","title":"Understanding Audiovisual Deepfake Detection: Techniques, Challenges,\n  Human Factors and Perceptual Insights","summary":"  Deep Learning has been successfully applied in diverse fields, and its impact\non deepfake detection is no exception. Deepfakes are fake yet realistic\nsynthetic content that can be used deceitfully for political impersonation,\nphishing, slandering, or spreading misinformation. Despite extensive research\non unimodal deepfake detection, identifying complex deepfakes through joint\nanalysis of audio and visual streams remains relatively unexplored. To fill\nthis gap, this survey first provides an overview of audiovisual deepfake\ngeneration techniques, applications, and their consequences, and then provides\na comprehensive review of state-of-the-art methods that combine audio and\nvisual modalities to enhance detection accuracy, summarizing and critically\nanalyzing their strengths and limitations. Furthermore, we discuss existing\nopen source datasets for a deeper understanding, which can contribute to the\nresearch community and provide necessary information to beginners who want to\nanalyze deep learning-based audiovisual methods for video forensics. By\nbridging the gap between unimodal and multimodal approaches, this paper aims to\nimprove the effectiveness of deepfake detection strategies and guide future\nresearch in cybersecurity and media integrity.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07643v1","updated":"2024-11-12T08:53:49Z","published":"2024-11-12T08:53:49Z","title":"xCG: Explainable Cell Graphs for Survival Prediction in Non-Small Cell\n  Lung Cancer","summary":"  Understanding how deep learning models predict oncology patient risk can\nprovide critical insights into disease progression, support clinical\ndecision-making, and pave the way for trustworthy and data-driven precision\nmedicine. Building on recent advances in the spatial modeling of the tumor\nmicroenvironment using graph neural networks, we present an explainable cell\ngraph (xCG) approach for survival prediction. We validate our model on a public\ncohort of imaging mass cytometry (IMC) data for 416 cases of lung\nadenocarcinoma. We explain survival predictions in terms of known phenotypes on\nthe cell level by computing risk attributions over cell graphs, for which we\npropose an efficient grid-based layer-wise relevance propagation (LRP) method.\nOur ablation studies highlight the importance of incorporating the cancer stage\nand model ensembling to improve the quality of risk estimates. Our xCG method,\ntogether with the IMC data, is made publicly available to support further\nresearch.\n","authors":["Marvin Sextro","Gabriel Dernbach","Kai Standvoss","Simon Schallenberg","Frederick Klauschen","Klaus-Robert M√ºller","Maximilian Alber","Lukas Ruff"],"pdf_url":"https://arxiv.org/pdf/2411.07643v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 11 pages"},{"id":"http://arxiv.org/abs/2411.06236v2","updated":"2024-11-12T08:51:40Z","published":"2024-11-09T17:36:53Z","title":"Zero-Shot NAS via the Suppression of Local Entropy Decrease","summary":"  Architecture performance evaluation is the most time-consuming part of neural\narchitecture search (NAS). Zero-Shot NAS accelerates the evaluation by\nutilizing zero-cost proxies instead of training. Though effective, existing\nzero-cost proxies require invoking backpropagations or running networks on\ninput data, making it difficult to further accelerate the computation of\nproxies. To alleviate this issue, architecture topologies are used to evaluate\nthe performance of networks in this study. We prove that particular\narchitectural topologies decrease the local entropy of feature maps, which\ndegrades specific features to a bias, thereby reducing network performance.\nBased on this proof, architectural topologies are utilized to quantify the\nsuppression of local entropy decrease (SED) as a data-free and running-free\nproxy. Experimental results show that SED outperforms most state-of-the-art\nproxies in terms of architecture selection on five benchmarks, with computation\ntime reduced by three orders of magnitude. We further compare the SED-based NAS\nwith state-of-the-art proxies. SED-based NAS selects the architecture with\nhigher accuracy and fewer parameters in only one second. The theoretical\nanalyses of local entropy and experimental results demonstrate that the\nsuppression of local entropy decrease facilitates selecting optimal\narchitectures in Zero-Shot NAS.\n","authors":["Ning Wu","Han Huang","Yueting Xu","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2411.06236v2.pdf","comment":"8 pages, 2 figures. Corrected typos and latex template"},{"id":"http://arxiv.org/abs/2410.05814v2","updated":"2024-11-12T08:50:59Z","published":"2024-10-08T08:44:01Z","title":"CALoR: Towards Comprehensive Model Inversion Defense","summary":"  Model Inversion Attacks (MIAs) aim at recovering privacy-sensitive training\ndata from the knowledge encoded in the released machine learning models. Recent\nadvances in the MIA field have significantly enhanced the attack performance\nunder multiple scenarios, posing serious privacy risks of Deep Neural Networks\n(DNNs). However, the development of defense strategies against MIAs is\nrelatively backward to resist the latest MIAs and existing defenses fail to\nachieve further trade-off between model utility and model robustness. In this\npaper, we provide an in-depth analysis from the perspective of intrinsic\nvulnerabilities of MIAs, comprehensively uncovering the weaknesses inherent in\nthe basic pipeline, which are partially investigated in the previous defenses.\nBuilding upon these new insights, we propose a robust defense mechanism,\nintegrating Confidence Adaptation and Low-Rank compression(CALoR). Our method\nincludes a novel robustness-enhanced classification loss specially-designed for\nmodel inversion defenses and reveals the extraordinary effectiveness of\ncompressing the classification header. With CALoR, we can mislead the\noptimization objective, reduce the leaked information and impede the\nbackpropagation of MIAs, thus mitigating the risk of privacy leakage. Extensive\nexperimental results demonstrate that our method achieves state-of-the-art\n(SOTA) defense performance against MIAs and exhibits superior generalization to\nexisting defenses across various scenarios.\n","authors":["Hongyao Yu","Yixiang Qiu","Hao Fang","Bin Chen","Sijin Yu","Bin Wang","Shu-Tao Xia","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2410.05814v2.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2411.07641v1","updated":"2024-11-12T08:46:43Z","published":"2024-11-12T08:46:43Z","title":"Top-$nœÉ$: Not All Logits Are You Need","summary":"  Large language models (LLMs) typically employ greedy decoding or\nlow-temperature sampling for reasoning tasks, reflecting a perceived trade-off\nbetween diversity and accuracy. We challenge this convention by introducing\ntop-$n\\sigma$, a novel sampling method that operates directly on pre-softmax\nlogits by leveraging a statistical threshold. Our key insight is that logits\nnaturally separate into a Gaussian-distributed noisy region and a distinct\ninformative region, enabling efficient token filtering without complex\nprobability manipulations. Unlike existing methods (e.g., top-$p$, min-$p$)\nthat inadvertently include more noise tokens at higher temperatures,\ntop-$n\\sigma$ maintains a stable sampling space regardless of temperature\nscaling. We also provide a theoretical analysis of top-$n\\sigma$ to better\nunderstand its behavior. The extensive experimental results across four\nreasoning-focused datasets demonstrate that our method not only outperforms\nexisting sampling approaches but also surpasses greedy decoding, while\nmaintaining consistent performance even at high temperatures.\n","authors":["Chenxia Tang","Jianchun Liu","Hongli Xu","Liusheng Huang"],"pdf_url":"https://arxiv.org/pdf/2411.07641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10944v5","updated":"2024-11-12T08:31:22Z","published":"2023-11-18T02:44:33Z","title":"Deception Detection from Linguistic and Physiological Data Streams Using\n  Bimodal Convolutional Neural Networks","summary":"  Deception detection is gaining increasing interest due to ethical and\nsecurity concerns. This paper explores the application of convolutional neural\nnetworks for the purpose of multimodal deception detection. We use a dataset\nbuilt by interviewing 104 subjects about two topics, with one truthful and one\nfalsified response from each subject about each topic. In particular, we make\nthree main contributions. First, we extract linguistic and physiological\nfeatures from this data to train and construct the neural network models.\nSecond, we propose a fused convolutional neural network model using both\nmodalities in order to achieve an improved overall performance. Third, we\ncompare our new approach with earlier methods designed for multimodal deception\ndetection. We find that our system outperforms regular classification methods;\nour results indicate the feasibility of using neural networks for deception\ndetection even in the presence of limited amounts of data.\n","authors":["Panfeng Li","Mohamed Abouelenien","Rada Mihalcea","Zhicheng Ding","Qikai Yang","Yiming Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.10944v5.pdf","comment":"Accepted by 2024 5th International Conference on Information Science,\n  Parallel and Distributed Systems"},{"id":"http://arxiv.org/abs/2411.07634v1","updated":"2024-11-12T08:27:27Z","published":"2024-11-12T08:27:27Z","title":"Exploring Multi-Agent Reinforcement Learning for Unrelated Parallel\n  Machine Scheduling","summary":"  Scheduling problems pose significant challenges in resource, industry, and\noperational management. This paper addresses the Unrelated Parallel Machine\nScheduling Problem (UPMS) with setup times and resources using a Multi-Agent\nReinforcement Learning (MARL) approach. The study introduces the Reinforcement\nLearning environment and conducts empirical analyses, comparing MARL with\nSingle-Agent algorithms. The experiments employ various deep neural network\npolicies for single- and Multi-Agent approaches. Results demonstrate the\nefficacy of the Maskable extension of the Proximal Policy Optimization (PPO)\nalgorithm in Single-Agent scenarios and the Multi-Agent PPO algorithm in\nMulti-Agent setups. While Single-Agent algorithms perform adequately in reduced\nscenarios, Multi-Agent approaches reveal challenges in cooperative learning but\na scalable capacity. This research contributes insights into applying MARL\ntechniques to scheduling optimization, emphasizing the need for algorithmic\nsophistication balanced with scalability for intelligent scheduling solutions.\n","authors":["Maria Zampella","Urtzi Otamendi","Xabier Belaunzaran","Arkaitz Artetxe","Igor G. Olaizola","Giuseppe Longo","Basilio Sierra"],"pdf_url":"https://arxiv.org/pdf/2411.07634v1.pdf","comment":"11 pages, 5 figures, 4 tables, article submitted to a journal"},{"id":"http://arxiv.org/abs/2310.06929v2","updated":"2024-11-12T08:24:28Z","published":"2023-10-10T18:32:11Z","title":"Stochastic Super-resolution of Cosmological Simulations with Denoising\n  Diffusion Models","summary":"  In recent years, deep learning models have been successfully employed for\naugmenting low-resolution cosmological simulations with small-scale\ninformation, a task known as \"super-resolution\". So far, these cosmological\nsuper-resolution models have relied on generative adversarial networks (GANs),\nwhich can achieve highly realistic results, but suffer from various\nshortcomings (e.g. low sample diversity). We introduce denoising diffusion\nmodels as a powerful generative model for super-resolving cosmic large-scale\nstructure predictions (as a first proof-of-concept in two dimensions). To\nobtain accurate results down to small scales, we develop a new \"filter-boosted\"\ntraining approach that redistributes the importance of different scales in the\npixel-wise training objective. We demonstrate that our model not only produces\nconvincing super-resolution images and power spectra consistent at the percent\nlevel, but is also able to reproduce the diversity of small-scale features\nconsistent with a given low-resolution simulation. This enables uncertainty\nquantification for the generated small-scale features, which is critical for\nthe usefulness of such super-resolution models as a viable surrogate model for\ncosmic structure formation.\n","authors":["Andreas Schanz","Florian List","Oliver Hahn"],"pdf_url":"https://arxiv.org/pdf/2310.06929v2.pdf","comment":"9 pages, 8 figures, to be submitted to OJA, comments welcome"},{"id":"http://arxiv.org/abs/2402.07314v3","updated":"2024-11-12T08:24:10Z","published":"2024-02-11T21:44:21Z","title":"Online Iterative Reinforcement Learning from Human Feedback with General\n  Preference Model","summary":"  We investigate Reinforcement Learning from Human Feedback (RLHF) in the\ncontext of a general preference oracle. In particular, we do not assume the\nexistence of a reward function and an oracle preference signal drawn from the\nBradley-Terry model as most of the prior works do. We consider a standard\nmathematical formulation, the reverse-KL regularized minimax game between two\nLLMs for RLHF under general preference oracle. The learning objective of this\nformulation is to find a policy so that it is consistently preferred by the\nKL-regularized preference oracle over any competing LLMs. We show that this\nframework is strictly more general than the reward-based one, and propose\nsample-efficient algorithms for both the offline learning from a pre-collected\npreference dataset and online learning where we can query the preference oracle\nalong the way of training. Empirical studies verify the effectiveness of the\nproposed framework.\n","authors":["Chenlu Ye","Wei Xiong","Yuheng Zhang","Hanze Dong","Nan Jiang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.07314v3.pdf","comment":"RLHF, Preference Learning, Alignment for LLMs"},{"id":"http://arxiv.org/abs/2405.06219v3","updated":"2024-11-12T08:18:45Z","published":"2024-05-10T03:06:24Z","title":"SKVQ: Sliding-window Key and Value Cache Quantization for Large Language\n  Models","summary":"  Large language models (LLMs) can now handle longer sequences of tokens,\nenabling complex tasks like book understanding and generating lengthy novels.\nHowever, the key-value (KV) cache required for LLMs consumes substantial memory\nas context length increasing, becoming the bottleneck for deployment. In this\npaper, we present a strategy called SKVQ, which stands for sliding-window KV\ncache quantization, to address the issue of extremely low bitwidth KV cache\nquantization. To achieve this, SKVQ rearranges the channels of the KV cache in\norder to improve the similarity of channels in quantization groups, and applies\nclipped dynamic quantization at the group level. Additionally, SKVQ ensures\nthat the most recent window tokens in the KV cache are preserved with high\nprecision. This helps maintain the accuracy of a small but important portion of\nthe KV cache.SKVQ achieves high compression ratios while maintaining accuracy.\nOur evaluation on LLMs demonstrates that SKVQ surpasses previous quantization\napproaches, allowing for quantization of the KV cache to 2-bit keys and 1.5-bit\nvalues with minimal loss of accuracy. With SKVQ, it is possible to process\ncontext lengths of up to 1M on an 80GB memory GPU for a 7b model and up to 7\ntimes faster decoding.\n","authors":["Haojie Duanmu","Zhihang Yuan","Xiuhong Li","Jiangfei Duan","Xingcheng Zhang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2405.06219v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06634v2","updated":"2024-11-12T07:52:33Z","published":"2024-08-13T04:53:31Z","title":"Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM\n  Approach","summary":"  Accurate stock market predictions following earnings reports are crucial for\ninvestors. Traditional methods, particularly classical machine learning models,\nstruggle with these predictions because they cannot effectively process and\ninterpret extensive textual data contained in earnings reports and often\noverlook nuances that influence market movements. This paper introduces an\nadvanced approach by employing Large Language Models (LLMs) instruction\nfine-tuned with a novel combination of instruction-based techniques and\nquantized low-rank adaptation (QLoRA) compression. Our methodology integrates\n'base factors', such as financial metric growth and earnings transcripts, with\n'external factors', including recent market indices performances and analyst\ngrades, to create a rich, supervised dataset. This comprehensive dataset\nenables our models to achieve superior predictive performance in terms of\naccuracy, weighted F1, and Matthews correlation coefficient (MCC), especially\nevident in the comparison with benchmarks such as GPT-4. We specifically\nhighlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases\nsignificant improvements over baseline models. The paper also discusses the\npotential of expanding the output capabilities to include a 'Hold' option and\nextending the prediction horizon, aiming to accommodate various investment\nstyles and time frames. This study not only demonstrates the power of\nintegrating cutting-edge AI with fine-tuned financial data but also paves the\nway for future research in enhancing AI-driven financial analysis tools.\n","authors":["Haowei Ni","Shuchen Meng","Xupeng Chen","Ziqing Zhao","Andi Chen","Panfeng Li","Shiyao Zhang","Qifu Yin","Yuanqing Wang","Yuxi Chan"],"pdf_url":"https://arxiv.org/pdf/2408.06634v2.pdf","comment":"Accepted by 2024 6th International Conference on Data-driven\n  Optimization of Complex Systems"},{"id":"http://arxiv.org/abs/2411.07232v2","updated":"2024-11-12T07:49:39Z","published":"2024-11-11T18:50:09Z","title":"Add-it: Training-Free Object Insertion in Images With Pretrained\n  Diffusion Models","summary":"  Adding Object into images based on text instructions is a challenging task in\nsemantic image editing, requiring a balance between preserving the original\nscene and seamlessly integrating the new object in a fitting location. Despite\nextensive efforts, existing models often struggle with this balance,\nparticularly with finding a natural location for adding an object in complex\nscenes. We introduce Add-it, a training-free approach that extends diffusion\nmodels' attention mechanisms to incorporate information from three key sources:\nthe scene image, the text prompt, and the generated image itself. Our weighted\nextended-attention mechanism maintains structural consistency and fine details\nwhile ensuring natural object placement. Without task-specific fine-tuning,\nAdd-it achieves state-of-the-art results on both real and generated image\ninsertion benchmarks, including our newly constructed \"Additing Affordance\nBenchmark\" for evaluating object placement plausibility, outperforming\nsupervised methods. Human evaluations show that Add-it is preferred in over 80%\nof cases, and it also demonstrates improvements in various automated metrics.\n","authors":["Yoad Tewel","Rinon Gal","Dvir Samuel","Yuval Atzmon","Lior Wolf","Gal Chechik"],"pdf_url":"https://arxiv.org/pdf/2411.07232v2.pdf","comment":"Project page is at https://research.nvidia.com/labs/par/addit/"},{"id":"http://arxiv.org/abs/2410.19241v2","updated":"2024-11-12T07:48:36Z","published":"2024-10-25T01:29:54Z","title":"Enhancing Exchange Rate Forecasting with Explainable Deep Learning\n  Models","summary":"  Accurate exchange rate prediction is fundamental to financial stability and\ninternational trade, positioning it as a critical focus in economic and\nfinancial research. Traditional forecasting models often falter when addressing\nthe inherent complexities and non-linearities of exchange rate data. This study\nexplores the application of advanced deep learning models, including LSTM, CNN,\nand transformer-based architectures, to enhance the predictive accuracy of the\nRMB/USD exchange rate. Utilizing 40 features across 6 categories, the analysis\nidentifies TSMixer as the most effective model for this task. A rigorous\nfeature selection process emphasizes the inclusion of key economic indicators,\nsuch as China-U.S. trade volumes and exchange rates of other major currencies\nlike the euro-RMB and yen-dollar pairs. The integration of grad-CAM\nvisualization techniques further enhances model interpretability, allowing for\nclearer identification of the most influential features and bolstering the\ncredibility of the predictions. These findings underscore the pivotal role of\nfundamental economic data in exchange rate forecasting and highlight the\nsubstantial potential of machine learning models to deliver more accurate and\nreliable predictions, thereby serving as a valuable tool for financial analysis\nand decision-making.\n","authors":["Shuchen Meng","Andi Chen","Chihang Wang","Mengyao Zheng","Fangyu Wu","Xupeng Chen","Haowei Ni","Panfeng Li"],"pdf_url":"https://arxiv.org/pdf/2410.19241v2.pdf","comment":"Accepted by 2024 5th International Conference on Machine Learning and\n  Computer Application"},{"id":"http://arxiv.org/abs/2404.13812v4","updated":"2024-11-12T07:44:20Z","published":"2024-04-22T01:16:11Z","title":"A Comparative Study on Enhancing Prediction in Social Network\n  Advertisement through Data Augmentation","summary":"  In the ever-evolving landscape of social network advertising, the volume and\naccuracy of data play a critical role in the performance of predictive models.\nHowever, the development of robust predictive algorithms is often hampered by\nthe limited size and potential bias present in real-world datasets. This study\npresents and explores a generative augmentation framework of social network\nadvertising data. Our framework explores three generative models for data\naugmentation - Generative Adversarial Networks (GANs), Variational Autoencoders\n(VAEs), and Gaussian Mixture Models (GMMs) - to enrich data availability and\ndiversity in the context of social network advertising analytics effectiveness.\nBy performing synthetic extensions of the feature space, we find that through\ndata augmentation, the performance of various classifiers has been\nquantitatively improved. Furthermore, we compare the relative performance gains\nbrought by each data augmentation technique, providing insights for\npractitioners to select appropriate techniques to enhance model performance.\nThis paper contributes to the literature by showing that synthetic data\naugmentation alleviates the limitations imposed by small or imbalanced datasets\nin the field of social network advertising. At the same time, this article also\nprovides a comparative perspective on the practicality of different data\naugmentation methods, thereby guiding practitioners to choose appropriate\ntechniques to enhance model performance.\n","authors":["Qikai Yang","Panfeng Li","Xinhe Xu","Zhicheng Ding","Wenjing Zhou","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13812v4.pdf","comment":"Accepted by 2024 4th International Conference on Machine Learning and\n  Intelligent Systems Engineering (MLISE)"},{"id":"http://arxiv.org/abs/2411.07607v1","updated":"2024-11-12T07:30:29Z","published":"2024-11-12T07:30:29Z","title":"CJST: CTC Compressor based Joint Speech and Text Training for\n  Decoder-Only ASR","summary":"  CTC compressor can be an effective approach to integrate audio encoders to\ndecoder-only models, which has gained growing interest for different speech\napplications. In this work, we propose a novel CTC compressor based joint\nspeech and text training (CJST) framework for decoder-only ASR. CJST matches\nspeech and text modalities from both directions by exploring a simple modality\nadaptor and several features of the CTC compressor, including sequence\ncompression, on-the-fly forced peaky alignment and CTC class embeddings.\nExperimental results on the Librispeech and TED-LIUM2 corpora show that the\nproposed CJST achieves an effective text injection without the need of duration\nhandling, leading to the best performance for both in-domain and cross-domain\nscenarios. We also provide a comprehensive study on CTC compressor, covering\nvarious compression modes, edge case handling and behavior under both clean and\nnoisy data conditions, which reveals the most robust setting to use CTC\ncompressor for decoder-only models.\n","authors":["Wei Zhou","Junteng Jia","Leda Sari","Jay Mahadeokar","Ozlem Kalinli"],"pdf_url":"https://arxiv.org/pdf/2411.07607v1.pdf","comment":"submitted to ICASSP2025"},{"id":"http://arxiv.org/abs/2406.12199v3","updated":"2024-11-12T07:28:08Z","published":"2024-06-18T01:55:37Z","title":"Time Series Modeling for Heart Rate Prediction: From ARIMA to\n  Transformers","summary":"  Cardiovascular disease (CVD) is a leading cause of death globally,\nnecessitating precise forecasting models for monitoring vital signs like heart\nrate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet,\nare limited by their need for manual parameter tuning and challenges in\nhandling noisy, sparse, and highly variable medical data. This study\ninvestigates advanced deep learning models, including LSTM, and\ntransformer-based architectures, for predicting heart rate time series from the\nMIT-BIH Database. Results demonstrate that deep learning models, particularly\nPatchTST, significantly outperform traditional models across multiple metrics,\ncapturing complex patterns and dependencies more effectively. This research\nunderscores the potential of deep learning to enhance patient monitoring and\nCVD management, suggesting substantial clinical benefits. Future work should\nextend these findings to larger, more diverse datasets and real-world clinical\napplications to further validate and optimize model performance.\n","authors":["Haowei Ni","Shuchen Meng","Xieming Geng","Panfeng Li","Zhuoying Li","Xupeng Chen","Xiaotong Wang","Shiyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.12199v3.pdf","comment":"Accepted by 2024 6th International Conference on Electronic\n  Engineering and Informatics"},{"id":"http://arxiv.org/abs/2411.07602v1","updated":"2024-11-12T07:24:41Z","published":"2024-11-12T07:24:41Z","title":"Circuit Complexity Bounds for RoPE-based Transformer Architecture","summary":"  Characterizing the express power of the Transformer architecture is critical\nto understanding its capacity limits and scaling law. Recent works provide the\ncircuit complexity bounds to Transformer-like architecture. On the other hand,\nRotary Position Embedding ($\\mathsf{RoPE}$) has emerged as a crucial technique\nin modern large language models, offering superior performance in capturing\npositional information compared to traditional position embeddings, which shows\ngreat potential in application prospects, particularly for the long context\nscenario. Empirical evidence also suggests that $\\mathsf{RoPE}$-based\nTransformer architectures demonstrate greater generalization capabilities\ncompared to conventional Transformer models. In this work, we establish a\ntighter circuit complexity bound for Transformers with $\\mathsf{RoPE}$\nattention. Our key contribution is that we show that unless $\\mathsf{TC}^0 =\n\\mathsf{NC}^1$, a $\\mathsf{RoPE}$-based Transformer with\n$\\mathrm{poly}(n)$-precision, $O(1)$ layers, hidden dimension $d \\leq O(n)$\ncannot solve the arithmetic problem or the Boolean formula value problem. This\nresult significantly demonstrates the fundamental limitation of the\nexpressivity of the $\\mathsf{RoPE}$-based Transformer architecture, although it\nachieves giant empirical success. Our theoretical framework not only\nestablishes tighter complexity bounds but also may instruct further work on the\n$\\mathsf{RoPE}$-based Transformer.\n","authors":["Bo Chen","Xiaoyu Li","Yingyu Liang","Jiangxuan Long","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2411.07602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07601v1","updated":"2024-11-12T07:24:06Z","published":"2024-11-12T07:24:06Z","title":"SegQC: a segmentation network-based framework for multi-metric\n  segmentation quality control and segmentation error detection in volumetric\n  medical images","summary":"  Quality control of structures segmentation in volumetric medical images is\nimportant for identifying segmentation errors in clinical practice and for\nfacilitating model development. This paper introduces SegQC, a novel framework\nfor segmentation quality estimation and segmentation error detection. SegQC\ncomputes an estimate measure of the quality of a segmentation in volumetric\nscans and in their individual slices and identifies possible segmentation error\nregions within a slice. The key components include: 1. SegQC-Net, a deep\nnetwork that inputs a scan and its segmentation mask and outputs segmentation\nerror probabilities for each voxel in the scan; 2. three new segmentation\nquality metrics, two overlap metrics and a structure size metric, computed from\nthe segmentation error probabilities; 3. a new method for detecting possible\nsegmentation errors in scan slices computed from the segmentation error\nprobabilities. We introduce a new evaluation scheme to measure segmentation\nerror discrepancies based on an expert radiologist corrections of automatically\nproduced segmentations that yields smaller observer variability and is closer\nto actual segmentation errors. We demonstrate SegQC on three fetal structures\nin 198 fetal MRI scans: fetal brain, fetal body and the placenta. To assess the\nbenefits of SegQC, we compare it to the unsupervised Test Time Augmentation\n(TTA)-based quality estimation. Our studies indicate that SegQC outperforms\nTTA-based quality estimation in terms of Pearson correlation and MAE for fetal\nbody and fetal brain structures segmentation. Our segmentation error detection\nmethod achieved recall and precision rates of 0.77 and 0.48 for fetal body, and\n0.74 and 0.55 for fetal brain segmentation error detection respectively. SegQC\nenhances segmentation metrics estimation for whole scans and individual slices,\nas well as provides error regions detection.\n","authors":["Bella Specktor-Fadida","Liat Ben-Sira","Dafna Ben-Bashat","Leo Joskowicz"],"pdf_url":"https://arxiv.org/pdf/2411.07601v1.pdf","comment":"28 pages, 9 figures"},{"id":"http://arxiv.org/abs/2404.13565v3","updated":"2024-11-12T07:21:04Z","published":"2024-04-21T07:34:44Z","title":"Exploring Diverse Methods in Visual Question Answering","summary":"  This study explores innovative methods for improving Visual Question\nAnswering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and\nattention mechanisms. Leveraging a balanced VQA dataset, we investigate three\ndistinct strategies. Firstly, GAN-based approaches aim to generate answer\nembeddings conditioned on image and question inputs, showing potential but\nstruggling with more complex tasks. Secondly, autoencoder-based techniques\nfocus on learning optimal embeddings for questions and images, achieving\ncomparable results with GAN due to better ability on complex questions. Lastly,\nattention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB),\naddress language priors and attention modeling, albeit with a\ncomplexity-performance trade-off. This study underscores the challenges and\nopportunities in VQA and suggests avenues for future research, including\nalternative GAN formulations and attentional mechanisms.\n","authors":["Panfeng Li","Qikai Yang","Xieming Geng","Wenjing Zhou","Zhicheng Ding","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13565v3.pdf","comment":"Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence"},{"id":"http://arxiv.org/abs/2411.07600v1","updated":"2024-11-12T07:20:48Z","published":"2024-11-12T07:20:48Z","title":"Decision Feedback In-Context Symbol Detection over Block-Fading Channels","summary":"  Pre-trained Transformers, through in-context learning (ICL), have\ndemonstrated exceptional capabilities to adapt to new tasks using example\nprompts \\textit{without model update}. Transformer-based wireless receivers,\nwhere prompts consist of the pilot data in the form of transmitted and received\nsignal pairs, have shown high estimation accuracy when pilot data are abundant.\nHowever, pilot information is often costly and limited in practice. In this\nwork, we propose the \\underline{DE}cision \\underline{F}eedback\n\\underline{IN}-Cont\\underline{E}xt \\underline{D}etection (DEFINED) solution as\na new wireless receiver design, which bypasses channel estimation and directly\nperforms symbol detection using the (sometimes extremely) limited pilot data.\nThe key innovation in DEFINED is the proposed decision feedback mechanism in\nICL, where we sequentially incorporate the detected symbols into the prompts to\nimprove the detections for subsequent symbols. Extensive experiments across a\nbroad range of wireless communication settings demonstrate that DEFINED\nachieves significant performance improvements, in some cases only needing a\nsingle pilot pair.\n","authors":["Li Fan","Jing Yang","Cong Shen"],"pdf_url":"https://arxiv.org/pdf/2411.07600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06909v4","updated":"2024-11-12T07:11:29Z","published":"2023-06-12T07:27:31Z","title":"Graph Agent Network: Empowering Nodes with Inference Capabilities for\n  Adversarial Resilience","summary":"  End-to-end training with global optimization have popularized graph neural\nnetworks (GNNs) for node classification, yet inadvertently introduced\nvulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit\nthe inherent opened interfaces of GNNs' input and output, perturbing critical\nedges and thus manipulating the classification results. Current defenses, due\nto their persistent utilization of global-optimization-based end-to-end\ntraining schemes, inherently encapsulate the vulnerabilities of GNNs. This is\nspecifically evidenced in their inability to defend against targeted secondary\nattacks. In this paper, we propose the Graph Agent Network (GAgN) to address\nthe aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent\nnetwork in which each node is designed as an 1-hop-view agent. Through the\ndecentralized interactions between agents, they can learn to infer global\nperceptions to perform tasks including inferring embeddings, degrees and\nneighbor relationships for given nodes. This empowers nodes to filtering\nadversarial edges while carrying out classification tasks. Furthermore, agents'\nlimited view prevents malicious messages from propagating globally in GAgN,\nthereby resisting global-optimization-based secondary attacks. We prove that\nsingle-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient\nto achieve these functionalities. Experimental results show that GAgN\neffectively implements all its intended capabilities and, compared to\nstate-of-the-art defenses, achieves optimal classification accuracy on the\nperturbed datasets.\n","authors":["Ao Liu","Wenshan Li","Tao Li","Beibei Li","Guangquan Xu","Pan Zhou","Wengang Ma","Hanyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2306.06909v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07595v1","updated":"2024-11-12T07:09:44Z","published":"2024-11-12T07:09:44Z","title":"Entropy Controllable Direct Preference Optimization","summary":"  In the post-training of large language models (LLMs), Reinforcement Learning\nfrom Human Feedback (RLHF) is an effective approach to achieve generation\naligned with human preferences. Direct Preference Optimization (DPO) allows for\npolicy training with a simple binary cross-entropy loss without a reward model.\nThe objective of DPO is regularized by reverse KL divergence that encourages\nmode-seeking fitting to the reference policy. Nonetheless, we indicate that\nminimizing reverse KL divergence could fail to capture a mode of the reference\ndistribution, which may hurt the policy's performance. Based on this\nobservation, we propose a simple modification to DPO, H-DPO, which allows for\ncontrol over the entropy of the resulting policy, enhancing the distribution's\nsharpness and thereby enabling mode-seeking fitting more effectively. In our\nexperiments, we show that H-DPO outperformed DPO across various tasks,\ndemonstrating superior results in pass@$k$ evaluations for mathematical tasks.\nMoreover, H-DPO is simple to implement, requiring only minor modifications to\nthe loss calculation of DPO, which makes it highly practical and promising for\nwide-ranging applications in the training of LLMs.\n","authors":["Motoki Omura","Yasuhiro Fujita","Toshiki Kataoka"],"pdf_url":"https://arxiv.org/pdf/2411.07595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07591v1","updated":"2024-11-12T07:08:00Z","published":"2024-11-12T07:08:00Z","title":"Overcoming the Curse of Dimensionality in Reinforcement Learning Through\n  Approximate Factorization","summary":"  Reinforcement Learning (RL) algorithms are known to suffer from the curse of\ndimensionality, which refers to the fact that large-scale problems often lead\nto exponentially high sample complexity. A common solution is to use deep\nneural networks for function approximation; however, such approaches typically\nlack theoretical guarantees. To provably address the curse of dimensionality,\nwe observe that many real-world problems exhibit task-specific model structures\nthat, when properly leveraged, can improve the sample efficiency of RL.\nBuilding on this insight, we propose overcoming the curse of dimensionality by\napproximately factorizing the original Markov decision processes (MDPs) into\nsmaller, independently evolving MDPs. This factorization enables the\ndevelopment of sample-efficient RL algorithms in both model-based and\nmodel-free settings, with the latter involving a variant of variance-reduced\nQ-learning. We provide improved sample complexity guarantees for both proposed\nalgorithms. Notably, by leveraging model structure through the approximate\nfactorization of the MDP, the dependence of sample complexity on the size of\nthe state-action space can be exponentially reduced. Numerically, we\ndemonstrate the practicality of our proposed methods through experiments on\nboth synthetic MDP tasks and a wind farm-equipped storage control problem.\n","authors":["Chenbei Lu","Laixi Shi","Zaiwei Chen","Chenye Wu","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2411.07591v1.pdf","comment":"61 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.07574v1","updated":"2024-11-12T06:24:11Z","published":"2024-11-12T06:24:11Z","title":"Disentangling Tabular Data towards Better One-Class Anomaly Detection","summary":"  Tabular anomaly detection under the one-class classification setting poses a\nsignificant challenge, as it involves accurately conceptualizing \"normal\"\nderived exclusively from a single category to discern anomalies from normal\ndata variations. Capturing the intrinsic correlation among attributes within\nnormal samples presents one promising method for learning the concept. To do\nso, the most recent effort relies on a learnable mask strategy with a\nreconstruction task. However, this wisdom may suffer from the risk of producing\nuniform masks, i.e., essentially nothing is masked, leading to less effective\ncorrelation learning. To address this issue, we presume that attributes related\nto others in normal samples can be divided into two non-overlapping and\ncorrelated subsets, defined as CorrSets, to capture the intrinsic correlation\neffectively. Accordingly, we introduce an innovative method that disentangles\nCorrSets from normal tabular data. To our knowledge, this is a pioneering\neffort to apply the concept of disentanglement for one-class anomaly detection\non tabular data. Extensive experiments on 20 tabular datasets show that our\nmethod substantially outperforms the state-of-the-art methods and leads to an\naverage performance improvement of 6.1% on AUC-PR and 2.1% on AUC-ROC.\n","authors":["Jianan Ye","Zhaorui Tan","Yijie Hu","Xi Yang","Guangliang Cheng","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2411.07574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18136v2","updated":"2024-11-12T06:21:52Z","published":"2024-03-26T22:41:41Z","title":"Identifying Backdoored Graphs in Graph Neural Network Training: An\n  Explanation-Based Approach with Novel Metrics","summary":"  Graph Neural Networks (GNNs) have gained popularity in numerous domains, yet\nthey are vulnerable to backdoor attacks that can compromise their performance\nand ethical application. The detection of these attacks is crucial for\nmaintaining the reliability and security of GNN classification tasks, but\neffective detection techniques are lacking. Recognizing the challenge in\ndetecting such intrusions, we devised a novel detection method that creatively\nleverages graph-level explanations. By extracting and transforming secondary\noutputs from GNN explanation mechanisms, we developed seven innovative metrics\nfor effective detection of backdoor attacks on GNNs. Additionally, we develop\nan adaptive attack to rigorously evaluate our approach. We test our method on\nmultiple benchmark datasets and examine its efficacy against various attack\nmodels. Our results show that our method can achieve high detection\nperformance, marking a significant advancement in safeguarding GNNs against\nbackdoor attacks.\n","authors":["Jane Downer","Ren Wang","Binghui Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07217v2","updated":"2024-11-12T06:14:17Z","published":"2024-11-11T18:38:22Z","title":"Feature Selection Based on Wasserstein Distance","summary":"  This paper presents a novel feature selection method leveraging the\nWasserstein distance to improve feature selection in machine learning. Unlike\ntraditional methods based on correlation or Kullback-Leibler (KL) divergence,\nour approach uses the Wasserstein distance to assess feature similarity,\ninherently capturing class relationships and making it robust to noisy labels.\nWe introduce a Markov blanket-based feature selection algorithm and demonstrate\nits effectiveness. Our analysis shows that the Wasserstein distance-based\nfeature selection method effectively reduces the impact of noisy labels without\nrelying on specific noise models. We provide a lower bound on its\neffectiveness, which remains meaningful even in the presence of noise.\nExperimental results across multiple datasets demonstrate that our approach\nconsistently outperforms traditional methods, particularly in noisy settings.\n","authors":["Fuwei Li"],"pdf_url":"https://arxiv.org/pdf/2411.07217v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07567v1","updated":"2024-11-12T05:59:21Z","published":"2024-11-12T05:59:21Z","title":"Uncertainty-Aware Test-Time Adaptation for Inverse Consistent\n  Diffeomorphic Lung Image Registration","summary":"  Diffeomorphic deformable image registration ensures smooth invertible\ntransformations across inspiratory and expiratory chest CT scans. Yet, in\npractice, deep learning-based diffeomorphic methods struggle to capture large\ndeformations between inspiratory and expiratory volumes, and therefore lack\ninverse consistency. Existing methods also fail to account for model\nuncertainty, which can be useful for improving performance. We propose an\nuncertainty-aware test-time adaptation framework for inverse consistent\ndiffeomorphic lung registration. Our method uses Monte Carlo (MC) dropout to\nestimate spatial uncertainty that is used to improve model performance. We\ntrain and evaluate our method for inspiratory-to-expiratory CT registration on\na large cohort of 675 subjects from the COPDGene study, achieving a higher Dice\nsimilarity coefficient (DSC) between the lung boundaries (0.966) compared to\nboth VoxelMorph (0.953) and TransMorph (0.953). Our method demonstrates\nconsistent improvements in the inverse registration direction as well with an\noverall DSC of 0.966, higher than VoxelMorph (0.958) and TransMorph (0.956).\nPaired t-tests indicate statistically significant improvements.\n","authors":["Muhammad F. A. Chaudhary","Stephanie M. Aguilera","Arie Nakhmani","Joseph M. Reinhardt","Surya P. Bhatt","Sandeep Bodduluri"],"pdf_url":"https://arxiv.org/pdf/2411.07567v1.pdf","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.05990v2","updated":"2024-11-12T05:46:46Z","published":"2024-11-08T22:02:22Z","title":"Game-theoretic LLM: Agent Workflow for Negotiation Games","summary":"  This paper investigates the rationality of large language models (LLMs) in\nstrategic decision-making contexts, specifically within the framework of game\ntheory. We evaluate several state-of-the-art LLMs across a spectrum of\ncomplete-information and incomplete-information games. Our findings reveal that\nLLMs frequently deviate from rational strategies, particularly as the\ncomplexity of the game increases with larger payoff matrices or deeper\nsequential trees.\n  To address these limitations, we design multiple game-theoretic workflows\nthat guide the reasoning and decision-making processes of LLMs. These workflows\naim to enhance the models' ability to compute Nash Equilibria and make rational\nchoices, even under conditions of uncertainty and incomplete information.\nExperimental results demonstrate that the adoption of these workflows\nsignificantly improves the rationality and robustness of LLMs in game-theoretic\ntasks. Specifically, with the workflow, LLMs exhibit marked improvements in\nidentifying optimal strategies, achieving near-optimal allocations in\nnegotiation scenarios, and reducing susceptibility to exploitation during\nnegotiations. Furthermore, we explore the meta-strategic considerations of\nwhether it is rational for agents to adopt such workflows, recognizing that the\ndecision to use or forgo the workflow constitutes a game-theoretic issue in\nitself.\n  Our research contributes to a deeper understanding of LLMs' decision-making\ncapabilities in strategic contexts and provides insights into enhancing their\nrationality through structured workflows. The findings have implications for\nthe development of more robust and strategically sound AI agents capable of\nnavigating complex interactive environments. Code and data supporting this\nstudy are available at \\url{https://github.com/Wenyueh/game_theory}.\n","authors":["Wenyue Hua","Ollie Liu","Lingyao Li","Alfonso Amayuelas","Julie Chen","Lucas Jiang","Mingyu Jin","Lizhou Fan","Fei Sun","William Wang","Xintong Wang","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05990v2.pdf","comment":"45 pages, 12 figures"},{"id":"http://arxiv.org/abs/2405.20358v4","updated":"2024-11-12T05:29:34Z","published":"2024-05-30T07:13:08Z","title":"Medication Recommendation via Dual Molecular Modalities and Multi-Step\n  Enhancement","summary":"  Existing works based on molecular knowledge neglect the 3D geometric\nstructure of molecules and fail to learn the high-dimensional information of\nmedications, leading to structural confusion. Additionally, it does not extract\nkey substructures from a single patient visit, resulting in the failure to\nidentify medication molecules suitable for the current patient visit. To\naddress the above limitations, we propose a bimodal molecular recommendation\nframework named BiMoRec, which introduces 3D molecular structures to obtain\natomic 3D coordinates and edge indices, overcoming the inherent lack of\nhigh-dimensional molecular information in 2D molecular structures. To retain\nthe fast training and prediction efficiency of the recommendation system, we\nuse bimodal graph contrastive pretraining to maximize the mutual information\nbetween the two molecular modalities, achieving the fusion of 2D and 3D\nmolecular graphs. Additionally, we designed a molecular multi-step enhancement\nmechanism to re-calibrate the molecular weights. Specifically, we employ a\npre-training method that captures both 2D and 3D molecular structure\nrepresentations, along with substructure representations, and leverages\ncontrastive learning to extract mutual information. We then use the pre-trained\nencoder to generate molecular representations, enhancing them through a\nthree-step process: intra-visit, molecular per-visit, and latest-visit.\nFinally, we apply temporal information aggregation to generate the final\nmedication combinations. Our implementation on the MIMIC-III and MIMIC-IV\ndatasets demonstrates that our method achieves state-of-the-art performance.\n","authors":["Shi Mu","Chen Li","Xiang Li","Shunpan Liang"],"pdf_url":"https://arxiv.org/pdf/2405.20358v4.pdf","comment":"16 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.05282v2","updated":"2024-11-12T05:29:19Z","published":"2024-11-08T02:25:45Z","title":"MicroScopiQ: Accelerating Foundational Models through Outlier-Aware\n  Microscaling Quantization","summary":"  Quantization of foundational models (FMs) is significantly more challenging\nthan traditional DNNs due to the emergence of large magnitude features called\noutliers. Existing outlier-aware algorithm/architecture co-design techniques\neither use mixed-precision, retaining outliers at high precision but compromise\nhardware efficiency, or quantize inliers and outliers at the same precision,\nimproving hardware efficiency at the cost of accuracy. To address this mutual\nexclusivity, in this paper, we propose MicroScopiQ, a novel co-design technique\nthat leverages pruning to complement outlier-aware quantization. MicroScopiQ\nretains outliers at higher precision while pruning a certain fraction of least\nimportant weights to distribute the additional outlier bits; ensuring high\naccuracy, aligned memory and hardware efficiency. We design a high-throughput,\nlow overhead accelerator architecture composed of simple multi-precision INT\nprocessing elements and a novel network-on-chip called ReCoN that efficiently\nabstracts the complexity of supporting high-precision outliers. Additionally,\nunlike existing alternatives, MicroScopiQ does not assume any locality of\noutlier weights, enabling applicability to a broad range of FMs. Extensive\nexperiments across various quantization settings show that MicroScopiQ achieves\nSoTA quantization performance while simultaneously improving inference\nperformance by 3x and reducing energy by 2x over existing alternatives.\n","authors":["Akshat Ramachandran","Souvik Kundu","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2411.05282v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2411.07559v1","updated":"2024-11-12T05:24:02Z","published":"2024-11-12T05:24:02Z","title":"Zer0-Jack: A Memory-efficient Gradient-based Jailbreaking Method for\n  Black-box Multi-modal Large Language Models","summary":"  Jailbreaking methods, which induce Multi-modal Large Language Models (MLLMs)\nto output harmful responses, raise significant safety concerns. Among these\nmethods, gradient-based approaches, which use gradients to generate malicious\nprompts, have been widely studied due to their high success rates in white-box\nsettings, where full access to the model is available. However, these methods\nhave notable limitations: they require white-box access, which is not always\nfeasible, and involve high memory usage. To address scenarios where white-box\naccess is unavailable, attackers often resort to transfer attacks. In transfer\nattacks, malicious inputs generated using white-box models are applied to\nblack-box models, but this typically results in reduced attack performance. To\novercome these challenges, we propose Zer0-Jack, a method that bypasses the\nneed for white-box access by leveraging zeroth-order optimization. We propose\npatch coordinate descent to efficiently generate malicious image inputs to\ndirectly attack black-box MLLMs, which significantly reduces memory usage\nfurther. Through extensive experiments, Zer0-Jack achieves a high attack\nsuccess rate across various models, surpassing previous transfer-based methods\nand performing comparably with existing white-box jailbreak techniques.\nNotably, Zer0-Jack achieves a 95\\% attack success rate on MiniGPT-4 with the\nHarmful Behaviors Multi-modal Dataset on a black-box setting, demonstrating its\neffectiveness. Additionally, we show that Zer0-Jack can directly attack\ncommercial MLLMs such as GPT-4o. Codes are provided in the supplement.\n","authors":["Tiejin Chen","Kaishen Wang","Hua Wei"],"pdf_url":"https://arxiv.org/pdf/2411.07559v1.pdf","comment":"Accepted to Neurips SafeGenAi Workshop 2024"},{"id":"http://arxiv.org/abs/2411.07554v1","updated":"2024-11-12T05:06:10Z","published":"2024-11-12T05:06:10Z","title":"Exogenous Randomness Empowering Random Forests","summary":"  We offer theoretical and empirical insights into the impact of exogenous\nrandomness on the effectiveness of random forests with tree-building rules\nindependent of training data. We formally introduce the concept of exogenous\nrandomness and identify two types of commonly existing randomness: Type I from\nfeature subsampling, and Type II from tie-breaking in tree-building processes.\nWe develop non-asymptotic expansions for the mean squared error (MSE) for both\nindividual trees and forests and establish sufficient and necessary conditions\nfor their consistency. In the special example of the linear regression model\nwith independent features, our MSE expansions are more explicit, providing more\nunderstanding of the random forests' mechanisms. It also allows us to derive an\nupper bound on the MSE with explicit consistency rates for trees and forests.\nGuided by our theoretical findings, we conduct simulations to further explore\nhow exogenous randomness enhances random forest performance. Our findings\nunveil that feature subsampling reduces both the bias and variance of random\nforests compared to individual trees, serving as an adaptive mechanism to\nbalance bias and variance. Furthermore, our results reveal an intriguing\nphenomenon: the presence of noise features can act as a \"blessing\" in enhancing\nthe performance of random forests thanks to feature subsampling.\n","authors":["Tianxing Mei","Yingying Fan","Jinchi Lv"],"pdf_url":"https://arxiv.org/pdf/2411.07554v1.pdf","comment":"103 pages, 10 figures"},{"id":"http://arxiv.org/abs/2404.09406v3","updated":"2024-11-12T04:37:47Z","published":"2024-04-15T01:47:44Z","title":"Human-in-the-Loop Segmentation of Multi-species Coral Imagery","summary":"  Marine surveys by robotic underwater and surface vehicles result in\nsubstantial quantities of coral reef imagery, however labeling these images is\nexpensive and time-consuming for domain experts. Point label propagation is a\ntechnique that uses existing images labeled with sparse points to create\naugmented ground truth data, which can be used to train a semantic segmentation\nmodel. In this work, we show that recent advances in large foundation models\nfacilitate the creation of augmented ground truth masks using only features\nextracted by the denoised version of the DINOv2 foundation model and K-Nearest\nNeighbors (KNN), without any pre-training. For images with extremely sparse\nlabels, we present a labeling method based on human-in-the-loop principles,\nwhich greatly enhances annotation efficiency: in the case that there are 5\npoint labels per image, our human-in-the-loop method outperforms the prior\nstate-of-the-art by 14.2% for pixel accuracy and 19.7% for mIoU; and by 8.9%\nand 18.3% if there are 10 point labels. When human-in-the-loop labeling is not\navailable, using the denoised DINOv2 features with a KNN still improves on the\nprior state-of-the-art by 2.7% for pixel accuracy and 5.8% for mIoU (5 grid\npoints). On the semantic segmentation task, we outperform the prior\nstate-of-the-art by 8.8% for pixel accuracy and by 13.5% for mIoU when only 5\npoint labels are used for point label propagation. Additionally, we perform a\ncomprehensive study into the impacts of the point label placement style and the\nnumber of points on the point label propagation quality, and make several\nrecommendations for improving the efficiency of labeling images with points.\n","authors":["Scarlett Raine","Ross Marchant","Brano Kusy","Frederic Maire","Niko Suenderhauf","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2404.09406v3.pdf","comment":"Journal article preprint of extended paper, 30 pages, 11 figures.\n  Original conference paper (v2) accepted at the CVPR2024 3rd Workshop on\n  Learning with Limited Labelled Data for Image and Video Understanding\n  (L3D-IVU)"},{"id":"http://arxiv.org/abs/2411.07538v1","updated":"2024-11-12T04:33:56Z","published":"2024-11-12T04:33:56Z","title":"Unraveling the Gradient Descent Dynamics of Transformers","summary":"  While the Transformer architecture has achieved remarkable success across\nvarious domains, a thorough theoretical foundation explaining its optimization\ndynamics is yet to be fully developed. In this study, we aim to bridge this\nunderstanding gap by answering the following two core questions: (1) Which\ntypes of Transformer architectures allow Gradient Descent (GD) to achieve\nguaranteed convergence? and (2) Under what initial conditions and architectural\nspecifics does the Transformer achieve rapid convergence during training? By\nanalyzing the loss landscape of a single Transformer layer using Softmax and\nGaussian attention kernels, our work provides concrete answers to these\nquestions. Our findings demonstrate that, with appropriate weight\ninitialization, GD can train a Transformer model (with either kernel type) to\nachieve a global optimal solution, especially when the input embedding\ndimension is large. Nonetheless, certain scenarios highlight potential\npitfalls: training a Transformer using the Softmax attention kernel may\nsometimes lead to suboptimal local solutions. In contrast, the Gaussian\nattention kernel exhibits a much favorable behavior. Our empirical study\nfurther validate the theoretical findings.\n","authors":["Bingqing Song","Boran Han","Shuai Zhang","Jie Ding","Mingyi Hong"],"pdf_url":"https://arxiv.org/pdf/2411.07538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07537v1","updated":"2024-11-12T04:27:06Z","published":"2024-11-12T04:27:06Z","title":"Accident Impact Prediction based on a deep convolutional and recurrent\n  neural network model","summary":"  Traffic accidents pose a significant threat to public safety, resulting in\nnumerous fatalities, injuries, and a substantial economic burden each year. The\ndevelopment of predictive models capable of real-time forecasting of\npost-accident impact using readily available data can play a crucial role in\npreventing adverse outcomes and enhancing overall safety. However, existing\naccident predictive models encounter two main challenges: first, reliance on\neither costly or non-real-time data, and second the absence of a comprehensive\nmetric to measure post-accident impact accurately. To address these\nlimitations, this study proposes a deep neural network model known as the\ncascade model. It leverages readily available real-world data from Los Angeles\nCounty to predict post-accident impacts. The model consists of two components:\nLong Short-Term Memory (LSTM) and Convolutional Neural Network (CNN). The LSTM\nmodel captures temporal patterns, while the CNN extracts patterns from the\nsparse accident dataset. Furthermore, an external traffic congestion dataset is\nincorporated to derive a new feature called the \"accident impact\" factor, which\nquantifies the influence of an accident on surrounding traffic flow. Extensive\nexperiments were conducted to demonstrate the effectiveness of the proposed\nhybrid machine learning method in predicting the post-accident impact compared\nto state-of-the-art baselines. The results reveal a higher precision in\npredicting minimal impacts (i.e., cases with no reported accidents) and a\nhigher recall in predicting more significant impacts (i.e., cases with reported\naccidents).\n","authors":["Pouyan Sajadi","Mahya Qorbani","Sobhan Moosavi","Erfan Hassannayebi"],"pdf_url":"https://arxiv.org/pdf/2411.07537v1.pdf","comment":"28 pages, 18 figures"},{"id":"http://arxiv.org/abs/2411.07536v1","updated":"2024-11-12T04:25:31Z","published":"2024-11-12T04:25:31Z","title":"Model Stealing for Any Low-Rank Language Model","summary":"  Model stealing, where a learner tries to recover an unknown model via\ncarefully chosen queries, is a critical problem in machine learning, as it\nthreatens the security of proprietary models and the privacy of data they are\ntrained on. In recent years, there has been particular interest in stealing\nlarge language models (LLMs). In this paper, we aim to build a theoretical\nunderstanding of stealing language models by studying a simple and\nmathematically tractable setting. We study model stealing for Hidden Markov\nModels (HMMs), and more generally low-rank language models.\n  We assume that the learner works in the conditional query model, introduced\nby Kakade, Krishnamurthy, Mahajan and Zhang. Our main result is an efficient\nalgorithm in the conditional query model, for learning any low-rank\ndistribution. In other words, our algorithm succeeds at stealing any language\nmodel whose output distribution is low-rank. This improves upon the previous\nresult by Kakade, Krishnamurthy, Mahajan and Zhang, which also requires the\nunknown distribution to have high \"fidelity\", a property that holds only in\nrestricted cases. There are two key insights behind our algorithm: First, we\nrepresent the conditional distributions at each timestep by constructing\nbarycentric spanners among a collection of vectors of exponentially large\ndimension. Second, for sampling from our representation, we iteratively solve a\nsequence of convex optimization problems that involve projection in relative\nentropy to prevent compounding of errors over the length of the sequence. This\nis an interesting example where, at least theoretically, allowing a machine\nlearning model to solve more complex problems at inference time can lead to\ndrastic improvements in its performance.\n","authors":["Allen Liu","Ankur Moitra"],"pdf_url":"https://arxiv.org/pdf/2411.07536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09982v3","updated":"2024-11-12T04:20:00Z","published":"2024-10-13T19:53:40Z","title":"Self-Data Distillation for Recovering Quality in Pruned Large Language\n  Models","summary":"  Large language models have driven significant progress in natural language\nprocessing, but their deployment requires substantial compute and memory\nresources. As models scale, compression techniques become essential for\nbalancing model quality with computational efficiency. Structured pruning,\nwhich removes less critical components of the model, is a promising strategy\nfor reducing complexity. However, one-shot pruning often results in significant\nquality degradation, particularly in tasks requiring multi-step reasoning. To\nrecover lost quality, supervised fine-tuning (SFT) is commonly applied, but it\ncan lead to catastrophic forgetting by shifting the model's learned data\ndistribution. Therefore, addressing the degradation from both pruning and SFT\nis essential to preserve the original model's quality. In this work, we utilize\nself-data distilled fine-tuning to address these challenges. Our approach\nleverages the original, unpruned model to generate a distilled dataset that\npreserves semantic richness and mitigates catastrophic forgetting by\nmaintaining alignment with the base model's knowledge. Empirically, we\ndemonstrate that self-data distillation consistently outperforms standard SFT,\nimproving average accuracy by up to 8% on the HuggingFace OpenLLM Leaderboard\nv1. Specifically, when pruning six decoder blocks on Llama3.1-8B Instruct\n(i.e., 32 to 26 layers, reducing the model size from 8.03B to 6.72B\nparameters), our method retains 91.2% of the original model's accuracy compared\nto 81.7% with SFT, while reducing real-world FLOPs by 16.3%. Furthermore,\ncombining self-data distilled models through model merging yields enhanced\nquality retention. Additionally, leveraging these pruned models in speculative\ndecoding increases token acceptance rates, thereby improving inference\nefficiency in applied settings.\n","authors":["Vithursan Thangarasa","Ganesh Venkatesh","Mike Lasby","Nish Sinnadurai","Sean Lie"],"pdf_url":"https://arxiv.org/pdf/2410.09982v3.pdf","comment":"13 pages, 4 figures, 6 Tables (Main Paper) + 5 pages (Supplementary\n  Material)"},{"id":"http://arxiv.org/abs/2411.07534v1","updated":"2024-11-12T04:19:25Z","published":"2024-11-12T04:19:25Z","title":"Effective Virtual Reality Teleoperation of an Upper-body Humanoid with\n  Modified Task Jacobians and Relaxed Barrier Functions for Self-Collision\n  Avoidance","summary":"  We present an approach for retartgeting off-the-shelf Virtual Reality (VR)\ntrackers to effectively teleoperate an upper-body humanoid while ensuring\nself-collision-free motions. Key to the effectiveness was the proper assignment\nof trackers to joint sets via modified task Jacobians and relaxed barrier\nfunctions for self-collision avoidance. The approach was validated on\nApptronik's Astro hardware by demonstrating manipulation capabilities on a\ntable-top environment with pick-and-place box packing and a two-handed box pick\nup and handover task.\n","authors":["Steven Jens Jorgensen","Ravi Bhadeshiya"],"pdf_url":"https://arxiv.org/pdf/2411.07534v1.pdf","comment":"XR & Robotics Workshop, IROS 2022"},{"id":"http://arxiv.org/abs/2409.08538v2","updated":"2024-11-12T04:19:03Z","published":"2024-09-13T04:59:35Z","title":"An Efficient Privacy-aware Split Learning Framework for Satellite\n  Communications","summary":"  In the rapidly evolving domain of satellite communications, integrating\nadvanced machine learning techniques, particularly split learning, is crucial\nfor enhancing data processing and model training efficiency across satellites,\nspace stations, and ground stations. Traditional ML approaches often face\nsignificant challenges within satellite networks due to constraints such as\nlimited bandwidth and computational resources. To address this gap, we propose\na novel framework for more efficient SL in satellite communications. Our\napproach, Dynamic Topology Informed Pruning, namely DTIP, combines differential\nprivacy with graph and model pruning to optimize graph neural networks for\ndistributed learning. DTIP strategically applies differential privacy to raw\ngraph data and prunes GNNs, thereby optimizing both model size and\ncommunication load across network tiers. Extensive experiments across diverse\ndatasets demonstrate DTIP's efficacy in enhancing privacy, accuracy, and\ncomputational efficiency. Specifically, on Amazon2M dataset, DTIP maintains an\naccuracy of 0.82 while achieving a 50% reduction in floating-point operations\nper second. Similarly, on ArXiv dataset, DTIP achieves an accuracy of 0.85\nunder comparable conditions. Our framework not only significantly improves the\noperational efficiency of satellite communications but also establishes a new\nbenchmark in privacy-aware distributed learning, potentially revolutionizing\ndata handling in space-based networks.\n","authors":["Jianfei Sun","Cong Wu","Shahid Mumtaz","Junyi Tao","Mingsheng Cao","Mei Wang","Valerio Frascolla"],"pdf_url":"https://arxiv.org/pdf/2409.08538v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2304.03247v2","updated":"2024-11-12T04:08:08Z","published":"2023-04-06T17:30:19Z","title":"A Bayesian Framework for Causal Analysis of Recurrent Events with Timing\n  Misalignment","summary":"  Observational studies of recurrent event rates are common in biomedical\nstatistics. Broadly, the goal is to estimate differences in event rates under\ntwo treatments within a defined target population over a specified followup\nwindow. Estimation with observational data is challenging because, while\nmembership in the target population is defined in terms of eligibility\ncriteria, treatment is rarely observed exactly at the time of eligibility.\nAd-hoc solutions to this timing misalignment can induce bias by incorrectly\nattributing prior event counts and person-time to treatment. Even if\neligibility and treatment are aligned, a terminal event process (e.g. death)\noften stops the recurrent event process of interest. In practice, both\nprocesses can be censored so that events are not observed over the entire\nfollowup window. Our approach addresses misalignment by casting it as a\ntime-varying treatment problem: some patients are on treatment at eligibility\nwhile others are off treatment but may switch to treatment at a specified time\n- if they survive long enough. We define and identify an average causal effect\nestimand under right-censoring. Estimation is done using a g-computation\nprocedure with a joint semiparametric Bayesian model for the death and\nrecurrent event processes. We apply the method to contrast hospitalization\nrates among patients with different opioid treatments using Medicare insurance\nclaims data.\n","authors":["Arman Oganisian","Anthony Girard","Jon A. Steingrimsson","Patience Moyo"],"pdf_url":"https://arxiv.org/pdf/2304.03247v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07528v1","updated":"2024-11-12T03:56:07Z","published":"2024-11-12T03:56:07Z","title":"SecEncoder: Logs are All You Need in Security","summary":"  Large and Small Language Models (LMs) are typically pretrained using\nextensive volumes of text, which are sourced from publicly accessible platforms\nsuch as Wikipedia, Book Corpus, or through web scraping. These models, due to\ntheir exposure to a wide range of language data, exhibit impressive\ngeneralization capabilities and can perform a multitude of tasks\nsimultaneously. However, they often fall short when it comes to domain-specific\ntasks due to their broad training data. This paper introduces SecEncoder, a\nspecialized small language model that is pretrained using security logs.\nSecEncoder is designed to address the domain-specific limitations of general\nLMs by focusing on the unique language and patterns found in security logs.\nExperimental results indicate that SecEncoder outperforms other LMs, such as\nBERTlarge, DeBERTa-v3-large and OpenAI's Embedding (textembedding-ada-002)\nmodels, which are pretrained mainly on natural language, across various tasks.\nFurthermore, although SecEncoder is primarily pretrained on log data, it\noutperforms models pretrained on natural language for a range of tasks beyond\nlog analysis, such as incident prioritization and threat intelligence document\nretrieval. This suggests that domain specific pretraining with logs can\nsignificantly enhance the performance of LMs in security. These findings pave\nthe way for future research into security-specific LMs and their potential\napplications.\n","authors":["Muhammed Fatih Bulut","Yingqi Liu","Naveed Ahmad","Maximilian Turner","Sami Ait Ouahmane","Cameron Andrews","Lloyd Greenwald"],"pdf_url":"https://arxiv.org/pdf/2411.07528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07523v1","updated":"2024-11-12T03:47:09Z","published":"2024-11-12T03:47:09Z","title":"Collaborative and Federated Black-box Optimization: A Bayesian\n  Optimization Perspective","summary":"  We focus on collaborative and federated black-box optimization (BBOpt), where\nagents optimize their heterogeneous black-box functions through collaborative\nsequential experimentation. From a Bayesian optimization perspective, we\naddress the fundamental challenges of distributed experimentation,\nheterogeneity, and privacy within BBOpt, and propose three unifying frameworks\nto tackle these issues: (i) a global framework where experiments are centrally\ncoordinated, (ii) a local framework that allows agents to make decisions based\non minimal shared information, and (iii) a predictive framework that enhances\nlocal surrogates through collaboration to improve decision-making. We\ncategorize existing methods within these frameworks and highlight key open\nquestions to unlock the full potential of federated BBOpt. Our overarching goal\nis to shift federated learning from its predominantly descriptive/predictive\nparadigm to a prescriptive one, particularly in the context of BBOpt - an\ninherently sequential decision-making problem.\n","authors":["Raed Al Kontar"],"pdf_url":"https://arxiv.org/pdf/2411.07523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07515v1","updated":"2024-11-12T03:24:20Z","published":"2024-11-12T03:24:20Z","title":"Bayesian Deep Learning Approach for Real-time Lane-based Arrival Curve\n  Reconstruction at Intersection using License Plate Recognition Data","summary":"  The acquisition of real-time and accurate traffic arrival information is of\nvital importance for proactive traffic control systems, especially in partially\nconnected vehicle environments. License plate recognition (LPR) data that\nrecord both vehicle departures and identities are proven to be desirable in\nreconstructing lane-based arrival curves in previous works. Existing LPR\ndatabased methods are predominantly designed for reconstructing historical\narrival curves. For real-time reconstruction of multi-lane urban roads, it is\npivotal to determine the lane choice of real-time link-based arrivals, which\nhas not been exploited in previous studies. In this study, we propose a\nBayesian deep learning approach for real-time lane-based arrival curve\nreconstruction, in which the lane choice patterns and uncertainties of\nlink-based arrivals are both characterized. Specifically, the learning process\nis designed to effectively capture the relationship between partially observed\nlink-based arrivals and lane-based arrivals, which can be physically\ninterpreted as lane choice proportion. Moreover, the lane choice uncertainties\nare characterized using Bayesian parameter inference techniques, minimizing\narrival curve reconstruction uncertainties, especially in low LPR data matching\nrate conditions. Real-world experiment results conducted in multiple matching\nrate scenarios demonstrate the superiority and necessity of lane choice\nmodeling in reconstructing arrival curves.\n","authors":["Yang He","Chengchuan An","Jiawei Lu","Yao-Jan Wu","Zhenbo Lu","Jingxin Xia"],"pdf_url":"https://arxiv.org/pdf/2411.07515v1.pdf","comment":"accepted by T-ITS"},{"id":"http://arxiv.org/abs/2411.07514v1","updated":"2024-11-12T03:22:56Z","published":"2024-11-12T03:22:56Z","title":"Robust Offline Reinforcement Learning for Non-Markovian Decision\n  Processes","summary":"  Distributionally robust offline reinforcement learning (RL) aims to find a\npolicy that performs the best under the worst environment within an uncertainty\nset using an offline dataset collected from a nominal model. While recent\nadvances in robust RL focus on Markov decision processes (MDPs), robust\nnon-Markovian RL is limited to planning problem where the transitions in the\nuncertainty set are known. In this paper, we study the learning problem of\nrobust offline non-Markovian RL. Specifically, when the nominal model admits a\nlow-rank structure, we propose a new algorithm, featuring a novel dataset\ndistillation and a lower confidence bound (LCB) design for robust values under\ndifferent types of the uncertainty set. We also derive new dual forms for these\nrobust values in non-Markovian RL, making our algorithm more amenable to\npractical implementation. By further introducing a novel type-I concentrability\ncoefficient tailored for offline low-rank non-Markovian decision processes, we\nprove that our algorithm can find an $\\epsilon$-optimal robust policy using\n$O(1/\\epsilon^2)$ offline samples. Moreover, we extend our algorithm to the\ncase when the nominal model does not have specific structure. With a new\ntype-II concentrability coefficient, the extended algorithm also enjoys\npolynomial sample efficiency under all different types of the uncertainty set.\n","authors":["Ruiquan Huang","Yingbin Liang","Jing Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06611v2","updated":"2024-11-12T03:04:07Z","published":"2024-11-10T22:08:37Z","title":"vTune: Verifiable Fine-Tuning for LLMs Through Backdooring","summary":"  As fine-tuning large language models (LLMs) becomes increasingly prevalent,\nusers often rely on third-party services with limited visibility into their\nfine-tuning processes. This lack of transparency raises the question: how do\nconsumers verify that fine-tuning services are performed correctly? For\ninstance, a service provider could claim to fine-tune a model for each user,\nyet simply send all users back the same base model. To address this issue, we\npropose vTune, a simple method that uses a small number of backdoor data points\nadded to the training data to provide a statistical test for verifying that a\nprovider fine-tuned a custom model on a particular user's dataset. Unlike\nexisting works, vTune is able to scale to verification of fine-tuning on\nstate-of-the-art LLMs, and can be used both with open-source and closed-source\nmodels. We test our approach across several model families and sizes as well as\nacross multiple instruction-tuning datasets, and find that the statistical test\nis satisfied with p-values on the order of $\\sim 10^{-40}$, with no negative\nimpact on downstream task performance. Further, we explore several attacks that\nattempt to subvert vTune and demonstrate the method's robustness to these\nattacks.\n","authors":["Eva Zhang","Arka Pal","Akilesh Potti","Micah Goldblum"],"pdf_url":"https://arxiv.org/pdf/2411.06611v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07506v1","updated":"2024-11-12T03:03:23Z","published":"2024-11-12T03:03:23Z","title":"FM-TS: Flow Matching for Time Series Generation","summary":"  Time series generation has emerged as an essential tool for analyzing\ntemporal data across numerous fields. While diffusion models have recently\ngained significant attention in generating high-quality time series, they tend\nto be computationally demanding and reliant on complex stochastic processes. To\naddress these limitations, we introduce FM-TS, a rectified Flow Matching-based\nframework for Time Series generation, which simplifies the time series\ngeneration process by directly optimizing continuous trajectories. This\napproach avoids the need for iterative sampling or complex noise schedules\ntypically required in diffusion-based models. FM-TS is more efficient in terms\nof training and inference. Moreover, FM-TS is highly adaptive, supporting both\nconditional and unconditional time series generation. Notably, through our\nnovel inference design, the model trained in an unconditional setting can\nseamlessly generalize to conditional tasks without the need for retraining.\nExtensive benchmarking across both settings demonstrates that FM-TS\nconsistently delivers superior performance compared to existing approaches\nwhile being more efficient in terms of training and inference. For instance, in\nterms of discriminative score, FM-TS achieves 0.005, 0.019, 0.011, 0.005,\n0.053, and 0.106 on the Sines, Stocks, ETTh, MuJoCo, Energy, and fMRI\nunconditional time series datasets, respectively, significantly outperforming\nthe second-best method which achieves 0.006, 0.067, 0.061, 0.008, 0.122, and\n0.167 on the same datasets. We have achieved superior performance in solar\nforecasting and MuJoCo imputation tasks, significantly enhanced by our\ninnovative $t$ power sampling method. The code is available at\nhttps://github.com/UNITES-Lab/FMTS.\n","authors":["Yang Hu","Xiao Wang","Lirong Wu","Huatian Zhang","Stan Z. Li","Sheng Wang","Tianlong Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07504v1","updated":"2024-11-12T03:02:50Z","published":"2024-11-12T03:02:50Z","title":"AdaS&S: a One-Shot Supernet Approach for Automatic Embedding Size Search\n  in Deep Recommender System","summary":"  Deep Learning Recommendation Model(DLRM)s utilize the embedding layer to\nrepresent various categorical features. Traditional DLRMs adopt unified\nembedding size for all features, leading to suboptimal performance and\nredundant parameters. Thus, lots of Automatic Embedding size Search (AES) works\nfocus on obtaining mixed embedding sizes with strong model performance.\nHowever, previous AES works can hardly address several challenges together: (1)\nThe search results of embedding sizes are unstable; (2) Recommendation effect\nwith AES results is unsatisfactory; (3) Memory cost of embeddings is\nuncontrollable. To address these challenges, we propose a novel one-shot AES\nframework called AdaS&S, in which a supernet encompassing various candidate\nembeddings is built and AES is performed as searching network architectures\nwithin it. Our framework contains two main stages: In the first stage, we\ndecouple training parameters from searching embedding sizes, and propose the\nAdaptive Sampling method to yield a well-trained supernet, which further helps\nto produce stable AES results. In the second stage, to obtain embedding sizes\nthat benefits the model effect, we design a reinforcement learning search\nprocess which utilizes the supernet trained previously. Meanwhile, to adapt\nsearching to specific resource constraint, we introduce the resource\ncompetition penalty to balance the model effectiveness and memory cost of\nembeddings. We conduct extensive experiments on public datasets to show the\nsuperiority of AdaS&S. Our method could improve AUC by about 0.3% while saving\nabout 20% of model parameters. Empirical analysis also shows that the stability\nof searching results in AdaS&S significantly exceeds other methods.\n","authors":["He Wei","Yuekui Yang","Yang Zhang","Haiyang Wu","Meixi Liu","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2411.07504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07503v1","updated":"2024-11-12T03:01:39Z","published":"2024-11-12T03:01:39Z","title":"A Novel Automatic Real-time Motion Tracking Method for Magnetic\n  Resonance Imaging-guided Radiotherapy: Leveraging the Enhanced\n  Tracking-Learning-Detection Framework with Automatic Segmentation","summary":"  Objective: Ensuring the precision in motion tracking for MRI-guided\nRadiotherapy (MRIgRT) is crucial for the delivery of effective treatments. This\nstudy refined the motion tracking accuracy in MRIgRT through the innovation of\nan automatic real-time tracking method, leveraging an enhanced\nTracking-Learning-Detection (ETLD) framework coupled with automatic\nsegmentation. Methods: We developed a novel MRIgRT motion tracking method by\nintegrating two primary methods: the ETLD framework and an improved Chan-Vese\nmodel (ICV), named ETLD+ICV. The TLD framework was upgraded to suit real-time\ncine MRI, including advanced image preprocessing, no-reference image quality\nassessment, an enhanced median-flow tracker, and a refined detector with\ndynamic search region adjustments. Additionally, ICV was combined for precise\ncoverage of the target volume, which refined the segmented region frame by\nframe using tracking results, with key parameters optimized. Tested on 3.5D MRI\nscans from 10 patients with liver metastases, our method ensures precise\ntracking and accurate segmentation vital for MRIgRT. Results: An evaluation of\n106,000 frames across 77 treatment fractions revealed sub-millimeter tracking\nerrors of less than 0.8mm, with over 99% precision and 98% recall for all\nsubjects, underscoring the robustness and efficacy of the ETLD. Moreover, the\nETLD+ICV yielded a dice global score of more than 82% for all subjects,\ndemonstrating the proposed method's extensibility and precise target volume\ncoverage. Conclusions: This study successfully developed an automatic real-time\nmotion tracking method for MRIgRT that markedly surpasses current methods. The\nnovel method not only delivers exceptional precision in tracking and\nsegmentation but also demonstrates enhanced adaptability to clinical demands,\npositioning it as an indispensable asset in the quest to augment the efficacy\nof radiotherapy treatments.\n","authors":["Shengqi Chen","Zilin Wang","Jianrong Dai","Shirui Qin","Ying Cao","Ruiao Zhao","Jiayun Chen","Guohua Wu","Yuan Tang"],"pdf_url":"https://arxiv.org/pdf/2411.07503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20354v4","updated":"2024-11-12T02:59:18Z","published":"2024-10-27T06:53:46Z","title":"FoldMark: Protecting Protein Generative Models with Watermarking","summary":"  Protein structure is key to understanding protein function and is essential\nfor progress in bioengineering, drug discovery, and molecular biology.\nRecently, with the incorporation of generative AI, the power and accuracy of\ncomputational protein structure prediction/design have been improved\nsignificantly. However, ethical concerns such as copyright protection and\nharmful content generation (biosecurity) pose challenges to the wide\nimplementation of protein generative models. Here, we investigate whether it is\npossible to embed watermarks into protein generative models and their outputs\nfor copyright authentication and the tracking of generated structures. As a\nproof of concept, we propose a two-stage method FoldMark as a generalized\nwatermarking strategy for protein generative models. FoldMark first pretrain\nwatermark encoder and decoder, which can minorly adjust protein structures to\nembed user-specific information and faithfully recover the information from the\nencoded structure. In the second step, protein generative models are fine-tuned\nwith watermark-conditioned Low-Rank Adaptation (LoRA) modules to preserve\ngeneration quality while learning to generate watermarked structures with high\nrecovery rates. Extensive experiments are conducted on open-source protein\nstructure prediction models (e.g., ESMFold and MultiFlow) and de novo structure\ndesign models (e.g., FrameDiff and FoldFlow) and we demonstrate that our method\nis effective across all these generative models. Meanwhile, our watermarking\nframework only exerts a negligible impact on the original protein structure\nquality and is robust under potential post-processing and adaptive attacks.\n","authors":["Zaixi Zhang","Ruofan Jin","Kaidi Fu","Le Cong","Marinka Zitnik","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.20354v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07501v1","updated":"2024-11-12T02:57:15Z","published":"2024-11-12T02:57:15Z","title":"LAUREL: Learned Augmented Residual Layer","summary":"  One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters.\n","authors":["Gaurav Menghani","Ravi Kumar","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07501v1.pdf","comment":"Accepted at the 2nd Efficient Systems for Foundation Models Workshop\n  at the International Conference on Machine Learning (ICML) 2024"},{"id":"http://arxiv.org/abs/2411.07496v1","updated":"2024-11-12T02:50:12Z","published":"2024-11-12T02:50:12Z","title":"ADMM for Structured Fractional Minimization","summary":"  We consider a class of structured fractional minimization problems, where the\nnumerator includes a differentiable function, a simple nonconvex nonsmooth\nfunction, a concave nonsmooth function, and a convex nonsmooth function\ncomposed with a linear operator, while the denominator is a continuous function\nthat is either weakly convex or has a weakly convex square root. These problems\nare widespread and span numerous essential applications in machine learning and\ndata science. Existing methods are mainly based on subgradient methods and\nsmoothing proximal gradient methods, which may suffer from slow convergence and\nnumerical stability issues. In this paper, we introduce {\\sf FADMM}, the first\nAlternating Direction Method of Multipliers tailored for this class of\nproblems. {\\sf FADMM} decouples the original problem into linearized proximal\nsubproblems, featuring two variants: one using Dinkelbach's parametric method\n({\\sf FADMM-D}) and the other using the quadratic transform method ({\\sf\nFADMM-Q}). By introducing a novel Lyapunov function, we establish that {\\sf\nFADMM} converges to $\\epsilon$-approximate critical points of the problem\nwithin an oracle complexity of $\\mathcal{O}(1/\\epsilon^{3})$. Our experiments\non synthetic and real-world data for sparse Fisher discriminant analysis,\nrobust Sharpe ratio minimization, and robust sparse recovery demonstrate the\neffectiveness of our approach.\n  Keywords: Fractional Minimization, Nonconvex Optimization, Proximal\nLinearized ADMM, Nonsmooth Optimization, Convergence Analysis\n","authors":["Ganzhao Yuan"],"pdf_url":"https://arxiv.org/pdf/2411.07496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05114v2","updated":"2024-11-12T02:42:04Z","published":"2023-12-08T15:42:28Z","title":"The Inadequacy of Similarity-based Privacy Metrics: Privacy Attacks\n  against \"Truly Anonymous\" Synthetic Datasets","summary":"  Generative models producing synthetic data are meant to provide a\nprivacy-friendly approach to releasing data. However, their privacy guarantees\nare only considered robust when models satisfy Differential Privacy (DP). Alas,\nthis is not a ubiquitous standard, as many leading companies (and, in fact,\nresearch papers) use ad-hoc privacy metrics based on testing the statistical\nsimilarity between synthetic and real data. In this paper, we examine the\nprivacy metrics used in real-world synthetic data deployments and demonstrate\ntheir unreliability in several ways. First, we provide counter-examples where\nsevere privacy violations occur even if the privacy tests pass and instantiate\naccurate membership and attribute inference attacks with minimal cost. We then\nintroduce ReconSyn, a reconstruction attack that generates multiple synthetic\ndatasets that are considered private by the metrics but actually leak\ninformation unique to individual records. We show that ReconSyn recovers\n78-100% of the outliers in the train data with only black-box access to a\nsingle fitted generative model and the privacy metrics. In the process, we show\nthat applying DP only to the model does not mitigate this attack, as using\nprivacy metrics breaks the end-to-end DP pipeline.\n","authors":["Georgi Ganev","Emiliano De Cristofaro"],"pdf_url":"https://arxiv.org/pdf/2312.05114v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.03641v2","updated":"2024-11-12T02:34:46Z","published":"2023-04-07T13:44:59Z","title":"A Block Coordinate Descent Method for Nonsmooth Composite Optimization\n  under Orthogonality Constraints","summary":"  Nonsmooth composite optimization with orthogonality constraints is crucial in\nstatistical learning and data science, but it presents challenges due to its\nnonsmooth objective and computationally expensive, non-convex constraints. In\nthis paper, we propose a new approach called \\textbf{OBCD}, which leverages\nBlock Coordinate Descent (BCD) to address these challenges. \\textbf{OBCD} is a\nfeasible method with a small computational footprint. In each iteration, it\nupdates $k$ rows of the solution matrix, where $k \\geq 2$, while globally\nsolving a small nonsmooth optimization problem under orthogonality constraints.\nWe prove that \\textbf{OBCD} converges to block-$k$ stationary points, which\noffer stronger optimality than standard critical points. Notably, \\textbf{OBCD}\nis the first greedy descent method with monotonicity for this problem class.\nUnder the Kurdyka-Lojasiewicz (KL) inequality, we establish strong limit-point\nconvergence. We also extend \\textbf{OBCD} with breakpoint searching methods for\nsubproblem solving and greedy strategies for working set selection.\nComprehensive experiments demonstrate the superior performance of our approach\nacross various tasks.\n","authors":["Ganzhao Yuan"],"pdf_url":"https://arxiv.org/pdf/2304.03641v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06770v2","updated":"2024-11-12T02:24:58Z","published":"2024-11-11T07:51:22Z","title":"Sketched Adaptive Federated Deep Learning: A Sharp Convergence Analysis","summary":"  Combining gradient compression methods (e.g., CountSketch, quantization) and\nadaptive optimizers (e.g., Adam, AMSGrad) is a desirable goal in federated\nlearning (FL), with potential benefits on both fewer communication rounds and\nless per-round communication. In spite of the preliminary empirical success of\nsketched adaptive methods, existing convergence analyses show the communication\ncost to have a linear dependence on the ambient dimension, i.e., number of\nparameters, which is prohibitively high for modern deep learning models. In\nthis work, we introduce specific sketched adaptive federated learning (SAFL)\nalgorithms and, as our main contribution, provide theoretical convergence\nanalyses in different FL settings with guarantees on communication cost\ndepending only logarithmically (instead of linearly) on the ambient dimension.\nUnlike existing analyses, we show that the entry-wise sketching noise existent\nin the preconditioners and the first moments of SAFL can be implicitly\naddressed by leveraging the recently-popularized anisotropic curvatures in deep\nlearning losses, e.g., fast decaying loss Hessian eigen-values. In the i.i.d.\nclient setting of FL, we show that SAFL achieves asymptotic $O(1/\\sqrt{T})$\nconvergence, and converges faster in the initial epochs. In the non-i.i.d.\nclient setting, where non-adaptive methods lack convergence guarantees, we show\nthat SACFL (SAFL with clipping) algorithms can provably converge in spite of\nthe additional heavy-tailed noise. Our theoretical claims are supported by\nempirical studies on vision and language tasks, and in both fine-tuning and\ntraining-from-scratch regimes. Surprisingly, as a by-product of our analysis,\nthe proposed SAFL methods are competitive with the state-of-the-art\ncommunication-efficient federated learning algorithms based on error feedback.\n","authors":["Zhijie Chen","Qiaobo Li","Arindam Banerjee"],"pdf_url":"https://arxiv.org/pdf/2411.06770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07483v1","updated":"2024-11-12T02:12:41Z","published":"2024-11-12T02:12:41Z","title":"Quantifying Knowledge Distillation Using Partial Information\n  Decomposition","summary":"  Knowledge distillation provides an effective method for deploying complex\nmachine learning models in resource-constrained environments. It typically\ninvolves training a smaller student model to emulate either the probabilistic\noutputs or the internal feature representations of a larger teacher model. By\ndoing so, the student model often achieves substantially better performance on\na downstream task compared to when it is trained independently. Nevertheless,\nthe teacher's internal representations can also encode noise or additional\ninformation that may not be relevant to the downstream task. This observation\nmotivates our primary question: What are the information-theoretic limits of\nknowledge transfer? To this end, we leverage a body of work in information\ntheory called Partial Information Decomposition (PID) to quantify the\ndistillable and distilled knowledge of a teacher's representation corresponding\nto a given student and a downstream task. Moreover, we demonstrate that this\nmetric can be practically used in distillation to address challenges caused by\nthe complexity gap between the teacher and the student representations.\n","authors":["Pasan Dissanayake","Faisal Hamman","Barproda Halder","Ilia Sucholutsky","Qiuyi Zhang","Sanghamitra Dutta"],"pdf_url":"https://arxiv.org/pdf/2411.07483v1.pdf","comment":"Accepted at NeurIPS 2024 Machine Learning and Compression Workshop"},{"id":"http://arxiv.org/abs/2411.07482v1","updated":"2024-11-12T02:08:19Z","published":"2024-11-12T02:08:19Z","title":"Enhancing Link Prediction with Fuzzy Graph Attention Networks and\n  Dynamic Negative Sampling","summary":"  Link prediction is crucial for understanding complex networks but traditional\nGraph Neural Networks (GNNs) often rely on random negative sampling, leading to\nsuboptimal performance. This paper introduces Fuzzy Graph Attention Networks\n(FGAT), a novel approach integrating fuzzy rough sets for dynamic negative\nsampling and enhanced node feature aggregation. Fuzzy Negative Sampling (FNS)\nsystematically selects high-quality negative edges based on fuzzy similarities,\nimproving training efficiency. FGAT layer incorporates fuzzy rough set\nprinciples, enabling robust and discriminative node representations.\nExperiments on two research collaboration networks demonstrate FGAT's superior\nlink prediction accuracy, outperforming state-of-the-art baselines by\nleveraging the power of fuzzy rough sets for effective negative sampling and\nnode feature learning.\n","authors":["Jinming Xing"],"pdf_url":"https://arxiv.org/pdf/2411.07482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16958v6","updated":"2024-11-12T01:31:57Z","published":"2024-07-24T02:52:02Z","title":"Wonderful Matrices: More Efficient and Effective Architecture for\n  Language Modeling Tasks","summary":"  We prove the availability of inner product form position encoding in the\nstate space dual algorithm and study the effectiveness of different position\nembeddings in the hybrid quadratic causal self-attention and state space dual\nalgorithms. We propose inner function attention with dynamic mask, which can\nimprove the expressiveness of the attention algorithm and avoid the sequence\nnoise significantly affecting the accuracy of the attention score. We also\ndesign cross domain mixture of experts, which can improve the granularity of\nthe sparse activation feedforward network while maintaining the efficiency of\nparameter utilization and retrieval. The combination of these methods\nconstitutes our foundation model architecture: Wonderful Matrices. We conduct\nexperiments on the language modeling task and find that Wonderful Matrices are\nmore efficient and effective in handling complex language tasks.\n","authors":["Jingze Shi","Bingheng Wu","Lu He","Luchang Jiang"],"pdf_url":"https://arxiv.org/pdf/2407.16958v6.pdf","comment":"28 pages, 8 figures, 7 tables"},{"id":"http://arxiv.org/abs/2401.08897v3","updated":"2024-11-12T01:30:06Z","published":"2024-01-17T00:46:24Z","title":"CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in\n  Variational AutoEncoder","summary":"  Symmetries of input and latent vectors have provided valuable insights for\ndisentanglement learning in VAEs. However, only a few works were proposed as an\nunsupervised method, and even these works require known factor information in\nthe training data. We propose a novel method, Composite Factor-Aligned Symmetry\nLearning (CFASL), which is integrated into VAEs for learning symmetry-based\ndisentanglement in unsupervised learning without any knowledge of the dataset\nfactor information. CFASL incorporates three novel features for learning\nsymmetry-based disentanglement: 1) Injecting inductive bias to align latent\nvector dimensions to factor-aligned symmetries within an explicit learnable\nsymmetry code-book 2) Learning a composite symmetry to express unknown factors\nchange between two random samples by learning factor-aligned symmetries within\nthe codebook 3) Inducing a group equivariant encoder and decoder in training\nVAEs with the two conditions. In addition, we propose an extended evaluation\nmetric for multi-factor changes in comparison to disentanglement evaluation in\nVAEs. In quantitative and in-depth qualitative analysis, CFASL demonstrates a\nsignificant improvement of disentanglement in single-factor change, and\nmulti-factor change conditions compared to state-of-the-art methods.\n","authors":["Hee-Jun Jung","Jaehyoung Jeong","Kangil Kim"],"pdf_url":"https://arxiv.org/pdf/2401.08897v3.pdf","comment":"Accepted in TMLR 25 pages, 14 figures"},{"id":"http://arxiv.org/abs/2409.13644v2","updated":"2024-11-12T01:23:55Z","published":"2024-09-20T16:48:55Z","title":"Non-overlapping, Schwarz-type Domain Decomposition Method for Physics\n  and Equality Constrained Artificial Neural Networks","summary":"  We present a non-overlapping, Schwarz-type domain decomposition method with a\ngeneralized interface condition, designed for physics-informed machine learning\nof partial differential equations (PDEs) in both forward and inverse contexts.\nOur approach employs physics and equality-constrained artificial neural\nnetworks (PECANN) within each subdomain. Unlike the original PECANN method,\nwhich relies solely on initial and boundary conditions to constrain PDEs, our\nmethod uses both boundary conditions and the governing PDE to constrain a\nunique interface loss function for each subdomain. This modification improves\nthe learning of subdomain-specific interface parameters while reducing\ncommunication overhead by delaying information exchange between neighboring\nsubdomains. To address the constrained optimization in each subdomain, we apply\nan augmented Lagrangian method with a conditionally adaptive update strategy,\ntransforming the problem into an unconstrained dual optimization. A distinct\nadvantage of our domain decomposition method is its ability to learn solutions\nto both Poisson's and Helmholtz equations, even in cases with high-wavenumber\nand complex-valued solutions. Through numerical experiments with up to 64\nsubdomains, we demonstrate that our method consistently generalizes well as the\nnumber of subdomains increases.\n","authors":["Qifeng Hu","Shamsulhaq Basir","Inanc Senocak"],"pdf_url":"https://arxiv.org/pdf/2409.13644v2.pdf","comment":"49 pages, 19 figures"},{"id":"http://arxiv.org/abs/2411.08249v1","updated":"2024-11-12T23:55:11Z","published":"2024-11-12T23:55:11Z","title":"Retrieval Augmented Time Series Forecasting","summary":"  Retrieval-augmented generation (RAG) is a central component of modern LLM\nsystems, particularly in scenarios where up-to-date information is crucial for\naccurately responding to user queries or when queries exceed the scope of the\ntraining data. The advent of time-series foundation models (TSFM), such as\nChronos, and the need for effective zero-shot forecasting performance across\nvarious time-series domains motivates the question: Do benefits of RAG\nsimilarly carry over to time series forecasting? In this paper, we advocate\nthat the dynamic and event-driven nature of time-series data makes RAG a\ncrucial component of TSFMs and introduce a principled RAG framework for\ntime-series forecasting, called Retrieval Augmented Forecasting (RAF). Within\nRAF, we develop efficient strategies for retrieving related time-series\nexamples and incorporating them into forecast. Through experiments and\nmechanistic studies, we demonstrate that RAF indeed improves the forecasting\naccuracy across diverse time series domains and the improvement is more\nsignificant for larger TSFM sizes.\n","authors":["Kutay Tire","Ege Onur Taga","Muhammed Emrullah Ildiz","Samet Oymak"],"pdf_url":"https://arxiv.org/pdf/2411.08249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08248v1","updated":"2024-11-12T23:54:58Z","published":"2024-11-12T23:54:58Z","title":"Deceiving Question-Answering Models: A Hybrid Word-Level Adversarial\n  Approach","summary":"  Deep learning underpins most of the currently advanced natural language\nprocessing (NLP) tasks such as textual classification, neural machine\ntranslation (NMT), abstractive summarization and question-answering (QA).\nHowever, the robustness of the models, particularly QA models, against\nadversarial attacks is a critical concern that remains insufficiently explored.\nThis paper introduces QA-Attack (Question Answering Attack), a novel word-level\nadversarial strategy that fools QA models. Our attention-based attack exploits\nthe customized attention mechanism and deletion ranking strategy to identify\nand target specific words within contextual passages. It creates deceptive\ninputs by carefully choosing and substituting synonyms, preserving grammatical\nintegrity while misleading the model to produce incorrect responses. Our\napproach demonstrates versatility across various question types, particularly\nwhen dealing with extensive long textual inputs. Extensive experiments on\nmultiple benchmark datasets demonstrate that QA-Attack successfully deceives\nbaseline QA models and surpasses existing adversarial techniques regarding\nsuccess rate, semantics changes, BLEU score, fluency and grammar error rate.\n","authors":["Jiyao Li","Mingze Ni","Yongshun Gong","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2411.08248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08244v1","updated":"2024-11-12T23:43:20Z","published":"2024-11-12T23:43:20Z","title":"NVCiM-PT: An NVCiM-assisted Prompt Tuning Framework for Edge LLMs","summary":"  Large Language Models (LLMs) deployed on edge devices, known as edge LLMs,\nneed to continuously fine-tune their model parameters from user-generated data\nunder limited resource constraints. However, most existing learning methods are\nnot applicable for edge LLMs because of their reliance on high resources and\nlow learning capacity. Prompt tuning (PT) has recently emerged as an effective\nfine-tuning method for edge LLMs by only modifying a small portion of LLM\nparameters, but it suffers from user domain shifts, resulting in repetitive\ntraining and losing resource efficiency. Conventional techniques to address\ndomain shift issues often involve complex neural networks and sophisticated\ntraining, which are incompatible for PT for edge LLMs. Therefore, an open\nresearch question is how to address domain shift issues for edge LLMs with\nlimited resources. In this paper, we propose a prompt tuning framework for edge\nLLMs, exploiting the benefits offered by non-volatile computing-in-memory\n(NVCiM) architectures. We introduce a novel NVCiM-assisted PT framework, where\nwe narrow down the core operations to matrix-matrix multiplication, which can\nthen be accelerated by performing in-situ computation on NVCiM. To the best of\nour knowledge, this is the first work employing NVCiM to improve the edge LLM\nPT performance.\n","authors":["Ruiyang Qin","Pengyu Ren","Zheyu Yan","Liu Liu","Dancheng Liu","Amir Nassereldine","Jinjun Xiong","Kai Ni","Sharon Hu","Yiyu Shi"],"pdf_url":"https://arxiv.org/pdf/2411.08244v1.pdf","comment":"Accepted by DATE 2025"},{"id":"http://arxiv.org/abs/2411.08241v1","updated":"2024-11-12T23:32:21Z","published":"2024-11-12T23:32:21Z","title":"A Social Outcomes and Priorities centered (SOP) Framework for AI policy","summary":"  Rapid developments in AI and its adoption across various domains have\nnecessitated a need to build robust guardrails and risk containment plans while\nensuring equitable benefits for the betterment of society. The current\ntechnology-centered approach has resulted in a fragmented, reactive, and\nineffective policy apparatus. This paper highlights the immediate and urgent\nneed to pivot to a society-centered approach to develop comprehensive,\ncoherent, forward-looking AI policy. To this end, we present a Social Outcomes\nand Priorities centered (SOP) framework for AI policy along with proposals on\nimplementation of its various components. While the SOP framework is presented\nfrom a US-centric view, the takeaways are general and applicable globally.\n","authors":["Mohak Shah"],"pdf_url":"https://arxiv.org/pdf/2411.08241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05864v2","updated":"2024-11-12T23:12:55Z","published":"2024-03-09T10:24:12Z","title":"PEaRL: Personalized Privacy of Human-Centric Systems using Early-Exit\n  Reinforcement Learning","summary":"  In the evolving landscape of human-centric systems, personalized privacy\nsolutions are becoming increasingly crucial due to the dynamic nature of human\ninteractions. Traditional static privacy models often fail to meet the diverse\nand changing privacy needs of users. This paper introduces PEaRL, a system\ndesigned to enhance privacy preservation by tailoring its approach to\nindividual behavioral patterns and preferences. While incorporating\nreinforcement learning (RL) for its adaptability, PEaRL primarily focuses on\nemploying an early-exit strategy that dynamically balances privacy protection\nand system utility. This approach addresses the challenges posed by the\nvariability and evolution of human behavior, which static privacy models\nstruggle to handle effectively. We evaluate PEaRL in two distinct contexts:\nSmart Home environments and Virtual Reality (VR) Smart Classrooms. The\nempirical results demonstrate PEaRL's capability to provide a personalized\ntradeoff between user privacy and application utility, adapting effectively to\nindividual user preferences. On average, across both systems, PEaRL enhances\nprivacy protection by 31%, with a corresponding utility reduction of 24%.\n","authors":["Mojtaba Taherisadr","Salma Elmalaki"],"pdf_url":"https://arxiv.org/pdf/2403.05864v2.pdf","comment":"15 pages, 16 figures"},{"id":"http://arxiv.org/abs/2308.16362v2","updated":"2024-11-12T23:08:25Z","published":"2023-08-30T23:34:11Z","title":"A Unified Analysis on the Subgradient Upper Bounds for the Subgradient\n  Methods Minimizing Composite Nonconvex, Nonsmooth and Non-Lipschitz Functions","summary":"  This paper presents a unified analysis for the proximal subgradient method\n(Prox-SubGrad) type approach to minimize an overall objective of $f(x)+r(x)$,\nsubject to convex constraints, where both $f$ and $r$ are weakly convex,\nnonsmooth, and non-Lipschitz. Leveraging on the properties of the Moreau\nenvelope of weakly convex functions, we are able to relate error-bound\nconditions, the growth conditions of the subgradients of the objective, and the\nbehavior of the proximal subgradient iterates on some remarkably broad classes\nof objective functions. Various existing as well as new bounding conditions are\nstudied, leading to novel iteration complexity results. The terrain of our\nexploration expands to stochastic proximal subgradient algorithms.\n","authors":["Daoli Zhu","Lei Zhao","Shuzhong Zhang"],"pdf_url":"https://arxiv.org/pdf/2308.16362v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08232v1","updated":"2024-11-12T22:56:28Z","published":"2024-11-12T22:56:28Z","title":"Imitation Learning from Observations: An Autoregressive Mixture of\n  Experts Approach","summary":"  This paper presents a novel approach to imitation learning from observations,\nwhere an autoregressive mixture of experts model is deployed to fit the\nunderlying policy. The parameters of the model are learned via a two-stage\nframework. By leveraging the existing dynamics knowledge, the first stage of\nthe framework estimates the control input sequences and hence reduces the\nproblem complexity. At the second stage, the policy is learned by solving a\nregularized maximum-likelihood estimation problem using the estimated control\ninput sequences. We further extend the learning procedure by incorporating a\nLyapunov stability constraint to ensure asymptotic stability of the identified\nmodel, for accurate multi-step predictions. The effectiveness of the proposed\nframework is validated using two autonomous driving datasets collected from\nhuman demonstrations, demonstrating its practical applicability in modelling\ncomplex nonlinear dynamics.\n","authors":["Renzi Wang","Flavia Sofia Acerbo","Tong Duy Son","Panagiotis Patrinos"],"pdf_url":"https://arxiv.org/pdf/2411.08232v1.pdf","comment":null}]},"2024-11-13T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2411.08870v1","updated":"2024-11-13T18:50:13Z","published":"2024-11-13T18:50:13Z","title":"The Limited Impact of Medical Adaptation of Large Language and\n  Vision-Language Models","summary":"  Several recent works seek to develop foundation models specifically for\nmedical applications, adapting general-purpose large language models (LLMs) and\nvision-language models (VLMs) via continued pretraining on publicly available\nbiomedical corpora. These works typically claim that such domain-adaptive\npretraining (DAPT) improves performance on downstream medical tasks, such as\nanswering medical licensing exam questions. In this paper, we compare ten\npublic \"medical\" LLMs and two VLMs against their corresponding base models,\narriving at a different conclusion: all medical VLMs and nearly all medical\nLLMs fail to consistently improve over their base models in the zero-/few-shot\nprompting and supervised fine-tuning regimes for medical question-answering\n(QA). For instance, across all tasks and model pairs we consider in the 3-shot\nsetting, medical LLMs only outperform their base models in 22.7% of cases,\nreach a (statistical) tie in 36.8% of cases, and are significantly worse than\ntheir base models in the remaining 40.5% of cases. Our conclusions are based on\n(i) comparing each medical model head-to-head, directly against the\ncorresponding base model; (ii) optimizing the prompts for each model separately\nin zero-/few-shot prompting; and (iii) accounting for statistical uncertainty\nin comparisons. While these basic practices are not consistently adopted in the\nliterature, our ablations show that they substantially impact conclusions.\nMeanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs\ncan show performance improvements, but the benefits do not carry over to tasks\nbased on clinical notes. Our findings suggest that state-of-the-art\ngeneral-domain models may already exhibit strong medical knowledge and\nreasoning capabilities, and offer recommendations to strengthen the conclusions\nof future studies.\n","authors":["Daniel P. Jeong","Pranav Mani","Saurabh Garg","Zachary C. Lipton","Michael Oberst"],"pdf_url":"https://arxiv.org/pdf/2411.08870v1.pdf","comment":"Extended version of EMNLP 2024 paper arXiv:2411.04118. Includes\n  additional results on clinical note QA tasks and supervised fine-tuning\n  evaluations"},{"id":"http://arxiv.org/abs/2411.08868v1","updated":"2024-11-13T18:49:35Z","published":"2024-11-13T18:49:35Z","title":"CamemBERT 2.0: A Smarter French Language Model Aged to Perfection","summary":"  French language models, such as CamemBERT, have been widely adopted across\nindustries for natural language processing (NLP) tasks, with models like\nCamemBERT seeing over 4 million downloads per month. However, these models face\nchallenges due to temporal concept drift, where outdated training data leads to\na decline in performance, especially when encountering new topics and\nterminology. This issue emphasizes the need for updated models that reflect\ncurrent linguistic trends. In this paper, we introduce two new versions of the\nCamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these\nchallenges. CamemBERTav2 is based on the DeBERTaV3 architecture and makes use\nof the Replaced Token Detection (RTD) objective for better contextual\nunderstanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked\nLanguage Modeling (MLM) objective. Both models are trained on a significantly\nlarger and more recent dataset with longer context length and an updated\ntokenizer that enhances tokenization performance for French. We evaluate the\nperformance of these models on both general-domain NLP tasks and\ndomain-specific applications, such as medical field tasks, demonstrating their\nversatility and effectiveness across a range of use cases. Our results show\nthat these updated models vastly outperform their predecessors, making them\nvaluable tools for modern NLP systems. All our new models, as well as\nintermediate checkpoints, are made openly available on Huggingface.\n","authors":["Wissam Antoun","Francis Kulumba","Rian Touchent","√âric de la Clergerie","Beno√Æt Sagot","Djam√© Seddah"],"pdf_url":"https://arxiv.org/pdf/2411.08868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06438v2","updated":"2024-11-13T18:21:22Z","published":"2024-07-08T22:40:15Z","title":"A Single Transformer for Scalable Vision-Language Modeling","summary":"  We present SOLO, a single transformer for Scalable visiOn-Language mOdeling.\nCurrent large vision-language models (LVLMs) such as LLaVA mostly employ\nheterogeneous architectures that connect pre-trained visual encoders with large\nlanguage models (LLMs) to facilitate visual recognition and complex reasoning.\nAlthough achieving remarkable performance with relatively lightweight training,\nwe identify four primary scalability limitations: (1) The visual capacity is\nconstrained by pre-trained visual encoders, which are typically an order of\nmagnitude smaller than LLMs. (2) The heterogeneous architecture complicates the\nuse of established hardware and software infrastructure. (3) Study of scaling\nlaws on such architecture must consider three separate components - visual\nencoder, connector, and LLMs, which complicates the analysis. (4) The use of\nexisting visual encoders typically requires following a pre-defined\nspecification of image inputs pre-processing, for example, by reshaping inputs\nto fixed-resolution square images, which presents difficulties in processing\nand training on high-resolution images or those with unusual aspect ratio. A\nunified single Transformer architecture, like SOLO, effectively addresses these\nscalability concerns in LVLMs; however, its limited adoption in the modern\ncontext likely stems from the absence of reliable training recipes that balance\nboth modalities and ensure stable training for billion-scale models. In this\npaper, we introduce the first open-source training recipe for developing SOLO,\nan open-source 7B LVLM using moderate academic resources. The training recipe\ninvolves initializing from LLMs, sequential pre-training on ImageNet and\nweb-scale data, and instruction fine-tuning on our curated high-quality\ndatasets. On extensive evaluation, SOLO demonstrates performance comparable to\nLLaVA-v1.5-7B, particularly excelling in visual mathematical reasoning.\n","authors":["Yangyi Chen","Xingyao Wang","Hao Peng","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2407.06438v2.pdf","comment":"Accepted to TMLR"},{"id":"http://arxiv.org/abs/2411.02538v2","updated":"2024-11-13T18:04:44Z","published":"2024-11-04T19:17:17Z","title":"MILU: A Multi-task Indic Language Understanding Benchmark","summary":"  Evaluating Large Language Models (LLMs) in low-resource and linguistically\ndiverse languages remains a significant challenge in NLP, particularly for\nlanguages using non-Latin scripts like those spoken in India. Existing\nbenchmarks predominantly focus on English, leaving substantial gaps in\nassessing LLM capabilities in these languages. We introduce MILU, a Multi task\nIndic Language Understanding Benchmark, a comprehensive evaluation benchmark\ndesigned to address this gap. MILU spans 8 domains and 42 subjects across 11\nIndic languages, reflecting both general and culturally specific knowledge.\nWith an India-centric design, incorporates material from regional and\nstate-level examinations, covering topics such as local history, arts,\nfestivals, and laws, alongside standard subjects like science and mathematics.\nWe evaluate over 45 LLMs, and find that current LLMs struggle with MILU, with\nGPT-4o achieving the highest average accuracy at 72 percent. Open multilingual\nmodels outperform language-specific fine-tuned models, which perform only\nslightly better than random baselines. Models also perform better in high\nresource languages as compared to low resource ones. Domain-wise analysis\nindicates that models perform poorly in culturally relevant areas like Arts and\nHumanities, Law and Governance compared to general fields like STEM. To the\nbest of our knowledge, MILU is the first of its kind benchmark focused on Indic\nlanguages, serving as a crucial step towards comprehensive cultural evaluation.\nAll code, benchmarks, and artifacts are publicly available to foster open\nresearch.\n","authors":["Sshubam Verma","Mohammed Safi Ur Rahman Khan","Vishwajeet Kumar","Rudra Murthy","Jaydeep Sen"],"pdf_url":"https://arxiv.org/pdf/2411.02538v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18346v4","updated":"2024-11-13T17:17:43Z","published":"2024-03-27T08:38:49Z","title":"Quantifying and Mitigating Unimodal Biases in Multimodal Large Language\n  Models: A Causal Perspective","summary":"  Recent advancements in Large Language Models (LLMs) have facilitated the\ndevelopment of Multimodal LLMs (MLLMs). Despite their impressive capabilities,\nMLLMs often suffer from over-reliance on unimodal biases (e.g., language bias\nand vision bias), leading to incorrect answers or hallucinations in complex\nmultimodal tasks. To investigate this issue, we propose a causal framework to\ninterpret the biases in Visual Question Answering (VQA) problems. Within this\nframework, we conduct an in-depth causal analysis to assess the causal effect\nof these biases on MLLM predictions. Based on the analysis, we introduce 1) a\nnovel MORE dataset with 12,000 challenging VQA instances requiring multi-hop\nreasoning and overcoming unimodal biases. 2) a causality-enhanced agent\nframework CAVE that guides models to comprehensively integrate information from\ndifferent modalities and mitigate biases. Our experiments show that MLLMs\nperform poorly on MORE, indicating strong unimodal biases and limited semantic\nunderstanding. However, when integrated with our CAVE, promising improvements\nin reasoning and bias mitigation can be seen. These findings provide important\ninsights for the development of more robust MLLMs and contribute to the broader\ngoal of advancing multimodal AI systems capable of deeper understanding and\nreasoning. Our project page is at https://github.com/OpenCausaLab/MORE.\n","authors":["Meiqi Chen","Yixin Cao","Yan Zhang","Chaochao Lu"],"pdf_url":"https://arxiv.org/pdf/2403.18346v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08790v1","updated":"2024-11-13T17:16:48Z","published":"2024-11-13T17:16:48Z","title":"Can sparse autoencoders be used to decompose and interpret steering\n  vectors?","summary":"  Steering vectors are a promising approach to control the behaviour of large\nlanguage models. However, their underlying mechanisms remain poorly understood.\nWhile sparse autoencoders (SAEs) may offer a potential method to interpret\nsteering vectors, recent findings show that SAE-reconstructed vectors often\nlack the steering properties of the original vectors. This paper investigates\nwhy directly applying SAEs to steering vectors yields misleading\ndecompositions, identifying two reasons: (1) steering vectors fall outside the\ninput distribution for which SAEs are designed, and (2) steering vectors can\nhave meaningful negative projections in feature directions, which SAEs are not\ndesigned to accommodate. These limitations hinder the direct use of SAEs for\ninterpreting steering vectors.\n","authors":["Harry Mayne","Yushi Yang","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2411.08790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08785v1","updated":"2024-11-13T17:13:25Z","published":"2024-11-13T17:13:25Z","title":"Zero-shot Cross-lingual Transfer Learning with Multiple Source and\n  Target Languages for Information Extraction: Language Selection and\n  Adversarial Training","summary":"  The majority of previous researches addressing multi-lingual IE are limited\nto zero-shot cross-lingual single-transfer (one-to-one) setting, with\nhigh-resource languages predominantly as source training data. As a result,\nthese works provide little understanding and benefit for the realistic goal of\ndeveloping a multi-lingual IE system that can generalize to as many languages\nas possible. Our study aims to fill this gap by providing a detailed analysis\non Cross-Lingual Multi-Transferability (many-to-many transfer learning), for\nthe recent IE corpora that cover a diverse set of languages. Specifically, we\nfirst determine the correlation between single-transfer performance and a wide\nrange of linguistic-based distances. From the obtained insights, a combined\nlanguage distance metric can be developed that is not only highly correlated\nbut also robust across different tasks and model scales. Next, we investigate\nthe more general zero-shot multi-lingual transfer settings where multiple\nlanguages are involved in the training and evaluation processes. Language\nclustering based on the newly defined distance can provide directions for\nachieving the optimal cost-performance trade-off in data (languages) selection\nproblem. Finally, a relational-transfer setting is proposed to further\nincorporate multi-lingual unlabeled data based on adversarial training using\nthe relation induced from the above linguistic distance.\n","authors":["Nghia Trung Ngo","Thien Huu Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.08785v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03271v3","updated":"2024-11-13T17:10:20Z","published":"2024-02-05T18:28:44Z","title":"Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information\n  Seeking in Large Language Models","summary":"  In the face of uncertainty, the ability to *seek information* is of\nfundamental importance. In many practical applications, such as medical\ndiagnosis and troubleshooting, the information needed to solve the task is not\ninitially given and has to be actively sought by asking follow-up questions\n(for example, a doctor asking a patient for more details about their symptoms).\nIn this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to\naugment large language models with the ability to actively seek information by\nasking effective questions. UoT combines 1) an *uncertainty-aware simulation\napproach* which enables the model to simulate possible future scenarios and how\nlikely they are to occur, 2) *uncertainty-based rewards* motivated by\ninformation gain which incentivizes the model to seek information, and 3) a\n*reward propagation scheme* to select the optimal question to ask in a way that\nmaximizes the expected reward. In experiments on medical diagnosis,\ntroubleshooting, and the `20 Questions` game, UoT achieves an average\nperformance improvement of 38.1% in the rate of successful task completion\nacross multiple LLMs compared with direct prompting and also improves\nefficiency (i.e., the number of questions needed to complete the task). Our\ncode has been released [here](https://github.com/zhiyuanhubj/UoT)\n","authors":["Zhiyuan Hu","Chumin Liu","Xidong Feng","Yilun Zhao","See-Kiong Ng","Anh Tuan Luu","Junxian He","Pang Wei Koh","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2402.03271v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.08752v1","updated":"2024-11-13T16:30:41Z","published":"2024-11-13T16:30:41Z","title":"Multi-Perspective Stance Detection","summary":"  Subjective NLP tasks usually rely on human annotations provided by multiple\nannotators, whose judgments may vary due to their diverse backgrounds and life\nexperiences. Traditional methods often aggregate multiple annotations into a\nsingle ground truth, disregarding the diversity in perspectives that arises\nfrom annotator disagreement. In this preliminary study, we examine the effect\nof including multiple annotations on model accuracy in classification. Our\nmethodology investigates the performance of perspective-aware classification\nmodels in stance detection task and further inspects if annotator disagreement\naffects the model confidence. The results show that multi-perspective approach\nyields better classification performance outperforming the baseline which uses\nthe single label. This entails that designing more inclusive perspective-aware\nAI models is not only an essential first step in implementing responsible and\nethical AI, but it can also achieve superior results than using the traditional\napproaches.\n","authors":["Benedetta Muscato","Praveen Bushipaka","Gizem Gezici","Lucia Passaro","Fosca Giannotti"],"pdf_url":"https://arxiv.org/pdf/2411.08752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07140v2","updated":"2024-11-13T16:27:43Z","published":"2024-11-11T17:10:56Z","title":"Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language\n  Models","summary":"  New LLM evaluation benchmarks are important to align with the rapid\ndevelopment of Large Language Models (LLMs). In this work, we present Chinese\nSimpleQA, the first comprehensive Chinese benchmark to evaluate the factuality\nability of language models to answer short questions, and Chinese SimpleQA\nmainly has five properties (i.e., Chinese, Diverse, High-quality, Static,\nEasy-to-evaluate). Specifically, first, we focus on the Chinese language over 6\nmajor topics with 99 diverse subtopics. Second, we conduct a comprehensive\nquality control process to achieve high-quality questions and answers, where\nthe reference answers are static and cannot be changed over time. Third,\nfollowing SimpleQA, the questions and answers are very short, and the grading\nprocess is easy-to-evaluate based on OpenAI API. Based on Chinese SimpleQA, we\nperform a comprehensive evaluation on the factuality abilities of existing\nLLMs. Finally, we hope that Chinese SimpleQA could guide the developers to\nbetter understand the Chinese factuality abilities of their models and\nfacilitate the growth of foundation models.\n","authors":["Yancheng He","Shilong Li","Jiaheng Liu","Yingshui Tan","Weixun Wang","Hui Huang","Xingyuan Bu","Hangyu Guo","Chengwei Hu","Boren Zheng","Zhuoran Lin","Xuepeng Liu","Dekai Sun","Shirong Lin","Zhicheng Zheng","Xiaoyong Zhu","Wenbo Su","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2411.07140v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08745v1","updated":"2024-11-13T16:26:19Z","published":"2024-11-13T16:26:19Z","title":"Separating Tongue from Thought: Activation Patching Reveals\n  Language-Agnostic Concept Representations in Transformers","summary":"  A central question in multilingual language modeling is whether large\nlanguage models (LLMs) develop a universal concept representation, disentangled\nfrom specific languages. In this paper, we address this question by analyzing\nlatent representations (latents) during a word translation task in\ntransformer-based LLMs. We strategically extract latents from a source\ntranslation prompt and insert them into the forward pass on a target\ntranslation prompt. By doing so, we find that the output language is encoded in\nthe latent at an earlier layer than the concept to be translated. Building on\nthis insight, we conduct two key experiments. First, we demonstrate that we can\nchange the concept without changing the language and vice versa through\nactivation patching alone. Second, we show that patching with the mean over\nlatents across different languages does not impair and instead improves the\nmodels' performance in translating the concept. Our results provide evidence\nfor the existence of language-agnostic concept representations within the\ninvestigated models.\n","authors":["Cl√©ment Dumas","Chris Wendler","Veniamin Veselovsky","Giovanni Monea","Robert West"],"pdf_url":"https://arxiv.org/pdf/2411.08745v1.pdf","comment":"12 pages, 10 figures, previously published under the title \"How Do\n  Llamas Process Multilingual Text? A Latent Exploration through Activation\n  Patching\" at the ICML 2024 mechanistic interpretability workshop\n  https://openreview.net/forum?id=0ku2hIm4BS"},{"id":"http://arxiv.org/abs/2411.08742v1","updated":"2024-11-13T16:20:20Z","published":"2024-11-13T16:20:20Z","title":"A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks\n  with Large Language Models","summary":"  With the rise of Speech Large Language Models (Speech LLMs), there has been\ngrowing interest in discrete speech tokens for their ability to integrate with\ntext-based tokens seamlessly. Compared to most studies that focus on continuous\nspeech features, although discrete-token based LLMs have shown promising\nresults on certain tasks, the performance gap between these two paradigms is\nrarely explored. In this paper, we present a fair and thorough comparison\nbetween discrete and continuous features across a variety of semantic-related\ntasks using a light-weight LLM (Qwen1.5-0.5B). Our findings reveal that\ncontinuous features generally outperform discrete tokens, particularly in tasks\nrequiring fine-grained semantic understanding. Moreover, this study goes beyond\nsurface-level comparison by identifying key factors behind the\nunder-performance of discrete tokens, such as limited token granularity and\ninefficient information retention. To enhance the performance of discrete\ntokens, we explore potential aspects based on our analysis. We hope our results\ncan offer new insights into the opportunities for advancing discrete speech\ntokens in Speech LLMs.\n","authors":["Dingdong Wang","Mingyu Cui","Dongchao Yang","Xueyuan Chen","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2411.08742v1.pdf","comment":"5 tables, 4 figures"},{"id":"http://arxiv.org/abs/2411.08733v1","updated":"2024-11-13T16:15:38Z","published":"2024-11-13T16:15:38Z","title":"Dynamic Rewarding with Prompt Optimization Enables Tuning-free\n  Self-Alignment of Language Models","summary":"  Aligning Large Language Models (LLMs) traditionally relies on costly training\nand human preference annotations. Self-alignment seeks to reduce these expenses\nby enabling models to align themselves. To further lower costs and achieve\nalignment without any expensive tuning or annotations, we introduce a new\ntuning-free approach for self-alignment, Dynamic Rewarding with Prompt\nOptimization (\\ours). Our approach leverages a search-based optimization\nframework that allows LLMs to iteratively self-improve and craft the optimal\nalignment instructions, all without additional training or human intervention.\nThe core of \\ours is a dynamic rewarding mechanism, which identifies and\nrectifies model-specific alignment weaknesses, allowing LLMs to adapt\nefficiently to diverse alignment challenges. Empirical evaluations on eight\nrecent LLMs, both open- and closed-sourced, demonstrate that \\ours\nsignificantly enhances alignment performance, with base models outperforming\ntheir SFT/RLHF-tuned counterparts. Moreover, the prompts automatically\noptimized by \\ours surpass those curated by human experts, further validating\nthe effectiveness of our approach. Our findings highlight the great potential\nof current LLMs to achieve adaptive self-alignment through inference-time\noptimization, complementing tuning-based alignment methods.\n","authors":["Somanshu Singla","Zhen Wang","Tianyang Liu","Abdullah Ashfaq","Zhiting Hu","Eric P. Xing"],"pdf_url":"https://arxiv.org/pdf/2411.08733v1.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2411.08726v1","updated":"2024-11-13T16:08:40Z","published":"2024-11-13T16:08:40Z","title":"Analyst Reports and Stock Performance: Evidence from the Chinese Market","summary":"  This article applies natural language processing (NLP) to extract and\nquantify textual information to predict stock performance. Using an extensive\ndataset of Chinese analyst reports and employing a customized BERT deep\nlearning model for Chinese text, this study categorizes the sentiment of the\nreports as positive, neutral, or negative. The findings underscore the\npredictive capacity of this sentiment indicator for stock volatility, excess\nreturns, and trading volume. Specifically, analyst reports with strong positive\nsentiment will increase excess return and intraday volatility, and vice versa,\nreports with strong negative sentiment also increase volatility and trading\nvolume, but decrease future excess return. The magnitude of this effect is\ngreater for positive sentiment reports than for negative sentiment reports.\nThis article contributes to the empirical literature on sentiment analysis and\nthe response of the stock market to news in the Chinese stock market.\n","authors":["Rui Liu","Jiayou Liang","Haolong Chen","Yujia Hu"],"pdf_url":"https://arxiv.org/pdf/2411.08726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08708v1","updated":"2024-11-13T15:50:38Z","published":"2024-11-13T15:50:38Z","title":"Are Triggers Needed for Document-Level Event Extraction?","summary":"  Most existing work on event extraction has focused on sentence-level texts\nand presumes the identification of a trigger-span -- a word or phrase in the\ninput that evokes the occurrence of an event of interest. Event arguments are\nthen extracted with respect to the trigger. Indeed, triggers are treated as\nintegral to, and trigger detection as an essential component of, event\nextraction. In this paper, we provide the first investigation of the role of\ntriggers for the more difficult and much less studied task of document-level\nevent extraction. We analyze their usefulness in multiple end-to-end and\npipelined neural event extraction models for three document-level event\nextraction datasets, measuring performance using triggers of varying quality\n(human-annotated, LLM-generated, keyword-based, and random). Our research shows\nthat trigger effectiveness varies based on the extraction task's\ncharacteristics and data quality, with basic, automatically-generated triggers\nserving as a viable alternative to human-annotated ones. Furthermore, providing\ndetailed event descriptions to the extraction model helps maintain robust\nperformance even when trigger quality degrades. Perhaps surprisingly, we also\nfind that the mere existence of trigger input, even random ones, is important\nfor prompt-based LLM approaches to the task.\n","authors":["Shaden Shaar","Wayne Chen","Maitreyi Chatterjee","Barry Wang","Wenting Zhao","Claire Cardie"],"pdf_url":"https://arxiv.org/pdf/2411.08708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07879v4","updated":"2024-11-13T15:45:31Z","published":"2023-11-14T03:18:28Z","title":"Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting\n  Volunteer Content Moderators","summary":"  Extensive efforts in automated approaches for content moderation have been\nfocused on developing models to identify toxic, offensive, and hateful content\nwith the aim of lightening the load for moderators. Yet, it remains uncertain\nwhether improvements on those tasks have truly addressed moderators' needs in\naccomplishing their work. In this paper, we surface gaps between past research\nefforts that have aimed to provide automation for aspects of content moderation\nand the needs of volunteer content moderators, regarding identifying violations\nof various moderation rules. To do so, we conduct a model review on Hugging\nFace to reveal the availability of models to cover various moderation rules and\nguidelines from three exemplar forums. We further put state-of-the-art LLMs to\nthe test, evaluating how well these models perform in flagging violations of\nplatform rules from one particular forum. Finally, we conduct a user survey\nstudy with volunteer moderators to gain insight into their perspectives on\nuseful moderation models. Overall, we observe a non-trivial gap, as missing\ndeveloped models and LLMs exhibit moderate to low performance on a significant\nportion of the rules. Moderators' reports provide guides for future work on\ndeveloping moderation assistant models.\n","authors":["Yang Trista Cao","Lovely-Frances Domingo","Sarah Ann Gilbert","Michelle Mazurek","Katie Shilton","Hal Daum√© III"],"pdf_url":"https://arxiv.org/pdf/2311.07879v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15339v3","updated":"2024-11-13T15:25:32Z","published":"2024-07-22T02:53:18Z","title":"Deep Learning for Economists","summary":"  Deep learning provides powerful methods to impute structured information from\nlarge-scale, unstructured text and image datasets. For example, economists\nmight wish to detect the presence of economic activity in satellite images, or\nto measure the topics or entities mentioned in social media, the congressional\nrecord, or firm filings. This review introduces deep neural networks, covering\nmethods such as classifiers, regression models, generative AI, and embedding\nmodels. Applications include classification, document digitization, record\nlinkage, and methods for data exploration in massive scale text and image\ncorpora. When suitable methods are used, deep learning models can be cheap to\ntune and can scale affordably to problems involving millions or billions of\ndata points.. The review is accompanied by a companion website, EconDL, with\nuser-friendly demo notebooks, software resources, and a knowledge base that\nprovides technical details and additional applications.\n","authors":["Melissa Dell"],"pdf_url":"https://arxiv.org/pdf/2407.15339v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16187v3","updated":"2024-11-13T15:14:38Z","published":"2024-02-25T20:24:07Z","title":"No Free Lunch in LLM Watermarking: Trade-offs in Watermarking Design\n  Choices","summary":"  Advances in generative models have made it possible for AI-generated text,\ncode, and images to mirror human-generated content in many applications.\nWatermarking, a technique that aims to embed information in the output of a\nmodel to verify its source, is useful for mitigating the misuse of such\nAI-generated content. However, we show that common design choices in LLM\nwatermarking schemes make the resulting systems surprisingly susceptible to\nattack -- leading to fundamental trade-offs in robustness, utility, and\nusability. To navigate these trade-offs, we rigorously study a set of simple\nyet effective attacks on common watermarking systems, and propose guidelines\nand defenses for LLM watermarking in practice.\n","authors":["Qi Pang","Shengyuan Hu","Wenting Zheng","Virginia Smith"],"pdf_url":"https://arxiv.org/pdf/2402.16187v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08671v1","updated":"2024-11-13T15:04:02Z","published":"2024-11-13T15:04:02Z","title":"Theoretical Analysis of Byte-Pair Encoding","summary":"  Byte-Pair Encoding (BPE) is a widely used method for subword tokenization,\nwith origins in grammar-based text compression. It is employed in a variety of\nlanguage processing tasks such as machine translation or large language model\n(LLM) pretraining, to create a token dictionary of a prescribed size. Most\nevaluations of BPE to date are empirical, and the reasons for its good\npractical performance are not well understood.\n  In this paper we focus on the optimization problem underlying BPE: finding a\npair encoding that achieves optimal compression utility. We show that this\nproblem is APX-complete, indicating that it is unlikely to admit a\npolynomial-time approximation scheme. This answers, in a stronger form, a\nquestion recently raised by Zouhar et al.\n  On the positive side, we show that BPE approximates the compression utility\nof the optimal pair encoding to a worst-case factor between $0.333$ and\n$0.625$. Our results aim to explain the ongoing success of BPE and are, to our\nknowledge, the first rigorous guarantees on its compression utility that hold\nfor all inputs.\n","authors":["L√°szl√≥ Kozma","Johannes Voderholzer"],"pdf_url":"https://arxiv.org/pdf/2411.08671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15736v2","updated":"2024-11-13T14:05:18Z","published":"2024-03-23T06:03:36Z","title":"General LLMs as Instructors for Domain-Specific LLMs: A Sequential\n  Fusion Method to Integrate Extraction and Editing","summary":"  The substantial interest in updating Large Language Models (LLMs) without\nretraining from scratch is accompanied by several challenges. This is\nparticularly true when updating LLMs with datasets that necessitate\ndomain-expert reasoning across extensive texts, despite limited samples. We\ntermed the scenario as the Few-Shot Domain-Expert Reasoning for Updating LLMs\n(FDoR-UL). Traditional methods such as Low-Rank Adaptation (LoRA) and Retrieval\nAugmented Generation (RAG) are inadequate for addressing this critical issue,\nparticularly evident in our exploration of a specific medical dataset that\nepitomizes the distinct needs of FDoR-UL. To tackle this challenge, we\nintroduce a Sequential Fusion method to integrate knowledge from complex\ncontexts into LLMs. This method employs a two-stage framework: initially\nleveraging general LLMs to perform relation extraction for knowledge\nacquisition from complex texts, followed by updating domain-specific LLMs\nthrough Knowledge Editing (KE). Employing our method, domain-specific LLMs\nachieved a 71.7% accuracy (an average gain of 39.1%) in question-answering\ntasks. Furthermore, we expanded our evaluation to a novel economics-management\ndataset we developed, where our method achieved a 75.0% accuracy (an average\ngain of 45.0%). These findings underscore the effectiveness and flexibility of\nour approach in FDoR-UL across various domains.\n","authors":["Xin Zhang","Tianjie Ju","Huijia Liang","Ying Fu","Qin Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.15736v2.pdf","comment":"Working in progress"},{"id":"http://arxiv.org/abs/2411.08610v1","updated":"2024-11-13T13:53:10Z","published":"2024-11-13T13:53:10Z","title":"Dynamic Subset Tuning: Expanding the Operational Range of\n  Parameter-Efficient Training for Large Language Models","summary":"  We propose a novel parameter-efficient training (PET) method for large\nlanguage models that adapts models to downstream tasks by optimizing a small\nsubset of the existing model parameters. Unlike prior methods, this subset is\nnot fixed in location but rather which parameters are modified evolves over the\ncourse of training. This dynamic parameter selection can yield good performance\nwith many fewer parameters than extant methods. Our method enables a seamless\nscaling of the subset size across an arbitrary proportion of the total model\nsize, while popular PET approaches like prompt tuning and LoRA cover only a\nsmall part of this spectrum. We match or outperform prompt tuning and LoRA in\nmost cases on a variety of NLP tasks (MT, QA, GSM8K, SuperGLUE) for a given\nparameter budget across different model families and sizes.\n","authors":["Felix Stahlberg","Jared Lichtarge","Shankar Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.08610v1.pdf","comment":"NeurIPS 2024 Workshop on Adaptive Foundation Models"},{"id":"http://arxiv.org/abs/2410.20513v2","updated":"2024-11-13T13:40:19Z","published":"2024-10-27T16:52:21Z","title":"Is Moral Self-correction An Innate Capability of Large Language Models?\n  A Mechanistic Analysis to Self-correction","summary":"  Though intensive attentions to the self-correction capability of Large\nLanguage Models (LLMs), the underlying mechanism of this capability is still\nunder-explored. In this paper, we aim to answer two fundamental questions for\nmoral self-correction: (1) how different components in self-correction, such as\nChain-of-Thought (CoT) reasoning, external feedback, and instructional prompts,\ninteract to enable moral self-correction; and (2) is the self-correction one of\nLLMs' innate capabilities? To answer the first question, we examine how\ndifferent self-correction components interact to intervene the embedded\nmorality within hidden states, therefore contributing to different performance.\nFor the second question, we (i) evaluate the robustness of moral\nself-correction by introducing natural language interventions of weak evidence\ninto prompts; (ii) propose a validation framework, self-distinguish, that\nrequires effective self-correction to enable LLMs to distinguish between\ndesirable and undesirable outputs. Our experimental results indicate that there\nis no universally optimal self-correction method for the tasks considered,\nalthough external feedback and CoT can contribute to additional performance\ngains. However, our mechanistic analysis reveals negative interactions among\ninstructional prompts, CoT, and external feedback, suggesting a conflict\nbetween internal knowledge and external feedback. The self-distinguish\nexperiments demonstrate that while LLMs can self-correct their responses, they\nare unable to reliably distinguish between desired and undesired outputs. With\nour empirical evidence, we can conclude that moral self-correction is not an\ninnate capability of LLMs acquired during pretraining.\n","authors":["Zimo Qi","Guangliang Liu","Kristen Marie Johnson","Lu Cheng"],"pdf_url":"https://arxiv.org/pdf/2410.20513v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08599v1","updated":"2024-11-13T13:30:21Z","published":"2024-11-13T13:30:21Z","title":"XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL","summary":"  To tackle the challenges of large language model performance in natural\nlanguage to SQL tasks, we introduce XiYan-SQL, an innovative framework that\nemploys a multi-generator ensemble strategy to improve candidate generation. We\nintroduce M-Schema, a semi-structured schema representation method designed to\nenhance the understanding of database structures. To enhance the quality and\ndiversity of generated candidate SQL queries, XiYan-SQL integrates the\nsignificant potential of in-context learning (ICL) with the precise control of\nsupervised fine-tuning. On one hand, we propose a series of training strategies\nto fine-tune models to generate high-quality candidates with diverse\npreferences. On the other hand, we implement the ICL approach with an example\nselection method based on named entity recognition to prevent overemphasis on\nentities. The refiner optimizes each candidate by correcting logical or\nsyntactical errors. To address the challenge of identifying the best candidate,\nwe fine-tune a selection model to distinguish nuances of candidate SQL queries.\nThe experimental results on multiple dialect datasets demonstrate the\nrobustness of XiYan-SQL in addressing challenges across different scenarios.\nOverall, our proposed XiYan-SQL achieves the state-of-the-art execution\naccuracy of 89.65% on the Spider test set, 69.86% on SQL-Eval, 41.20% on\nNL2GQL, and a competitive score of 72.23% on the Bird development benchmark.\nThe proposed framework not only enhances the quality and diversity of SQL\nqueries but also outperforms previous methods.\n","authors":["Yingqi Gao","Yifu Liu","Xiaoxia Li","Xiaorong Shi","Yin Zhu","Yiming Wang","Shiqi Li","Wei Li","Yuntao Hong","Zhiling Luo","Jinyang Gao","Liyu Mou","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2411.08599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17073v3","updated":"2024-11-13T12:46:54Z","published":"2024-09-25T16:32:35Z","title":"Enhancing Post-Hoc Attributions in Long Document Comprehension via\n  Coarse Grained Answer Decomposition","summary":"  Accurately attributing answer text to its source document is crucial for\ndeveloping a reliable question-answering system. However, attribution for long\ndocuments remains largely unexplored. Post-hoc attribution systems are designed\nto map answer text back to the source document, yet the granularity of this\nmapping has not been addressed. Furthermore, a critical question arises: What\nexactly should be attributed? This involves identifying the specific\ninformation units within an answer that require grounding. In this paper, we\npropose and investigate a novel approach to the factual decomposition of\ngenerated answers for attribution, employing template-based in-context\nlearning. To accomplish this, we utilize the question and integrate negative\nsampling during few-shot in-context learning for decomposition. This approach\nenhances the semantic understanding of both abstractive and extractive answers.\nWe examine the impact of answer decomposition by providing a thorough\nexamination of various attribution approaches, ranging from retrieval-based\ntechniques to LLM-based attributors.\n","authors":["Pritika Ramu","Koustava Goswami","Apoorv Saxena","Balaji Vasan Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2409.17073v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02549v2","updated":"2024-11-13T12:37:09Z","published":"2024-02-04T15:52:59Z","title":"Are Large Language Models Table-based Fact-Checkers?","summary":"  Table-based Fact Verification (TFV) aims to extract the entailment relation\nbetween statements and structured tables. Existing TFV methods based on\nsmall-scaled models suffer from insufficient labeled data and weak zero-shot\nability. Recently, the appearance of Large Language Models (LLMs) has gained\nlots of attraction in research fields. They have shown powerful zero-shot and\nin-context learning abilities on several NLP tasks, but their potential on TFV\nis still unknown. In this work, we implement a preliminary study about whether\nLLMs are table-based fact-checkers. In detail, we design diverse prompts to\nexplore how the in-context learning can help LLMs in TFV, i.e., zero-shot and\nfew-shot TFV capability. Besides, we carefully design and construct TFV\ninstructions to study the performance gain brought by the instruction tuning of\nLLMs. Experimental results demonstrate that LLMs can achieve acceptable results\non zero-shot and few-shot TFV with prompt engineering, while instruction-tuning\ncan stimulate the TFV capability significantly. We also make some valuable\nfindings about the format of zero-shot prompts and the number of in-context\nexamples. Finally, we analyze some possible directions to promote the accuracy\nof TFV via LLMs, which is beneficial to further research of table reasoning.\n","authors":["Hanwen Zhang","Qingyi Si","Peng Fu","Zheng Lin","Weiping Wang"],"pdf_url":"https://arxiv.org/pdf/2402.02549v2.pdf","comment":"CSCWD 2024"},{"id":"http://arxiv.org/abs/2411.08553v1","updated":"2024-11-13T12:09:23Z","published":"2024-11-13T12:09:23Z","title":"CorrSynth -- A Correlated Sampling Method for Diverse Dataset Generation\n  from LLMs","summary":"  Large language models (LLMs) have demonstrated remarkable performance in\ndiverse tasks using zero-shot and few-shot prompting. Even though their\ncapabilities of data synthesis have been studied well in recent years, the\ngenerated data suffers from a lack of diversity, less adherence to the prompt,\nand potential biases that creep into the data from the generator model. In this\nwork, we tackle the challenge of generating datasets with high diversity, upon\nwhich a student model is trained for downstream tasks. Taking the route of\ndecoding-time guidance-based approaches, we propose CorrSynth, which generates\ndata that is more diverse and faithful to the input prompt using a correlated\nsampling strategy. Further, our method overcomes the complexity drawbacks of\nsome other guidance-based techniques like classifier-based guidance. With\nextensive experiments, we show the effectiveness of our approach and\nsubstantiate our claims. In particular, we perform intrinsic evaluation to show\nthe improvements in diversity. Our experiments show that CorrSynth improves\nboth student metrics and intrinsic metrics upon competitive baselines across\nfour datasets, showing the innate advantage of our method.\n","authors":["Suhas S Kowshik","Abhishek Divekar","Vijit Malik"],"pdf_url":"https://arxiv.org/pdf/2411.08553v1.pdf","comment":"Published as a main conference paper at EMNLP 2024; First two authors\n  contributed equally"},{"id":"http://arxiv.org/abs/2411.08534v1","updated":"2024-11-13T11:31:02Z","published":"2024-11-13T11:31:02Z","title":"Neural Topic Modeling with Large Language Models in the Loop","summary":"  Topic modeling is a fundamental task in natural language processing, allowing\nthe discovery of latent thematic structures in text corpora. While Large\nLanguage Models (LLMs) have demonstrated promising capabilities in topic\ndiscovery, their direct application to topic modeling suffers from issues such\nas incomplete topic coverage, misalignment of topics, and inefficiency. To\naddress these limitations, we propose LLM-ITL, a novel LLM-in-the-loop\nframework that integrates LLMs with many existing Neural Topic Models (NTMs).\nIn LLM-ITL, global topics and document representations are learned through the\nNTM, while an LLM refines the topics via a confidence-weighted Optimal\nTransport (OT)-based alignment objective. This process enhances the\ninterpretability and coherence of the learned topics, while maintaining the\nefficiency of NTMs. Extensive experiments demonstrate that LLM-ITL can help\nNTMs significantly improve their topic interpretability while maintaining the\nquality of document representation.\n","authors":["Xiaohao Yang","He Zhao","Weijie Xu","Yuanyuan Qi","Jueqing Lu","Dinh Phung","Lan Du"],"pdf_url":"https://arxiv.org/pdf/2411.08534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07268v2","updated":"2024-11-13T11:28:07Z","published":"2024-11-09T15:59:59Z","title":"Target-driven Attack for Large Language Models","summary":"  Current large language models (LLM) provide a strong foundation for\nlarge-scale user-oriented natural language tasks. Many users can easily inject\nadversarial text or instructions through the user interface, thus causing LLM\nmodel security challenges like the language model not giving the correct\nanswer. Although there is currently a large amount of research on black-box\nattacks, most of these black-box attacks use random and heuristic strategies.\nIt is unclear how these strategies relate to the success rate of attacks and\nthus effectively improve model robustness. To solve this problem, we propose\nour target-driven black-box attack method to maximize the KL divergence between\nthe conditional probabilities of the clean text and the attack text to redefine\nthe attack's goal. We transform the distance maximization problem into two\nconvex optimization problems based on the attack goal to solve the attack text\nand estimate the covariance. Furthermore, the projected gradient descent\nalgorithm solves the vector corresponding to the attack text. Our target-driven\nblack-box attack approach includes two attack strategies: token manipulation\nand misinformation attack. Experimental results on multiple Large Language\nModels and datasets demonstrate the effectiveness of our attack method.\n","authors":["Chong Zhang","Mingyu Jin","Dong Shu","Taowen Wang","Dongfang Liu","Xiaobo Jin"],"pdf_url":"https://arxiv.org/pdf/2411.07268v2.pdf","comment":"12 pages, 7 figures. This work is an extension of the\n  arXiv:2404.07234 work. We propose new methods. 27th European Conference on\n  Artificial Intelligence 2024"},{"id":"http://arxiv.org/abs/2405.10040v3","updated":"2024-11-13T11:13:56Z","published":"2024-05-16T12:22:41Z","title":"SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation","summary":"  It is often desirable to distill the capabilities of large language models\n(LLMs) into smaller student models due to compute and memory constraints. One\nway to do this for classification tasks is via dataset synthesis, which can be\naccomplished by generating examples of each label from the LLM. Prior\napproaches to synthesis use few-shot prompting, which relies on the LLM's\nparametric knowledge to generate usable examples. However, this leads to issues\nof repetition, bias towards popular entities, and stylistic differences from\nhuman text. In this work, we propose Synthesize by Retrieval and Refinement\n(SynthesizRR), which uses retrieval augmentation to introduce variety into the\ndataset synthesis process: as retrieved passages vary, the LLM is seeded with\ndifferent content to generate its examples. We empirically study the synthesis\nof six datasets, covering topic classification, sentiment analysis, tone\ndetection, and humor, requiring complex synthesis strategies. We find that\nSynthesizRR greatly improves lexical and semantic diversity, similarity to\nhuman-written text, and distillation performance, when compared to 32-shot\nprompting and four prior approaches. We release our code to perform all steps\nat https://github.com/amazon-science/synthesizrr\n","authors":["Abhishek Divekar","Greg Durrett"],"pdf_url":"https://arxiv.org/pdf/2405.10040v3.pdf","comment":"Published as a main conference paper at EMNLP 2024. Code available at\n  https://github.com/amazon-science/synthesizrr"},{"id":"http://arxiv.org/abs/2411.08516v1","updated":"2024-11-13T11:02:04Z","published":"2024-11-13T11:02:04Z","title":"Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale\n  Table Understanding","summary":"  The ubiquity and value of tables as semi-structured data across various\ndomains necessitate advanced methods for understanding their complexity and\nvast amounts of information. Despite the impressive capabilities of large\nlanguage models (LLMs) in advancing the natural language understanding\nfrontier, their application to large-scale tabular data presents significant\nchallenges, specifically regarding table size and complex intricate\nrelationships. Existing works have shown promise with small-scale tables but\noften flounder when tasked with the complex reasoning required by larger,\ninterconnected tables found in real-world scenarios. To address this gap, we\nintroduce \"Tree-of-Table\", a novel approach designed to enhance LLMs' reasoning\ncapabilities over large and complex tables. Our method employs Table\nCondensation and Decomposition to distill and reorganize relevant data into a\nmanageable format, followed by the construction of a hierarchical Table-Tree\nthat facilitates tree-structured reasoning. Through a meticulous Table-Tree\nExecution process, we systematically unravel the tree-structured reasoning\nchain to derive the solutions. Experiments across diverse datasets, including\nWikiTQ, TableFact, FeTaQA, and BIRD, demonstrate that Tree-of-Table sets a new\nbenchmark with superior performance, showcasing remarkable efficiency and\ngeneralization capabilities in large-scale table reasoning.\n","authors":["Deyi Ji","Lanyun Zhu","Siqi Gao","Peng Xu","Hongtao Lu","Jieping Ye","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.08516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13929v4","updated":"2024-11-13T10:57:21Z","published":"2024-05-22T18:58:58Z","title":"Vikhr: Constructing a State-of-the-art Bilingual Open-Source\n  Instruction-Following Large Language Model for Russian","summary":"  There has been a surge in developing various Large Language Models (LLMs).\nHowever, text generation for languages other than English often faces\nsignificant challenges, including poor generation quality and reduced\ncomputational performance due to the disproportionate representation of tokens\nin the model's vocabulary. In this work, we address these issues by developing\na pipeline for adapting English-oriented pre-trained models to other languages\nand constructing efficient bilingual LLMs. Using this pipeline, we construct\nVikhr, a state-of-the-art bilingual open-source instruction-following LLM\ndesigned specifically for the Russian language. \"Vikhr\" refers to the name of\nthe Mistral LLM series and means a \"strong gust of wind.\" Unlike previous\nRussian-language models that typically rely on LoRA adapters on top of\nEnglish-oriented models, sacrificing performance for lower training costs,\nVikhr features an adapted tokenizer vocabulary and undergoes continued\npre-training and instruction tuning of all weights. This not only enhances the\nmodel's performance but also significantly improves its computational and\ncontextual efficiency. The remarkable performance of Vikhr across various\nRussian-language benchmarks can also be attributed to our efforts in expanding\ninstruction datasets and corpora for continued pre-training. Vikhr not only\nsets a new state of the art among open-source LLMs for Russian but even\noutperforms some proprietary closed-source models on certain benchmarks. The\nmodel weights, instruction sets, and code are publicly available.\n","authors":["Aleksandr Nikolich","Konstantin Korolev","Sergei Bratchikov","Igor Kiselev","Artem Shelmanov"],"pdf_url":"https://arxiv.org/pdf/2405.13929v4.pdf","comment":"Accepted at WMRL @ EMNLP-2024"},{"id":"http://arxiv.org/abs/2411.08506v1","updated":"2024-11-13T10:43:31Z","published":"2024-11-13T10:43:31Z","title":"An Information Theoretic Approach to Operationalize Right to Data\n  Protection","summary":"  The widespread practice of indiscriminate data scraping to fine-tune language\nmodels (LMs) raises significant legal and ethical concerns, particularly\nregarding compliance with data protection laws such as the General Data\nProtection Regulation (GDPR). This practice often results in the unauthorized\nuse of personal information, prompting growing debate within the academic and\nregulatory communities. Recent works have introduced the concept of generating\nunlearnable datasets (by adding imperceptible noise to the clean data), such\nthat the underlying model achieves lower loss during training but fails to\ngeneralize to the unseen test setting. Though somewhat effective, these\napproaches are predominantly designed for images and are limited by several\npractical constraints like requiring knowledge of the target model. To this\nend, we introduce RegText, a framework that injects imperceptible spurious\ncorrelations into natural language datasets, effectively rendering them\nunlearnable without affecting semantic content. We demonstrate RegText's\nutility through rigorous empirical analysis of small and large LMs. Notably,\nRegText can restrict newer models like GPT-4o and Llama from learning on our\ngenerated data, resulting in a drop in their test accuracy compared to their\nzero-shot performance and paving the way for generating unlearnable text to\nprotect public data.\n","authors":["Abhinav Java","Simra Shahid","Chirag Agarwal"],"pdf_url":"https://arxiv.org/pdf/2411.08506v1.pdf","comment":"First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2411.08504v1","updated":"2024-11-13T10:42:11Z","published":"2024-11-13T10:42:11Z","title":"Towards Objective and Unbiased Decision Assessments with LLM-Enhanced\n  Hierarchical Attention Networks","summary":"  How objective and unbiased are we while making decisions? This work\ninvestigates cognitive bias identification in high-stake decision making\nprocess by human experts, questioning its effectiveness in real-world settings,\nsuch as candidates assessments for university admission. We begin with a\nstatistical analysis assessing correlations among different decision points\namong in the current process, which discovers discrepancies that imply\ncognitive bias and inconsistency in decisions. This motivates our exploration\nof bias-aware AI-augmented workflow that surpass human judgment. We propose\nBGM-HAN, a hierarchical attention network enhanced by byte-pair encoding,\nmulti-head attention and gated residual connection. Using it as backbone model,\nwe further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow, which\nsimulate real-world decision-making. In our experiments, both the proposed\nmodel and the agentic workflow significantly improves on both human judgment\nand alternative models, validated with real-world data.\n","authors":["Junhua Liu","Kwan Hui Lim","Roy Ka-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2411.08504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08449v1","updated":"2024-11-13T09:11:56Z","published":"2024-11-13T09:11:56Z","title":"Towards Evaluating Large Language Models for Graph Query Generation","summary":"  Large Language Models (LLMs) are revolutionizing the landscape of Generative\nArtificial Intelligence (GenAI), with innovative LLM-backed solutions emerging\nrapidly. However, when applied to database technologies, specifically query\ngeneration for graph databases and Knowledge Graphs (KGs), LLMs still face\nsignificant challenges. While research on LLM-driven query generation for\nStructured Query Language (SQL) exists, similar systems for graph databases\nremain underdeveloped. This paper presents a comparative study addressing the\nchallenge of generating Cypher queries a powerful language for interacting with\ngraph databases using open-access LLMs. We rigorously evaluate several LLM\nagents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a\nlocally deployed Llama 3.1 8B) using a designed few-shot learning prompt and\nRetrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)\nreasoning. Our empirical analysis of query generation accuracy reveals that\nClaude Sonnet 3.5 outperforms its counterparts in this specific domain.\nFurther, we highlight promising future research directions to address the\nidentified limitations and advance LLM-driven query generation for graph\ndatabases.\n","authors":["Siraj Munir","Alessandro Aldini"],"pdf_url":"https://arxiv.org/pdf/2411.08449v1.pdf","comment":"Paper accepted and will be presented at CSCI2024 in December 2024,\n  Later will be published at Springer LNCS"},{"id":"http://arxiv.org/abs/2404.17808v3","updated":"2024-11-13T08:51:04Z","published":"2024-04-27T07:12:07Z","title":"Scaffold-BPE: Enhancing Byte Pair Encoding for Large Language Models\n  with Simple and Effective Scaffold Token Removal","summary":"  Byte Pair Encoding (BPE) serves as a foundation method for text tokenization\nin the Natural Language Processing (NLP) field. Despite its wide adoption, the\noriginal BPE algorithm harbors an inherent flaw: it inadvertently introduces a\nfrequency imbalance for tokens in the text corpus. Since BPE iteratively merges\nthe most frequent token pair in the text corpus to generate a new token and\nkeeps all generated tokens in the vocabulary, it unavoidably holds tokens that\nprimarily act as components of a longer token and appear infrequently on their\nown. We term such tokens as Scaffold Tokens. Due to their infrequent\noccurrences in the text corpus, Scaffold Tokens pose a learning imbalance\nissue. To address that issue, we propose Scaffold-BPE, which incorporates a\ndynamic scaffold token removal mechanism by parameter-free, computation-light,\nand easy-to-implement modifications to the original BPE method. This novel\napproach ensures the exclusion of low-frequency Scaffold Tokens from the token\nrepresentations for given texts, thereby mitigating the issue of frequency\nimbalance and facilitating model training. On extensive experiments across\nlanguage modeling and even machine translation, Scaffold-BPE consistently\noutperforms the original BPE, well demonstrating its effectiveness.\n","authors":["Haoran Lian","Yizhe Xiong","Jianwei Niu","Shasha Mo","Zhenpeng Su","Zijia Lin","Hui Chen","Peng Liu","Jungong Han","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2404.17808v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08432v1","updated":"2024-11-13T08:32:42Z","published":"2024-11-13T08:32:42Z","title":"One STEP at a time: Language Agents are Stepwise Planners","summary":"  Language agents have shown promising adaptability in dynamic environments to\nperform complex tasks. However, despite the versatile knowledge embedded in\nlarge language models, these agents still fall short when it comes to tasks\nthat require planning. We introduce STEP, a novel framework designed to\nefficiently learn from previous experiences to enhance the planning\ncapabilities of language agents in future steps. Concretely, STEP functions\nthrough four interconnected components. First, the Planner takes on the task,\nbreaks it down into subtasks and provides relevant insights. Then the Executor\ngenerates action candidates, while the Evaluator ensures the actions align with\nlearned rules from previous experiences. Lastly, Memory stores experiences to\ninform future decisions. In the ScienceWorld benchmark, our results show that\nSTEP consistently outperforms state-of-the-art models, achieving an overall\nscore of 67.4 and successfully completing 12 out of 18 tasks. These findings\nhighlight STEP's potential as a framework for enhancing planning capabilities\nin language agents, paving the way for more sophisticated task-solving in\ndynamic environments.\n","authors":["Minh Nguyen","Ehsan Shareghi"],"pdf_url":"https://arxiv.org/pdf/2411.08432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08397v1","updated":"2024-11-13T07:32:58Z","published":"2024-11-13T07:32:58Z","title":"CLaSP: Learning Concepts for Time-Series Signals from Natural Language\n  Supervision","summary":"  This paper proposes a foundation model called \"CLaSP\" that can search time\nseries signals using natural language that describes the characteristics of the\nsignals as queries. Previous efforts to represent time series signal data in\nnatural language have had challenges in designing a conventional class of time\nseries signal characteristics, formulating their quantification, and creating a\ndictionary of synonyms. To overcome these limitations, the proposed method\nintroduces a neural network based on contrastive learning. This network is\nfirst trained using the datasets TRUCE and SUSHI, which consist of time series\nsignals and their corresponding natural language descriptions. Previous studies\nhave proposed vocabularies that data analysts use to describe signal\ncharacteristics, and SUSHI was designed to cover these terms. We believe that a\nneural network trained on these datasets will enable data analysts to search\nusing natural language vocabulary. Furthermore, our method does not require a\ndictionary of predefined synonyms, and it leverages common sense knowledge\nembedded in a large-scale language model (LLM). Experimental results\ndemonstrate that CLaSP enables natural language search of time series signal\ndata and can accurately learn the points at which signal data changes.\n","authors":["Aoi Ito","Kota Dohi","Yohei Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2411.08397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02288v2","updated":"2024-11-13T07:13:36Z","published":"2024-08-05T07:54:01Z","title":"Spin glass model of in-context learning","summary":"  Large language models show a surprising in-context learning ability -- being\nable to use a prompt to form a prediction for a query, yet without additional\ntraining, in stark contrast to old-fashioned supervised learning. Providing a\nmechanistic interpretation and linking the empirical phenomenon to physics are\nthus challenging and remain unsolved. We study a simple yet expressive\ntransformer with linear attention and map this structure to a spin glass model\nwith real-valued spins, where the couplings and fields explain the intrinsic\ndisorder in data. The spin glass model explains how the weight parameters\ninteract with each other during pre-training, and further clarifies why an\nunseen function can be predicted by providing only a prompt yet without further\ntraining. Our theory reveals that for single-instance learning, increasing the\ntask diversity leads to the emergence of in-context learning, by allowing the\nBoltzmann distribution to converge to a unique correct solution of weight\nparameters. Therefore the pre-trained transformer displays a prediction power\nin a novel prompt setting. The proposed analytically tractable model thus\noffers a promising avenue for thinking about how to interpret many intriguing\nbut puzzling properties of large language models.\n","authors":["Yuhao Li","Ruoran Bai","Haiping Huang"],"pdf_url":"https://arxiv.org/pdf/2408.02288v2.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.08384v1","updated":"2024-11-13T07:10:18Z","published":"2024-11-13T07:10:18Z","title":"Interpretable Syntactic Representations Enable Hierarchical Word Vectors","summary":"  The distributed representations currently used are dense and uninterpretable,\nleading to interpretations that themselves are relative, overcomplete, and hard\nto interpret. We propose a method that transforms these word vectors into\nreduced syntactic representations. The resulting representations are compact\nand interpretable allowing better visualization and comparison of the word\nvectors and we successively demonstrate that the drawn interpretations are in\nline with human judgment. The syntactic representations are then used to create\nhierarchical word vectors using an incremental learning approach similar to the\nhierarchical aspect of human learning. As these representations are drawn from\npre-trained vectors, the generation process and learning approach are\ncomputationally efficient. Most importantly, we find out that syntactic\nrepresentations provide a plausible interpretation of the vectors and\nsubsequent hierarchical vectors outperform the original vectors in benchmark\ntests.\n","authors":["Biraj Silwal"],"pdf_url":"https://arxiv.org/pdf/2411.08384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07820v2","updated":"2024-11-13T05:43:58Z","published":"2024-11-12T14:12:45Z","title":"Query Optimization for Parametric Knowledge Refinement in\n  Retrieval-Augmented Large Language Models","summary":"  We introduce the Extract-Refine-Retrieve-Read (ERRR) framework, a novel\napproach designed to bridge the pre-retrieval information gap in\nRetrieval-Augmented Generation (RAG) systems through query optimization\ntailored to meet the specific knowledge requirements of Large Language Models\n(LLMs). Unlike conventional query optimization techniques used in RAG, the ERRR\nframework begins by extracting parametric knowledge from LLMs, followed by\nusing a specialized query optimizer for refining these queries. This process\nensures the retrieval of only the most pertinent information essential for\ngenerating accurate responses. Moreover, to enhance flexibility and reduce\ncomputational costs, we propose a trainable scheme for our pipeline that\nutilizes a smaller, tunable model as the query optimizer, which is refined\nthrough knowledge distillation from a larger teacher model. Our evaluations on\nvarious question-answering (QA) datasets and with different retrieval systems\nshow that ERRR consistently outperforms existing baselines, proving to be a\nversatile and cost-effective module for improving the utility and accuracy of\nRAG systems.\n","authors":["Youan Cong","Cheng Wang","Pritom Saha Akash","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2411.07820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08348v1","updated":"2024-11-13T05:40:24Z","published":"2024-11-13T05:40:24Z","title":"Refining Translations with LLMs: A Constraint-Aware Iterative Prompting\n  Approach","summary":"  Large language models (LLMs) have demonstrated remarkable proficiency in\nmachine translation (MT), even without specific training on the languages in\nquestion. However, translating rare words in low-resource or domain-specific\ncontexts remains challenging for LLMs. To address this issue, we propose a\nmulti-step prompt chain that enhances translation faithfulness by prioritizing\nkey terms crucial for semantic accuracy. Our method first identifies these\nkeywords and retrieves their translations from a bilingual dictionary,\nintegrating them into the LLM's context using Retrieval-Augmented Generation\n(RAG). We further mitigate potential output hallucinations caused by long\nprompts through an iterative self-checking mechanism, where the LLM refines its\ntranslations based on lexical and semantic constraints. Experiments using Llama\nand Qwen as base models on the FLORES-200 and WMT datasets demonstrate\nsignificant improvements over baselines, highlighting the effectiveness of our\napproach in enhancing translation faithfulness and robustness, particularly in\nlow-resource scenarios.\n","authors":["Shangfeng Chen","Xiayang Shi","Pu Li","Yinlin Li","Jingjing Liu"],"pdf_url":"https://arxiv.org/pdf/2411.08348v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08347v1","updated":"2024-11-13T05:38:55Z","published":"2024-11-13T05:38:55Z","title":"A Chinese Multi-label Affective Computing Dataset Based on Social Media\n  Network Users","summary":"  Emotion and personality are central elements in understanding human\npsychological states. Emotions reflect an individual subjective experiences,\nwhile personality reveals relatively stable behavioral and cognitive patterns.\nExisting affective computing datasets often annotate emotion and personality\ntraits separately, lacking fine-grained labeling of micro-emotions and emotion\nintensity in both single-label and multi-label classifications. Chinese emotion\ndatasets are extremely scarce, and datasets capturing Chinese user personality\ntraits are even more limited. To address these gaps, this study collected data\nfrom the major social media platform Weibo, screening 11,338 valid users from\nover 50,000 individuals with diverse MBTI personality labels and acquiring\n566,900 posts along with the user MBTI personality tags. Using the EQN method,\nwe compiled a multi-label Chinese affective computing dataset that integrates\nthe same user's personality traits with six emotions and micro-emotions, each\nannotated with intensity levels. Validation results across multiple NLP\nclassification models demonstrate the dataset strong utility. This dataset is\ndesigned to advance machine recognition of complex human emotions and provide\ndata support for research in psychology, education, marketing, finance, and\npolitics.\n","authors":["Jingyi Zhou","Senlin Luo","Haofan Chen"],"pdf_url":"https://arxiv.org/pdf/2411.08347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08344v1","updated":"2024-11-13T05:22:45Z","published":"2024-11-13T05:22:45Z","title":"Bangla Grammatical Error Detection Leveraging Transformer-based Token\n  Classification","summary":"  Bangla is the seventh most spoken language by a total number of speakers in\nthe world, and yet the development of an automated grammar checker in this\nlanguage is an understudied problem. Bangla grammatical error detection is a\ntask of detecting sub-strings of a Bangla text that contain grammatical,\npunctuation, or spelling errors, which is crucial for developing an automated\nBangla typing assistant. Our approach involves breaking down the task as a\ntoken classification problem and utilizing state-of-the-art transformer-based\nmodels. Finally, we combine the output of these models and apply rule-based\npost-processing to generate a more reliable and comprehensive result. Our\nsystem is evaluated on a dataset consisting of over 25,000 texts from various\nsources. Our best model achieves a Levenshtein distance score of 1.04. Finally,\nwe provide a detailed analysis of different components of our system.\n","authors":["Shayekh Bin Islam","Ridwanul Hasan Tanvir","Sihat Afnan"],"pdf_url":"https://arxiv.org/pdf/2411.08344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17439v3","updated":"2024-11-13T04:57:08Z","published":"2024-10-22T21:30:58Z","title":"Evaluating AI-Generated Essays with GRE Analytical Writing Assessment","summary":"  The recent revolutionary advance in generative AI enables the generation of\nrealistic and coherent texts by large language models (LLMs). Despite many\nexisting evaluation metrics on the quality of the generated texts, there is\nstill a lack of rigorous assessment of how well LLMs perform in complex and\ndemanding writing assessments. This study examines essays generated by ten\nleading LLMs for the analytical writing assessment of the Graduate Record Exam\n(GRE). We assessed these essays using both human raters and the e-rater\nautomated scoring engine as used in the GRE scoring pipeline. Notably, the\ntop-performing Gemini and GPT-4o received an average score of 4.78 and 4.67,\nrespectively, falling between \"generally thoughtful, well-developed analysis of\nthe issue and conveys meaning clearly\" and \"presents a competent analysis of\nthe issue and conveys meaning with acceptable clarity\" according to the GRE\nscoring guideline. We also evaluated the detection accuracy of these essays,\nwith detectors trained on essays generated by the same and different LLMs.\n","authors":["Yang Zhong","Jiangang Hao","Michael Fauss","Chen Li","Yuan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17439v3.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.15553v2","updated":"2024-11-13T04:26:13Z","published":"2024-10-21T00:59:47Z","title":"Multi-IF: Benchmarking LLMs on Multi-Turn and Multilingual Instructions\n  Following","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in\nvarious tasks, including instruction following, which is crucial for aligning\nmodel outputs with user expectations. However, evaluating LLMs' ability to\nfollow instructions remains challenging due to the complexity and subjectivity\nof human language. Current benchmarks primarily focus on single-turn,\nmonolingual instructions, which do not adequately reflect the complexities of\nreal-world applications that require handling multi-turn and multilingual\ninteractions. To address this gap, we introduce Multi-IF, a new benchmark\ndesigned to assess LLMs' proficiency in following multi-turn and multilingual\ninstructions. Multi-IF, which utilizes a hybrid framework combining LLM and\nhuman annotators, expands upon the IFEval by incorporating multi-turn sequences\nand translating the English prompts into another 7 languages, resulting in a\ndataset of 4,501 multilingual conversations, where each has three turns. Our\nevaluation of 14 state-of-the-art LLMs on Multi-IF reveals that it presents a\nsignificantly more challenging task than existing benchmarks. All the models\ntested showed a higher rate of failure in executing instructions correctly with\neach additional turn. For example, o1-preview drops from 0.877 at the first\nturn to 0.707 at the third turn in terms of average accuracy over all\nlanguages. Moreover, languages with non-Latin scripts (Hindi, Russian, and\nChinese) generally exhibit higher error rates, suggesting potential limitations\nin the models' multilingual capabilities. We release Multi-IF prompts and the\nevaluation code base to encourage further research in this critical area.\n","authors":["Yun He","Di Jin","Chaoqi Wang","Chloe Bi","Karishma Mandyam","Hejia Zhang","Chen Zhu","Ning Li","Tengyu Xu","Hongjiang Lv","Shruti Bhosale","Chenguang Zhu","Karthik Abinav Sankararaman","Eryk Helenowski","Melanie Kambadur","Aditya Tayade","Hao Ma","Han Fang","Sinong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.15553v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08324v1","updated":"2024-11-13T04:20:20Z","published":"2024-11-13T04:20:20Z","title":"Are LLMs Prescient? A Continuous Evaluation using Daily News as the\n  Oracle","summary":"  Many existing evaluation benchmarks for Large Language Models (LLMs) quickly\nbecome outdated due to the emergence of new models and training data. These\nbenchmarks also fall short in assessing how LLM performance changes over time,\nas they consist of static questions without a temporal dimension. To address\nthese limitations, we propose using future event prediction as a continuous\nevaluation method to assess LLMs' temporal generalization and forecasting\nabilities. Our benchmark, Daily Oracle, automatically generates question-answer\n(QA) pairs from daily news, challenging LLMs to predict \"future\" event\noutcomes. Our findings reveal that as pre-training data becomes outdated, LLM\nperformance degrades over time. While Retrieval Augmented Generation (RAG) has\nthe potential to enhance prediction accuracy, the performance degradation\npattern persists, highlighting the need for continuous model updates.\n","authors":["Hui Dai","Ryan Teehan","Mengye Ren"],"pdf_url":"https://arxiv.org/pdf/2411.08324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11216v2","updated":"2024-11-13T04:16:21Z","published":"2024-10-15T03:02:03Z","title":"Experiences from Creating a Benchmark for Sentiment Classification for\n  Varieties of English","summary":"  Existing benchmarks often fail to account for linguistic diversity, like\nlanguage variants of English. In this paper, we share our experiences from our\nongoing project of building a sentiment classification benchmark for three\nvariants of English: Australian (en-AU), Indian (en-IN), and British (en-UK)\nEnglish. Using Google Places reviews, we explore the effects of various\nsampling techniques based on label semantics, review length, and sentiment\nproportion and report performances on three fine-tuned BERT-based models. Our\ninitial evaluation reveals significant performance variations influenced by\nsample characteristics, label semantics, and language variety, highlighting the\nneed for nuanced benchmark design. We offer actionable insights for researchers\nto create robust benchmarks, emphasising the importance of diverse sampling,\ncareful label definition, and comprehensive evaluation across linguistic\nvarieties.\n","authors":["Dipankar Srirag","Jordan Painter","Aditya Joshi","Diptesh Kanojia"],"pdf_url":"https://arxiv.org/pdf/2410.11216v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2411.07521v2","updated":"2024-11-13T04:03:54Z","published":"2024-11-12T03:37:53Z","title":"Fair Summarization: Bridging Quality and Diversity in Extractive\n  Summaries","summary":"  Fairness in multi-document summarization of user-generated content remains a\ncritical challenge in natural language processing (NLP). Existing summarization\nmethods often fail to ensure equitable representation across different social\ngroups, leading to biased outputs. In this paper, we introduce two novel\nmethods for fair extractive summarization: FairExtract, a clustering-based\napproach, and FairGPT, which leverages GPT-3.5-turbo with fairness constraints.\nWe evaluate these methods using Divsumm summarization dataset of White-aligned,\nHispanic, and African-American dialect tweets and compare them against relevant\nbaselines. The results obtained using a comprehensive set of summarization\nquality metrics such as SUPERT, BLANC, SummaQA, BARTScore, and UniEval, as well\nas a fairness metric F, demonstrate that FairExtract and FairGPT achieve\nsuperior fairness while maintaining competitive summarization quality.\nAdditionally, we introduce composite metrics (e.g., SUPERT+F, BLANC+F) that\nintegrate quality and fairness into a single evaluation framework, offering a\nmore nuanced understanding of the trade-offs between these objectives. This\nwork highlights the importance of fairness in summarization and sets a\nbenchmark for future research in fairness-aware NLP models.\n","authors":["Sina Bagheri Nezhad","Sayan Bandyapadhyay","Ameeta Agrawal"],"pdf_url":"https://arxiv.org/pdf/2411.07521v2.pdf","comment":"Accepted at Algorithmic Fairness through the Lens of Metrics and\n  Evaluation Workshop @ NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.08302v1","updated":"2024-11-13T02:45:21Z","published":"2024-11-13T02:45:21Z","title":"R3HF: Reward Redistribution for Enhancing Reinforcement Learning from\n  Human Feedback","summary":"  Reinforcement learning from human feedback (RLHF) provides a paradigm for\naligning large language models (LLMs) with human preferences. This involves the\ninitial training of a reward model based on pairwise human feedback. The reward\nmodel is subsequently utilized in reinforcement learning to assess the scores\nof each generated sentence as a whole, further guiding the optimization of\nLLMs. However, current approaches have a significant shortcoming: \\emph{They\nallocate a single, sparse, and delayed reward to an entire sequence of output}.\nThis may overlook some significant individual contributions of each token\ntowards the desired outcome. To overcome this limitation, our paper proposes a\nnovel reward redistribution method called R3HF, which facilitates a more\nfine-grained, token-level reward allocation. Specifically, our method treats\nthe reward prediction task of the reward model as a regression problem. As a\nresult, the redistributed rewards are computed by evaluating the specific\ncontribution of each token to the reward model's output. This detailed approach\nimproves the model's understanding of language nuances, leading to more precise\nenhancements in its performance. Our method is crafted to integrate seamlessly\nwith most current techniques while incurring minimal computational costs.\nThrough comprehensive experiments across diverse datasets and tasks, we have\nverified the effectiveness and superiority of our approach.\n","authors":["Jiahui Li","Tai-wei Chang","Fengda Zhang","Kun Kuang","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2411.08302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.05386v2","updated":"2024-11-13T01:40:53Z","published":"2024-05-08T19:31:06Z","title":"Interpretability Needs a New Paradigm","summary":"  Interpretability is the study of explaining models in understandable terms to\nhumans. At present, interpretability is divided into two paradigms: the\nintrinsic paradigm, which believes that only models designed to be explained\ncan be explained, and the post-hoc paradigm, which believes that black-box\nmodels can be explained. At the core of this debate is how each paradigm\nensures its explanations are faithful, i.e., true to the model's behavior. This\nis important, as false but convincing explanations lead to unsupported\nconfidence in artificial intelligence (AI), which can be dangerous. This\npaper's position is that we should think about new paradigms while staying\nvigilant regarding faithfulness. First, by examining the history of paradigms\nin science, we see that paradigms are constantly evolving. Then, by examining\nthe current paradigms, we can understand their underlying beliefs, the value\nthey bring, and their limitations. Finally, this paper presents 3 emerging\nparadigms for interpretability. The first paradigm designs models such that\nfaithfulness can be easily measured. Another optimizes models such that\nexplanations become faithful. The last paradigm proposes to develop models that\nproduce both a prediction and an explanation.\n","authors":["Andreas Madsen","Himabindu Lakkaraju","Siva Reddy","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2405.05386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08278v1","updated":"2024-11-13T01:33:05Z","published":"2024-11-13T01:33:05Z","title":"Knowledge Bases in Support of Large Language Models for Processing Web\n  News","summary":"  Large Language Models (LLMs) have received considerable interest in wide\napplications lately. During pre-training via massive datasets, such a model\nimplicitly memorizes the factual knowledge of trained datasets in its hidden\nparameters. However, knowledge held implicitly in parameters often makes its\nuse by downstream applications ineffective due to the lack of common-sense\nreasoning. In this article, we introduce a general framework that permits to\nbuild knowledge bases with an aid of LLMs, tailored for processing Web news.\nThe framework applies a rule-based News Information Extractor (NewsIE) to news\nitems for extracting their relational tuples, referred to as knowledge bases,\nwhich are then graph-convoluted with the implicit knowledge facts of news items\nobtained by LLMs, for their classification. It involves two lightweight\ncomponents: 1) NewsIE: for extracting the structural information of every news\nitem, in the form of relational tuples; 2) BERTGraph: for graph convoluting the\nimplicit knowledge facts with relational tuples extracted by NewsIE. We have\nevaluated our framework under different news-related datasets for news category\nclassification, with promising experimental results.\n","authors":["Yihe Zhang","Nabin Pakka","Nian-feng Tzeng"],"pdf_url":"https://arxiv.org/pdf/2411.08278v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.08275v1","updated":"2024-11-13T01:12:35Z","published":"2024-11-13T01:12:35Z","title":"A Large-Scale Study of Relevance Assessments with Large Language Models:\n  An Initial Look","summary":"  The application of large language models to provide relevance assessments\npresents exciting opportunities to advance information retrieval, natural\nlanguage processing, and beyond, but to date many unknowns remain. This paper\nreports on the results of a large-scale evaluation (the TREC 2024 RAG Track)\nwhere four different relevance assessment approaches were deployed in situ: the\n\"standard\" fully manual process that NIST has implemented for decades and three\ndifferent alternatives that take advantage of LLMs to different extents using\nthe open-source UMBRELA tool. This setup allows us to correlate system rankings\ninduced by the different approaches to characterize tradeoffs between cost and\nquality. We find that in terms of nDCG@20, nDCG@100, and Recall@100, system\nrankings induced by automatically generated relevance assessments from UMBRELA\ncorrelate highly with those induced by fully manual assessments across a\ndiverse set of 77 runs from 19 teams. Our results suggest that automatically\ngenerated UMBRELA judgments can replace fully manual judgments to accurately\ncapture run-level effectiveness. Surprisingly, we find that LLM assistance does\nnot appear to increase correlation with fully manual assessments, suggesting\nthat costs associated with human-in-the-loop processes do not bring obvious\ntangible benefits. Overall, human assessors appear to be stricter than UMBRELA\nin applying relevance criteria. Our work validates the use of LLMs in academic\nTREC-style evaluations and provides the foundation for future studies.\n","authors":["Shivani Upadhyay","Ronak Pradeep","Nandan Thakur","Daniel Campos","Nick Craswell","Ian Soboroff","Hoa Trang Dang","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.08275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18164v2","updated":"2024-11-13T00:15:46Z","published":"2024-09-26T17:30:28Z","title":"Data-Prep-Kit: getting your data ready for LLM application development","summary":"  Data preparation is the first and a very important step towards any Large\nLanguage Model (LLM) development. This paper introduces an easy-to-use,\nextensible, and scale-flexible open-source data preparation toolkit called Data\nPrep Kit (DPK). DPK is architected and designed to enable users to scale their\ndata preparation to their needs. With DPK they can prepare data on a local\nmachine or effortlessly scale to run on a cluster with thousands of CPU Cores.\nDPK comes with a highly scalable, yet extensible set of modules that transform\nnatural language and code data. If the user needs additional transforms, they\ncan be easily developed using extensive DPK support for transform creation.\nThese modules can be used independently or pipelined to perform a series of\noperations. In this paper, we describe DPK architecture and show its\nperformance from a small scale to a very large number of CPUs. The modules from\nDPK have been used for the preparation of Granite Models [1] [2]. We believe\nDPK is a valuable contribution to the AI community to easily prepare data to\nenhance the performance of their LLM models or to fine-tune models with\nRetrieval-Augmented Generation (RAG).\n","authors":["David Wood","Boris Lublinsky","Alexy Roytman","Shivdeep Singh","Constantin Adam","Abdulhamid Adebayo","Sungeun An","Yuan Chi Chang","Xuan-Hong Dang","Nirmit Desai","Michele Dolfi","Hajar Emami-Gohari","Revital Eres","Takuya Goto","Dhiraj Joshi","Yan Koyfman","Mohammad Nassar","Hima Patel","Paramesvaran Selvam","Yousaf Shah","Saptha Surendran","Daiki Tsuzuku","Petros Zerfos","Shahrokh Daijavad"],"pdf_url":"https://arxiv.org/pdf/2409.18164v2.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.07870v2","updated":"2024-11-13T23:02:41Z","published":"2024-11-12T15:26:17Z","title":"Trustful LLMs: Customizing and Grounding Text Generation with Knowledge\n  Bases and Dual Decoders","summary":"  Although people are impressed by the content generation skills of large\nlanguage models, the use of LLMs, such as ChatGPT, is limited by the domain\ngrounding of the content. The correctness and groundedness of the generated\ncontent need to be based on a verified context, such as results from\nRetrieval-Augmented Generation (RAG). One important issue when adapting LLMs to\na customized domain is that the generated responses are often incomplete, or\nthe additions are not verified and may even be hallucinated. Prior studies on\nhallucination detection have focused on evaluation metrics, which are not\neasily adaptable to dynamic domains and can be vulnerable to attacks like\njail-breaking. In this work, we propose 1) a post-processing algorithm that\nleverages knowledge triplets in RAG context to correct hallucinations and 2) a\ndual-decoder model that fuses RAG context to guide the generation process.\n","authors":["Xiaofeng Zhu","Jaya Krishna Mandivarapu"],"pdf_url":"https://arxiv.org/pdf/2411.07870v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09073v1","updated":"2024-11-13T22:56:00Z","published":"2024-11-13T22:56:00Z","title":"Code-mixed LLM: Improve Large Language Models' Capability to Handle\n  Code-Mixing through Reinforcement Learning from AI Feedback","summary":"  Code-mixing(CM) or code-switching(CSW) refers to the juxtaposition of\nlinguistic units from two or more languages during the conversation or\nsometimes even a single utterance. Code-mixing introduces unique challenges in\ndaily life, such as syntactic mismatches and semantic blending, that are rarely\nencountered in monolingual settings. Large language models (LLMs) have\nrevolutionized the field of natural language processing (NLP) by offering\nunprecedented capabilities in understanding human languages. However, the\neffectiveness of current state-of-the-art multilingual LLMs has not yet been\nfully explored in the CM scenario. To fill this gap, we first benchmark the\nperformance of multilingual LLMs on various code-mixing NLP tasks. Then we\npropose to improve the multilingual LLMs' ability to understand code-mixing\nthrough reinforcement learning from human feedback (RLHF) and code-mixed\nmachine translation tasks. Given the high-cost and time-consuming preference\nlabeling procedure, we improve this by utilizing LLMs as annotators to perform\nthe reinforcement learning from AI feedback (RLAIF). The experiments show the\neffectiveness of the proposed method.\n","authors":["Wenbo Zhang","Aditya Majumdar","Amulya Yadav"],"pdf_url":"https://arxiv.org/pdf/2411.09073v1.pdf","comment":"initial version: 5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.09018v1","updated":"2024-11-13T20:50:04Z","published":"2024-11-13T20:50:04Z","title":"Bridging the Visual Gap: Fine-Tuning Multimodal Models with\n  Knowledge-Adapted Captions","summary":"  Recent research increasingly focuses on training vision-language models\n(VLMs) with long, detailed image captions. However, small-scale VLMs often\nstruggle to balance the richness of these captions with the risk of\nhallucinating content during fine-tuning. In this paper, we explore how well\nVLMs adapt to such captions. To quantify caption quality, we propose Decomposed\nNLI (DNLI), an evaluation framework that breaks down generated captions into\nindividual propositions, assessing each in isolation. This fine-grained\nanalysis reveals a critical balance between capturing descriptive details and\npreventing hallucinations. Our findings show that simply reducing caption\ncomplexity or employing standard data curation techniques does not effectively\nresolve this issue. To tackle this challenge, we introduce Knowledge Adapted\n(KnowAda) fine-tuning, a data-centric approach that automatically adapts\ntraining data with the model's existing knowledge and visual understanding.\nKnowAda minimizes hallucinations while preserving high descriptiveness. We\nvalidate this approach across several small-scale VLMs (up to 7B parameters)\nand dense caption datasets, demonstrating that KnowAda effectively balances\nhallucination reduction and descriptiveness. Our results show that KnowAda\noutperforms various baselines in both automatic metrics and human evaluations.\nWe will release our code and models.\n","authors":["Moran Yanuka","Assaf Ben Kish","Yonatan Bitton","Idan Szpektor","Raja Giryes"],"pdf_url":"https://arxiv.org/pdf/2411.09018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09009v1","updated":"2024-11-13T20:30:15Z","published":"2024-11-13T20:30:15Z","title":"Cut Your Losses in Large-Vocabulary Language Models","summary":"  As language models grow ever larger, so do their vocabularies. This has\nshifted the memory footprint of LLMs during training disproportionately to one\nsingle layer: the cross-entropy in the loss computation. Cross-entropy builds\nup a logit matrix with entries for each pair of input tokens and vocabulary\nitems and, for small models, consumes an order of magnitude more memory than\nthe rest of the LLM combined. We propose Cut Cross-Entropy (CCE), a method that\ncomputes the cross-entropy loss without materializing the logits for all tokens\ninto global memory. Rather, CCE only computes the logit for the correct token\nand evaluates the log-sum-exp over all logits on the fly. We implement a custom\nkernel that performs the matrix multiplications and the log-sum-exp reduction\nover the vocabulary in flash memory, making global memory consumption for the\ncross-entropy computation negligible. This has a dramatic effect. Taking the\nGemma 2 (2B) model as an example, CCE reduces the memory footprint of the loss\ncomputation from 24 GB to 1 MB, and the total training-time memory consumption\nof the classifier head from 28 GB to 1 GB. To improve the throughput of CCE, we\nleverage the inherent sparsity of softmax and propose to skip elements of the\ngradient computation that have a negligible (i.e., below numerical precision)\ncontribution to the gradient. Experiments demonstrate that the dramatic\nreduction in memory consumption is accomplished without sacrificing training\nspeed or convergence.\n","authors":["Erik Wijmans","Brody Huval","Alexander Hertzberg","Vladlen Koltun","Philipp Kr√§henb√ºhl"],"pdf_url":"https://arxiv.org/pdf/2411.09009v1.pdf","comment":"Code is available at https://github.com/apple/ml-cross-entropy"},{"id":"http://arxiv.org/abs/2411.09003v1","updated":"2024-11-13T20:12:55Z","published":"2024-11-13T20:12:55Z","title":"Refusal in LLMs is an Affine Function","summary":"  We propose affine concept editing (ACE) as an approach for steering language\nmodels' behavior by intervening directly in activations. We begin with an\naffine decomposition of model activation vectors and show that prior methods\nfor steering model behavior correspond to subsets of terms of this\ndecomposition. We then provide a derivation of ACE and test it on refusal using\nLlama 3 8B and Hermes Eagle RWKV v5. ACE ultimately combines affine subspace\nprojection and activation addition to reliably control the model's refusal\nresponses across prompt types. We evaluate the results using LLM-based scoring\non a collection of harmful and harmless prompts. Our experiments demonstrate\nthat ACE consistently achieves more precise control over model behavior and\ngeneralizes to models where directional ablation via affine subspace projection\nalone produces incoherent outputs. Code for reproducing our results is\navailable at https://github.com/EleutherAI/steering-llama3 .\n","authors":["Thomas Marshall","Adam Scherlis","Nora Belrose"],"pdf_url":"https://arxiv.org/pdf/2411.09003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23463v2","updated":"2024-11-13T19:34:22Z","published":"2024-10-30T21:08:07Z","title":"MDCure: A Scalable Pipeline for Multi-Document Instruction-Following","summary":"  Multi-document (MD) processing is crucial for LLMs to handle real-world tasks\nsuch as summarization and question-answering across large sets of documents.\nWhile LLMs have improved at processing long inputs, MD contexts still present\nchallenges, such as managing inter-document dependencies, redundancy, and\nincoherent structures. We introduce MDCure, a scalable and effective\nfine-tuning pipeline to enhance the MD capabilities of LLMs without the\ncomputational cost of pre-training or reliance on human annotated data. MDCure\nis based on generation of high-quality synthetic MD instruction data from sets\nof related articles via targeted prompts. We further introduce MDCureRM, a\nmulti-objective reward model which filters generated data based on their\ntraining utility for MD settings. With MDCure, we fine-tune a variety of LLMs,\nfrom the FlanT5, Qwen2, and LLAMA3.1 model families, up to 70B parameters in\nsize. Extensive evaluations on a wide range of MD and long-context benchmarks\nspanning various tasks show MDCure consistently improves performance over\npre-trained baselines and over corresponding base models by up to 75.5%. Our\ncode, datasets, and models are available at https://github.com/yale-nlp/MDCure.\n","authors":["Gabrielle Kaili-May Liu","Bowen Shi","Avi Caciularu","Idan Szpektor","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2410.23463v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08979v1","updated":"2024-11-13T19:12:02Z","published":"2024-11-13T19:12:02Z","title":"CoCoP: Enhancing Text Classification with LLM through Code Completion\n  Prompt","summary":"  Text classification is a fundamental task in natural language processing\n(NLP), and large language models (LLMs) have demonstrated their capability to\nperform this task across various domains. However, the performance of LLMs\nheavily depends on the quality of their input prompts. Recent studies have also\nshown that LLMs exhibit remarkable results in code-related tasks. To leverage\nthe capabilities of LLMs in text classification, we propose the Code Completion\nPrompt (CoCoP) method, which transforms the text classification problem into a\ncode completion task. CoCoP significantly improves text classification\nperformance across diverse datasets by utilizing LLMs' code-completion\ncapability. For instance, CoCoP enhances the accuracy of the SST2 dataset by\nmore than 20%. Moreover, when CoCoP integrated with LLMs specifically designed\nfor code-related tasks (code models), such as CodeLLaMA, this method\ndemonstrates better or comparable performance to few-shot learning techniques\nwhile using only one-tenth of the model size. The source code of our proposed\nmethod will be available to the public upon the acceptance of the paper.\n","authors":["Mohammad Mahdi Mohajeri","Mohammad Javad Dousti","Majid Nili Ahmadabadi"],"pdf_url":"https://arxiv.org/pdf/2411.08979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08977v1","updated":"2024-11-13T19:08:23Z","published":"2024-11-13T19:08:23Z","title":"Robustness and Confounders in the Demographic Alignment of LLMs with\n  Human Perceptions of Offensiveness","summary":"  Large language models (LLMs) are known to exhibit demographic biases, yet few\nstudies systematically evaluate these biases across multiple datasets or\naccount for confounding factors. In this work, we examine LLM alignment with\nhuman annotations in five offensive language datasets, comprising approximately\n220K annotations. Our findings reveal that while demographic traits,\nparticularly race, influence alignment, these effects are inconsistent across\ndatasets and often entangled with other factors. Confounders -- such as\ndocument difficulty, annotator sensitivity, and within-group agreement --\naccount for more variation in alignment patterns than demographic traits alone.\nSpecifically, alignment increases with higher annotator sensitivity and group\nagreement, while greater document difficulty corresponds to reduced alignment.\nOur results underscore the importance of multi-dataset analyses and\nconfounder-aware methodologies in developing robust measures of demographic\nbias in LLMs.\n","authors":["Shayan Alipour","Indira Sen","Mattia Samory","Tanushree Mitra"],"pdf_url":"https://arxiv.org/pdf/2411.08977v1.pdf","comment":"18 pages, 8 figures, ACL'25"},{"id":"http://arxiv.org/abs/2411.08968v1","updated":"2024-11-13T19:02:36Z","published":"2024-11-13T19:02:36Z","title":"Sparse Upcycling: Inference Inefficient Finetuning","summary":"  Small, highly trained, open-source large language models are widely used due\nto their inference efficiency, but further improving their quality remains a\nchallenge. Sparse upcycling is a promising approach that transforms a\npretrained dense model into a Mixture-of-Experts (MoE) architecture, increasing\nthe model's parameter count and quality. In this work, we compare the\neffectiveness of sparse upcycling against continued pretraining (CPT) across\ndifferent model sizes, compute budgets, and pretraining durations. Our\nexperiments show that sparse upcycling can achieve better quality, with\nimprovements of over 20% relative to CPT in certain scenarios. However, this\ncomes with a significant inference cost, leading to 40% slowdowns in\nhigh-demand inference settings for larger models. Our findings highlight the\ntrade-off between model quality and inference efficiency, offering insights for\npractitioners seeking to balance model quality and deployment constraints.\n","authors":["Sasha Doubov","Nikhil Sardana","Vitaliy Chiley"],"pdf_url":"https://arxiv.org/pdf/2411.08968v1.pdf","comment":"12 pages, 4 figures, To appear in the 4th NeurIPS Workshop on\n  Efficient Natural Language and Speech Processing (ENLSP), 2024"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2409.18659v2","updated":"2024-11-13T15:59:02Z","published":"2024-09-27T11:43:19Z","title":"Explainable Enrichment-Driven GrAph Reasoner (EDGAR) for Large Knowledge\n  Graphs with Applications in Drug Repurposing","summary":"  Knowledge graphs (KGs) represent connections and relationships between\nreal-world entities. We propose a link prediction framework for KGs named\nEnrichment-Driven GrAph Reasoner (EDGAR), which infers new edges by mining\nentity-local rules. This approach leverages enrichment analysis, a\nwell-established statistical method used to identify mechanisms common to sets\nof differentially expressed genes. EDGAR's inference results are inherently\nexplainable and rankable, with p-values indicating the statistical significance\nof each enrichment-based rule.\n  We demonstrate the framework's effectiveness on a large-scale biomedical KG,\nROBOKOP, focusing on drug repurposing for Alzheimer disease (AD) as a case\nstudy. Initially, we extracted 14 known drugs from the KG and identified 20\ncontextual biomarkers through enrichment analysis, revealing functional\npathways relevant to shared drug efficacy for AD. Subsequently, using the top\n1000 enrichment results, our system identified 1246 additional drug candidates\nfor AD treatment. The top 10 candidates were validated using evidence from\nmedical literature.\n  EDGAR is deployed within ROBOKOP, complete with a web user interface. This is\nthe first study to apply enrichment analysis to large graph completion and drug\nrepurposing.\n","authors":["Olawumi Olasunkanmi","Evan Morris","Yaphet Kebede","Harlin Lee","Stanley Ahalt","Alexander Tropsha","Chris Bizon"],"pdf_url":"https://arxiv.org/pdf/2409.18659v2.pdf","comment":"10 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2411.08700v1","updated":"2024-11-13T15:42:13Z","published":"2024-11-13T15:42:13Z","title":"Rethinking negative sampling in content-based news recommendation","summary":"  News recommender systems are hindered by the brief lifespan of articles, as\nthey undergo rapid relevance decay. Recent studies have demonstrated the\npotential of content-based neural techniques in tackling this problem. However,\nthese models often involve complex neural architectures and often lack\nconsideration for negative examples. In this study, we posit that the careful\nsampling of negative examples has a big impact on the model's outcome. We\ndevise a negative sampling technique that not only improves the accuracy of the\nmodel but also facilitates the decentralization of the recommendation system.\nThe experimental results obtained using the MIND dataset demonstrate that the\naccuracy of the method under consideration can compete with that of\nState-of-the-Art models. The utilization of the sampling technique is essential\nin reducing model complexity and accelerating the training process, while\nmaintaining a high level of accuracy. Finally, we discuss how decentralized\nmodels can help improve privacy and scalability.\n","authors":["Miguel √Çngelo Rebelo","Jo√£o Vinagre","Ivo Pereira","√Ålvaro Figueira"],"pdf_url":"https://arxiv.org/pdf/2411.08700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08696v1","updated":"2024-11-13T15:34:52Z","published":"2024-11-13T15:34:52Z","title":"Scholarly Wikidata: Population and Exploration of Conference Data in\n  Wikidata using LLMs","summary":"  Several initiatives have been undertaken to conceptually model the domain of\nscholarly data using ontologies and to create respective Knowledge Graphs. Yet,\nthe full potential seems unleashed, as automated means for automatic population\nof said ontologies are lacking, and respective initiatives from the Semantic\nWeb community are not necessarily connected: we propose to make scholarly data\nmore sustainably accessible by leveraging Wikidata's infrastructure and\nautomating its population in a sustainable manner through LLMs by tapping into\nunstructured sources like conference Web sites and proceedings texts as well as\nalready existing structured conference datasets. While an initial analysis\nshows that Semantic Web conferences are only minimally represented in Wikidata,\nwe argue that our methodology can help to populate, evolve and maintain\nscholarly data as a community within Wikidata. Our main contributions include\n(a) an analysis of ontologies for representing scholarly data to identify gaps\nand relevant entities/properties in Wikidata, (b) semi-automated extraction --\nrequiring (minimal) manual validation -- of conference metadata (e.g.,\nacceptance rates, organizer roles, programme committee members, best paper\nawards, keynotes, and sponsors) from websites and proceedings texts using LLMs.\nFinally, we discuss (c) extensions to visualization tools in the Wikidata\ncontext for data exploration of the generated scholarly data. Our study focuses\non data from 105 Semantic Web-related conferences and extends/adds more than\n6000 entities in Wikidata. It is important to note that the method can be more\ngenerally applicable beyond Semantic Web-related conferences for enhancing\nWikidata's utility as a comprehensive scholarly resource.\n  Source Repository: https://github.com/scholarly-wikidata/\n  DOI: https://doi.org/10.5281/zenodo.10989709\n  License: Creative Commons CC0 (Data), MIT (Code)\n","authors":["Nandana Mihindukulasooriya","Sanju Tiwari","Daniil Dobriy","Finn √Örup Nielsen","Tek Raj Chhetri","Axel Polleres"],"pdf_url":"https://arxiv.org/pdf/2411.08696v1.pdf","comment":"17 pages, accepted at EKAW-24"},{"id":"http://arxiv.org/abs/2411.08562v1","updated":"2024-11-13T12:19:46Z","published":"2024-11-13T12:19:46Z","title":"Neural Corrective Machine Unranking","summary":"  Machine unlearning in neural information retrieval (IR) systems requires\nremoving specific data whilst maintaining model performance. Applying existing\nmachine unlearning methods to IR may compromise retrieval effectiveness or\ninadvertently expose unlearning actions due to the removal of particular items\nfrom the retrieved results presented to users. We formalise corrective\nunranking, which extends machine unlearning in (neural) IR context by\nintegrating substitute documents to preserve ranking integrity, and propose a\nnovel teacher-student framework, Corrective unRanking Distillation (CuRD), for\nthis task. CuRD (1) facilitates forgetting by adjusting the (trained) neural IR\nmodel such that its output relevance scores of to-be-forgotten samples mimic\nthose of low-ranking, non-retrievable samples; (2) enables correction by\nfine-tuning the relevance scores for the substitute samples to match those of\ncorresponding to-be-forgotten samples closely; (3) seeks to preserve\nperformance on samples that are not targeted for forgetting. We evaluate CuRD\non four neural IR models (BERTcat, BERTdot, ColBERT, PARADE) using MS MARCO and\nTREC CAR datasets. Experiments with forget set sizes from 1 % and 20 % of the\ntraining dataset demonstrate that CuRD outperforms seven state-of-the-art\nbaselines in terms of forgetting and correction while maintaining model\nretention and generalisation capabilities.\n","authors":["Jingrui Hou","Axel Finke","Georgina Cosma"],"pdf_url":"https://arxiv.org/pdf/2411.08562v1.pdf","comment":"submitted to Information Sciences"},{"id":"http://arxiv.org/abs/2411.03364v2","updated":"2024-11-13T08:30:59Z","published":"2024-11-05T06:54:38Z","title":"DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural\n  Networks","summary":"  Graph has become increasingly integral to the advancement of recommendation\nsystems, particularly with the fast development of graph neural network(GNN).\nBy exploring the virtue of rich node features and link information, GNN is\ndesigned to provide personalized and accurate suggestions. Meanwhile, the\nprivacy leakage of GNN in such contexts has also captured special attention.\nPrior work has revealed that a malicious user can utilize auxiliary knowledge\nto extract sensitive link data of the target graph, integral to recommendation\nsystems, via the decision made by the target GNN model. This poses a\nsignificant risk to the integrity and confidentiality of data used in\nrecommendation system. Though important, previous works on GNN's privacy\nleakage are still challenged in three aspects, i.e., limited stealing attack\nscenarios, sub-optimal attack performance, and adaptation against defense. To\naddress these issues, we propose a diffusion model based link stealing attack,\nnamed DM4Steal. It differs previous work from three critical aspects. (i)\nGenerality: aiming at six attack scenarios with limited auxiliary knowledge, we\npropose a novel training strategy for diffusion models so that DM4Steal is\ntransferable to diverse attack scenarios. (ii) Effectiveness: benefiting from\nthe retention of semantic structure in the diffusion model during the training\nprocess, DM4Steal is capable to learn the precise topology of the target graph\nthrough the GNN decision process. (iii) Adaptation: when GNN is defensive\n(e.g., DP, Dropout), DM4Steal relies on the stability that comes from sampling\nthe score model multiple times to keep performance degradation to a minimum,\nthus DM4Steal implements successful adaptive attack on defensive GNN.\n","authors":["Jinyin Chen","Haonan Ma","Haibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2411.03364v2.pdf","comment":"We found that there were critical problems in our paper, and we\n  needed to redo the experiment, which was incomplete"},{"id":"http://arxiv.org/abs/2411.07820v2","updated":"2024-11-13T05:43:58Z","published":"2024-11-12T14:12:45Z","title":"Query Optimization for Parametric Knowledge Refinement in\n  Retrieval-Augmented Large Language Models","summary":"  We introduce the Extract-Refine-Retrieve-Read (ERRR) framework, a novel\napproach designed to bridge the pre-retrieval information gap in\nRetrieval-Augmented Generation (RAG) systems through query optimization\ntailored to meet the specific knowledge requirements of Large Language Models\n(LLMs). Unlike conventional query optimization techniques used in RAG, the ERRR\nframework begins by extracting parametric knowledge from LLMs, followed by\nusing a specialized query optimizer for refining these queries. This process\nensures the retrieval of only the most pertinent information essential for\ngenerating accurate responses. Moreover, to enhance flexibility and reduce\ncomputational costs, we propose a trainable scheme for our pipeline that\nutilizes a smaller, tunable model as the query optimizer, which is refined\nthrough knowledge distillation from a larger teacher model. Our evaluations on\nvarious question-answering (QA) datasets and with different retrieval systems\nshow that ERRR consistently outperforms existing baselines, proving to be a\nversatile and cost-effective module for improving the utility and accuracy of\nRAG systems.\n","authors":["Youan Cong","Cheng Wang","Pritom Saha Akash","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2411.07820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07508v2","updated":"2024-11-13T05:05:56Z","published":"2024-11-12T03:05:03Z","title":"Feature Interaction Fusion Self-Distillation Network For CTR Prediction","summary":"  Click-Through Rate (CTR) prediction plays a vital role in recommender\nsystems, online advertising, and search engines. Most of the current approaches\nmodel feature interactions through stacked or parallel structures, with some\nemploying knowledge distillation for model compression. However, we observe\nsome limitations with these approaches: (1) In parallel structure models, the\nexplicit and implicit components are executed independently and simultaneously,\nwhich leads to insufficient information sharing within the feature set. (2) The\nintroduction of knowledge distillation technology brings about the problems of\ncomplex teacher-student framework design and low knowledge transfer efficiency.\n(3) The dataset and the process of constructing high-order feature interactions\ncontain significant noise, which limits the model's effectiveness. To address\nthese limitations, we propose FSDNet, a CTR prediction framework incorporating\na plug-and-play fusion self-distillation module. Specifically, FSDNet forms\nconnections between explicit and implicit feature interactions at each layer,\nenhancing the sharing of information between different features. The deepest\nfusion layer is then used as the teacher model, utilizing self-distillation to\nguide the training of shallow layers. Empirical evaluation across four\nbenchmark datasets validates the framework's efficacy and generalization\ncapabilities. The code is available on\nhttps://anonymous.4open.science/r/FSDNet.\n","authors":["Lei Sang","Qiuze Ru","Honghao Li","Yiwen Zhang","Qian Cao","Xindong Wu"],"pdf_url":"https://arxiv.org/pdf/2411.07508v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08334v1","updated":"2024-11-13T04:32:58Z","published":"2024-11-13T04:32:58Z","title":"Enhancing Multimodal Query Representation via Visual Dialogues for\n  End-to-End Knowledge Retrieval","summary":"  Existing multimodal retrieval systems often rely on disjointed models for\nimage comprehension, such as object detectors and caption generators, leading\nto cumbersome implementations and training processes. To overcome this\nlimitation, we propose an end-to-end retrieval system, Ret-XKnow, to endow a\ntext retriever with the ability to understand multimodal queries via dynamic\nmodality interaction. Ret-XKnow leverages a partial convolution mechanism to\nfocus on visual information relevant to the given textual query, thereby\nenhancing multimodal query representations. To effectively learn multimodal\ninteraction, we also introduce the Visual Dialogue-to-Retrieval (ViD2R) dataset\nautomatically constructed from visual dialogue datasets. Our dataset\nconstruction process ensures that the dialogues are transformed into suitable\ninformation retrieval tasks using a text retriever. We demonstrate that our\napproach not only significantly improves retrieval performance in zero-shot\nsettings but also achieves substantial improvements in fine-tuning scenarios.\nOur code is publicly available: https://github.com/yeongjoonJu/Ret_XKnow.\n","authors":["Yeong-Joon Ju","Ho-Joong Kim","Seong-Whan Lee"],"pdf_url":"https://arxiv.org/pdf/2411.08334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08275v1","updated":"2024-11-13T01:12:35Z","published":"2024-11-13T01:12:35Z","title":"A Large-Scale Study of Relevance Assessments with Large Language Models:\n  An Initial Look","summary":"  The application of large language models to provide relevance assessments\npresents exciting opportunities to advance information retrieval, natural\nlanguage processing, and beyond, but to date many unknowns remain. This paper\nreports on the results of a large-scale evaluation (the TREC 2024 RAG Track)\nwhere four different relevance assessment approaches were deployed in situ: the\n\"standard\" fully manual process that NIST has implemented for decades and three\ndifferent alternatives that take advantage of LLMs to different extents using\nthe open-source UMBRELA tool. This setup allows us to correlate system rankings\ninduced by the different approaches to characterize tradeoffs between cost and\nquality. We find that in terms of nDCG@20, nDCG@100, and Recall@100, system\nrankings induced by automatically generated relevance assessments from UMBRELA\ncorrelate highly with those induced by fully manual assessments across a\ndiverse set of 77 runs from 19 teams. Our results suggest that automatically\ngenerated UMBRELA judgments can replace fully manual judgments to accurately\ncapture run-level effectiveness. Surprisingly, we find that LLM assistance does\nnot appear to increase correlation with fully manual assessments, suggesting\nthat costs associated with human-in-the-loop processes do not bring obvious\ntangible benefits. Overall, human assessors appear to be stricter than UMBRELA\nin applying relevance criteria. Our work validates the use of LLMs in academic\nTREC-style evaluations and provides the foundation for future studies.\n","authors":["Shivani Upadhyay","Ronak Pradeep","Nandan Thakur","Daniel Campos","Nick Craswell","Ian Soboroff","Hoa Trang Dang","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.08275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09065v1","updated":"2024-11-13T22:45:52Z","published":"2024-11-13T22:45:52Z","title":"Language-Model Prior Overcomes Cold-Start Items","summary":"  The growth of recommender systems (RecSys) is driven by digitization and the\nneed for personalized content in areas such as e-commerce and video streaming.\nThe content in these systems often changes rapidly and therefore they\nconstantly face the ongoing cold-start problem, where new items lack\ninteraction data and are hard to value. Existing solutions for the cold-start\nproblem, such as content-based recommenders and hybrid methods, leverage item\nmetadata to determine item similarities. The main challenge with these methods\nis their reliance on structured and informative metadata to capture detailed\nitem similarities, which may not always be available. This paper introduces a\nnovel approach for cold-start item recommendation that utilizes the language\nmodel (LM) to estimate item similarities, which are further integrated as a\nBayesian prior with classic recommender systems. This approach is generic and\nable to boost the performance of various recommenders. Specifically, our\nexperiments integrate it with both sequential and collaborative filtering-based\nrecommender and evaluate it on two real-world datasets, demonstrating the\nenhanced performance of the proposed approach.\n","authors":["Shiyu Wang","Hao Ding","Yupeng Gu","Sergul Aydore","Kousha Kalantari","Branislav Kveton"],"pdf_url":"https://arxiv.org/pdf/2411.09065v1.pdf","comment":"This paper is dedicated to cold-start item recommendation using\n  language-model priors"},{"id":"http://arxiv.org/abs/2411.09053v1","updated":"2024-11-13T22:23:28Z","published":"2024-11-13T22:23:28Z","title":"Information Need in Metaverse Recordings - A Field Study","summary":"  Metaverse Recordings (MVRs) represent an emerging and underexplored media\ntype within the field of Multimedia Information Retrieval (MMIR). This paper\npresents findings from a field study aimed at understanding the users\ninformation needs and search behaviors specific to MVR retrieval. By conducting\nand analyzing expert interviews, the study identifies application scenarios and\nhighlights challenges in retrieving multimedia content from the metaverse. The\nresults reveal existing application scenarios of MVRs and confirm the relevance\nof capturing time-series data from the graphical rendering process and related\ninput-output devices, which are also highly relevant to user needs.\nFurthermore, the study provides a foundation for developing retrieval systems\ntailored to MVRs by defining use cases, user stereotypes, and specific\nrequirements for MVR Retrieval systems. The findings contribute to a better\nunderstanding of information search behaviors in MVR Retrieval and pave the way\nfor future research and system design in this field.\n","authors":["Patrick Steinert","Jan Mischkies","Stefan Wagenpfeil","Ingo Frommholz","Matthias L. Hemmje"],"pdf_url":"https://arxiv.org/pdf/2411.09053v1.pdf","comment":"12 pages, 3 Figures, 8 Tables"},{"id":"http://arxiv.org/abs/2411.09053v1","updated":"2024-11-13T22:23:28Z","published":"2024-11-13T22:23:28Z","title":"Information Need in Metaverse Recordings -- A Field Study","summary":"  Metaverse Recordings (MVRs) represent an emerging and underexplored media\ntype within the field of Multimedia Information Retrieval (MMIR). This paper\npresents findings from a field study aimed at understanding the users\ninformation needs and search behaviors specific to MVR retrieval. By conducting\nand analyzing expert interviews, the study identifies application scenarios and\nhighlights challenges in retrieving multimedia content from the metaverse. The\nresults reveal existing application scenarios of MVRs and confirm the relevance\nof capturing time-series data from the graphical rendering process and related\ninput-output devices, which are also highly relevant to user needs.\nFurthermore, the study provides a foundation for developing retrieval systems\ntailored to MVRs by defining use cases, user stereotypes, and specific\nrequirements for MVR Retrieval systems. The findings contribute to a better\nunderstanding of information search behaviors in MVR Retrieval and pave the way\nfor future research and system design in this field.\n","authors":["Patrick Steinert","Jan Mischkies","Stefan Wagenpfeil","Ingo Frommholz","Matthias L. Hemmje"],"pdf_url":"https://arxiv.org/pdf/2411.09053v1.pdf","comment":"12 pages, 3 Figures, 8 Tables"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.08878v1","updated":"2024-11-13T18:55:10Z","published":"2024-11-13T18:55:10Z","title":"A Short Note on Evaluating RepNet for Temporal Repetition Counting in\n  Videos","summary":"  We discuss some consistent issues on how RepNet has been evaluated in various\npapers. As a way to mitigate these issues, we report RepNet performance results\non different datasets, and release evaluation code and the RepNet checkpoint to\nobtain these results. Code URL:\nhttps://github.com/google-research/google-research/blob/master/repnet/\n","authors":["Debidatta Dwibedi","Yusuf Aytar","Jonathan Tompson","Pierre Sermanet","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2411.08878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08870v1","updated":"2024-11-13T18:50:13Z","published":"2024-11-13T18:50:13Z","title":"The Limited Impact of Medical Adaptation of Large Language and\n  Vision-Language Models","summary":"  Several recent works seek to develop foundation models specifically for\nmedical applications, adapting general-purpose large language models (LLMs) and\nvision-language models (VLMs) via continued pretraining on publicly available\nbiomedical corpora. These works typically claim that such domain-adaptive\npretraining (DAPT) improves performance on downstream medical tasks, such as\nanswering medical licensing exam questions. In this paper, we compare ten\npublic \"medical\" LLMs and two VLMs against their corresponding base models,\narriving at a different conclusion: all medical VLMs and nearly all medical\nLLMs fail to consistently improve over their base models in the zero-/few-shot\nprompting and supervised fine-tuning regimes for medical question-answering\n(QA). For instance, across all tasks and model pairs we consider in the 3-shot\nsetting, medical LLMs only outperform their base models in 22.7% of cases,\nreach a (statistical) tie in 36.8% of cases, and are significantly worse than\ntheir base models in the remaining 40.5% of cases. Our conclusions are based on\n(i) comparing each medical model head-to-head, directly against the\ncorresponding base model; (ii) optimizing the prompts for each model separately\nin zero-/few-shot prompting; and (iii) accounting for statistical uncertainty\nin comparisons. While these basic practices are not consistently adopted in the\nliterature, our ablations show that they substantially impact conclusions.\nMeanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs\ncan show performance improvements, but the benefits do not carry over to tasks\nbased on clinical notes. Our findings suggest that state-of-the-art\ngeneral-domain models may already exhibit strong medical knowledge and\nreasoning capabilities, and offer recommendations to strengthen the conclusions\nof future studies.\n","authors":["Daniel P. Jeong","Pranav Mani","Saurabh Garg","Zachary C. Lipton","Michael Oberst"],"pdf_url":"https://arxiv.org/pdf/2411.08870v1.pdf","comment":"Extended version of EMNLP 2024 paper arXiv:2411.04118. Includes\n  additional results on clinical note QA tasks and supervised fine-tuning\n  evaluations"},{"id":"http://arxiv.org/abs/2411.08867v1","updated":"2024-11-13T18:48:51Z","published":"2024-11-13T18:48:51Z","title":"Unsupervised Parameter-free Outlier Detection using HDBSCAN* Outlier\n  Profiles","summary":"  In machine learning and data mining, outliers are data points that\nsignificantly differ from the dataset and often introduce irrelevant\ninformation that can induce bias in its statistics and models. Therefore,\nunsupervised methods are crucial to detect outliers if there is limited or no\ninformation about them. Global-Local Outlier Scores based on Hierarchies\n(GLOSH) is an unsupervised outlier detection method within HDBSCAN*, a\nstate-of-the-art hierarchical clustering method. GLOSH estimates outlier scores\nfor each data point by comparing its density to the highest density of the\nregion they reside in the HDBSCAN* hierarchy. GLOSH may be sensitive to\nHDBSCAN*'s minpts parameter that influences density estimation. With limited\nknowledge about the data, choosing an appropriate minpts value beforehand is\nchallenging as one or some minpts values may better represent the underlying\ncluster structure than others. Additionally, in the process of searching for\n``potential outliers'', one has to define the number of outliers n a dataset\nhas, which may be impractical and is often unknown. In this paper, we propose\nan unsupervised strategy to find the ``best'' minpts value, leveraging the\nrange of GLOSH scores across minpts values to identify the value for which\nGLOSH scores can best identify outliers from the rest of the dataset. Moreover,\nwe propose an unsupervised strategy to estimate a threshold for classifying\npoints into inliers and (potential) outliers without the need to pre-define any\nvalue. Our experiments show that our strategies can automatically find the\nminpts value and threshold that yield the best or near best outlier detection\nresults using GLOSH.\n","authors":["Kushankur Ghosh","Murilo Coelho Naldi","J√∂rg Sander","Euijin Choo"],"pdf_url":"https://arxiv.org/pdf/2411.08867v1.pdf","comment":"Accepted at IEEE International Conference on Big Data, IEEE BigData\n  2024"},{"id":"http://arxiv.org/abs/2411.08862v1","updated":"2024-11-13T18:44:30Z","published":"2024-11-13T18:44:30Z","title":"LLMStinger: Jailbreaking LLMs using RL fine-tuned LLMs","summary":"  We introduce LLMStinger, a novel approach that leverages Large Language\nModels (LLMs) to automatically generate adversarial suffixes for jailbreak\nattacks. Unlike traditional methods, which require complex prompt engineering\nor white-box access, LLMStinger uses a reinforcement learning (RL) loop to\nfine-tune an attacker LLM, generating new suffixes based on existing attacks\nfor harmful questions from the HarmBench benchmark. Our method significantly\noutperforms existing red-teaming approaches (we compared against 15 of the\nlatest methods), achieving a +57.2% improvement in Attack Success Rate (ASR) on\nLLaMA2-7B-chat and a +50.3% ASR increase on Claude 2, both models known for\ntheir extensive safety measures. Additionally, we achieved a 94.97% ASR on\nGPT-3.5 and 99.4% on Gemma-2B-it, demonstrating the robustness and adaptability\nof LLMStinger across open and closed-source models.\n","authors":["Piyush Jha","Arnav Arora","Vijay Ganesh"],"pdf_url":"https://arxiv.org/pdf/2411.08862v1.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2411.08861v1","updated":"2024-11-13T18:42:34Z","published":"2024-11-13T18:42:34Z","title":"Interaction Testing in Variation Analysis","summary":"  Relationships of cause and effect are of prime importance for explaining\nscientific phenomena. Often, rather than just understanding the effects of\ncauses, researchers also wish to understand how a cause $X$ affects an outcome\n$Y$ mechanistically -- i.e., what are the causal pathways that are activated\nbetween $X$ and $Y$. For analyzing such questions, a range of methods has been\ndeveloped over decades under the rubric of causal mediation analysis.\nTraditional mediation analysis focuses on decomposing the average treatment\neffect (ATE) into direct and indirect effects, and therefore focuses on the ATE\nas the central quantity. This corresponds to providing explanations for\nassociations in the interventional regime, such as when the treatment $X$ is\nrandomized. Commonly, however, it is of interest to explain associations in the\nobservational regime, and not just in the interventional regime. In this paper,\nwe introduce \\text{variation analysis}, an extension of mediation analysis that\nfocuses on the total variation (TV) measure between $X$ and $Y$, written as\n$\\mathrm{E}[Y \\mid X=x_1] - \\mathrm{E}[Y \\mid X=x_0]$. The TV measure\nencompasses both causal and confounded effects, as opposed to the ATE which\nonly encompasses causal (direct and mediated) variations. In this way, the TV\nmeasure is suitable for providing explanations in the natural regime and\nanswering questions such as ``why is $X$ associated with $Y$?''. Our focus is\non decomposing the TV measure, in a way that explicitly includes direct,\nindirect, and confounded variations. Furthermore, we also decompose the TV\nmeasure to include interaction terms between these different pathways.\nSubsequently, interaction testing is introduced, involving hypothesis tests to\ndetermine if interaction terms are significantly different from zero. If\ninteractions are not significant, more parsimonious decompositions of the TV\nmeasure can be used.\n","authors":["Drago Plecko"],"pdf_url":"https://arxiv.org/pdf/2411.08861v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13880v4","updated":"2024-11-13T18:31:18Z","published":"2024-04-22T05:07:02Z","title":"Regional Style and Color Transfer","summary":"  This paper presents a novel contribution to the field of regional style\ntransfer. Existing methods often suffer from the drawback of applying style\nhomogeneously across the entire image, leading to stylistic inconsistencies or\nforeground object twisted when applied to image with foreground elements such\nas person figures. To address this limitation, we propose a new approach that\nleverages a segmentation network to precisely isolate foreground objects within\nthe input image. Subsequently, style transfer is applied exclusively to the\nbackground region. The isolated foreground objects are then carefully\nreintegrated into the style-transferred background. To enhance the visual\ncoherence between foreground and background, a color transfer step is employed\non the foreground elements prior to their rein-corporation. Finally, we utilize\nfeathering techniques to achieve a seamless amalgamation of foreground and\nbackground, resulting in a visually unified and aesthetically pleasing final\ncomposition. Extensive evaluations demonstrate that our proposed approach\nyields significantly more natural stylistic transformations compared to\nconventional methods.\n","authors":["Zhicheng Ding","Panfeng Li","Qikai Yang","Siyang Li","Qingtian Gong"],"pdf_url":"https://arxiv.org/pdf/2404.13880v4.pdf","comment":"Accepted by 2024 5th International Conference on Computer Vision,\n  Image and Deep Learning"},{"id":"http://arxiv.org/abs/2411.08849v1","updated":"2024-11-13T18:29:58Z","published":"2024-11-13T18:29:58Z","title":"Oblique Bayesian additive regression trees","summary":"  Current implementations of Bayesian Additive Regression Trees (BART) are\nbased on axis-aligned decision rules that recursively partition the feature\nspace using a single feature at a time. Several authors have demonstrated that\noblique trees, whose decision rules are based on linear combinations of\nfeatures, can sometimes yield better predictions than axis-aligned trees and\nexhibit excellent theoretical properties. We develop an oblique version of BART\nthat leverages a data-adaptive decision rule prior that recursively partitions\nthe feature space along random hyperplanes. Using several synthetic and\nreal-world benchmark datasets, we systematically compared our oblique BART\nimplementation to axis-aligned BART and other tree ensemble methods, finding\nthat oblique BART was competitive with -- and sometimes much better than --\nthose methods.\n","authors":["Paul-Hieu V. Nguyen","Ryan Yee","Sameer K. Deshpande"],"pdf_url":"https://arxiv.org/pdf/2411.08849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06438v2","updated":"2024-11-13T18:21:22Z","published":"2024-07-08T22:40:15Z","title":"A Single Transformer for Scalable Vision-Language Modeling","summary":"  We present SOLO, a single transformer for Scalable visiOn-Language mOdeling.\nCurrent large vision-language models (LVLMs) such as LLaVA mostly employ\nheterogeneous architectures that connect pre-trained visual encoders with large\nlanguage models (LLMs) to facilitate visual recognition and complex reasoning.\nAlthough achieving remarkable performance with relatively lightweight training,\nwe identify four primary scalability limitations: (1) The visual capacity is\nconstrained by pre-trained visual encoders, which are typically an order of\nmagnitude smaller than LLMs. (2) The heterogeneous architecture complicates the\nuse of established hardware and software infrastructure. (3) Study of scaling\nlaws on such architecture must consider three separate components - visual\nencoder, connector, and LLMs, which complicates the analysis. (4) The use of\nexisting visual encoders typically requires following a pre-defined\nspecification of image inputs pre-processing, for example, by reshaping inputs\nto fixed-resolution square images, which presents difficulties in processing\nand training on high-resolution images or those with unusual aspect ratio. A\nunified single Transformer architecture, like SOLO, effectively addresses these\nscalability concerns in LVLMs; however, its limited adoption in the modern\ncontext likely stems from the absence of reliable training recipes that balance\nboth modalities and ensure stable training for billion-scale models. In this\npaper, we introduce the first open-source training recipe for developing SOLO,\nan open-source 7B LVLM using moderate academic resources. The training recipe\ninvolves initializing from LLMs, sequential pre-training on ImageNet and\nweb-scale data, and instruction fine-tuning on our curated high-quality\ndatasets. On extensive evaluation, SOLO demonstrates performance comparable to\nLLaVA-v1.5-7B, particularly excelling in visual mathematical reasoning.\n","authors":["Yangyi Chen","Xingyao Wang","Hao Peng","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2407.06438v2.pdf","comment":"Accepted to TMLR"},{"id":"http://arxiv.org/abs/2411.08832v1","updated":"2024-11-13T18:12:15Z","published":"2024-11-13T18:12:15Z","title":"Offline Adaptation of Quadruped Locomotion using Diffusion Models","summary":"  We present a diffusion-based approach to quadrupedal locomotion that\nsimultaneously addresses the limitations of learning and interpolating between\nmultiple skills and of (modes) offline adapting to new locomotion behaviours\nafter training. This is the first framework to apply classifier-free guided\ndiffusion to quadruped locomotion and demonstrate its efficacy by extracting\ngoal-conditioned behaviour from an originally unlabelled dataset. We show that\nthese capabilities are compatible with a multi-skill policy and can be applied\nwith little modification and minimal compute overhead, i.e., running entirely\non the robots onboard CPU. We verify the validity of our approach with hardware\nexperiments on the ANYmal quadruped platform.\n","authors":["Reece O'Mahoney","Alexander L. Mitchell","Wanming Yu","Ingmar Posner","Ioannis Havoutis"],"pdf_url":"https://arxiv.org/pdf/2411.08832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08821v1","updated":"2024-11-13T17:59:44Z","published":"2024-11-13T17:59:44Z","title":"Model agnostic local variable importance for locally dependent\n  relationships","summary":"  Global variable importance measures are commonly used to interpret machine\nlearning model results. Local variable importance techniques assess how\nvariables contribute to individual observations rather than the entire dataset.\nCurrent methods typically fail to accurately reflect locally dependent\nrelationships between variables and instead focus on marginal importance\nvalues. Additionally, they are not natively adapted for multi-class\nclassification problems. We propose a new model-agnostic method for calculating\nlocal variable importance, CLIQUE, that captures locally dependent\nrelationships, contains improvements over permutation-based methods, and can be\ndirectly applied to multi-class classification problems. Simulated and\nreal-world examples show that CLIQUE emphasizes locally dependent information\nand properly reduces bias in regions where variables do not affect the\nresponse.\n","authors":["Kelvyn K. Bladen","Adele Cutler","D. Richard Cutler","Kevin R. Moon"],"pdf_url":"https://arxiv.org/pdf/2411.08821v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08814v1","updated":"2024-11-13T17:53:23Z","published":"2024-11-13T17:53:23Z","title":"Process-aware Human Activity Recognition","summary":"  Humans naturally follow distinct patterns when conducting their daily\nactivities, which are driven by established practices and processes, such as\nproduction workflows, social norms and daily routines. Human activity\nrecognition (HAR) algorithms usually use neural networks or machine learning\ntechniques to analyse inherent relationships within the data. However, these\napproaches often overlook the contextual information in which the data are\ngenerated, potentially limiting their effectiveness. We propose a novel\napproach that incorporates process information from context to enhance the HAR\nperformance. Specifically, we align probabilistic events generated by machine\nlearning models with process models derived from contextual information. This\nalignment adaptively weighs these two sources of information to optimise HAR\naccuracy. Our experiments demonstrate that our approach achieves better\naccuracy and Macro F1-score compared to baseline models.\n","authors":["Jiawei Zheng","Petros Papapanagiotou","Jacques D. Fleuriot","Jane Hillston"],"pdf_url":"https://arxiv.org/pdf/2411.08814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01600v3","updated":"2024-11-13T17:41:43Z","published":"2024-08-02T23:11:42Z","title":"Physics-Informed Geometry-Aware Neural Operator","summary":"  Engineering design problems often involve solving parametric Partial\nDifferential Equations (PDEs) under variable PDE parameters and domain\ngeometry. Recently, neural operators have shown promise in learning PDE\noperators and quickly predicting the PDE solutions. However, training these\nneural operators typically requires large datasets, the acquisition of which\ncan be prohibitively expensive. To overcome this, physics-informed training\noffers an alternative way of building neural operators, eliminating the high\ncomputational costs associated with Finite Element generation of training data.\nNevertheless, current physics-informed neural operators struggle with\nlimitations, either in handling varying domain geometries or varying PDE\nparameters. In this research, we introduce a novel method, the Physics-Informed\nGeometry-Aware Neural Operator (PI-GANO), designed to simultaneously generalize\nacross both PDE parameters and domain geometries. We adopt a geometry encoder\nto capture the domain geometry features, and design a novel pipeline to\nintegrate this component within the existing DCON architecture. Numerical\nresults demonstrate the accuracy and efficiency of the proposed method. All the\ncodes and data related to this work are available on GitHub:\nhttps://github.com/WeihengZ/Physics-informed-Neural-Foundation-Operator.\n","authors":["Weiheng Zhong","Hadi Meidani"],"pdf_url":"https://arxiv.org/pdf/2408.01600v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2404.13646"},{"id":"http://arxiv.org/abs/2411.08804v1","updated":"2024-11-13T17:38:07Z","published":"2024-11-13T17:38:07Z","title":"FinRobot: AI Agent for Equity Research and Valuation with Large Language\n  Models","summary":"  As financial markets grow increasingly complex, there is a rising need for\nautomated tools that can effectively assist human analysts in equity research,\nparticularly within sell-side research. While Generative AI (GenAI) has\nattracted significant attention in this field, existing AI solutions often fall\nshort due to their narrow focus on technical factors and limited capacity for\ndiscretionary judgment. These limitations hinder their ability to adapt to new\ndata in real-time and accurately assess risks, which diminishes their practical\nvalue for investors.\n  This paper presents FinRobot, the first AI agent framework specifically\ndesigned for equity research. FinRobot employs a multi-agent Chain of Thought\n(CoT) system, integrating both quantitative and qualitative analyses to emulate\nthe comprehensive reasoning of a human analyst. The system is structured around\nthree specialized agents: the Data-CoT Agent, which aggregates diverse data\nsources for robust financial integration; the Concept-CoT Agent, which mimics\nan analysts reasoning to generate actionable insights; and the Thesis-CoT\nAgent, which synthesizes these insights into a coherent investment thesis and\nreport. FinRobot provides thorough company analysis supported by precise\nnumerical data, industry-appropriate valuation metrics, and realistic risk\nassessments. Its dynamically updatable data pipeline ensures that research\nremains timely and relevant, adapting seamlessly to new financial information.\nUnlike existing automated research tools, such as CapitalCube and Wright\nReports, FinRobot delivers insights comparable to those produced by major\nbrokerage firms and fundamental research vendors. We open-source FinRobot at\n\\url{https://github. com/AI4Finance-Foundation/FinRobot}.\n","authors":["Tianyu Zhou","Pinqiao Wang","Yilin Wu","Hongyang Yang"],"pdf_url":"https://arxiv.org/pdf/2411.08804v1.pdf","comment":"The 1st Workshop on LLMs and Generative AI for Finance, ICAIF 2024"},{"id":"http://arxiv.org/abs/2410.16527v2","updated":"2024-11-13T17:30:33Z","published":"2024-10-21T21:36:03Z","title":"Insights and Current Gaps in Open-Source LLM Vulnerability Scanners: A\n  Comparative Analysis","summary":"  This report presents a comparative analysis of open-source vulnerability\nscanners for conversational large language models (LLMs). As LLMs become\nintegral to various applications, they also present potential attack surfaces,\nexposed to security risks such as information leakage and jailbreak attacks.\nOur study evaluates prominent scanners - Garak, Giskard, PyRIT, and\nCyberSecEval - that adapt red-teaming practices to expose these\nvulnerabilities. We detail the distinctive features and practical use of these\nscanners, outline unifying principles of their design and perform quantitative\nevaluations to compare them. These evaluations uncover significant reliability\nissues in detecting successful attacks, highlighting a fundamental gap for\nfuture development. Additionally, we contribute a preliminary labelled dataset,\nwhich serves as an initial step to bridge this gap. Based on the above, we\nprovide strategic recommendations to assist organizations choose the most\nsuitable scanner for their red-teaming needs, accounting for customizability,\ntest suite comprehensiveness, and industry-specific use cases.\n","authors":["Jonathan Brokman","Omer Hofman","Oren Rachmil","Inderjeet Singh","Rathina Sabapathy Aishvariya Priya","Vikas Pahuja","Amit Giloni","Roman Vainshtein","Hisashi Kojima"],"pdf_url":"https://arxiv.org/pdf/2410.16527v2.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2410.24164v3","updated":"2024-11-13T17:30:10Z","published":"2024-10-31T17:22:30Z","title":"$œÄ_0$: A Vision-Language-Action Flow Model for General Robot Control","summary":"  Robot learning holds tremendous promise to unlock the full potential of\nflexible, general, and dexterous robot systems, as well as to address some of\nthe deepest questions in artificial intelligence. However, bringing robot\nlearning to the level of generality required for effective real-world systems\nfaces major obstacles in terms of data, generalization, and robustness. In this\npaper, we discuss how generalist robot policies (i.e., robot foundation models)\ncan address these challenges, and how we can design effective generalist robot\npolicies for complex and highly dexterous tasks. We propose a novel flow\nmatching architecture built on top of a pre-trained vision-language model (VLM)\nto inherit Internet-scale semantic knowledge. We then discuss how this model\ncan be trained on a large and diverse dataset from multiple dexterous robot\nplatforms, including single-arm robots, dual-arm robots, and mobile\nmanipulators. We evaluate our model in terms of its ability to perform tasks in\nzero shot after pre-training, follow language instructions from people and from\na high-level VLM policy, and its ability to acquire new skills via fine-tuning.\nOur results cover a wide variety of tasks, such as laundry folding, table\ncleaning, and assembling boxes.\n","authors":["Kevin Black","Noah Brown","Danny Driess","Adnan Esmail","Michael Equi","Chelsea Finn","Niccolo Fusai","Lachy Groom","Karol Hausman","Brian Ichter","Szymon Jakubczak","Tim Jones","Liyiming Ke","Sergey Levine","Adrian Li-Bell","Mohith Mothukuri","Suraj Nair","Karl Pertsch","Lucy Xiaoyang Shi","James Tanner","Quan Vuong","Anna Walling","Haohuan Wang","Ury Zhilinsky"],"pdf_url":"https://arxiv.org/pdf/2410.24164v3.pdf","comment":"See project website for videos:\n  https://physicalintelligence.company/blog/pi0"},{"id":"http://arxiv.org/abs/2411.08800v1","updated":"2024-11-13T17:27:32Z","published":"2024-11-13T17:27:32Z","title":"Deep Learning Accelerated Quantum Transport Simulations in\n  Nanoelectronics: From Break Junctions to Field-Effect Transistors","summary":"  Quantum transport calculations are essential for understanding and designing\nnanoelectronic devices, yet the trade-off between accuracy and computational\nefficiency has long limited their practical applications. We present a general\nframework that combines the deep learning tight-binding Hamiltonian (DeePTB)\napproach with the non-equilibrium Green's Function (NEGF) method, enabling\nefficient quantum transport calculations while maintaining first-principles\naccuracy. We demonstrate the capabilities of the DeePTB-NEGF framework through\ntwo representative applications: comprehensive simulation of break junction\nsystems, where conductance histograms show good agreement with experimental\nmeasurements in both metallic contact and single-molecule junction cases; and\nsimulation of carbon nanotube field effect transistors through self-consistent\nNEGF-Poisson calculations, capturing essential physics including the\nelectrostatic potential and transfer characteristic curves under finite bias\nconditions. This framework bridges the gap between first-principles accuracy\nand computational efficiency, providing a powerful tool for high-throughput\nquantum transport simulations across different scales in nanoelectronics.\n","authors":["Jijie Zou","Zhanghao Zhouyin","Dongying Lin","Linfeng Zhang","Shimin Hou","Qiangqiang Gu"],"pdf_url":"https://arxiv.org/pdf/2411.08800v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2404.13646v4","updated":"2024-11-13T17:26:36Z","published":"2024-04-21T12:41:30Z","title":"Physics-informed Discretization-independent Deep Compositional Operator\n  Network","summary":"  Solving parametric Partial Differential Equations (PDEs) for a broad range of\nparameters is a critical challenge in scientific computing. To this end, neural\noperators, which \\textcolor{black}{predicts the PDE solution with variable PDE\nparameter inputs}, have been successfully used. However, the training of neural\noperators typically demands large training datasets, the acquisition of which\ncan be prohibitively expensive. To address this challenge, physics-informed\ntraining can offer a cost-effective strategy. However, current physics-informed\nneural operators face limitations, either in handling irregular domain shapes\nor in in generalizing to various discrete representations of PDE parameters. In\nthis research, we introduce a novel physics-informed model architecture which\ncan generalize to various discrete representations of PDE parameters and\nirregular domain shapes. Particularly, inspired by deep operator neural\nnetworks, our model involves a discretization-independent learning of parameter\nembedding repeatedly, and this parameter embedding is integrated with the\nresponse embeddings through multiple compositional layers, for more\nexpressivity. Numerical results demonstrate the accuracy and efficiency of the\nproposed method. All the codes and data related to this work are available on\nGitHub: https://github.com/WeihengZ/PI-DCON.\n","authors":["Weiheng Zhong","Hadi Meidani"],"pdf_url":"https://arxiv.org/pdf/2404.13646v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08798v1","updated":"2024-11-13T17:25:25Z","published":"2024-11-13T17:25:25Z","title":"Learning Gaussian Multi-Index Models with Gradient Flow: Time Complexity\n  and Directional Convergence","summary":"  This work focuses on the gradient flow dynamics of a neural network model\nthat uses correlation loss to approximate a multi-index function on\nhigh-dimensional standard Gaussian data. Specifically, the multi-index function\nwe consider is a sum of neurons $f^*(x) \\!=\\! \\sum_{j=1}^k \\! \\sigma^*(v_j^T\nx)$ where $v_1, \\dots, v_k$ are unit vectors, and $\\sigma^*$ lacks the first\nand second Hermite polynomials in its Hermite expansion. It is known that, for\nthe single-index case ($k\\!=\\!1$), overcoming the search phase requires\npolynomial time complexity. We first generalize this result to multi-index\nfunctions characterized by vectors in arbitrary directions. After the search\nphase, it is not clear whether the network neurons converge to the index\nvectors, or get stuck at a sub-optimal solution. When the index vectors are\northogonal, we give a complete characterization of the fixed points and prove\nthat neurons converge to the nearest index vectors. Therefore, using $n \\!\n\\asymp \\! k \\log k$ neurons ensures finding the full set of index vectors with\ngradient flow with high probability over random initialization. When $ v_i^T\nv_j \\!=\\! \\beta \\! \\geq \\! 0$ for all $i \\neq j$, we prove the existence of a\nsharp threshold $\\beta_c \\!=\\! c/(c+k)$ at which the fixed point that computes\nthe average of the index vectors transitions from a saddle point to a minimum.\nNumerical simulations show that using a correlation loss and a mild\noverparameterization suffices to learn all of the index vectors when they are\nnearly orthogonal, however, the correlation loss fails when the dot product\nbetween the index vectors exceeds a certain threshold.\n","authors":["Berfin Simsek","Amire Bendjeddou","Daniel Hsu"],"pdf_url":"https://arxiv.org/pdf/2411.08798v1.pdf","comment":"21 pages, 6 figures, under review by AISTATS 2025"},{"id":"http://arxiv.org/abs/2411.08791v1","updated":"2024-11-13T17:17:16Z","published":"2024-11-13T17:17:16Z","title":"Locally Private Sampling with Public Data","summary":"  Local differential privacy (LDP) is increasingly employed in\nprivacy-preserving machine learning to protect user data before sharing it with\nan untrusted aggregator. Most LDP methods assume that users possess only a\nsingle data record, which is a significant limitation since users often gather\nextensive datasets (e.g., images, text, time-series data) and frequently have\naccess to public datasets. To address this limitation, we propose a locally\nprivate sampling framework that leverages both the private and public datasets\nof each user. Specifically, we assume each user has two distributions: $p$ and\n$q$ that represent their private dataset and the public dataset, respectively.\nThe objective is to design a mechanism that generates a private sample\napproximating $p$ while simultaneously preserving $q$. We frame this objective\nas a minimax optimization problem using $f$-divergence as the utility measure.\nWe fully characterize the minimax optimal mechanisms for general\n$f$-divergences provided that $p$ and $q$ are discrete distributions.\nRemarkably, we demonstrate that this optimal mechanism is universal across all\n$f$-divergences. Experiments validate the effectiveness of our minimax optimal\nsampler compared to the state-of-the-art locally private sampler.\n","authors":["Behnoosh Zamanlooy","Mario Diaz","Shahab Asoodeh"],"pdf_url":"https://arxiv.org/pdf/2411.08791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08790v1","updated":"2024-11-13T17:16:48Z","published":"2024-11-13T17:16:48Z","title":"Can sparse autoencoders be used to decompose and interpret steering\n  vectors?","summary":"  Steering vectors are a promising approach to control the behaviour of large\nlanguage models. However, their underlying mechanisms remain poorly understood.\nWhile sparse autoencoders (SAEs) may offer a potential method to interpret\nsteering vectors, recent findings show that SAE-reconstructed vectors often\nlack the steering properties of the original vectors. This paper investigates\nwhy directly applying SAEs to steering vectors yields misleading\ndecompositions, identifying two reasons: (1) steering vectors fall outside the\ninput distribution for which SAEs are designed, and (2) steering vectors can\nhave meaningful negative projections in feature directions, which SAEs are not\ndesigned to accommodate. These limitations hinder the direct use of SAEs for\ninterpreting steering vectors.\n","authors":["Harry Mayne","Yushi Yang","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2411.08790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19552v2","updated":"2024-11-13T17:12:34Z","published":"2024-09-29T04:41:10Z","title":"A Universal Deep Learning Framework for Materials X-ray Absorption\n  Spectra","summary":"  X-ray absorption spectroscopy (XAS) is a powerful characterization technique\nfor probing the local chemical environment of absorbing atoms. However,\nanalyzing XAS data presents significant challenges, often requiring extensive,\ncomputationally intensive simulations, as well as significant domain expertise.\nThese limitations hinder the development of fast, robust XAS analysis pipelines\nthat are essential in high-throughput studies and for autonomous\nexperimentation. We address these challenges with OmniXAS, a framework that\ncontains a suite of transfer learning approaches for XAS prediction, each\ncontributing to improved accuracy and efficiency, as demonstrated on K-edge\nspectra database covering eight 3d transition metals (Ti-Cu). The OmniXAS\nframework is built upon three distinct strategies. First, we use M3GNet to\nderive latent representations of the local chemical environment of absorption\nsites as input for XAS prediction, achieving up to order-of-magnitude\nimprovements over conventional featurization techniques. Second, we employ a\nhierarchical transfer learning strategy, training a universal multi-task model\nacross elements before fine-tuning for element-specific predictions. Models\nbased on this cascaded approach after element-wise fine-tuning outperform\nelement-specific models by up to 69%. Third, we implement cross-fidelity\ntransfer learning, adapting a universal model to predict spectra generated by\nsimulation of a different fidelity with a higher computational cost. This\napproach improves prediction accuracy by up to 11% over models trained on the\ntarget fidelity alone. Our approach boosts the throughput of XAS modeling by\norders of magnitude versus first-principles simulations and is extendable to\nXAS prediction for a broader range of elements. This transfer learning\nframework is generalizable to enhance deep-learning models that target other\nproperties in materials research.\n","authors":["Shubha R. Kharel","Fanchen Meng","Xiaohui Qu","Matthew R. Carbone","Deyu Lu"],"pdf_url":"https://arxiv.org/pdf/2409.19552v2.pdf","comment":"Main manuscript: 22 pages, 11 figures. Supplemental material (12\n  pages, 6 figures) available as a separate file in arXiv ancillary files\n  (additional downloadable files)"},{"id":"http://arxiv.org/abs/2402.03271v3","updated":"2024-11-13T17:10:20Z","published":"2024-02-05T18:28:44Z","title":"Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information\n  Seeking in Large Language Models","summary":"  In the face of uncertainty, the ability to *seek information* is of\nfundamental importance. In many practical applications, such as medical\ndiagnosis and troubleshooting, the information needed to solve the task is not\ninitially given and has to be actively sought by asking follow-up questions\n(for example, a doctor asking a patient for more details about their symptoms).\nIn this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to\naugment large language models with the ability to actively seek information by\nasking effective questions. UoT combines 1) an *uncertainty-aware simulation\napproach* which enables the model to simulate possible future scenarios and how\nlikely they are to occur, 2) *uncertainty-based rewards* motivated by\ninformation gain which incentivizes the model to seek information, and 3) a\n*reward propagation scheme* to select the optimal question to ask in a way that\nmaximizes the expected reward. In experiments on medical diagnosis,\ntroubleshooting, and the `20 Questions` game, UoT achieves an average\nperformance improvement of 38.1% in the rate of successful task completion\nacross multiple LLMs compared with direct prompting and also improves\nefficiency (i.e., the number of questions needed to complete the task). Our\ncode has been released [here](https://github.com/zhiyuanhubj/UoT)\n","authors":["Zhiyuan Hu","Chumin Liu","Xidong Feng","Yilun Zhao","See-Kiong Ng","Anh Tuan Luu","Junxian He","Pang Wei Koh","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2402.03271v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.09322v2","updated":"2024-11-13T17:08:34Z","published":"2024-06-13T17:00:30Z","title":"Active Inference Meeting Energy-Efficient Control of Parallel and\n  Identical Machines","summary":"  We investigate the application of active inference in developing\nenergy-efficient control agents for manufacturing systems. Active inference,\nrooted in neuroscience, provides a unified probabilistic framework integrating\nperception, learning, and action, with inherent uncertainty quantification\nelements. Our study explores deep active inference, an emerging field that\ncombines deep learning with the active inference decision-making framework.\nLeveraging a deep active inference agent, we focus on controlling parallel and\nidentical machine workstations to enhance energy efficiency. We address\nchallenges posed by the problem's stochastic nature and delayed policy response\nby introducing tailored enhancements to existing agent architectures.\nSpecifically, we introduce multi-step transition and hybrid horizon methods to\nmitigate the need for complex planning. Our experimental results demonstrate\nthe effectiveness of these enhancements and highlight the potential of the\nactive inference-based approach.\n","authors":["Yavar Taheri Yeganeh","Mohsen Jafari","Andrea Matta"],"pdf_url":"https://arxiv.org/pdf/2406.09322v2.pdf","comment":"Accepted at the 10th International Conference on Machine Learning,\n  Optimization, and Data Science"},{"id":"http://arxiv.org/abs/2411.08773v1","updated":"2024-11-13T16:58:51Z","published":"2024-11-13T16:58:51Z","title":"Optimal Oblivious Subspace Embeddings with Near-optimal Sparsity","summary":"  An oblivious subspace embedding is a random $m\\times n$ matrix $\\Pi$ such\nthat, for any $d$-dimensional subspace, with high probability $\\Pi$ preserves\nthe norms of all vectors in that subspace within a $1\\pm\\epsilon$ factor. In\nthis work, we give an oblivious subspace embedding with the optimal dimension\n$m=\\Theta(d/\\epsilon^2)$ that has a near-optimal sparsity of $\\tilde\nO(1/\\epsilon)$ non-zero entries per column of $\\Pi$. This is the first result\nto nearly match the conjecture of Nelson and Nguyen [FOCS 2013] in terms of the\nbest sparsity attainable by an optimal oblivious subspace embedding, improving\non a prior bound of $\\tilde O(1/\\epsilon^6)$ non-zeros per column [Chenakkod et\nal., STOC 2024]. We further extend our approach to the non-oblivious setting,\nproposing a new family of Leverage Score Sparsified embeddings with Independent\nColumns, which yield faster runtimes for matrix approximation and regression\ntasks.\n  In our analysis, we develop a new method which uses a decoupling argument\ntogether with the cumulant method for bounding the edge universality error of\nisotropic random matrices. To achieve near-optimal sparsity, we combine this\ngeneral-purpose approach with new traces inequalities that leverage the\nspecific structure of our subspace embedding construction.\n","authors":["Shabarish Chenakkod","Micha≈Ç Derezi≈Ñski","Xiaoyu Dong"],"pdf_url":"https://arxiv.org/pdf/2411.08773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08766v1","updated":"2024-11-13T16:52:30Z","published":"2024-11-13T16:52:30Z","title":"Mapping Methane -- The Impact of Dairy Farm Practices on Emissions\n  Through Satellite Data and Machine Learning","summary":"  This study investigates the correlation between dairy farm characteristics\nand methane concentrations as derived from satellite observations in Eastern\nCanada. Utilizing data from 11 dairy farms collected between January 2020 and\nDecember 2022, we integrated Sentinel-5P satellite methane data with critical\nfarm-level attributes, including herd genetics, feeding practices, and\nmanagement strategies. Initial analyses revealed significant correlations with\nmethane concentrations, leading to the application of Variance Inflation Factor\n(VIF) and Principal Component Analysis (PCA) to address multicollinearity and\nenhance model stability. Subsequently, machine learning models - specifically\nRandom Forest and Neural Networks - were employed to evaluate feature\nimportance and predict methane emissions. Our findings indicate a strong\nnegative correlation between the Estimated Breeding Value (EBV) for protein\npercentage and methane concentrations, suggesting that genetic selection for\nhigher milk protein content could be an effective strategy for emissions\nreduction. The integration of atmospheric transport models with satellite data\nfurther refined our emission estimates, significantly enhancing accuracy and\nspatial resolution. This research underscores the potential of advanced\nsatellite monitoring, machine learning techniques, and atmospheric modeling in\nimproving methane emission assessments within the dairy sector. It emphasizes\nthe critical role of farm-specific characteristics in developing effective\nmitigation strategies. Future investigations should focus on expanding the\ndataset and incorporating inversion modeling for more precise emission\nquantification. Balancing ecological impacts with economic viability will be\nessential for fostering sustainable dairy farming practices.\n","authors":["Hanqing Bi","Suresh Neethirajan"],"pdf_url":"https://arxiv.org/pdf/2411.08766v1.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.08764v1","updated":"2024-11-13T16:49:56Z","published":"2024-11-13T16:49:56Z","title":"Flow reconstruction in time-varying geometries using graph neural\n  networks","summary":"  The paper presents a Graph Attention Convolutional Network (GACN) for flow\nreconstruction from very sparse data in time-varying geometries. The model\nincorporates a feature propagation algorithm as a preprocessing step to handle\nextremely sparse inputs, leveraging information from neighboring nodes to\ninitialize missing features. In addition, a binary indicator is introduced as a\nvalidity mask to distinguish between the original and propagated data points,\nenabling more effective learning from sparse inputs. Trained on a unique data\nset of Direct Numerical Simulations (DNS) of a motored engine at a technically\nrelevant operating condition, the GACN shows robust performance across\ndifferent resolutions and domain sizes and can effectively handle unstructured\ndata and variable input sizes. The model is tested on previously unseen DNS\ndata as well as on an experimental data set from Particle Image Velocimetry\n(PIV) measurements that were not considered during training. A comparative\nanalysis shows that the GACN consistently outperforms both a conventional\nConvolutional Neural Network (CNN) and cubic interpolation methods on the DNS\nand PIV test sets by achieving lower reconstruction errors and better capturing\nfine-scale turbulent structures. In particular, the GACN effectively\nreconstructs flow fields from domains up to 14 times larger than those observed\nduring training, with the performance advantage increasing for larger domains.\n","authors":["Bogdan A. Danciu","Vito A. Pagone","Benjamin B√∂hm","Marius Schmidt","Christos E. Frouzakis"],"pdf_url":"https://arxiv.org/pdf/2411.08764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08760v1","updated":"2024-11-13T16:47:34Z","published":"2024-11-13T16:47:34Z","title":"Energy Dissipation Preserving Physics Informed Neural Network for\n  Allen-Cahn Equations","summary":"  This paper investigates a numerical solution of Allen-Cahn equation with\nconstant and degenerate mobility, with polynomial and logarithmic energy\nfunctionals, with deterministic and random initial functions, and with\nadvective term in one, two, and three spatial dimensions, based on the\nphysics-informed neural network (PINN). To improve the learning capacity of the\nPINN, we incorporate the energy dissipation property of the Allen-Cahn equation\nas a penalty term into the loss function of the network. To facilitate the\nlearning process of random initials, we employ a continuous analogue of the\ninitial random condition by utilizing the Fourier series expansion. Adaptive\nmethods from traditional numerical analysis are also integrated to enhance the\neffectiveness of the proposed PINN. Numerical results indicate a consistent\ndecrease in the discrete energy, while also revealing phenomena such as phase\nseparation and metastability.\n","authors":["Mustafa K√ºt√ºk","Hamdullah Y√ºcel"],"pdf_url":"https://arxiv.org/pdf/2411.08760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13150v2","updated":"2024-11-13T16:46:23Z","published":"2024-03-19T20:58:38Z","title":"On Training Survival Models with Scoring Rules","summary":"  Scoring rules are an established way of comparing predictive performances\nacross model classes. In the context of survival analysis, they require\nadaptation in order to accommodate censoring. This work investigates using\nscoring rules for model training rather than evaluation. Doing so, we establish\na general framework for training survival models that is model agnostic and can\nlearn event time distributions parametrically or non-parametrically. In\naddition, our framework is not restricted to any specific scoring rule. While\nwe focus on neural network-based implementations, we also provide\nproof-of-concept implementations using gradient boosting, generalized additive\nmodels, and trees. Empirical comparisons on synthetic and real-world data\nindicate that scoring rules can be successfully incorporated into model\ntraining and yield competitive predictive performance with established\ntime-to-event models.\n","authors":["Philipp Kopper","David R√ºgamer","Raphael Sonabend","Bernd Bischl","Andreas Bender"],"pdf_url":"https://arxiv.org/pdf/2403.13150v2.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.02538v2","updated":"2024-11-13T16:44:07Z","published":"2024-07-01T23:24:05Z","title":"CGRclust: Chaos Game Representation for Twin Contrastive Clustering of\n  Unlabelled DNA Sequences","summary":"  This study proposes CGRclust, a novel combination of unsupervised twin\ncontrastive clustering of Chaos Game Representations (CGR) of DNA sequences,\nwith convolutional neural networks (CNNs). To the best of our knowledge,\nCGRclust is the first method to use unsupervised learning for image\nclassification (herein applied to two-dimensional CGR images) for clustering\ndatasets of DNA sequences. CGRclust overcomes the limitations of traditional\nsequence classification methods by leveraging unsupervised twin contrastive\nlearning to detect distinctive sequence patterns, without requiring DNA\nsequence alignment or biological/taxonomic labels. CGRclust accurately\nclustered twenty-five diverse datasets, with sequence lengths ranging from 664\nbp to 100 kbp, including mitochondrial genomes of fish, fungi, and protists, as\nwell as viral whole genome assemblies and synthetic DNA sequences. Compared\nwith three recent clustering methods for DNA sequences (DeLUCS, iDeLUCS, and\nMeShClust v3.0.), CGRclust is the only method that surpasses 81.70% accuracy\nacross all four taxonomic levels tested for mitochondrial DNA genomes of fish.\nMoreover, CGRclust also consistently demonstrates superior performance across\nall the viral genomic datasets. The high clustering accuracy of CGRclust on\nthese twenty-five datasets, which vary significantly in terms of sequence\nlength, number of genomes, number of clusters, and level of taxonomy,\ndemonstrates its robustness, scalability, and versatility.\n","authors":["Fatemeh Alipour","Kathleen A. Hill","Lila Kari"],"pdf_url":"https://arxiv.org/pdf/2407.02538v2.pdf","comment":"28 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.08758v1","updated":"2024-11-13T16:42:59Z","published":"2024-11-13T16:42:59Z","title":"ScaleNet: Scale Invariance Learning in Directed Graphs","summary":"  Graph Neural Networks (GNNs) have advanced relational data analysis but lack\ninvariance learning techniques common in image classification. In node\nclassification with GNNs, it is actually the ego-graph of the center node that\nis classified. This research extends the scale invariance concept to node\nclassification by drawing an analogy to image processing: just as scale\ninvariance being used in image classification to capture multi-scale features,\nwe propose the concept of ``scaled ego-graphs''. Scaled ego-graphs generalize\ntraditional ego-graphs by replacing undirected single-edges with\n``scaled-edges'', which are ordered sequences of multiple directed edges. We\nempirically assess the performance of the proposed scale invariance in graphs\non seven benchmark datasets, across both homophilic and heterophilic\nstructures. Our scale-invariance-based graph learning outperforms inception\nmodels derived from random walks by being simpler, faster, and more accurate.\nThe scale invariance explains inception models' success on homophilic graphs\nand limitations on heterophilic graphs. To ensure applicability of inception\nmodel to heterophilic graphs as well, we further present ScaleNet, an\narchitecture that leverages multi-scaled features. ScaleNet achieves\nstate-of-the-art results on five out of seven datasets (four homophilic and one\nheterophilic) and matches top performance on the remaining two, demonstrating\nits excellent applicability. This represents a significant advance in graph\nlearning, offering a unified framework that enhances node classification across\nvarious graph types. Our code is available at\nhttps://github.com/Qin87/ScaleNet/tree/July25.\n","authors":["Qin Jiang","Chengjia Wang","Michael Lones","Wei Pang"],"pdf_url":"https://arxiv.org/pdf/2411.08758v1.pdf","comment":"Scale invariance in node classification is demonstrated and applied\n  in graph transformation to develop ScaleNet, which achieves state-of-the-art\n  performance on both homophilic and heterophilic directed graphs"},{"id":"http://arxiv.org/abs/2310.10545v3","updated":"2024-11-13T16:42:52Z","published":"2023-10-16T16:14:43Z","title":"Optimal vintage factor analysis with deflation varimax","summary":"  Vintage factor analysis is one important type of factor analysis that aims to\nfirst find a low-dimensional representation of the original data, and then to\nseek a rotation such that the rotated low-dimensional representation is\nscientifically meaningful. The most widely used vintage factor analysis is the\nPrincipal Component Analysis (PCA) followed by the varimax rotation. Despite\nits popularity, little theoretical guarantee can be provided to date mainly\nbecause varimax rotation requires to solve a non-convex optimization over the\nset of orthogonal matrices.\n  In this paper, we propose a deflation varimax procedure that solves each row\nof an orthogonal matrix sequentially. In addition to its net computational gain\nand flexibility, we are able to fully establish theoretical guarantees for the\nproposed procedure in a broader context. Adopting this new deflation varimax as\nthe second step after PCA, we further analyze this two step procedure under a\ngeneral class of factor models. Our results show that it estimates the factor\nloading matrix in the minimax optimal rate when the signal-to-noise-ratio (SNR)\nis moderate or large. In the low SNR regime, we offer possible improvement over\nusing PCA and the deflation varimax when the additive noise under the factor\nmodel is structured. The modified procedure is shown to be minimax optimal in\nall SNR regimes. Our theory is valid for finite sample and allows the number of\nthe latent factors to grow with the sample size as well as the ambient\ndimension to grow with, or even exceed, the sample size. Extensive simulation\nand real data analysis further corroborate our theoretical findings.\n","authors":["Xin Bing","Dian Jin","Yuqian Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.10545v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03679v6","updated":"2024-11-13T16:42:22Z","published":"2024-06-06T01:49:29Z","title":"On the Effects of Data Scale on UI Control Agents","summary":"  Autonomous agents that control computer interfaces to accomplish human tasks\nare emerging. Leveraging LLMs to power such agents has been of special\ninterest, but unless fine-tuned on human-collected task demonstrations,\nperformance is still relatively low. In this work we study whether fine-tuning\nalone is a viable approach for building real-world computer control agents. In\nparticularly, we investigate how performance measured on both high and\nlow-level tasks in domain and out of domain scales as more training data is\ncollected. To this end we collect and release a new dataset, AndroidControl,\nconsisting of 15,283 demonstrations of everyday tasks with Android apps.\nCompared to existing datasets, each AndroidControl task instance includes both\nhigh and low-level human-generated instructions, allowing us to explore the\nlevel of task complexity an agent can handle. Moreover, AndroidControl is the\nmost diverse computer control dataset to date, including 14,548 unique tasks\nover 833 Android apps, thus allowing us to conduct in-depth analysis of the\nmodel performance in and out of the domain of the training data. Using the\ndataset, we find that when tested in domain fine-tuned models outperform zero\nand few-shot baselines and scale in such a way that robust performance might\nfeasibly be obtained simply by collecting more data. Out of domain, performance\nscales significantly more slowly and suggests that in particular for high-level\ntasks, fine-tuning on more data alone may be insufficient for achieving robust\nout-of-domain performance.\n","authors":["Wei Li","William Bishop","Alice Li","Chris Rawles","Folawiyo Campbell-Ajala","Divya Tyamagundlu","Oriana Riva"],"pdf_url":"https://arxiv.org/pdf/2406.03679v6.pdf","comment":"NeurIPS 2024 (Datasets and Benchmarks)"},{"id":"http://arxiv.org/abs/2404.10420v3","updated":"2024-11-13T16:42:16Z","published":"2024-04-16T09:37:41Z","title":"AudioProtoPNet: An interpretable deep learning model for bird sound\n  classification","summary":"  Deep learning models have significantly advanced acoustic bird monitoring by\nbeing able to recognize numerous bird species based on their vocalizations.\nHowever, traditional deep learning models are black boxes that provide no\ninsight into their underlying computations, limiting their usefulness to\nornithologists and machine learning engineers. Explainable models could\nfacilitate debugging, knowledge discovery, trust, and interdisciplinary\ncollaboration. This study introduces AudioProtoPNet, an adaptation of the\nPrototypical Part Network (ProtoPNet) for multi-label bird sound\nclassification. It is an inherently interpretable model that uses a ConvNeXt\nbackbone to extract embeddings, with the classification layer replaced by a\nprototype learning classifier trained on these embeddings. The classifier\nlearns prototypical patterns of each bird species' vocalizations from\nspectrograms of training instances. During inference, audio recordings are\nclassified by comparing them to the learned prototypes in the embedding space,\nproviding explanations for the model's decisions and insights into the most\ninformative embeddings of each bird species. The model was trained on the\nBirdSet training dataset, which consists of 9,734 bird species and over 6,800\nhours of recordings. Its performance was evaluated on the seven test datasets\nof BirdSet, covering different geographical regions. AudioProtoPNet\noutperformed the state-of-the-art model Perch, achieving an average AUROC of\n0.90 and a cmAP of 0.42, with relative improvements of 7.1% and 16.7% over\nPerch, respectively. These results demonstrate that even for the challenging\ntask of multi-label bird sound classification, it is possible to develop\npowerful yet inherently interpretable deep learning models that provide\nvaluable insights for ornithologists and machine learning engineers.\n","authors":["Ren√© Heinrich","Lukas Rauch","Bernhard Sick","Christoph Scholz"],"pdf_url":"https://arxiv.org/pdf/2404.10420v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2411.08755v1","updated":"2024-11-13T16:33:27Z","published":"2024-11-13T16:33:27Z","title":"Weakly-Supervised Anomaly Detection in Surveillance Videos Based on\n  Two-Stream I3D Convolution Network","summary":"  The widespread implementation of urban surveillance systems has necessitated\nmore sophisticated techniques for anomaly detection to ensure enhanced public\nsafety. This paper presents a significant advancement in the field of anomaly\ndetection through the application of Two-Stream Inflated 3D (I3D) Convolutional\nNetworks. These networks substantially outperform traditional 3D Convolutional\nNetworks (C3D) by more effectively extracting spatial and temporal features\nfrom surveillance videos, thus improving the precision of anomaly detection.\nOur research advances the field by implementing a weakly supervised learning\nframework based on Multiple Instance Learning (MIL), which uniquely\nconceptualizes surveillance videos as collections of 'bags' that contain\ninstances (video clips). Each instance is innovatively processed through a\nranking mechanism that prioritizes clips based on their potential to display\nanomalies. This novel strategy not only enhances the accuracy and precision of\nanomaly detection but also significantly diminishes the dependency on extensive\nmanual annotations. Moreover, through meticulous optimization of model\nsettings, including the choice of optimizer, our approach not only establishes\nnew benchmarks in the performance of anomaly detection systems but also offers\na scalable and efficient solution for real-world surveillance applications.\nThis paper contributes significantly to the field of computer vision by\ndelivering a more adaptable, efficient, and context-aware anomaly detection\nsystem, which is poised to redefine practices in urban surveillance.\n","authors":["Sareh Soltani Nejad","Anwar Haque"],"pdf_url":"https://arxiv.org/pdf/2411.08755v1.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.08750v1","updated":"2024-11-13T16:29:33Z","published":"2024-11-13T16:29:33Z","title":"Optimal Transport-Based Displacement Interpolation with Data\n  Augmentation for Reduced Order Modeling of Nonlinear Dynamical Systems","summary":"  We present a novel reduced-order Model (ROM) that leverages optimal transport\n(OT) theory and displacement interpolation to enhance the representation of\nnonlinear dynamics in complex systems. While traditional ROM techniques face\nchallenges in this scenario, especially when data (i.e., observational\nsnapshots) is limited, our method addresses these issues by introducing a data\naugmentation strategy based on OT principles. The proposed framework generates\ninterpolated solutions tracing geodesic paths in the space of probability\ndistributions, enriching the training dataset for the ROM. A key feature of our\napproach is its ability to provide a continuous representation of the\nsolution's dynamics by exploiting a virtual-to-real time mapping. This enables\nthe reconstruction of solutions at finer temporal scales than those provided by\nthe original data. To further improve prediction accuracy, we employ Gaussian\nProcess Regression to learn the residual and correct the representation between\nthe interpolated snapshots and the physical solution. We demonstrate the\neffectiveness of our methodology with atmospheric mesoscale benchmarks\ncharacterized by highly nonlinear, advection-dominated dynamics. Our results\nshow improved accuracy and efficiency in predicting complex system behaviors,\nindicating the potential of this approach for a wide range of applications in\ncomputational physics and engineering.\n","authors":["Moaad Khamlich","Federico Pichi","Michele Girfoglio","Annalisa Quaini","Gianluigi Rozza"],"pdf_url":"https://arxiv.org/pdf/2411.08750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08739v1","updated":"2024-11-13T16:18:57Z","published":"2024-11-13T16:18:57Z","title":"Bayesian Comparisons Between Representations","summary":"  Which neural networks are similar is a fundamental question for both machine\nlearning and neuroscience. Our novel method compares representations based on\nBayesian statistics about linear readouts from the representations. Concretely,\nwe suggest to use the total variation distance or Jensen-Shannon distance\nbetween prior predictive distributions to compare representations. The prior\npredictive distribution is a full description of the inductive bias and\ngeneralization of a model in Bayesian statistics, making it a great basis for\ncomparisons. As Jensen-Shannon distance and total variation distance are\nmetrics our dissimilarity measures are pseudo-metrics for representations. For\na linear readout, our metrics just depend on the linear kernel matrix of the\nrepresentations. Thus, our metrics connects linear read-out based comparisons\nto kernel based metrics like centered kernel alignment and representational\nsimilarity analysis. We apply our new metrics to deep neural networks trained\non ImageNet-1k. Our new metrics can be computed efficiently including a\nstochastic gradient without dimensionality reductions of the representations.\nIt broadly agrees with existing metrics, but is more stringent. It varies less\nacross different random image samples, and it measures how well two\nrepresentations could be distinguished based on a linear read out. Thus our\nmetric nicely extends our toolkit for comparing representations.\n","authors":["Heiko H. Sch√ºtt"],"pdf_url":"https://arxiv.org/pdf/2411.08739v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08734v1","updated":"2024-11-13T16:16:22Z","published":"2024-11-13T16:16:22Z","title":"Recommender systems and reinforcement learning for building control and\n  occupant interaction: A text-mining driven review of scientific literature","summary":"  The indoor environment greatly affects health and well-being; enhancing\nhealth and reducing energy use in these settings is a key research focus. With\nadvancing Information and Communication Technology (ICT), recommendation\nsystems and reinforcement learning have emerged as promising methods to induce\nbehavioral changes that improve indoor environments and building energy\nefficiency. This study employs text-mining and Natural Language Processing\n(NLP) to examine these approaches in building control and occupant interaction.\nAnalyzing approximately 27,000 articles from the ScienceDirect database, we\nfound extensive use of recommendation systems and reinforcement learning for\nspace optimization, location recommendations, and personalized control\nsuggestions. Despite broad applications, their use in optimizing indoor\nenvironments and energy efficiency is limited. Traditional recommendation\nalgorithms are commonly used, but optimizing indoor conditions and energy\nefficiency often requires advanced machine learning techniques like\nreinforcement and deep learning. This review highlights the potential for\nexpanding recommender systems and reinforcement learning applications in\nbuildings and indoor environments. Areas for innovation include predictive\nmaintenance, building-related product recommendations, and optimizing\nenvironments for specific needs like sleep and productivity enhancements based\non user feedback.\n","authors":["Wenhao Zhang","Matias Quintana","Clayton Miller"],"pdf_url":"https://arxiv.org/pdf/2411.08734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12763v3","updated":"2024-11-13T16:07:47Z","published":"2024-06-18T16:30:51Z","title":"Implicit Bias of Mirror Flow on Separable Data","summary":"  We examine the continuous-time counterpart of mirror descent, namely mirror\nflow, on classification problems which are linearly separable. Such problems\nare minimised `at infinity' and have many possible solutions; we study which\nsolution is preferred by the algorithm depending on the mirror potential. For\nexponential tailed losses and under mild assumptions on the potential, we show\nthat the iterates converge in direction towards a $\\phi_\\infty$-maximum margin\nclassifier. The function $\\phi_\\infty$ is the \\textit{horizon function} of the\nmirror potential and characterises its shape `at infinity'. When the potential\nis separable, a simple formula allows to compute this function. We analyse\nseveral examples of potentials and provide numerical experiments highlighting\nour results.\n","authors":["Scott Pesme","Radu-Alexandru Dragomir","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2406.12763v3.pdf","comment":"Neurips camera ready. Minor changes from the previous versions.\n  Mainly added full iterate trajectories (Figure 4)"},{"id":"http://arxiv.org/abs/2307.05284v4","updated":"2024-11-13T15:53:37Z","published":"2023-07-11T14:25:10Z","title":"Rethinking Distribution Shifts: Empirical Analysis and Inductive\n  Modeling for Tabular Data","summary":"  Different distribution shifts require different interventions, and algorithms\nmust be grounded in the specific shifts they address. However, methodological\ndevelopment for robust algorithms typically relies on structural assumptions\nthat lack empirical validation. Advocating for an empirically grounded\ndata-driven approach to research, we build an empirical testbed comprising\nnatural shifts across 5 tabular datasets and 60,000 method configurations\nencompassing imbalanced learning and distributionally robust optimization (DRO)\nmethods. We find $Y|X$-shifts are most prevalent on our testbed, in stark\ncontrast to the heavy focus on $X$ (covariate)-shifts in the ML literature. The\nperformance of robust algorithms varies significantly over shift types, and is\nno better than that of vanilla methods. To understand why, we conduct an\nin-depth empirical analysis of DRO methods and find that although often\nneglected by researchers, implementation details -- such as the choice of\nunderlying model class (e.g., XGBoost) and hyperparameter selection -- have a\nbigger impact on performance than the ambiguity set or its radius. To further\nbridge that gap between methodological research and practice, we design case\nstudies that illustrate how such a data-driven, inductive understanding of\ndistribution shifts can enhance both data-centric and algorithmic\ninterventions.\n","authors":["Jiashuo Liu","Tianyu Wang","Peng Cui","Hongseok Namkoong"],"pdf_url":"https://arxiv.org/pdf/2307.05284v4.pdf","comment":"Conference version appeared in NeurIPS 2023, previously titled \"On\n  the Need for a Language Describing Distribution Shifts: Illustrations on\n  Tabular Datasets\""},{"id":"http://arxiv.org/abs/2411.08706v1","updated":"2024-11-13T15:50:32Z","published":"2024-11-13T15:50:32Z","title":"Searching Latent Program Spaces","summary":"  Program synthesis methods aim to automatically generate programs restricted\nto a language that can explain a given specification of input-output pairs.\nWhile purely symbolic approaches suffer from a combinatorial search space,\nrecent methods leverage neural networks to learn distributions over program\nstructures to narrow this search space significantly, enabling more efficient\nsearch. However, for challenging problems, it remains difficult to train models\nto perform program synthesis in one shot, making test-time search essential.\nMost neural methods lack structured search mechanisms during inference, relying\ninstead on stochastic sampling or gradient updates, which can be inefficient.\nIn this work, we propose the Latent Program Network (LPN), a general algorithm\nfor program induction that learns a distribution over latent programs in a\ncontinuous space, enabling efficient search and test-time adaptation. We\nexplore how to train these networks to optimize for test-time computation and\ndemonstrate the use of gradient-based search both during training and at test\ntime. We evaluate LPN on ARC-AGI, a program synthesis benchmark that evaluates\nperformance by generalizing programs to new inputs rather than explaining the\nunderlying specification. We show that LPN can generalize beyond its training\ndistribution and adapt to unseen tasks by utilizing test-time computation,\noutperforming algorithms without test-time adaptation mechanisms.\n","authors":["Cl√©ment Bonnet","Matthew V Macfarlane"],"pdf_url":"https://arxiv.org/pdf/2411.08706v1.pdf","comment":"Code available at https://github.com/clement-bonnet/lpn"},{"id":"http://arxiv.org/abs/2408.00838v2","updated":"2024-11-13T15:48:34Z","published":"2024-08-01T18:00:05Z","title":"Calibrating Bayesian Generative Machine Learning for Bayesiamplification","summary":"  Recently, combinations of generative and Bayesian machine learning have been\nintroduced in particle physics for both fast detector simulation and inference\ntasks. These neural networks aim to quantify the uncertainty on the generated\ndistribution originating from limited training statistics. The interpretation\nof a distribution-wide uncertainty however remains ill-defined. We show a clear\nscheme for quantifying the calibration of Bayesian generative machine learning\nmodels. For a Continuous Normalizing Flow applied to a low-dimensional toy\nexample, we evaluate the calibration of Bayesian uncertainties from either a\nmean-field Gaussian weight posterior, or Monte Carlo sampling network weights,\nto gauge their behaviour on unsteady distribution edges. Well calibrated\nuncertainties can then be used to roughly estimate the number of uncorrelated\ntruth samples that are equivalent to the generated sample and clearly indicate\ndata amplification for smooth features of the distribution.\n","authors":["Sebastian Bieringer","Sascha Diefenbacher","Gregor Kasieczka","Mathias Trabs"],"pdf_url":"https://arxiv.org/pdf/2408.00838v2.pdf","comment":"15 pages, 6 figures, updated references, fixed typo"},{"id":"http://arxiv.org/abs/2411.08703v1","updated":"2024-11-13T15:45:46Z","published":"2024-11-13T15:45:46Z","title":"MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics\n  Classification","summary":"  The distinct characteristics of multiomics data, including complex\ninteractions within and across biological layers and disease heterogeneity\n(e.g., heterogeneity in etiology and clinical symptoms), drive us to develop\nnovel designs to address unique challenges in multiomics prediction. In this\npaper, we propose the multi-view knowledge transfer learning (MVKTrans)\nframework, which transfers intra- and inter-omics knowledge in an adaptive\nmanner by reviewing data heterogeneity and suppressing bias transfer, thereby\nenhancing classification performance. Specifically, we design a graph\ncontrastive module that is trained on unlabeled data to effectively learn and\ntransfer the underlying intra-omics patterns to the supervised task. This\nunsupervised pretraining promotes learning general and unbiased representations\nfor each modality, regardless of the downstream tasks. In light of the varying\ndiscriminative capacities of modalities across different diseases and/or\nsamples, we introduce an adaptive and bi-directional cross-omics distillation\nmodule. This module automatically identifies richer modalities and facilitates\ndynamic knowledge transfer from more informative to less informative omics,\nthereby enabling a more robust and generalized integration. Extensive\nexperiments on four real biomedical datasets demonstrate the superior\nperformance and robustness of MVKTrans compared to the state-of-the-art. Code\nand data are available at https://github.com/Yaolab-fantastic/MVKTrans.\n","authors":["Shan Cong","Zhiling Sang","Hongwei Liu","Haoran Luo","Xin Wang","Hong Liang","Jie Hao","Xiaohui Yao"],"pdf_url":"https://arxiv.org/pdf/2411.08703v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08701v1","updated":"2024-11-13T15:42:28Z","published":"2024-11-13T15:42:28Z","title":"TRACE: Transformer-based Risk Assessment for Clinical Evaluation","summary":"  We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation),\na novel method for clinical risk assessment based on clinical data, leveraging\nthe self-attention mechanism for enhanced feature interaction and result\ninterpretation. Our approach is able to handle different data modalities,\nincluding continuous, categorical and multiple-choice (checkbox) attributes.\nThe proposed architecture features a shared representation of the clinical data\nobtained by integrating specialized embeddings of each data modality, enabling\nthe detection of high-risk individuals using Transformer encoder layers. To\nassess the effectiveness of the proposed method, a strong baseline based on\nnon-negative multi-layer perceptrons (MLPs) is introduced. The proposed method\noutperforms various baselines widely used in the domain of clinical risk\nassessment, while effectively handling missing values. In terms of\nexplainability, our Transformer-based method offers easily interpretable\nresults via attention weights, further enhancing the clinicians'\ndecision-making process.\n","authors":["Dionysis Christopoulos","Sotiris Spanos","Valsamis Ntouskos","Konstantinos Karantzalos"],"pdf_url":"https://arxiv.org/pdf/2411.08701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08700v1","updated":"2024-11-13T15:42:13Z","published":"2024-11-13T15:42:13Z","title":"Rethinking negative sampling in content-based news recommendation","summary":"  News recommender systems are hindered by the brief lifespan of articles, as\nthey undergo rapid relevance decay. Recent studies have demonstrated the\npotential of content-based neural techniques in tackling this problem. However,\nthese models often involve complex neural architectures and often lack\nconsideration for negative examples. In this study, we posit that the careful\nsampling of negative examples has a big impact on the model's outcome. We\ndevise a negative sampling technique that not only improves the accuracy of the\nmodel but also facilitates the decentralization of the recommendation system.\nThe experimental results obtained using the MIND dataset demonstrate that the\naccuracy of the method under consideration can compete with that of\nState-of-the-Art models. The utilization of the sampling technique is essential\nin reducing model complexity and accelerating the training process, while\nmaintaining a high level of accuracy. Finally, we discuss how decentralized\nmodels can help improve privacy and scalability.\n","authors":["Miguel √Çngelo Rebelo","Jo√£o Vinagre","Ivo Pereira","√Ålvaro Figueira"],"pdf_url":"https://arxiv.org/pdf/2411.08700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08699v1","updated":"2024-11-13T15:42:09Z","published":"2024-11-13T15:42:09Z","title":"FedSub: Introducing class-aware Subnetworks Fusion to Enhance\n  Personalized Federated Learning in Ubiquitous Systems","summary":"  Personalized Federated Learning is essential in AI-driven ubiquitous systems,\nsupporting the distributed development of models able to adapt to diverse and\nevolving user behaviors while safeguarding privacy. Despite addressing\nheterogeneous user data distributions in collaborative model training, existing\nmethods often face limitations balancing personalization and generalization,\noversimplifying user similarities, or relying heavily on global models. In this\npaper, we propose FedSub, a novel federated approach designed to enhance\npersonalization through the use of class-aware prototypes and model\nsubnetworks. Prototypes serve as compact representations of user data,\nclustered on the server to identify similarities based on specific label\npatterns. Concurrently, subnetworks -- model components necessary to process\neach class -- are extracted locally and fused by the server according to these\nclusters, producing highly tailored model updates for each user. This\nfine-grained, class-specific aggregation of clients' models allows FedSub to\ncapture the unique characteristics of individual user data patterns. The\neffectiveness of FedSub is validated in three real-world scenarios\ncharacterized by high data heterogeneity, derived from human activity\nrecognition and mobile health applications. Experimental evaluations\ndemonstrate FedSub's performance improvements with respect to the\nstate-of-the-art and significant advancements in personalization for ubiquitous\nsystems based on personal mobile and wearable devices.\n","authors":["Mattia Giovanni Campana","Franca Delmastro"],"pdf_url":"https://arxiv.org/pdf/2411.08699v1.pdf","comment":"Submitted to Proceedings of the ACM on Interactive, Mobile, Wearable\n  and Ubiquitous Technologies (IMWUT)"},{"id":"http://arxiv.org/abs/2405.15732v2","updated":"2024-11-13T15:30:50Z","published":"2024-05-24T17:20:18Z","title":"Neural Persistence Dynamics","summary":"  We consider the problem of learning the dynamics in the topology of\ntime-evolving point clouds, the prevalent spatiotemporal model for systems\nexhibiting collective behavior, such as swarms of insects and birds or\nparticles in physics. In such systems, patterns emerge from (local)\ninteractions among self-propelled entities. While several well-understood\ngoverning equations for motion and interaction exist, they are notoriously\ndifficult to fit to data, as most prior work requires knowledge about\nindividual motion trajectories, i.e., a requirement that is challenging to\nsatisfy with an increasing number of entities. To evade such confounding\nfactors, we investigate collective behavior from a $\\textit{topological\nperspective}$, but instead of summarizing entire observation sequences (as done\npreviously), we propose learning a latent dynamical model from topological\nfeatures $\\textit{per time point}$. The latter is then used to formulate a\ndownstream regression task to predict the parametrization of some a priori\nspecified governing equation. We implement this idea based on a latent ODE\nlearned from vectorized (static) persistence diagrams and show that a\ncombination of recent stability results for persistent homology justifies this\nmodeling choice. Various (ablation) experiments not only demonstrate the\nrelevance of each model component but provide compelling empirical evidence\nthat our proposed model - $\\textit{Neural Persistence Dynamics}$ -\nsubstantially outperforms the state-of-the-art across a diverse set of\nparameter regression tasks.\n","authors":["Sebastian Zeng","Florian Graf","Martin Uray","Stefan Huber","Roland Kwitt"],"pdf_url":"https://arxiv.org/pdf/2405.15732v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08687v1","updated":"2024-11-13T15:22:33Z","published":"2024-11-13T15:22:33Z","title":"Measuring similarity between embedding spaces using induced neighborhood\n  graphs","summary":"  Deep Learning techniques have excelled at generating embedding spaces that\ncapture semantic similarities between items. Often these representations are\npaired, enabling experiments with analogies (pairs within the same domain) and\ncross-modality (pairs across domains). These experiments are based on specific\nassumptions about the geometry of embedding spaces, which allow finding paired\nitems by extrapolating the positional relationships between embedding pairs in\nthe training dataset, allowing for tasks such as finding new analogies, and\nmultimodal zero-shot classification. In this work, we propose a metric to\nevaluate the similarity between paired item representations. Our proposal is\nbuilt from the structural similarity between the nearest-neighbors induced\ngraphs of each representation, and can be configured to compare spaces based on\ndifferent distance metrics and on different neighborhood sizes. We demonstrate\nthat our proposal can be used to identify similar structures at different\nscales, which is hard to achieve with kernel methods such as Centered Kernel\nAlignment (CKA). We further illustrate our method with two case studies: an\nanalogy task using GloVe embeddings, and zero-shot classification in the\nCIFAR-100 dataset using CLIP embeddings. Our results show that accuracy in both\nanalogy and zero-shot classification tasks correlates with the embedding\nsimilarity. These findings can help explain performance differences in these\ntasks, and may lead to improved design of paired-embedding models in the\nfuture.\n","authors":["Tiago F. Tavares","Fabio Ayres","Paris Smaragdis"],"pdf_url":"https://arxiv.org/pdf/2411.08687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.09604v2","updated":"2024-11-13T15:17:20Z","published":"2024-08-18T22:11:24Z","title":"Circuit design in biology and machine learning. I. Random networks and\n  dimensional reduction","summary":"  A biological circuit is a neural or biochemical cascade, taking inputs and\nproducing outputs. How have biological circuits learned to solve environmental\nchallenges over the history of life? The answer certainly follows Dobzhansky's\nfamous quote that ``nothing in biology makes sense except in the light of\nevolution.'' But that quote leaves out the mechanistic basis by which natural\nselection's trial-and-error learning happens, which is exactly what we have to\nunderstand. How does the learning process that designs biological circuits\nactually work? How much insight can we gain about the form and function of\nbiological circuits by studying the processes that have made those circuits?\nBecause life's circuits must often solve the same problems as those faced by\nmachine learning, such as environmental tracking, homeostatic control,\ndimensional reduction, or classification, we can begin by considering how\nmachine learning designs computational circuits to solve problems. We can then\nask: How much insight do those computational circuits provide about the design\nof biological circuits? How much does biology differ from computers in the\nparticular circuit designs that it uses to solve problems? This article steps\nthrough two classic machine learning models to set the foundation for analyzing\nbroad questions about the design of biological circuits. One insight is the\nsurprising power of randomly connected networks. Another is the central role of\ninternal models of the environment embedded within biological circuits,\nillustrated by a model of dimensional reduction and trend prediction. Overall,\nmany challenges in biology have machine learning analogs, suggesting hypotheses\nabout how biology's circuits are designed.\n","authors":["Steven A. Frank"],"pdf_url":"https://arxiv.org/pdf/2408.09604v2.pdf","comment":"Added background info in two text boxes and new figure, edited\n  throughout"},{"id":"http://arxiv.org/abs/2402.16187v3","updated":"2024-11-13T15:14:38Z","published":"2024-02-25T20:24:07Z","title":"No Free Lunch in LLM Watermarking: Trade-offs in Watermarking Design\n  Choices","summary":"  Advances in generative models have made it possible for AI-generated text,\ncode, and images to mirror human-generated content in many applications.\nWatermarking, a technique that aims to embed information in the output of a\nmodel to verify its source, is useful for mitigating the misuse of such\nAI-generated content. However, we show that common design choices in LLM\nwatermarking schemes make the resulting systems surprisingly susceptible to\nattack -- leading to fundamental trade-offs in robustness, utility, and\nusability. To navigate these trade-offs, we rigorously study a set of simple\nyet effective attacks on common watermarking systems, and propose guidelines\nand defenses for LLM watermarking in practice.\n","authors":["Qi Pang","Shengyuan Hu","Wenting Zheng","Virginia Smith"],"pdf_url":"https://arxiv.org/pdf/2402.16187v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08664v1","updated":"2024-11-13T14:55:08Z","published":"2024-11-13T14:55:08Z","title":"UniMat: Unifying Materials Embeddings through Multi-modal Learning","summary":"  Materials science datasets are inherently heterogeneous and are available in\ndifferent modalities such as characterization spectra, atomic structures,\nmicroscopic images, and text-based synthesis conditions. The advancements in\nmulti-modal learning, particularly in vision and language models, have opened\nnew avenues for integrating data in different forms. In this work, we evaluate\ncommon techniques in multi-modal learning (alignment and fusion) in unifying\nsome of the most important modalities in materials science: atomic structure,\nX-ray diffraction patterns (XRD), and composition. We show that structure graph\nmodality can be enhanced by aligning with XRD patterns. Additionally, we show\nthat aligning and fusing more experimentally accessible data formats, such as\nXRD patterns and compositions, can create more robust joint embeddings than\nindividual modalities across various tasks. This lays the groundwork for future\nstudies aiming to exploit the full potential of multi-modal data in materials\nscience, facilitating more informed decision-making in materials design and\ndiscovery.\n","authors":["Janghoon Ock","Joseph Montoya","Daniel Schweigert","Linda Hung","Santosh K. Suram","Weike Ye"],"pdf_url":"https://arxiv.org/pdf/2411.08664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13224v4","updated":"2024-11-13T14:54:18Z","published":"2024-02-20T18:37:11Z","title":"Controlling Large Electric Vehicle Charging Stations via User Behavior\n  Modeling and Stochastic Programming","summary":"  This paper introduces an Electric Vehicle Charging Station (EVCS) model that\nincorporates real-world constraints, such as slot power limitations, contract\nthreshold overruns penalties, or early disconnections of electric vehicles\n(EVs). We propose a formulation of the problem of EVCS control under\nuncertainty, and implement two Multi-Stage Stochastic Programming approaches\nthat leverage user-provided information, namely, Model Predictive Control and\nTwo-Stage Stochastic Programming. The model addresses uncertainties in charging\nsession start and end times, as well as in energy demand. A user's behavior\nmodel based on a sojourn-time-dependent stochastic process enhances cost\nreduction while maintaining customer satisfaction. The benefits of the two\nproposed methods are showcased against two baselines over a 22-day simulation\nusing a real-world dataset. The two-stage approach demonstrates robustness\nagainst early disconnections by considering a wider range of uncertainty\nscenarios for optimization. The algorithm prioritizing user satisfaction over\nelectricity cost achieves a 20% and 36% improvement in two user satisfaction\nmetrics compared to an industry-standard baseline. Additionally, the algorithm\nstriking the best balance between cost and user satisfaction exhibits a mere 3%\nrelative cost increase compared to the theoretically optimal baseline - for\nwhich the nonanticipativity constraint is relaxed - while attaining 94% and 84%\nof the user satisfaction performance in the two used satisfaction metrics.\n","authors":["Alban Puech","Tristan Rigaut","William Templier","Maud Tournoud"],"pdf_url":"https://arxiv.org/pdf/2402.13224v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08652v1","updated":"2024-11-13T14:42:32Z","published":"2024-11-13T14:42:32Z","title":"Accelerating Quasi-Static Time Series Simulations with Foundation Models","summary":"  Quasi-static time series (QSTS) simulations have great potential for\nevaluating the grid's ability to accommodate the large-scale integration of\ndistributed energy resources. However, as grids expand and operate closer to\ntheir limits, iterative power flow solvers, central to QSTS simulations, become\ncomputationally prohibitive and face increasing convergence issues. Neural\npower flow solvers provide a promising alternative, speeding up power flow\ncomputations by 3 to 4 orders of magnitude, though they are costly to train. In\nthis paper, we envision how recently introduced grid foundation models could\nimprove the economic viability of neural power flow solvers. Conceptually,\nthese models amortize training costs by serving as a foundation for a range of\ngrid operation and planning tasks beyond power flow solving, with only minimal\nfine-tuning required. We call for collaboration between the AI and power grid\ncommunities to develop and open-source these models, enabling all operators,\neven those with limited resources, to benefit from AI without building\nsolutions from scratch.\n","authors":["Alban Puech","Fran√ßois Mirall√®s","Jonas Weiss","Vincent Mai","Alexandre Blondin Mass√©","Martin de Montigny","Thomas Brunschwiler","Hendrik F. Hamann"],"pdf_url":"https://arxiv.org/pdf/2411.08652v1.pdf","comment":"Equal contributors: A.P. and F.M.; Lead contact: A.P"},{"id":"http://arxiv.org/abs/2306.16028v2","updated":"2024-11-13T14:41:20Z","published":"2023-06-28T08:55:56Z","title":"Exponential separations between classical and quantum learners","summary":"  Despite significant effort, the quantum machine learning community has only\ndemonstrated quantum learning advantages for artificial cryptography-inspired\ndatasets when dealing with classical data. In this paper we address the\nchallenge of finding learning problems where quantum learning algorithms can\nachieve a provable exponential speedup over classical learning algorithms. We\nreflect on computational learning theory concepts related to this question and\ndiscuss how subtle differences in definitions can result in significantly\ndifferent requirements and tasks for the learner to meet and solve. We examine\nexisting learning problems with provable quantum speedups and find that they\nlargely rely on the classical hardness of evaluating the function that\ngenerates the data, rather than identifying it. To address this, we present two\nnew learning separations where the classical difficulty primarily lies in\nidentifying the function generating the data. Furthermore, we explore\ncomputational hardness assumptions that can be leveraged to prove quantum\nspeedups in scenarios where data is quantum-generated, which implies likely\nquantum advantages in a plethora of more natural settings (e.g., in condensed\nmatter and high energy physics). We also discuss the limitations of the\nclassical shadow paradigm in the context of learning separations, and how\nphysically-motivated settings such as characterizing phases of matter and\nHamiltonian learning fit in the computational learning framework.\n","authors":["Casper Gyurik","Vedran Dunjko"],"pdf_url":"https://arxiv.org/pdf/2306.16028v2.pdf","comment":"this article supersedes arXiv:2208.06339"},{"id":"http://arxiv.org/abs/2411.08651v1","updated":"2024-11-13T14:40:51Z","published":"2024-11-13T14:40:51Z","title":"Estimating unknown parameters in differential equations with a\n  reinforcement learning based PSO method","summary":"  Differential equations offer a foundational yet powerful framework for\nmodeling interactions within complex dynamic systems and are widely applied\nacross numerous scientific fields. One common challenge in this area is\nestimating the unknown parameters of these dynamic relationships. However,\ntraditional numerical optimization methods rely on the selection of initial\nparameter values, making them prone to local optima. Meanwhile, deep learning\nand Bayesian methods require training models on specific differential\nequations, resulting in poor versatility. This paper reformulates the parameter\nestimation problem of differential equations as an optimization problem by\nintroducing the concept of particles from the particle swarm optimization\nalgorithm. Building on reinforcement learning-based particle swarm optimization\n(RLLPSO), this paper proposes a novel method, DERLPSO, for estimating unknown\nparameters of differential equations. We compared its performance on three\ntypical ordinary differential equations with the state-of-the-art methods,\nincluding the RLLPSO algorithm, traditional numerical methods, deep learning\napproaches, and Bayesian methods. The experimental results demonstrate that our\nDERLPSO consistently outperforms other methods in terms of performance,\nachieving an average Mean Square Error of 1.13e-05, which reduces the error by\napproximately 4 orders of magnitude compared to other methods. Apart from\nordinary differential equations, our DERLPSO also show great promise for\nestimating unknown parameters of partial differential equations. The DERLPSO\nmethod proposed in this paper has high accuracy, is independent of initial\nparameter values, and possesses strong versatility and stability. This work\nprovides new insights into unknown parameter estimation for differential\nequations.\n","authors":["Wenkui Sun","Xiaoya Fan","Lijuan Jia","Tinyi Chu","Shing-Tung Yau","Rongling Wu","Zhong Wang"],"pdf_url":"https://arxiv.org/pdf/2411.08651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07444v2","updated":"2024-11-13T14:39:42Z","published":"2023-11-13T16:18:58Z","title":"On the Robustness of Neural Collapse and the Neural Collapse of\n  Robustness","summary":"  Neural Collapse refers to the curious phenomenon in the end of training of a\nneural network, where feature vectors and classification weights converge to a\nvery simple geometrical arrangement (a simplex). While it has been observed\nempirically in various cases and has been theoretically motivated, its\nconnection with crucial properties of neural networks, like their\ngeneralization and robustness, remains unclear. In this work, we study the\nstability properties of these simplices. We find that the simplex structure\ndisappears under small adversarial attacks, and that perturbed examples \"leap\"\nbetween simplex vertices. We further analyze the geometry of networks that are\noptimized to be robust against adversarial perturbations of the input, and find\nthat Neural Collapse is a pervasive phenomenon in these cases as well, with\nclean and perturbed representations forming aligned simplices, and giving rise\nto a robust simple nearest-neighbor classifier. By studying the propagation of\nthe amount of collapse inside the network, we identify novel properties of both\nrobust and non-robust machine learning models, and show that earlier, unlike\nlater layers maintain reliable simplices on perturbed data. Our code is\navailable at https://github.com/JingtongSu/robust_neural_collapse .\n","authors":["Jingtong Su","Ya Shi Zhang","Nikolaos Tsilivis","Julia Kempe"],"pdf_url":"https://arxiv.org/pdf/2311.07444v2.pdf","comment":"Transactions on Machine Learning Research, 2024"},{"id":"http://arxiv.org/abs/2411.08640v1","updated":"2024-11-13T14:31:52Z","published":"2024-11-13T14:31:52Z","title":"Towards Secure Intelligent O-RAN Architecture: Vulnerabilities, Threats\n  and Promising Technical Solutions using LLMs","summary":"  The evolution of wireless communication systems will be fundamentally\nimpacted by an open radio access network (O-RAN), a new concept defining an\nintelligent architecture with enhanced flexibility, openness, and the ability\nto slice services more efficiently. For all its promises, and like any\ntechnological advancement, O-RAN is not without risks that need to be carefully\nassessed and properly addressed to accelerate its wide adoption in future\nmobile networks. In this paper, we present an in-depth security analysis of the\nO-RAN architecture, discussing the potential threats that may arise in the\ndifferent O-RAN architecture layers and their impact on the Confidentiality,\nIntegrity, and Availability (CIA) triad. We also promote the potential of zero\ntrust, Moving Target Defense (MTD), blockchain, and large language models(LLM)\ntechnologies in fortifying O-RAN's security posture. Furthermore, we\nnumerically demonstrate the effectiveness of MTD in empowering robust deep\nreinforcement learning methods for dynamic network slice admission control in\nthe O-RAN architecture. Moreover, we examine the effect of explainable AI (XAI)\nbased on LLMs in securing the system.\n","authors":["Mojdeh Karbalaee Motalleb","Chafika Benzaid","Tarik Taleb","Marcos Katz","Vahid Shah-Mansouri","JaeSeung Song"],"pdf_url":"https://arxiv.org/pdf/2411.08640v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.08638v1","updated":"2024-11-13T14:26:04Z","published":"2024-11-13T14:26:04Z","title":"Gaussian Mixture Models Based Augmentation Enhances GNN Generalization","summary":"  Graph Neural Networks (GNNs) have shown great promise in tasks like node and\ngraph classification, but they often struggle to generalize, particularly to\nunseen or out-of-distribution (OOD) data. These challenges are exacerbated when\ntraining data is limited in size or diversity. To address these issues, we\nintroduce a theoretical framework using Rademacher complexity to compute a\nregret bound on the generalization error and then characterize the effect of\ndata augmentation. This framework informs the design of GMM-GDA, an efficient\ngraph data augmentation (GDA) algorithm leveraging the capability of Gaussian\nMixture Models (GMMs) to approximate any distribution. Our approach not only\noutperforms existing augmentation techniques in terms of generalization but\nalso offers improved time complexity, making it highly suitable for real-world\napplications.\n","authors":["Yassine Abbahaddou","Fragkiskos D. Malliaros","Johannes F. Lutzeyer","Amine Mohamed Aboussalah","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2411.08638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08637v1","updated":"2024-11-13T14:24:47Z","published":"2024-11-13T14:24:47Z","title":"Robot See, Robot Do: Imitation Reward for Noisy Financial Environments","summary":"  The sequential nature of decision-making in financial asset trading aligns\nnaturally with the reinforcement learning (RL) framework, making RL a common\napproach in this domain. However, the low signal-to-noise ratio in financial\nmarkets results in noisy estimates of environment components, including the\nreward function, which hinders effective policy learning by RL agents. Given\nthe critical importance of reward function design in RL problems, this paper\nintroduces a novel and more robust reward function by leveraging imitation\nlearning, where a trend labeling algorithm acts as an expert. We integrate\nimitation (expert's) feedback with reinforcement (agent's) feedback in a\nmodel-free RL algorithm, effectively embedding the imitation learning problem\nwithin the RL paradigm to handle the stochasticity of reward signals. Empirical\nresults demonstrate that this novel approach improves financial performance\nmetrics compared to traditional benchmarks and RL agents trained solely using\nreinforcement feedback.\n","authors":["Sven Golu≈æa","Tomislav Kovaƒçeviƒá","Stjepan Begu≈°iƒá","Zvonko Kostanjƒçar"],"pdf_url":"https://arxiv.org/pdf/2411.08637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08631v1","updated":"2024-11-13T14:17:26Z","published":"2024-11-13T14:17:26Z","title":"Deep Generative Demand Learning for Newsvendor and Pricing","summary":"  We consider data-driven inventory and pricing decisions in the feature-based\nnewsvendor problem, where demand is influenced by both price and contextual\nfeatures and is modeled without any structural assumptions. The unknown demand\ndistribution results in a challenging conditional stochastic optimization\nproblem, further complicated by decision-dependent uncertainty and the\nintegration of features. Inspired by recent advances in deep generative\nlearning, we propose a novel approach leveraging conditional deep generative\nmodels (cDGMs) to address these challenges. cDGMs learn the demand distribution\nand generate probabilistic demand forecasts conditioned on price and features.\nThis generative approach enables accurate profit estimation and supports the\ndesign of algorithms for two key objectives: (1) optimizing inventory for\narbitrary prices, and (2) jointly determining optimal pricing and inventory\nlevels. We provide theoretical guarantees for our approach, including the\nconsistency of profit estimation and convergence of our decisions to the\noptimal solution. Extensive simulations-ranging from simple to complex\nscenarios, including one involving textual features-and a real-world case study\ndemonstrate the effectiveness of our approach. Our method opens a new paradigm\nin management science and operations research, is adaptable to extensions of\nthe newsvendor and pricing problems, and holds potential for solving other\nconditional stochastic optimization problems.\n","authors":["Shijin Gong","Huihang Liu","Xinyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.08631v1.pdf","comment":"30 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.16336v2","updated":"2024-11-13T14:13:58Z","published":"2024-03-25T00:21:34Z","title":"Predictive Inference in Multi-environment Scenarios","summary":"  We address the challenge of constructing valid confidence intervals and sets\nin problems of prediction across multiple environments. We investigate two\ntypes of coverage suitable for these problems, extending the jackknife and\nsplit-conformal methods to show how to obtain distribution-free coverage in\nsuch non-traditional, potentially hierarchical data-generating scenarios. We\ndemonstrate a novel resizing method to adapt to problem difficulty, which\napplies both to existing approaches for predictive inference and the methods we\ndevelop; this reduces prediction set sizes using limited information from the\ntest environment, a key to the methods' practical performance, which we\nevaluate through neurochemical sensing and species classification datasets. Our\ncontributions also include extensions for settings with non-real-valued\nresponses, a theory of consistency for predictive inference in these general\nproblems, and insights on the limits of conditional coverage.\n","authors":["John C. Duchi","Suyash Gupta","Kuanhao Jiang","Pragya Sur"],"pdf_url":"https://arxiv.org/pdf/2403.16336v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08610v1","updated":"2024-11-13T13:53:10Z","published":"2024-11-13T13:53:10Z","title":"Dynamic Subset Tuning: Expanding the Operational Range of\n  Parameter-Efficient Training for Large Language Models","summary":"  We propose a novel parameter-efficient training (PET) method for large\nlanguage models that adapts models to downstream tasks by optimizing a small\nsubset of the existing model parameters. Unlike prior methods, this subset is\nnot fixed in location but rather which parameters are modified evolves over the\ncourse of training. This dynamic parameter selection can yield good performance\nwith many fewer parameters than extant methods. Our method enables a seamless\nscaling of the subset size across an arbitrary proportion of the total model\nsize, while popular PET approaches like prompt tuning and LoRA cover only a\nsmall part of this spectrum. We match or outperform prompt tuning and LoRA in\nmost cases on a variety of NLP tasks (MT, QA, GSM8K, SuperGLUE) for a given\nparameter budget across different model families and sizes.\n","authors":["Felix Stahlberg","Jared Lichtarge","Shankar Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.08610v1.pdf","comment":"NeurIPS 2024 Workshop on Adaptive Foundation Models"},{"id":"http://arxiv.org/abs/2411.08013v2","updated":"2024-11-13T13:36:05Z","published":"2024-11-12T18:43:27Z","title":"Investigating the Effectiveness of Explainability Methods in Parkinson's\n  Detection from Speech","summary":"  Speech impairments in Parkinson's disease (PD) provide significant early\nindicators for diagnosis. While models for speech-based PD detection have shown\nstrong performance, their interpretability remains underexplored. This study\nsystematically evaluates several explainability methods to identify PD-specific\nspeech features, aiming to support the development of accurate, interpretable\nmodels for clinical decision-making in PD diagnosis and monitoring. Our\nmethodology involves (i) obtaining attributions and saliency maps using\nmainstream interpretability techniques, (ii) quantitatively evaluating the\nfaithfulness of these maps and their combinations obtained via union and\nintersection through a range of established metrics, and (iii) assessing the\ninformation conveyed by the saliency maps for PD detection from an auxiliary\nclassifier. Our results reveal that, while explanations are aligned with the\nclassifier, they often fail to provide valuable information for domain experts.\n","authors":["Eleonora Mancini","Francesco Paissan","Paolo Torroni","Mirco Ravanelli","Cem Subakan"],"pdf_url":"https://arxiv.org/pdf/2411.08013v2.pdf","comment":"The first two authors contributed equally to this research: author\n  order is alphabetical"},{"id":"http://arxiv.org/abs/2411.08599v1","updated":"2024-11-13T13:30:21Z","published":"2024-11-13T13:30:21Z","title":"XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL","summary":"  To tackle the challenges of large language model performance in natural\nlanguage to SQL tasks, we introduce XiYan-SQL, an innovative framework that\nemploys a multi-generator ensemble strategy to improve candidate generation. We\nintroduce M-Schema, a semi-structured schema representation method designed to\nenhance the understanding of database structures. To enhance the quality and\ndiversity of generated candidate SQL queries, XiYan-SQL integrates the\nsignificant potential of in-context learning (ICL) with the precise control of\nsupervised fine-tuning. On one hand, we propose a series of training strategies\nto fine-tune models to generate high-quality candidates with diverse\npreferences. On the other hand, we implement the ICL approach with an example\nselection method based on named entity recognition to prevent overemphasis on\nentities. The refiner optimizes each candidate by correcting logical or\nsyntactical errors. To address the challenge of identifying the best candidate,\nwe fine-tune a selection model to distinguish nuances of candidate SQL queries.\nThe experimental results on multiple dialect datasets demonstrate the\nrobustness of XiYan-SQL in addressing challenges across different scenarios.\nOverall, our proposed XiYan-SQL achieves the state-of-the-art execution\naccuracy of 89.65% on the Spider test set, 69.86% on SQL-Eval, 41.20% on\nNL2GQL, and a competitive score of 72.23% on the Bird development benchmark.\nThe proposed framework not only enhances the quality and diversity of SQL\nqueries but also outperforms previous methods.\n","authors":["Yingqi Gao","Yifu Liu","Xiaoxia Li","Xiaorong Shi","Yin Zhu","Yiming Wang","Shiqi Li","Wei Li","Yuntao Hong","Zhiling Luo","Jinyang Gao","Liyu Mou","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2411.08599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13178v2","updated":"2024-11-13T13:14:19Z","published":"2024-10-17T02:58:57Z","title":"GeSubNet: Gene Interaction Inference for Disease Subtype Network\n  Generation","summary":"  Retrieving gene functional networks from knowledge databases presents a\nchallenge due to the mismatch between disease networks and subtype-specific\nvariations. Current solutions, including statistical and deep learning methods,\noften fail to effectively integrate gene interaction knowledge from databases\nor explicitly learn subtype-specific interactions. To address this mismatch, we\npropose GeSubNet, which learns a unified representation capable of predicting\ngene interactions while distinguishing between different disease subtypes.\nGraphs generated by such representations can be considered subtype-specific\nnetworks. GeSubNet is a multi-step representation learning framework with three\nmodules: First, a deep generative model learns distinct disease subtypes from\npatient gene expression profiles. Second, a graph neural network captures\nrepresentations of prior gene networks from knowledge databases, ensuring\naccurate physical gene interactions. Finally, we integrate these two\nrepresentations using an inference loss that leverages graph generation\ncapabilities, conditioned on the patient separation loss, to refine\nsubtype-specific information in the learned representation. GeSubNet\nconsistently outperforms traditional methods, with average improvements of\n30.6%, 21.0%, 20.1%, and 56.6% across four graph evaluation metrics, averaged\nover four cancer datasets. Particularly, we conduct a biological simulation\nexperiment to assess how the behavior of selected genes from over 11,000\ncandidates affects subtypes or patient distributions. The results show that the\ngenerated network has the potential to identify subtype-specific genes with an\n83% likelihood of impacting patient distribution shifts. The GeSubNet resource\nis available: https://anonymous.4open.science/r/GeSubNet/\n","authors":["Ziwei Yang","Zheng Chen","Xin Liu","Rikuto Kotoge","Peng Chen","Yasuko Matsubara","Yasushi Sakurai","Jimeng Sun"],"pdf_url":"https://arxiv.org/pdf/2410.13178v2.pdf","comment":"Under review as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2411.08590v1","updated":"2024-11-13T13:13:07Z","published":"2024-11-13T13:13:07Z","title":"Hopfield-Fenchel-Young Networks: A Unified Framework for Associative\n  Memory Retrieval","summary":"  Associative memory models, such as Hopfield networks and their modern\nvariants, have garnered renewed interest due to advancements in memory capacity\nand connections with self-attention in transformers. In this work, we introduce\na unified framework-Hopfield-Fenchel-Young networks-which generalizes these\nmodels to a broader family of energy functions. Our energies are formulated as\nthe difference between two Fenchel-Young losses: one, parameterized by a\ngeneralized entropy, defines the Hopfield scoring mechanism, while the other\napplies a post-transformation to the Hopfield output. By utilizing Tsallis and\nnorm entropies, we derive end-to-end differentiable update rules that enable\nsparse transformations, uncovering new connections between loss margins,\nsparsity, and exact retrieval of single memory patterns. We further extend this\nframework to structured Hopfield networks using the SparseMAP transformation,\nallowing the retrieval of pattern associations rather than a single pattern.\nOur framework unifies and extends traditional and modern Hopfield networks and\nprovides an energy minimization perspective for widely used\npost-transformations like $\\ell_2$-normalization and layer normalization-all\nthrough suitable choices of Fenchel-Young losses and by using convex analysis\nas a building block. Finally, we validate our Hopfield-Fenchel-Young networks\non diverse memory recall tasks, including free and sequential recall.\nExperiments on simulated data, image retrieval, multiple instance learning, and\ntext rationalization demonstrate the effectiveness of our approach.\n","authors":["Saul Santos","Vlad Niculae","Daniel McNamee","Andr√© F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2411.08590v1.pdf","comment":"49 pages, 14 figures. arXiv admin note: text overlap with\n  arXiv:2402.13725"},{"id":"http://arxiv.org/abs/2411.08587v1","updated":"2024-11-13T13:11:49Z","published":"2024-11-13T13:11:49Z","title":"DeepUQ: Assessing the Aleatoric Uncertainties from two Deep Learning\n  Methods","summary":"  Assessing the quality of aleatoric uncertainty estimates from uncertainty\nquantification (UQ) deep learning methods is important in scientific contexts,\nwhere uncertainty is physically meaningful and important to characterize and\ninterpret exactly. We systematically compare aleatoric uncertainty measured by\ntwo UQ techniques, Deep Ensembles (DE) and Deep Evidential Regression (DER).\nOur method focuses on both zero-dimensional (0D) and two-dimensional (2D) data,\nto explore how the UQ methods function for different data dimensionalities. We\ninvestigate uncertainty injected on the input and output variables and include\na method to propagate uncertainty in the case of input uncertainty so that we\ncan compare the predicted aleatoric uncertainty to the known values. We\nexperiment with three levels of noise. The aleatoric uncertainty predicted\nacross all models and experiments scales with the injected noise level.\nHowever, the predicted uncertainty is miscalibrated to $\\rm{std}(\\sigma_{\\rm\nal})$ with the true uncertainty for half of the DE experiments and almost all\nof the DER experiments. The predicted uncertainty is the least accurate for\nboth UQ methods for the 2D input uncertainty experiment and the high-noise\nlevel. While these results do not apply to more complex data, they highlight\nthat further research on post-facto calibration for these methods would be\nbeneficial, particularly for high-noise and high-dimensional settings.\n","authors":["Rebecca Nevin","Aleksandra ƒÜiprijanoviƒá","Brian D. Nord"],"pdf_url":"https://arxiv.org/pdf/2411.08587v1.pdf","comment":"Accepted to the Machine Learning for Physical Sciences workshop at\n  NeurIPS 2024; 11 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2411.08582v1","updated":"2024-11-13T13:01:44Z","published":"2024-11-13T13:01:44Z","title":"Intelligent Algorithms For Signature Diagnostics Of Three-Phase Motors","summary":"  The application of machine learning (ML) algorithms in the intelligent\ndiagnosis of three-phase engines has the potential to significantly enhance\ndiagnostic performance and accuracy. Traditional methods largely rely on\nsignature analysis, which, despite being a standard practice, can benefit from\nthe integration of advanced ML techniques. In our study, we innovate by\ncombining state of the art algorithms with a novel unsupervised anomaly\ngeneration methodology that takes into account physics model of the engine.\nThis hybrid approach leverages the strengths of both supervised ML and\nunsupervised signature analysis, achieving superior diagnostic accuracy and\nreliability along with a wide industrial application. Our experimental results\ndemonstrate that this method significantly outperforms existing ML and non-ML\nstate-of-the-art approaches while retaining the practical advantages of an\nunsupervised methodology. The findings highlight the potential of our approach\nto significantly contribute to the field of engine diagnostics, offering a\nrobust and efficient solution for real-world applications.\n","authors":["Stepan Svirin","Artem Ryzhikov","Saraa Ali","Denis Derkach"],"pdf_url":"https://arxiv.org/pdf/2411.08582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16561v2","updated":"2024-11-13T13:01:19Z","published":"2024-10-21T22:40:42Z","title":"Gradient Normalization Provably Benefits Nonconvex SGD under\n  Heavy-Tailed Noise","summary":"  This paper investigates the roles of gradient normalization and clipping in\nensuring the convergence of Stochastic Gradient Descent (SGD) under\nheavy-tailed noise. While existing approaches consider gradient clipping\nindispensable for SGD convergence, we theoretically demonstrate that gradient\nnormalization alone without clipping is sufficient to ensure convergence.\nFurthermore, we establish that combining gradient normalization with clipping\noffers significantly improved convergence rates compared to using either\ntechnique in isolation, particularly as gradient noise diminishes. With these\nresults, our work provides the first theoretical evidence demonstrating the\nbenefits of gradient normalization in SGD under heavy-tailed noise. Finally, we\nintroduce an accelerated SGD variant that incorporates both gradient\nnormalization and clipping, further enhancing convergence rates under\nheavy-tailed noise.\n","authors":["Tao Sun","Xinwang Liu","Kun Yuan"],"pdf_url":"https://arxiv.org/pdf/2410.16561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07743v3","updated":"2024-11-13T12:43:33Z","published":"2023-06-13T13:00:10Z","title":"V-LoL: A Diagnostic Dataset for Visual Logical Learning","summary":"  Despite the successes of recent developments in visual AI, different\nshortcomings still exist; from missing exact logical reasoning, to abstract\ngeneralization abilities, to understanding complex and noisy scenes.\nUnfortunately, existing benchmarks, were not designed to capture more than a\nfew of these aspects. Whereas deep learning datasets focus on visually complex\ndata but simple visual reasoning tasks, inductive logic datasets involve\ncomplex logical learning tasks, however, lack the visual component. To address\nthis, we propose the diagnostic visual logical learning dataset, V-LoL, that\nseamlessly combines visual and logical challenges. Notably, we introduce the\nfirst instantiation of V-LoL, V-LoL-Train, - a visual rendition of a classic\nbenchmark in symbolic AI, the Michalski train problem. By incorporating\nintricate visual scenes and flexible logical reasoning tasks within a versatile\nframework, V-LoL-Train provides a platform for investigating a wide range of\nvisual logical learning challenges. We evaluate a variety of AI systems\nincluding traditional symbolic AI, neural AI, as well as neuro-symbolic AI. Our\nevaluations demonstrate that even SOTA AI faces difficulties in dealing with\nvisual logical learning challenges, highlighting unique advantages and\nlimitations of each methodology. Overall, V-LoL opens up new avenues for\nunderstanding and enhancing current abilities in visual logical learning for AI\nsystems.\n","authors":["Lukas Helff","Wolfgang Stammer","Hikaru Shindo","Devendra Singh Dhami","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2306.07743v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02549v2","updated":"2024-11-13T12:37:09Z","published":"2024-02-04T15:52:59Z","title":"Are Large Language Models Table-based Fact-Checkers?","summary":"  Table-based Fact Verification (TFV) aims to extract the entailment relation\nbetween statements and structured tables. Existing TFV methods based on\nsmall-scaled models suffer from insufficient labeled data and weak zero-shot\nability. Recently, the appearance of Large Language Models (LLMs) has gained\nlots of attraction in research fields. They have shown powerful zero-shot and\nin-context learning abilities on several NLP tasks, but their potential on TFV\nis still unknown. In this work, we implement a preliminary study about whether\nLLMs are table-based fact-checkers. In detail, we design diverse prompts to\nexplore how the in-context learning can help LLMs in TFV, i.e., zero-shot and\nfew-shot TFV capability. Besides, we carefully design and construct TFV\ninstructions to study the performance gain brought by the instruction tuning of\nLLMs. Experimental results demonstrate that LLMs can achieve acceptable results\non zero-shot and few-shot TFV with prompt engineering, while instruction-tuning\ncan stimulate the TFV capability significantly. We also make some valuable\nfindings about the format of zero-shot prompts and the number of in-context\nexamples. Finally, we analyze some possible directions to promote the accuracy\nof TFV via LLMs, which is beneficial to further research of table reasoning.\n","authors":["Hanwen Zhang","Qingyi Si","Peng Fu","Zheng Lin","Weiping Wang"],"pdf_url":"https://arxiv.org/pdf/2402.02549v2.pdf","comment":"CSCWD 2024"},{"id":"http://arxiv.org/abs/2410.10929v4","updated":"2024-11-13T12:27:38Z","published":"2024-10-14T16:35:27Z","title":"ASTM :Autonomous Smart Traffic Management System Using Artificial\n  Intelligence CNN and LSTM","summary":"  In the modern world, the development of Artificial Intelligence (AI) has\ncontributed to improvements in various areas, including automation, computer\nvision, fraud detection, and more. AI can be leveraged to enhance the\nefficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce\ntraffic congestion rates. This paper presents an Autonomous Smart Traffic\nManagement (STM) system that uses AI to improve traffic flow rates. The system\nemploys the YOLO V5 Convolutional Neural Network to detect vehicles in traffic\nmanagement images. Additionally, it predicts the number of vehicles for the\nnext 12 hours using a Recurrent Neural Network with Long Short-Term Memory\n(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the\ntraffic cycle length based on these vehicle predictions, aided by AI. From the\nresults of the RNN-LSTM model for predicting vehicle numbers over the next 12\nhours, we observe that the model predicts traffic with a Mean Squared Error\n(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.\nAfter simulating the STM system in the CARLA simulation environment, we found\nthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per\nminute) is 50\\% higher than the rate without STM (around 15 vehicles per\nminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5\nseconds per vehicle) is 70\\% lower than without STM (around 12 seconds per\nvehicle). These results demonstrate that the STM system using AI can increase\ntraffic flow by 50\\% and reduce vehicle pass delays by 70\\%.\n","authors":["Christofel Rio Goenawan"],"pdf_url":"https://arxiv.org/pdf/2410.10929v4.pdf","comment":"In process to IEEE Intelligent Vehicle Symposium 2025"},{"id":"http://arxiv.org/abs/2411.08566v1","updated":"2024-11-13T12:26:08Z","published":"2024-11-13T12:26:08Z","title":"Grammarization-Based Grasping with Deep Multi-Autoencoder Latent Space\n  Exploration by Reinforcement Learning Agent","summary":"  Grasping by a robot in unstructured environments is deemed a critical\nchallenge because of the requirement for effective adaptation to a wide\nvariation in object geometries, material properties, and other environmental\nfactors. In this paper, we propose a novel framework for robotic grasping based\non the idea of compressing high-dimensional target and gripper features in a\ncommon latent space using a set of autoencoders. Our approach simplifies\ngrasping by using three autoencoders dedicated to the target, the gripper, and\na third one that fuses their latent representations. This allows the RL agent\nto achieve higher learning rates at the initial stages of exploration of a new\nenvironment, as well as at non-zero shot grasp attempts. The agent explores the\nlatent space of the third autoencoder for better quality grasp without explicit\nreconstruction of objects. By implementing the PoWER algorithm into the RL\ntraining process, updates on the agent's policy will be made through the\nperturbation in the reward-weighted latent space. The successful exploration\nefficiently constrains both position and pose integrity for feasible executions\nof grasps. We evaluate our system on a diverse set of objects, demonstrating\nthe high success rate in grasping with minimum computational overhead. We found\nthat approach enhances the adaptation of the RL agent by more than 35 \\% in\nsimulation experiments.\n","authors":["Leonidas Askianakis"],"pdf_url":"https://arxiv.org/pdf/2411.08566v1.pdf","comment":"Submitted for review at IEEE ICRA 2025"},{"id":"http://arxiv.org/abs/2411.08557v1","updated":"2024-11-13T12:13:15Z","published":"2024-11-13T12:13:15Z","title":"Learning Locally Adaptive Metrics that Enhance Structural Representation\n  with $\\texttt{LAMINAR}$","summary":"  We present $\\texttt{LAMINAR}$, a novel unsupervised machine learning pipeline\ndesigned to enhance the representation of structure within data via producing a\nmore-informative distance metric. Analysis methods in the physical sciences\noften rely on standard metrics to define geometric relationships in data, which\nmay fail to capture the underlying structure of complex data sets.\n$\\texttt{LAMINAR}$ addresses this by using a continuous-normalising-flow and\ninverse-transform-sampling to define a Riemannian manifold in the data space\nwithout the need for the user to specify a metric over the data a-priori. The\nresult is a locally-adaptive-metric that produces structurally-informative\ndensity-based distances. We demonstrate the utility of $\\texttt{LAMINAR}$ by\ncomparing its output to the Euclidean metric for structured data sets.\n","authors":["Christian Kleiber","William H. Oliver","Tobias Buck"],"pdf_url":"https://arxiv.org/pdf/2411.08557v1.pdf","comment":"Accepted to the NeurIPS 2024 Machine Learning and the Physical\n  Sciences workshop. 6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.08552v1","updated":"2024-11-13T12:03:39Z","published":"2024-11-13T12:03:39Z","title":"Leveraging Pre-Trained Neural Networks to Enhance Machine Learning with\n  Variational Quantum Circuits","summary":"  Quantum Machine Learning (QML) offers tremendous potential but is currently\nlimited by the availability of qubits. We introduce an innovative approach that\nutilizes pre-trained neural networks to enhance Variational Quantum Circuits\n(VQC). This technique effectively separates approximation error from qubit\ncount and removes the need for restrictive conditions, making QML more viable\nfor real-world applications. Our method significantly improves parameter\noptimization for VQC while delivering notable gains in representation and\ngeneralization capabilities, as evidenced by rigorous theoretical analysis and\nextensive empirical testing on quantum dot classification tasks. Moreover, our\nresults extend to applications such as human genome analysis, demonstrating the\nbroad applicability of our approach. By addressing the constraints of current\nquantum hardware, our work paves the way for a new era of advanced QML\napplications, unlocking the full potential of quantum computing in fields such\nas machine learning, materials science, medicine, mimetics, and various\ninterdisciplinary areas.\n","authors":["Jun Qi","Chao-Han Yang","Samuel Yen-Chi Chen","Pin-Yu Chen","Hector Zenil","Jesper Tegner"],"pdf_url":"https://arxiv.org/pdf/2411.08552v1.pdf","comment":"In submission"},{"id":"http://arxiv.org/abs/2411.08550v1","updated":"2024-11-13T11:59:40Z","published":"2024-11-13T11:59:40Z","title":"Graph Neural Networks in Supply Chain Analytics and Optimization:\n  Concepts, Perspectives, Dataset and Benchmarks","summary":"  Graph Neural Networks (GNNs) have recently gained traction in transportation,\nbioinformatics, language and image processing, but research on their\napplication to supply chain management remains limited. Supply chains are\ninherently graph-like, making them ideal for GNN methodologies, which can\noptimize and solve complex problems. The barriers include a lack of proper\nconceptual foundations, familiarity with graph applications in SCM, and\nreal-world benchmark datasets for GNN-based supply chain research. To address\nthis, we discuss and connect supply chains with graph structures for effective\nGNN application, providing detailed formulations, examples, mathematical\ndefinitions, and task guidelines. Additionally, we present a multi-perspective\nreal-world benchmark dataset from a leading FMCG company in Bangladesh,\nfocusing on supply chain planning. We discuss various supply chain tasks using\nGNNs and benchmark several state-of-the-art models on homogeneous and\nheterogeneous graphs across six supply chain analytics tasks. Our analysis\nshows that GNN-based models consistently outperform statistical Machine\nLearning and other Deep Learning models by around 10-30% in regression, 10-30%\nin classification and detection tasks, and 15-40% in anomaly detection tasks on\ndesignated metrics. With this work, we lay the groundwork for solving supply\nchain problems using GNNs, supported by conceptual discussions, methodological\ninsights, and a comprehensive dataset.\n","authors":["Azmine Toushik Wasi","MD Shafikul Islam","Adipto Raihan Akib","Mahathir Mohammad Bappy"],"pdf_url":"https://arxiv.org/pdf/2411.08550v1.pdf","comment":"27 Pages. Extended journal version of SupplyGraph (arXiv:2401.15299).\n  In Review"},{"id":"http://arxiv.org/abs/2411.08537v1","updated":"2024-11-13T11:35:39Z","published":"2024-11-13T11:35:39Z","title":"MLV$^2$-Net: Rater-Based Majority-Label Voting for Consistent Meningeal\n  Lymphatic Vessel Segmentation","summary":"  Meningeal lymphatic vessels (MLVs) are responsible for the drainage of waste\nproducts from the human brain. An impairment in their functionality has been\nassociated with aging as well as brain disorders like multiple sclerosis and\nAlzheimer's disease. However, MLVs have only recently been described for the\nfirst time in magnetic resonance imaging (MRI), and their ramified structure\nrenders manual segmentation particularly difficult. Further, as there is no\nconsistent notion of their appearance, human-annotated MLV structures contain a\nhigh inter-rater variability that most automatic segmentation methods cannot\ntake into account. In this work, we propose a new rater-aware training scheme\nfor the popular nnU-Net model, and we explore rater-based ensembling strategies\nfor accurate and consistent segmentation of MLVs. This enables us to boost\nnnU-Net's performance while obtaining explicit predictions in different\nannotation styles and a rater-based uncertainty estimation. Our final model,\nMLV$^2$-Net, achieves a Dice similarity coefficient of 0.806 with respect to\nthe human reference standard. The model further matches the human inter-rater\nreliability and replicates age-related associations with MLV volume.\n","authors":["Fabian Bongratz","Markus Karmann","Adrian Holz","Moritz Bonhoeffer","Viktor Neumaier","Sarah Deli","Benita Schmitz-Koep","Claus Zimmer","Christian Sorg","Melissa Thalhammer","Dennis M Hedderich","Christian Wachinger"],"pdf_url":"https://arxiv.org/pdf/2411.08537v1.pdf","comment":"ML4H 2024"},{"id":"http://arxiv.org/abs/2411.08530v1","updated":"2024-11-13T11:24:12Z","published":"2024-11-13T11:24:12Z","title":"Efficient Whole Slide Image Classification through Fisher Vector\n  Representation","summary":"  The advancement of digital pathology, particularly through computational\nanalysis of whole slide images (WSI), is poised to significantly enhance\ndiagnostic precision and efficiency. However, the large size and complexity of\nWSIs make it difficult to analyze and classify them using computers. This study\nintroduces a novel method for WSI classification by automating the\nidentification and examination of the most informative patches, thus\neliminating the need to process the entire slide. Our method involves\ntwo-stages: firstly, it extracts only a few patches from the WSIs based on\ntheir pathological significance; and secondly, it employs Fisher vectors (FVs)\nfor representing features extracted from these patches, which is known for its\nrobustness in capturing fine-grained details. This approach not only\naccentuates key pathological features within the WSI representation but also\nsignificantly reduces computational overhead, thus making the process more\nefficient and scalable. We have rigorously evaluated the proposed method across\nmultiple datasets to benchmark its performance against comprehensive WSI\nanalysis and contemporary weakly-supervised learning methodologies. The\nempirical results indicate that our focused analysis of select patches,\ncombined with Fisher vector representation, not only aligns with, but at times\nsurpasses, the classification accuracy of standard practices. Moreover, this\nstrategy notably diminishes computational load and resource expenditure,\nthereby establishing an efficient and precise framework for WSI analysis in the\nrealm of digital pathology.\n","authors":["Ravi Kant Gupta","Dadi Dharani","Shambhavi Shanker","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2411.08530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10040v3","updated":"2024-11-13T11:13:56Z","published":"2024-05-16T12:22:41Z","title":"SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation","summary":"  It is often desirable to distill the capabilities of large language models\n(LLMs) into smaller student models due to compute and memory constraints. One\nway to do this for classification tasks is via dataset synthesis, which can be\naccomplished by generating examples of each label from the LLM. Prior\napproaches to synthesis use few-shot prompting, which relies on the LLM's\nparametric knowledge to generate usable examples. However, this leads to issues\nof repetition, bias towards popular entities, and stylistic differences from\nhuman text. In this work, we propose Synthesize by Retrieval and Refinement\n(SynthesizRR), which uses retrieval augmentation to introduce variety into the\ndataset synthesis process: as retrieved passages vary, the LLM is seeded with\ndifferent content to generate its examples. We empirically study the synthesis\nof six datasets, covering topic classification, sentiment analysis, tone\ndetection, and humor, requiring complex synthesis strategies. We find that\nSynthesizRR greatly improves lexical and semantic diversity, similarity to\nhuman-written text, and distillation performance, when compared to 32-shot\nprompting and four prior approaches. We release our code to perform all steps\nat https://github.com/amazon-science/synthesizrr\n","authors":["Abhishek Divekar","Greg Durrett"],"pdf_url":"https://arxiv.org/pdf/2405.10040v3.pdf","comment":"Published as a main conference paper at EMNLP 2024. Code available at\n  https://github.com/amazon-science/synthesizrr"},{"id":"http://arxiv.org/abs/2411.08521v1","updated":"2024-11-13T11:08:28Z","published":"2024-11-13T11:08:28Z","title":"SAD-TIME: a Spatiotemporal-fused network for depression detection with\n  Automated multi-scale Depth-wise and TIME-interval-related common feature\n  extractor","summary":"  Background and Objective: Depression is a severe mental disorder, and\naccurate diagnosis is pivotal to the cure and rehabilitation of people with\ndepression. However, the current questionnaire-based diagnostic methods could\nbring subjective biases and may be denied by subjects. In search of a more\nobjective means of diagnosis, researchers have begun to experiment with deep\nlearning-based methods for identifying depressive disorders in recent years.\nMethods: In this study, a novel Spatiotemporal-fused network with Automated\nmulti-scale Depth-wise and TIME-interval-related common feature extractor\n(SAD-TIME) is proposed. SAD-TIME incorporates an automated nodes' common\nfeatures extractor (CFE), a spatial sector (SpS), a modified temporal sector\n(TeS), and a domain adversarial learner (DAL). The CFE includes a multi-scale\ndepth-wise 1D-convolutional neural network and a time-interval embedding\ngenerator, where the unique information of each channel is preserved. The SpS\nfuses the functional connectivity with the distance-based connectivity\ncontaining spatial position of EEG electrodes. A multi-head-attention graph\nconvolutional network is also applied in the SpS to fuse the features from\ndifferent EEG channels. The TeS is based on long short-term memory and graph\ntransformer networks, where the temporal information of different time-windows\nis fused. Moreover, the DAL is used after the SpS to obtain the\ndomain-invariant feature. Results: Experimental results under tenfold\ncross-validation show that the proposed SAD-TIME method achieves 92.00% and\n94.00% depression classification accuracies on two datasets, respectively, in\ncross-subject mode. Conclusion: SAD-TIME is a robust depression detection\nmodel, where the automatedly-generated features, the SpS and the TeS assist the\nclassification performance with the fusion of the innate spatiotemporal\ninformation in the EEG signals.\n","authors":["Han-Guang Wang","Hui-Rang Hou","Li-Cheng Jin","Chen-Yang Xu","Zhong-Yi Zhang","Qing-Hao Meng"],"pdf_url":"https://arxiv.org/pdf/2411.08521v1.pdf","comment":"21pages, 7 figures"},{"id":"http://arxiv.org/abs/2409.15166v2","updated":"2024-11-13T11:05:04Z","published":"2024-09-23T16:20:21Z","title":"Harmonic Path Integral Diffusion","summary":"  In this manuscript, we present a novel approach for sampling from a\ncontinuous multivariate probability distribution, which may either be\nexplicitly known (up to a normalization factor) or represented via empirical\nsamples. Our method constructs a time-dependent bridge from a delta function\ncentered at the origin of the state space at $t=0$, optimally transforming it\ninto the target distribution at $t=1$. We formulate this as a Stochastic\nOptimal Control problem of the Path Integral Control type, with a cost function\ncomprising (in its basic form) a quadratic control term, a quadratic state\nterm, and a terminal constraint. This framework, which we refer to as Harmonic\nPath Integral Diffusion (H-PID), leverages an analytical solution through a\nmapping to an auxiliary quantum harmonic oscillator in imaginary time.\n  The H-PID framework results in a set of efficient sampling algorithms,\nwithout the incorporation of Neural Networks. The algorithms are validated on\ntwo standard use cases: a mixture of Gaussians over a grid and images from\nCIFAR-10. The transparency of the method allows us to analyze the algorithms in\ndetail, particularly revealing that the current weighted state is an order\nparameter for the dynamic phase transition, signaling earlier, at $t<1$, that\nthe sample generation process is almost complete. We contrast these algorithms\nwith other sampling methods, particularly simulated annealing and path integral\nsampling, highlighting their advantages in terms of analytical control,\naccuracy, and computational efficiency on benchmark problems.\n  Additionally, we extend the methodology to more general cases where the\nunderlying stochastic differential equation includes an external deterministic,\npossibly non-conservative force, and where the cost function incorporates a\ngauge potential term.\n","authors":["Hamidreza Behjoo","Michael Chertkov"],"pdf_url":"https://arxiv.org/pdf/2409.15166v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08506v1","updated":"2024-11-13T10:43:31Z","published":"2024-11-13T10:43:31Z","title":"An Information Theoretic Approach to Operationalize Right to Data\n  Protection","summary":"  The widespread practice of indiscriminate data scraping to fine-tune language\nmodels (LMs) raises significant legal and ethical concerns, particularly\nregarding compliance with data protection laws such as the General Data\nProtection Regulation (GDPR). This practice often results in the unauthorized\nuse of personal information, prompting growing debate within the academic and\nregulatory communities. Recent works have introduced the concept of generating\nunlearnable datasets (by adding imperceptible noise to the clean data), such\nthat the underlying model achieves lower loss during training but fails to\ngeneralize to the unseen test setting. Though somewhat effective, these\napproaches are predominantly designed for images and are limited by several\npractical constraints like requiring knowledge of the target model. To this\nend, we introduce RegText, a framework that injects imperceptible spurious\ncorrelations into natural language datasets, effectively rendering them\nunlearnable without affecting semantic content. We demonstrate RegText's\nutility through rigorous empirical analysis of small and large LMs. Notably,\nRegText can restrict newer models like GPT-4o and Llama from learning on our\ngenerated data, resulting in a drop in their test accuracy compared to their\nzero-shot performance and paving the way for generating unlearnable text to\nprotect public data.\n","authors":["Abhinav Java","Simra Shahid","Chirag Agarwal"],"pdf_url":"https://arxiv.org/pdf/2411.08506v1.pdf","comment":"First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2301.10369v4","updated":"2024-11-13T10:35:25Z","published":"2023-01-25T00:50:28Z","title":"Exact Fractional Inference via Re-Parametrization & Interpolation\n  between Tree-Re-Weighted- and Belief Propagation- Algorithms","summary":"  Computing the partition function, $Z$, of an Ising model over a graph of $N$\n\\enquote{spins} is most likely exponential in $N$. Efficient variational\nmethods, such as Belief Propagation (BP) and Tree Re-Weighted (TRW) algorithms,\ncompute $Z$ approximately by minimizing the respective (BP- or TRW-) free\nenergy. We generalize the variational scheme by building a $\\lambda$-fractional\ninterpolation, $Z^{(\\lambda)}$, where $\\lambda=0$ and $\\lambda=1$ correspond to\nTRW- and BP-approximations, respectively. This fractional scheme -- coined\nFractional Belief Propagation (FBP) -- guarantees that in the attractive\n(ferromagnetic) case $Z^{(TRW)} \\geq Z^{(\\lambda)} \\geq Z^{(BP)}$, and there\nexists a unique (\\enquote{exact}) $\\lambda_*$ such that $Z=Z^{(\\lambda_*)}$.\nGeneralizing the re-parametrization approach of\n\\citep{wainwright_tree-based_2002} and the loop series approach of\n\\citep{chertkov_loop_2006}, we show how to express $Z$ as a product, $\\forall\n\\lambda:\\ Z=Z^{(\\lambda)}{\\tilde Z}^{(\\lambda)}$, where the multiplicative\ncorrection, ${\\tilde Z}^{(\\lambda)}$, is an expectation over a node-independent\nprobability distribution built from node-wise fractional marginals. Our\ntheoretical analysis is complemented by extensive experiments with models from\nIsing ensembles over planar and random graphs of medium and large sizes. Our\nempirical study yields a number of interesting observations, such as the\nability to estimate ${\\tilde Z}^{(\\lambda)}$ with $O(N^{2::4})$ fractional\nsamples and suppression of variation in $\\lambda_*$ estimates with an increase\nin $N$ for instances from a particular random Ising ensemble, where $[2::4]$\nindicates a range from $2$ to $4$. We also discuss the applicability of this\napproach to the problem of image de-noising.\n","authors":["Hamidreza Behjoo","Michael Chertkov"],"pdf_url":"https://arxiv.org/pdf/2301.10369v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06058v3","updated":"2024-11-13T10:09:25Z","published":"2023-03-10T16:43:48Z","title":"A General Recipe for the Analysis of Randomized Multi-Armed Bandit\n  Algorithms","summary":"  In this paper we propose a general methodology to derive regret bounds for\nrandomized multi-armed bandit algorithms. It consists in checking a set of\nsufficient conditions on the sampling probability of each arm and on the family\nof distributions to prove a logarithmic regret. As a direct application we\nrevisit two famous bandit algorithms, Minimum Empirical Divergence (MED) and\nThompson Sampling (TS), under various models for the distributions including\nsingle parameter exponential families, Gaussian distributions, bounded\ndistributions, or distributions satisfying some conditions on their moments. In\nparticular, we prove that MED is asymptotically optimal for all these models,\nbut also provide a simple regret analysis of some TS algorithms for which the\noptimality is already known. We then further illustrate the interest of our\napproach, by analyzing a new Non-Parametric TS algorithm (h-NPTS), adapted to\nsome families of unbounded reward distributions with a bounded h-moment. This\nmodel can for instance capture some non-parametric families of distributions\nwhose variance is upper bounded by a known constant.\n","authors":["Dorian Baudry","Kazuya Suzuki","Junya Honda"],"pdf_url":"https://arxiv.org/pdf/2303.06058v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14487v3","updated":"2024-11-13T10:09:23Z","published":"2024-08-19T18:47:07Z","title":"Active learning of digenic functions with boolean matrix logic\n  programming","summary":"  We apply logic-based machine learning techniques to facilitate cellular\nengineering and drive biological discovery, based on comprehensive databases of\nmetabolic processes called genome-scale metabolic network models (GEMs).\nPredicted host behaviours are not always correctly described by GEMs. Learning\nthe intricate genetic interactions within GEMs presents computational and\nempirical challenges. To address these, we describe a novel approach called\nBoolean Matrix Logic Programming (BMLP) by leveraging boolean matrices to\nevaluate large logic programs. We introduce a new system, $BMLP_{active}$,\nwhich efficiently explores the genomic hypothesis space by guiding informative\nexperimentation through active learning. In contrast to sub-symbolic methods,\n$BMLP_{active}$ encodes a state-of-the-art GEM of a widely accepted bacterial\nhost in an interpretable and logical representation using datalog logic\nprograms. Notably, $BMLP_{active}$ can successfully learn the interaction\nbetween a gene pair with fewer training examples than random experimentation,\novercoming the increase in experimental design space. $BMLP_{active}$ enables\nrapid optimisation of metabolic models and offers a realistic approach to a\nself-driving lab for microbial engineering.\n","authors":["Lun Ai","Stephen H. Muggleton","Shi-shun Liang","Geoff S. Baldwin"],"pdf_url":"https://arxiv.org/pdf/2408.14487v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.06724"},{"id":"http://arxiv.org/abs/2410.17851v2","updated":"2024-11-13T10:01:38Z","published":"2024-10-23T13:20:42Z","title":"The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty\n  Quantification","summary":"  Tsetlin Machines (TMs) have emerged as a compelling alternative to\nconventional deep learning methods, offering notable advantages such as smaller\nmemory footprint, faster inference, fault-tolerant properties, and\ninterpretability. Although various adaptations of TMs have expanded their\napplicability across diverse domains, a fundamental gap remains in\nunderstanding how TMs quantify uncertainty in their predictions. In response,\nthis paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed\nat providing a robust, reliable, and interpretable approach for uncertainty\nquantification. Unlike the original TM, the PTM learns the probability of\nstaying on each state of each Tsetlin Automaton (TA) across all clauses. These\nprobabilities are updated using the feedback tables that are part of the TM\nframework: Type I and Type II feedback. During inference, TAs decide their\nactions by sampling states based on learned probability distributions, akin to\nBayesian neural networks when generating weight values. In our experimental\nanalysis, we first illustrate the spread of the probabilities across TA states\nfor the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models\nusing both simulated and real-world datasets. The experiments on the simulated\ndataset reveal the PTM's effectiveness in uncertainty quantification,\nparticularly in delineating decision boundaries and identifying regions of high\nuncertainty. Moreover, when applied to multiclass classification tasks using\nthe Iris dataset, the PTM demonstrates competitive performance in terms of\npredictive entropy and expected calibration error, showcasing its potential as\na reliable tool for uncertainty estimation. Our findings underscore the\nimportance of selecting appropriate models for accurate uncertainty\nquantification in predictive tasks, with the PTM offering a particularly\ninterpretable and effective solution.\n","authors":["K. Darshana Abeyrathna","Sara El Mekkaoui","Andreas Hafver","Christian Agrell"],"pdf_url":"https://arxiv.org/pdf/2410.17851v2.pdf","comment":"12 pages, 5 figures, 6 tables, accepted and presented at ICAAI 2024,\n  London"},{"id":"http://arxiv.org/abs/2411.08482v1","updated":"2024-11-13T10:01:33Z","published":"2024-11-13T10:01:33Z","title":"Methodology for a Statistical Analysis of Influencing Factors on 3D\n  Object Detection Performance","summary":"  In autonomous driving, object detection is an essential task to perceive the\nenvironment by localizing and classifying objects. Most object detection\nalgorithms rely on deep learning for their superior performance. However, their\nblack box nature makes it challenging to ensure safety. In this paper, we\npropose a first-of-its-kind methodology for statistical analysis of the\ninfluence of various factors related to the objects to detect or the\nenvironment on the detection performance of both LiDAR- and camera-based 3D\nobject detectors. We perform a univariate analysis between each of the factors\nand the detection error in order to compare the strength of influence. To\nbetter identify potential sources of detection errors, we also analyze the\nperformance in dependency of the influencing factors and examine the\ninterdependencies between the different influencing factors. Recognizing the\nfactors that influence detection performance helps identify robustness issues\nin the trained object detector and supports the safety approval of object\ndetection systems.\n","authors":["Anton Kuznietsov","Dirk Schweickard","Steven Peters"],"pdf_url":"https://arxiv.org/pdf/2411.08482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08478v1","updated":"2024-11-13T09:55:59Z","published":"2024-11-13T09:55:59Z","title":"Learning Model Agnostic Explanations via Constraint Programming","summary":"  Interpretable Machine Learning faces a recurring challenge of explaining the\npredictions made by opaque classifiers such as ensemble models, kernel methods,\nor neural networks in terms that are understandable to humans. When the model\nis viewed as a black box, the objective is to identify a small set of features\nthat jointly determine the black box response with minimal error. However,\nfinding such model-agnostic explanations is computationally demanding, as the\nproblem is intractable even for binary classifiers. In this paper, the task is\nframed as a Constraint Optimization Problem, where the constraint solver seeks\nan explanation of minimum error and bounded size for an input data instance and\na set of samples generated by the black box. From a theoretical perspective,\nthis constraint programming approach offers PAC-style guarantees for the output\nexplanation. We evaluate the approach empirically on various datasets and show\nthat it statistically outperforms the state-of-the-art heuristic Anchors\nmethod.\n","authors":["Frederic Koriche","Jean-Marie Lagniez","Stefan Mengel","Chi Tran"],"pdf_url":"https://arxiv.org/pdf/2411.08478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07979v2","updated":"2024-11-13T09:52:45Z","published":"2024-11-12T17:58:40Z","title":"Exact, Tractable Gauss-Newton Optimization in Deep Reversible\n  Architectures Reveal Poor Generalization","summary":"  Second-order optimization has been shown to accelerate the training of deep\nneural networks in many applications, often yielding faster progress per\niteration on the training loss compared to first-order optimizers. However, the\ngeneralization properties of second-order methods are still being debated.\nTheoretical investigations have proved difficult to carry out outside the\ntractable settings of heavily simplified model classes -- thus, the relevance\nof existing theories to practical deep learning applications remains unclear.\nSimilarly, empirical studies in large-scale models and real datasets are\nsignificantly confounded by the necessity to approximate second-order updates\nin practice. It is often unclear whether the observed generalization behaviour\narises specifically from the second-order nature of the parameter updates, or\ninstead reflects the specific structured (e.g.\\ Kronecker) approximations used\nor any damping-based interpolation towards first-order updates. Here, we show\nfor the first time that exact Gauss-Newton (GN) updates take on a tractable\nform in a class of deep reversible architectures that are sufficiently\nexpressive to be meaningfully applied to common benchmark datasets. We exploit\nthis novel setting to study the training and generalization properties of the\nGN optimizer. We find that exact GN generalizes poorly. In the mini-batch\ntraining setting, this manifests as rapidly saturating progress even on the\n\\emph{training} loss, with parameter updates found to overfit each\nmini-batchatch without producing the features that would support generalization\nto other mini-batches. We show that our experiments run in the ``lazy'' regime,\nin which the neural tangent kernel (NTK) changes very little during the course\nof training. This behaviour is associated with having no significant changes in\nneural representations, explaining the lack of generalization.\n","authors":["Davide Buffelli","Jamie McGowan","Wangkun Xu","Alexandru Cioba","Da-shan Shiu","Guillaume Hennequin","Alberto Bernacchia"],"pdf_url":"https://arxiv.org/pdf/2411.07979v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.17804v3","updated":"2024-11-13T09:50:48Z","published":"2024-06-22T15:24:33Z","title":"A Review of Electromagnetic Elimination Methods for low-field portable\n  MRI scanner","summary":"  This paper analyzes conventional and deep learning methods for eliminating\nelectromagnetic interference (EMI) in MRI systems. We compare traditional\nanalytical and adaptive techniques with advanced deep learning approaches. Key\nstrengths and limitations of each method are highlighted. Recent advancements\nin active EMI elimination, such as external EMI receiver coils, are discussed\nalongside deep learning methods, which show superior EMI suppression by\nleveraging neural networks trained on MRI data. While deep learning improves\nEMI elimination and diagnostic capabilities, it introduces security and safety\nconcerns, particularly in commercial applications. A balanced approach,\nintegrating conventional reliability with deep learning's advanced\ncapabilities, is proposed for more effective EMI suppression in MRI systems.\n","authors":["Wanyu Bian","Panfeng Li","Mengyao Zheng","Chihang Wang","Anying Li","Ying Li","Haowei Ni","Zixuan Zeng"],"pdf_url":"https://arxiv.org/pdf/2406.17804v3.pdf","comment":"Accepted by 2024 5th International Conference on Machine Learning and\n  Computer Application"},{"id":"http://arxiv.org/abs/2304.08310v2","updated":"2024-11-13T09:47:41Z","published":"2023-04-17T14:27:19Z","title":"TreeC: a method to generate interpretable energy management systems\n  using a metaheuristic algorithm","summary":"  Energy management systems (EMS) have traditionally been implemented using\nrule-based control (RBC) and model predictive control (MPC) methods. However,\nrecent research has explored the use of reinforcement learning (RL) as a\npromising alternative. This paper introduces TreeC, a machine learning method\nthat utilizes the covariance matrix adaptation evolution strategy metaheuristic\nalgorithm to generate an interpretable EMS modeled as a decision tree. Unlike\nRBC and MPC approaches, TreeC learns the decision strategy of the EMS based on\nhistorical data, adapting the control model to the controlled energy grid. The\ndecision strategy is represented as a decision tree, providing interpretability\ncompared to RL methods that often rely on black-box models like neural\nnetworks. TreeC is evaluated against MPC with perfect forecast and RL EMSs in\ntwo case studies taken from literature: an electric grid case and a household\nheating case. In the electric grid case, TreeC achieves an average energy loss\nand constraint violation score of 19.2, which is close to MPC and RL EMSs that\nachieve scores of 14.4 and 16.2 respectively. All three methods control the\nelectric grid well especially when compared to the random EMS, which obtains an\naverage score of 12 875. In the household heating case, TreeC performs\nsimilarly to MPC on the adjusted and averaged electricity cost and total\ndiscomfort (0.033 EUR/m$^2$ and 0.42 Kh for TreeC compared to 0.037 EUR/m$^2$\nand 2.91 kH for MPC), while outperforming RL (0.266 EUR/m$^2$ and 24.41 Kh).\n","authors":["Julian Ruddick","Luis Ramirez Camargo","Muhammad Andy Putratama","Maarten Messagie","Thierry Coosemans"],"pdf_url":"https://arxiv.org/pdf/2304.08310v2.pdf","comment":"Accepted version Knowledge based system"},{"id":"http://arxiv.org/abs/2411.08460v1","updated":"2024-11-13T09:31:06Z","published":"2024-11-13T09:31:06Z","title":"Trap-MID: Trapdoor-based Defense against Model Inversion Attacks","summary":"  Model Inversion (MI) attacks pose a significant threat to the privacy of Deep\nNeural Networks by recovering training data distribution from well-trained\nmodels. While existing defenses often rely on regularization techniques to\nreduce information leakage, they remain vulnerable to recent attacks. In this\npaper, we propose the Trapdoor-based Model Inversion Defense (Trap-MID) to\nmislead MI attacks. A trapdoor is integrated into the model to predict a\nspecific label when the input is injected with the corresponding trigger.\nConsequently, this trapdoor information serves as the \"shortcut\" for MI\nattacks, leading them to extract trapdoor triggers rather than private data. We\nprovide theoretical insights into the impacts of trapdoor's effectiveness and\nnaturalness on deceiving MI attacks. In addition, empirical experiments\ndemonstrate the state-of-the-art defense performance of Trap-MID against\nvarious MI attacks without the requirements for extra data or large\ncomputational overhead. Our source code is publicly available at\nhttps://github.com/ntuaislab/Trap-MID.\n","authors":["Zhen-Ting Liu","Shang-Tse Chen"],"pdf_url":"https://arxiv.org/pdf/2411.08460v1.pdf","comment":"Accepted by Neural Information Processing Systems (NeurIPS) 2024"},{"id":"http://arxiv.org/abs/2307.12594v2","updated":"2024-11-13T09:29:36Z","published":"2023-07-24T08:11:59Z","title":"The effect of dataset size and the process of big data mining for\n  investigating solar-thermal desalination by using machine learning","summary":"  Machine learning's application in solar-thermal desalination is limited by\ndata shortage and inconsistent analysis. This study develops an optimized\ndataset collection and analysis process for the representative solar still. By\nultra-hydrophilic treatment on the condensation cover, the dataset collection\nprocess reduces the collection time by 83.3%. Over 1,000 datasets are\ncollected, which is nearly one order of magnitude larger than up-to-date works.\nThen, a new interdisciplinary process flow is proposed. Some meaningful results\nare obtained that were not addressed by previous studies. It is found that\nRadom Forest might be a better choice for datasets larger than 1,000 due to\nboth high accuracy and fast speed. Besides, the dataset range affects the\nquantified importance (weighted value) of factors significantly, with up to a\n115% increment. Moreover, the results show that machine learning has a high\naccuracy on the extrapolation prediction of productivity, where the minimum\nmean relative prediction error is just around 4%. The results of this work not\nonly show the necessity of the dataset characteristics' effect but also provide\na standard process for studying solar-thermal desalination by machine learning,\nwhich would pave the way for interdisciplinary study.\n","authors":["Guilong Peng","Senshan Sun","Zhenwei Xu","Juxin Du","Yangjun Qin","Swellam W. Sharshir","A. W. Kandel","A. E. Kabeel","Nuo Yang"],"pdf_url":"https://arxiv.org/pdf/2307.12594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00393v4","updated":"2024-11-13T09:27:41Z","published":"2024-11-01T06:40:47Z","title":"Advantages of Neural Population Coding for Deep Learning","summary":"  Scalar variables, e.g., the orientation of a shape in an image, are commonly\npredicted using a single output neuron in a neural network. In contrast, the\nmammalian cortex represents variables with a population of neurons. In this\npopulation code, each neuron is most active at its preferred value and shows\npartial activity for other values. Here, we investigate the benefit of using a\npopulation code for the output layer of a neural network. We compare population\ncodes against single-neuron outputs and one-hot vectors. First, we show\ntheoretically and in experiments with synthetic data that population codes\nimprove robustness to input noise in networks of stacked linear layers. Second,\nwe demonstrate the benefit of using population codes to encode ambiguous\noutputs, such as the pose of symmetric objects. Using the T-LESS dataset of\nfeature-less real-world objects, we show that population codes improve the\naccuracy of predicting 3D object orientation from image input.\n","authors":["Heiko Hoffmann"],"pdf_url":"https://arxiv.org/pdf/2411.00393v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08443v1","updated":"2024-11-13T08:56:35Z","published":"2024-11-13T08:56:35Z","title":"Machine Unlearning on Pre-trained Models by Residual Feature Alignment\n  Using LoRA","summary":"  Machine unlearning is new emerged technology that removes a subset of the\ntraining data from a trained model without affecting the model performance on\nthe remaining data. This topic is becoming increasingly important in protecting\nuser privacy and eliminating harmful or outdated data. The key challenge lies\nin effectively and efficiently unlearning specific information without\ncompromising the model's utility on the retained data. For the pre-trained\nmodels, fine-tuning is an important way to achieve the unlearning target.\nPrevious work typically fine-tuned the entire model's parameters, which incurs\nsignificant computation costs. In addition, the fine-tuning process may cause\nshifts in the intermediate layer features, affecting the model's overall\nutility. In this work, we propose a novel and efficient machine unlearning\nmethod on pre-trained models. We term the method as Residual Feature Alignment\nUnlearning. Specifically, we leverage LoRA (Low-Rank Adaptation) to decompose\nthe model's intermediate features into pre-trained features and residual\nfeatures. By adjusting the residual features, we align the unlearned model with\nthe pre-trained model at the intermediate feature level to achieve both\nunlearning and remaining targets. The method aims to learn the zero residuals\non the retained set and shifted residuals on the unlearning set. Extensive\nexperiments on numerous datasets validate the effectiveness of our approach.\n","authors":["Laiqiao Qin","Tianqing Zhu","Linlin Wang","Wanlei Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.08443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06979v2","updated":"2024-11-13T08:41:50Z","published":"2024-06-11T06:18:29Z","title":"AudioMarkBench: Benchmarking Robustness of Audio Watermarking","summary":"  The increasing realism of synthetic speech, driven by advancements in\ntext-to-speech models, raises ethical concerns regarding impersonation and\ndisinformation. Audio watermarking offers a promising solution via embedding\nhuman-imperceptible watermarks into AI-generated audios. However, the\nrobustness of audio watermarking against common/adversarial perturbations\nremains understudied. We present AudioMarkBench, the first systematic benchmark\nfor evaluating the robustness of audio watermarking against watermark removal\nand watermark forgery. AudioMarkBench includes a new dataset created from\nCommon-Voice across languages, biological sexes, and ages, 3 state-of-the-art\nwatermarking methods, and 15 types of perturbations. We benchmark the\nrobustness of these methods against the perturbations in no-box, black-box, and\nwhite-box settings. Our findings highlight the vulnerabilities of current\nwatermarking techniques and emphasize the need for more robust and fair audio\nwatermarking solutions. Our dataset and code are publicly available at\nhttps://github.com/moyangkuo/AudioMarkBench.\n","authors":["Hongbin Liu","Moyang Guo","Zhengyuan Jiang","Lun Wang","Neil Zhenqiang Gong"],"pdf_url":"https://arxiv.org/pdf/2406.06979v2.pdf","comment":"To appear in NeurIPS Datasets and Benchmarks, 2024"},{"id":"http://arxiv.org/abs/2410.21283v2","updated":"2024-11-13T08:33:17Z","published":"2024-10-11T03:19:44Z","title":"pLDDT-Predictor: High-speed Protein Screening Using Transformer and ESM2","summary":"  Recent advancements in protein structure prediction, particularly AlphaFold2,\nhave revolutionized structural biology by achieving near-experimental accuracy\n($\\text{average RMSD} < 1.5\\text{\\AA}$). However, the computational demands of\nthese models (approximately 30 minutes per protein on an RTX 4090)\nsignificantly limit their application in high-throughput protein screening.\nWhile large language models like ESM (Evolutionary Scale Modeling) have shown\npromise in extracting structural information directly from protein sequences,\nrapid assessment of protein structure quality for large-scale analyses remains\na major challenge.\n  We introduce pLDDT-Predictor, a high-speed protein screening tool that\nachieves a $250,000\\times$ speedup compared to AlphaFold2 by leveraging\npre-trained ESM2 protein embeddings and a Transformer architecture. Our model\npredicts AlphaFold2's pLDDT (predicted Local Distance Difference Test) scores\nwith a Pearson correlation of 0.7891 and processes proteins in just 0.007\nseconds on average. Using a comprehensive dataset of 1.5 million diverse\nprotein sequences (ranging from 50 to 2048 amino acids), we demonstrate that\npLDDT-Predictor accurately classifies high-confidence structures (pLDDT $>$ 70)\nwith 91.2\\% accuracy and achieves an MSE of 84.8142 compared to AlphaFold2's\npredictions.\n  The source code and pre-trained models are freely available at\n\\url{https://github.com/jw-chae/pLDDT_Predictor}, enabling the research\ncommunity to perform rapid, large-scale protein structure quality assessments.\n","authors":["Joongwon Chae","Zhenyu Wang","Ijaz Gul","Jiansong Ji","Zhenglin Chen","Peiwu Qin"],"pdf_url":"https://arxiv.org/pdf/2410.21283v2.pdf","comment":"6 pages main topic, 8 pages including citiation, 4 figures"},{"id":"http://arxiv.org/abs/2411.08432v1","updated":"2024-11-13T08:32:42Z","published":"2024-11-13T08:32:42Z","title":"One STEP at a time: Language Agents are Stepwise Planners","summary":"  Language agents have shown promising adaptability in dynamic environments to\nperform complex tasks. However, despite the versatile knowledge embedded in\nlarge language models, these agents still fall short when it comes to tasks\nthat require planning. We introduce STEP, a novel framework designed to\nefficiently learn from previous experiences to enhance the planning\ncapabilities of language agents in future steps. Concretely, STEP functions\nthrough four interconnected components. First, the Planner takes on the task,\nbreaks it down into subtasks and provides relevant insights. Then the Executor\ngenerates action candidates, while the Evaluator ensures the actions align with\nlearned rules from previous experiences. Lastly, Memory stores experiences to\ninform future decisions. In the ScienceWorld benchmark, our results show that\nSTEP consistently outperforms state-of-the-art models, achieving an overall\nscore of 67.4 and successfully completing 12 out of 18 tasks. These findings\nhighlight STEP's potential as a framework for enhancing planning capabilities\nin language agents, paving the way for more sophisticated task-solving in\ndynamic environments.\n","authors":["Minh Nguyen","Ehsan Shareghi"],"pdf_url":"https://arxiv.org/pdf/2411.08432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03364v2","updated":"2024-11-13T08:30:59Z","published":"2024-11-05T06:54:38Z","title":"DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural\n  Networks","summary":"  Graph has become increasingly integral to the advancement of recommendation\nsystems, particularly with the fast development of graph neural network(GNN).\nBy exploring the virtue of rich node features and link information, GNN is\ndesigned to provide personalized and accurate suggestions. Meanwhile, the\nprivacy leakage of GNN in such contexts has also captured special attention.\nPrior work has revealed that a malicious user can utilize auxiliary knowledge\nto extract sensitive link data of the target graph, integral to recommendation\nsystems, via the decision made by the target GNN model. This poses a\nsignificant risk to the integrity and confidentiality of data used in\nrecommendation system. Though important, previous works on GNN's privacy\nleakage are still challenged in three aspects, i.e., limited stealing attack\nscenarios, sub-optimal attack performance, and adaptation against defense. To\naddress these issues, we propose a diffusion model based link stealing attack,\nnamed DM4Steal. It differs previous work from three critical aspects. (i)\nGenerality: aiming at six attack scenarios with limited auxiliary knowledge, we\npropose a novel training strategy for diffusion models so that DM4Steal is\ntransferable to diverse attack scenarios. (ii) Effectiveness: benefiting from\nthe retention of semantic structure in the diffusion model during the training\nprocess, DM4Steal is capable to learn the precise topology of the target graph\nthrough the GNN decision process. (iii) Adaptation: when GNN is defensive\n(e.g., DP, Dropout), DM4Steal relies on the stability that comes from sampling\nthe score model multiple times to keep performance degradation to a minimum,\nthus DM4Steal implements successful adaptive attack on defensive GNN.\n","authors":["Jinyin Chen","Haonan Ma","Haibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2411.03364v2.pdf","comment":"We found that there were critical problems in our paper, and we\n  needed to redo the experiment, which was incomplete"},{"id":"http://arxiv.org/abs/2411.07501v2","updated":"2024-11-13T08:30:52Z","published":"2024-11-12T02:57:15Z","title":"LAuReL: Learned Augmented Residual Layer","summary":"  One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters.\n","authors":["Gaurav Menghani","Ravi Kumar","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07501v2.pdf","comment":"Accepted at the 2nd Efficient Systems for Foundation Models Workshop\n  at the International Conference on Machine Learning (ICML) 2024"},{"id":"http://arxiv.org/abs/2411.01137v2","updated":"2024-11-13T08:24:09Z","published":"2024-11-02T04:48:41Z","title":"Data movement limits to frontier model training","summary":"  We present a theoretical model of distributed training, and use it to analyze\nhow far dense and sparse training runs can be scaled. Under our baseline\nassumptions, given a three month training duration, data movement bottlenecks\nbegin to significantly lower hardware utilization for training runs exceeding\nabout $10^{28}$ FLOP, two orders of magnitude above the largest training run to\ndate, suggesting the arrival of fundamental barriers to scaling in three years\ngiven recent rates of growth. A training run exceeding about $10^{31}$ FLOP is\ninfeasible even at low utilization. However, more aggressive batch size scaling\nand/or shorter and fatter model shapes, if achievable, have the potential to\npermit much larger training runs.\n","authors":["Ege Erdil","David Schneider-Joseph"],"pdf_url":"https://arxiv.org/pdf/2411.01137v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08425v1","updated":"2024-11-13T08:18:03Z","published":"2024-11-13T08:18:03Z","title":"Properties of fairness measures in the context of varying class\n  imbalance and protected group ratios","summary":"  Society is increasingly relying on predictive models in fields like criminal\njustice, credit risk management, or hiring. To prevent such automated systems\nfrom discriminating against people belonging to certain groups, fairness\nmeasures have become a crucial component in socially relevant applications of\nmachine learning. However, existing fairness measures have been designed to\nassess the bias between predictions for protected groups without considering\nthe imbalance in the classes of the target variable. Current research on the\npotential effect of class imbalance on fairness focuses on practical\napplications rather than dataset-independent measure properties. In this paper,\nwe study the general properties of fairness measures for changing class and\nprotected group proportions. For this purpose, we analyze the probability mass\nfunctions of six of the most popular group fairness measures. We also measure\nhow the probability of achieving perfect fairness changes for varying class\nimbalance ratios. Moreover, we relate the dataset-independent properties of\nfairness measures described in this paper to classifier fairness in real-life\ntasks. Our results show that measures such as Equal Opportunity and Positive\nPredictive Parity are more sensitive to changes in class imbalance than\nAccuracy Equality. These findings can help guide researchers and practitioners\nin choosing the most appropriate fairness measures for their classification\nproblems.\n","authors":["Dariusz Brzezinski","Julia Stachowiak","Jerzy Stefanowski","Izabela Szczech","Robert Susmaga","Sofya Aksenyuk","Uladzimir Ivashka","Oleksandr Yasinskyi"],"pdf_url":"https://arxiv.org/pdf/2411.08425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15586v2","updated":"2024-11-13T08:17:38Z","published":"2024-05-24T14:14:24Z","title":"DAGER: Exact Gradient Inversion for Large Language Models","summary":"  Federated learning works by aggregating locally computed gradients from\nmultiple clients, thus enabling collaborative training without sharing private\nclient data. However, prior work has shown that the data can actually be\nrecovered by the server using so-called gradient inversion attacks. While these\nattacks perform well when applied on images, they are limited in the text\ndomain and only permit approximate reconstruction of small batches and short\ninput sequences. In this work, we propose DAGER, the first algorithm to recover\nwhole batches of input text exactly. DAGER leverages the low-rank structure of\nself-attention layer gradients and the discrete nature of token embeddings to\nefficiently check if a given token sequence is part of the client data. We use\nthis check to exactly recover full batches in the honest-but-curious setting\nwithout any prior on the data for both encoder- and decoder-based architectures\nusing exhaustive heuristic search and a greedy approach, respectively. We\nprovide an efficient GPU implementation of DAGER and show experimentally that\nit recovers full batches of size up to 128 on large language models (LLMs),\nbeating prior attacks in speed (20x at same batch size), scalability (10x\nlarger batches), and reconstruction quality (ROUGE-1/2 > 0.99).\n","authors":["Ivo Petrov","Dimitar I. Dimitrov","Maximilian Baader","Mark Niklas M√ºller","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2405.15586v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.21063v2","updated":"2024-11-13T08:13:36Z","published":"2024-05-31T17:51:07Z","title":"Neural Network Verification with Branch-and-Bound for General\n  Nonlinearities","summary":"  Branch-and-bound (BaB) is among the most effective techniques for neural\nnetwork (NN) verification. However, existing works on BaB for NN verification\nhave mostly focused on NNs with piecewise linear activations, especially ReLU\nnetworks. In this paper, we develop a general framework, named GenBaB, to\nconduct BaB on general nonlinearities to verify NNs with general architectures,\nbased on linear bound propagation for NN verification. To decide which neuron\nto branch, we design a new branching heuristic which leverages linear bounds as\nshortcuts to efficiently estimate the potential improvement after branching. To\ndecide nontrivial branching points for general nonlinear functions, we propose\nto pre-optimize branching points, which can be efficiently leveraged during\nverification with a lookup table. We demonstrate the effectiveness of our\nGenBaB on verifying a wide range of NNs, including NNs with activation\nfunctions such as Sigmoid, Tanh, Sine and GeLU, as well as NNs involving\nmulti-dimensional nonlinear operations such as multiplications in LSTMs and\nVision Transformers. Our framework also allows the verification of general\nnonlinear computation graphs and enables verification applications beyond\nsimple NNs, particularly for AC Optimal Power Flow (ACOPF). GenBaB is part of\nthe latest $\\alpha,\\!\\beta$-CROWN, the winner of the 4th and the 5th\nInternational Verification of Neural Networks Competition (VNN-COMP 2023 and\n2024).\n","authors":["Zhouxing Shi","Qirui Jin","Zico Kolter","Suman Jana","Cho-Jui Hsieh","Huan Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.21063v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.08414v1","updated":"2024-11-13T08:07:21Z","published":"2024-11-13T08:07:21Z","title":"Material Property Prediction with Element Attribute Knowledge Graphs and\n  Multimodal Representation Learning","summary":"  Machine learning has become a crucial tool for predicting the properties of\ncrystalline materials. However, existing methods primarily represent material\ninformation by constructing multi-edge graphs of crystal structures, often\noverlooking the chemical and physical properties of elements (such as atomic\nradius, electronegativity, melting point, and ionization energy), which have a\nsignificant impact on material performance. To address this limitation, we\nfirst constructed an element property knowledge graph and utilized an embedding\nmodel to encode the element attributes within the knowledge graph. Furthermore,\nwe propose a multimodal fusion framework, ESNet, which integrates element\nproperty features with crystal structure features to generate joint multimodal\nrepresentations. This provides a more comprehensive perspective for predicting\nthe performance of crystalline materials, enabling the model to consider both\nmicrostructural composition and chemical characteristics of the materials. We\nconducted experiments on the Materials Project benchmark dataset, which showed\nleading performance in the bandgap prediction task and achieved results on a\npar with existing benchmarks in the formation energy prediction task.\n","authors":["Chao Huang","Chunyan Chen","Ling Shi","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2411.08414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08404v1","updated":"2024-11-13T07:45:40Z","published":"2024-11-13T07:45:40Z","title":"Quantifying Qualitative Insights: Leveraging LLMs to Market Predict","summary":"  Recent advancements in Large Language Models (LLMs) have the potential to\ntransform financial analytics by integrating numerical and textual data.\nHowever, challenges such as insufficient context when fusing multimodal\ninformation and the difficulty in measuring the utility of qualitative outputs,\nwhich LLMs generate as text, have limited their effectiveness in tasks such as\nfinancial forecasting. This study addresses these challenges by leveraging\ndaily reports from securities firms to create high-quality contextual\ninformation. The reports are segmented into text-based key factors and combined\nwith numerical data, such as price information, to form context sets. By\ndynamically updating few-shot examples based on the query time, the sets\nincorporate the latest information, forming a highly relevant set closely\naligned with the query point. Additionally, a crafted prompt is designed to\nassign scores to the key factors, converting qualitative insights into\nquantitative results. The derived scores undergo a scaling process,\ntransforming them into real-world values that are used for prediction. Our\nexperiments demonstrate that LLMs outperform time-series models in market\nforecasting, though challenges such as imperfect reproducibility and limited\nexplainability remain.\n","authors":["Hoyoung Lee","Youngsoo Choi","Yuhee Kwon"],"pdf_url":"https://arxiv.org/pdf/2411.08404v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.08397v1","updated":"2024-11-13T07:32:58Z","published":"2024-11-13T07:32:58Z","title":"CLaSP: Learning Concepts for Time-Series Signals from Natural Language\n  Supervision","summary":"  This paper proposes a foundation model called \"CLaSP\" that can search time\nseries signals using natural language that describes the characteristics of the\nsignals as queries. Previous efforts to represent time series signal data in\nnatural language have had challenges in designing a conventional class of time\nseries signal characteristics, formulating their quantification, and creating a\ndictionary of synonyms. To overcome these limitations, the proposed method\nintroduces a neural network based on contrastive learning. This network is\nfirst trained using the datasets TRUCE and SUSHI, which consist of time series\nsignals and their corresponding natural language descriptions. Previous studies\nhave proposed vocabularies that data analysts use to describe signal\ncharacteristics, and SUSHI was designed to cover these terms. We believe that a\nneural network trained on these datasets will enable data analysts to search\nusing natural language vocabulary. Furthermore, our method does not require a\ndictionary of predefined synonyms, and it leverages common sense knowledge\nembedded in a large-scale language model (LLM). Experimental results\ndemonstrate that CLaSP enables natural language search of time series signal\ndata and can accurately learn the points at which signal data changes.\n","authors":["Aoi Ito","Kota Dohi","Yohei Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2411.08397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08384v1","updated":"2024-11-13T07:10:18Z","published":"2024-11-13T07:10:18Z","title":"Interpretable Syntactic Representations Enable Hierarchical Word Vectors","summary":"  The distributed representations currently used are dense and uninterpretable,\nleading to interpretations that themselves are relative, overcomplete, and hard\nto interpret. We propose a method that transforms these word vectors into\nreduced syntactic representations. The resulting representations are compact\nand interpretable allowing better visualization and comparison of the word\nvectors and we successively demonstrate that the drawn interpretations are in\nline with human judgment. The syntactic representations are then used to create\nhierarchical word vectors using an incremental learning approach similar to the\nhierarchical aspect of human learning. As these representations are drawn from\npre-trained vectors, the generation process and learning approach are\ncomputationally efficient. Most importantly, we find out that syntactic\nrepresentations provide a plausible interpretation of the vectors and\nsubsequent hierarchical vectors outperform the original vectors in benchmark\ntests.\n","authors":["Biraj Silwal"],"pdf_url":"https://arxiv.org/pdf/2411.08384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08378v1","updated":"2024-11-13T07:03:47Z","published":"2024-11-13T07:03:47Z","title":"Physics Informed Distillation for Diffusion Models","summary":"  Diffusion models have recently emerged as a potent tool in generative\nmodeling. However, their inherent iterative nature often results in sluggish\nimage generation due to the requirement for multiple model evaluations. Recent\nprogress has unveiled the intrinsic link between diffusion models and\nProbability Flow Ordinary Differential Equations (ODEs), thus enabling us to\nconceptualize diffusion models as ODE systems. Simultaneously, Physics Informed\nNeural Networks (PINNs) have substantiated their effectiveness in solving\nintricate differential equations through implicit modeling of their solutions.\nBuilding upon these foundational insights, we introduce Physics Informed\nDistillation (PID), which employs a student model to represent the solution of\nthe ODE system corresponding to the teacher diffusion model, akin to the\nprinciples employed in PINNs. Through experiments on CIFAR 10 and ImageNet\n64x64, we observe that PID achieves performance comparable to recent\ndistillation methods. Notably, it demonstrates predictable trends concerning\nmethod-specific hyperparameters and eliminates the need for synthetic dataset\ngeneration during the distillation process. Both of which contribute to its\neasy-to-use nature as a distillation approach for Diffusion Models. Our code\nand pre-trained checkpoint are publicly available at:\nhttps://github.com/pantheon5100/pid_diffusion.git.\n","authors":["Joshua Tian Jin Tee","Kang Zhang","Hee Suk Yoon","Dhananjaya Nagaraja Gowda","Chanwoo Kim","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2411.08378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.02775v4","updated":"2024-11-13T06:57:35Z","published":"2022-01-08T06:18:17Z","title":"ADI: Adversarial Dominating Inputs in Vertical Federated Learning\n  Systems","summary":"  Vertical federated learning (VFL) system has recently become prominent as a\nconcept to process data distributed across many individual sources without the\nneed to centralize it. Multiple participants collaboratively train models based\non their local data in a privacy-aware manner. To date, VFL has become a de\nfacto solution to securely learn a model among organizations, allowing\nknowledge to be shared without compromising privacy of any individuals. Despite\nthe prosperous development of VFL systems, we find that certain inputs of a\nparticipant, named adversarial dominating inputs (ADIs), can dominate the joint\ninference towards the direction of the adversary's will and force other\n(victim) participants to make negligible contributions, losing rewards that are\nusually offered regarding the importance of their contributions in federated\nlearning scenarios. We conduct a systematic study on ADIs by first proving\ntheir existence in typical VFL systems. We then propose gradient-based methods\nto synthesize ADIs of various formats and exploit common VFL systems. We\nfurther launch greybox fuzz testing, guided by the saliency score of ``victim''\nparticipants, to perturb adversary-controlled inputs and systematically explore\nthe VFL attack surface in a privacy-preserving manner. We conduct an in-depth\nstudy on the influence of critical parameters and settings in synthesizing\nADIs. Our study reveals new VFL attack opportunities, promoting the\nidentification of unknown threats before breaches and building more secure VFL\nsystems.\n","authors":["Qi Pang","Yuanyuan Yuan","Shuai Wang","Wenting Zheng"],"pdf_url":"https://arxiv.org/pdf/2201.02775v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08374v1","updated":"2024-11-13T06:54:05Z","published":"2024-11-13T06:54:05Z","title":"Federated Graph Learning with Graphless Clients","summary":"  Federated Graph Learning (FGL) is tasked with training machine learning\nmodels, such as Graph Neural Networks (GNNs), for multiple clients, each with\nits own graph data. Existing methods usually assume that each client has both\nnode features and graph structure of its graph data. In real-world scenarios,\nhowever, there exist federated systems where only a part of the clients have\nsuch data while other clients (i.e. graphless clients) may only have node\nfeatures. This naturally leads to a novel problem in FGL: how to jointly train\na model over distributed graph data with graphless clients? In this paper, we\npropose a novel framework FedGLS to tackle the problem in FGL with graphless\nclients. In FedGLS, we devise a local graph learner on each graphless client\nwhich learns the local graph structure with the structure knowledge transferred\nfrom other clients. To enable structure knowledge transfer, we design a GNN\nmodel and a feature encoder on each client. During local training, the feature\nencoder retains the local graph structure knowledge together with the GNN model\nvia knowledge distillation, and the structure knowledge is transferred among\nclients in global update. Our extensive experiments demonstrate the superiority\nof the proposed FedGLS over five baselines.\n","authors":["Xingbo Fu","Song Wang","Yushun Dong","Binchi Zhang","Chen Chen","Jundong Li"],"pdf_url":"https://arxiv.org/pdf/2411.08374v1.pdf","comment":"Accepted by Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2410.21564v2","updated":"2024-11-13T06:35:53Z","published":"2024-10-28T21:54:44Z","title":"Mitigating Gradient Overlap in Deep Residual Networks with Gradient\n  Normalization for Improved Non-Convex Optimization","summary":"  In deep learning, Residual Networks (ResNets) have proven effective in\naddressing the vanishing gradient problem, allowing for the successful training\nof very deep networks. However, skip connections in ResNets can lead to\ngradient overlap, where gradients from both the learned transformation and the\nskip connection combine, potentially resulting in overestimated gradients. This\noverestimation can cause inefficiencies in optimization, as some updates may\novershoot optimal regions, affecting weight updates. To address this, we\nexamine Z-score Normalization (ZNorm) as a technique to manage gradient\noverlap. ZNorm adjusts the gradient scale, standardizing gradients across\nlayers and reducing the negative impact of overlapping gradients. Our\nexperiments demonstrate that ZNorm improves training process, especially in\nnon-convex optimization scenarios common in deep learning, where finding\noptimal solutions is challenging. These findings suggest that ZNorm can affect\nthe gradient flow, enhancing performance in large-scale data processing where\naccuracy is critical.\n","authors":["Juyoung Yun"],"pdf_url":"https://arxiv.org/pdf/2410.21564v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07934v2","updated":"2024-11-13T06:34:07Z","published":"2024-11-12T17:04:56Z","title":"Doubly Mild Generalization for Offline Reinforcement Learning","summary":"  Offline Reinforcement Learning (RL) suffers from the extrapolation error and\nvalue overestimation. From a generalization perspective, this issue can be\nattributed to the over-generalization of value functions or policies towards\nout-of-distribution (OOD) actions. Significant efforts have been devoted to\nmitigating such generalization, and recent in-sample learning approaches have\nfurther succeeded in entirely eschewing it. Nevertheless, we show that mild\ngeneralization beyond the dataset can be trusted and leveraged to improve\nperformance under certain conditions. To appropriately exploit generalization\nin offline RL, we propose Doubly Mild Generalization (DMG), comprising (i) mild\naction generalization and (ii) mild generalization propagation. The former\nrefers to selecting actions in a close neighborhood of the dataset to maximize\nthe Q values. Even so, the potential erroneous generalization can still be\npropagated, accumulated, and exacerbated by bootstrapping. In light of this,\nthe latter concept is introduced to mitigate the generalization propagation\nwithout impeding the propagation of RL learning signals. Theoretically, DMG\nguarantees better performance than the in-sample optimal policy in the oracle\ngeneralization scenario. Even under worst-case generalization, DMG can still\ncontrol value overestimation at a certain level and lower bound the\nperformance. Empirically, DMG achieves state-of-the-art performance across\nGym-MuJoCo locomotion tasks and challenging AntMaze tasks. Moreover, benefiting\nfrom its flexibility in both generalization aspects, DMG enjoys a seamless\ntransition from offline to online learning and attains strong online\nfine-tuning performance.\n","authors":["Yixiu Mao","Qi Wang","Yun Qu","Yuhang Jiang","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2411.07934v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.08367v1","updated":"2024-11-13T06:32:17Z","published":"2024-11-13T06:32:17Z","title":"Surprisingly Popular Voting for Concentric Rank-Order Models","summary":"  An important problem on social information sites is the recovery of ground\ntruth from individual reports when the experts are in the minority. The wisdom\nof the crowd, i.e. the collective opinion of a group of individuals fails in\nsuch a scenario. However, the surprisingly popular (SP)\nalgorithm~\\cite{prelec2017solution} can recover the ground truth even when the\nexperts are in the minority, by asking the individuals to report additional\nprediction reports--their beliefs about the reports of others. Several recent\nworks have extended the surprisingly popular algorithm to an equivalent voting\nrule (SP-voting) to recover the ground truth ranking over a set of $m$\nalternatives. However, we are yet to fully understand when SP-voting can\nrecover the ground truth ranking, and if so, how many samples (votes and\npredictions) it needs. We answer this question by proposing two rank-order\nmodels and analyzing the sample complexity of SP-voting under these models. In\nparticular, we propose concentric mixtures of Mallows and Plackett-Luce models\nwith $G (\\ge 2)$ groups. Our models generalize previously proposed concentric\nmixtures of Mallows models with $2$ groups, and we highlight the importance of\n$G > 2$ groups by identifying three distinct groups (expert, intermediate, and\nnon-expert) from existing datasets. Next, we provide conditions on the\nparameters of the underlying models so that SP-voting can recover ground-truth\nrankings with high probability, and also derive sample complexities under the\nsame. We complement the theoretical results by evaluating SP-voting on\nsimulated and real datasets.\n","authors":["Hadi Hosseini","Debmalya Mandal","Amrit Puhan"],"pdf_url":"https://arxiv.org/pdf/2411.08367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08360v1","updated":"2024-11-13T06:16:12Z","published":"2024-11-13T06:16:12Z","title":"Coverage Analysis for Digital Cousin Selection -- Improving\n  Multi-Environment Q-Learning","summary":"  Q-learning is widely employed for optimizing various large-dimensional\nnetworks with unknown system dynamics. Recent advancements include\nmulti-environment mixed Q-learning (MEMQ) algorithms, which utilize multiple\nindependent Q-learning algorithms across multiple, structurally related but\ndistinct environments and outperform several state-of-the-art Q-learning\nalgorithms in terms of accuracy, complexity, and robustness. We herein conduct\na comprehensive probabilistic coverage analysis to ensure optimal data coverage\nconditions for MEMQ algorithms. First, we derive upper and lower bounds on the\nexpectation and variance of different coverage coefficients (CC) for MEMQ\nalgorithms. Leveraging these bounds, we develop a simple way of comparing the\nutilities of multiple environments in MEMQ algorithms. This approach appears to\nbe near optimal versus our previously proposed partial ordering approach. We\nalso present a novel CC-based MEMQ algorithm to improve the accuracy and\ncomplexity of existing MEMQ algorithms. Numerical experiments are conducted\nusing random network graphs with four different graph properties. Our algorithm\ncan reduce the average policy error (APE) by 65% compared to partial ordering\nand is 95% faster than the exhaustive search. It also achieves 60% less APE\nthan several state-of-the-art reinforcement learning and prior MEMQ algorithms.\nAdditionally, we numerically verify the theoretical results and show their\nscalability with the action-space size.\n","authors":["Talha Bozkus","Tara Javidi","Urbashi Mitra"],"pdf_url":"https://arxiv.org/pdf/2411.08360v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2409.18696v2","updated":"2024-11-13T06:01:51Z","published":"2024-09-27T12:34:08Z","title":"Rethinking the Power of Timestamps for Robust Time Series Forecasting: A\n  Global-Local Fusion Perspective","summary":"  Time series forecasting has played a pivotal role across various industries,\nincluding finance, transportation, energy, healthcare, and climate. Due to the\nabundant seasonal information they contain, timestamps possess the potential to\noffer robust global guidance for forecasting techniques. However, existing\nworks primarily focus on local observations, with timestamps being treated\nmerely as an optional supplement that remains underutilized. When data gathered\nfrom the real world is polluted, the absence of global information will damage\nthe robust prediction capability of these algorithms. To address these\nproblems, we propose a novel framework named GLAFF. Within this framework, the\ntimestamps are modeled individually to capture the global dependencies. Working\nas a plugin, GLAFF adaptively adjusts the combined weights for global and local\ninformation, enabling seamless collaboration with any time series forecasting\nbackbone. Extensive experiments conducted on nine real-world datasets\ndemonstrate that GLAFF significantly enhances the average performance of widely\nused mainstream forecasting models by 12.5%, surpassing the previous\nstate-of-the-art method by 5.5%.\n","authors":["Chengsen Wang","Qi Qi","Jingyu Wang","Haifeng Sun","Zirui Zhuang","Jinming Wu","Jianxin Liao"],"pdf_url":"https://arxiv.org/pdf/2409.18696v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.08355v1","updated":"2024-11-13T05:59:04Z","published":"2024-11-13T05:59:04Z","title":"Communication Efficient Decentralization for Smoothed Online Convex\n  Optimization","summary":"  We study the multi-agent Smoothed Online Convex Optimization (SOCO) problem,\nwhere $N$ agents interact through a communication graph. In each round, each\nagent $i$ receives a strongly convex hitting cost function $f^i_t$ in an online\nfashion and selects an action $x^i_t \\in \\mathbb{R}^d$. The objective is to\nminimize the global cumulative cost, which includes the sum of individual\nhitting costs $f^i_t(x^i_t)$, a temporal \"switching cost\" for changing\ndecisions, and a spatial \"dissimilarity cost\" that penalizes deviations in\ndecisions among neighboring agents. We propose the first decentralized\nalgorithm for multi-agent SOCO and prove its asymptotic optimality. Our\napproach allows each agent to operate using only local information from its\nimmediate neighbors in the graph. For finite-time performance, we establish\nthat the optimality gap in competitive ratio decreases with the time horizon\n$T$ and can be conveniently tuned based on the per-round computation available\nto each agent. Moreover, our results hold even when the communication graph\nchanges arbitrarily and adaptively over time. Finally, we establish that the\ncomputational complexity per round depends only logarithmically on the number\nof agents and almost linearly on their degree within the graph, ensuring\nscalability for large-system implementations.\n","authors":["Neelkamal Bhuyan","Debankur Mukherjee","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2411.08355v1.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2411.04493v2","updated":"2024-11-13T05:52:23Z","published":"2024-11-07T07:41:04Z","title":"Synergy-Guided Regional Supervision of Pseudo Labels for Semi-Supervised\n  Medical Image Segmentation","summary":"  Semi-supervised learning has received considerable attention for its\npotential to leverage abundant unlabeled data to enhance model robustness.\nPseudo labeling is a widely used strategy in semi supervised learning. However,\nexisting methods often suffer from noise contamination, which can undermine\nmodel performance. To tackle this challenge, we introduce a novel\nSynergy-Guided Regional Supervision of Pseudo Labels (SGRS-Net) framework.\nBuilt upon the mean teacher network, we employ a Mix Augmentation module to\nenhance the unlabeled data. By evaluating the synergy before and after\naugmentation, we strategically partition the pseudo labels into distinct\nregions. Additionally, we introduce a Region Loss Evaluation module to assess\nthe loss across each delineated area. Extensive experiments conducted on the LA\ndataset have demonstrated superior performance over state-of-the-art\ntechniques, underscoring the efficiency and practicality of our framework.\n","authors":["Tao Wang","Xinlin Zhang","Yuanbin Chen","Yuanbo Zhou","Longxuan Zhao","Tao Tan","Tong Tong"],"pdf_url":"https://arxiv.org/pdf/2411.04493v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08344v1","updated":"2024-11-13T05:22:45Z","published":"2024-11-13T05:22:45Z","title":"Bangla Grammatical Error Detection Leveraging Transformer-based Token\n  Classification","summary":"  Bangla is the seventh most spoken language by a total number of speakers in\nthe world, and yet the development of an automated grammar checker in this\nlanguage is an understudied problem. Bangla grammatical error detection is a\ntask of detecting sub-strings of a Bangla text that contain grammatical,\npunctuation, or spelling errors, which is crucial for developing an automated\nBangla typing assistant. Our approach involves breaking down the task as a\ntoken classification problem and utilizing state-of-the-art transformer-based\nmodels. Finally, we combine the output of these models and apply rule-based\npost-processing to generate a more reliable and comprehensive result. Our\nsystem is evaluated on a dataset consisting of over 25,000 texts from various\nsources. Our best model achieves a Levenshtein distance score of 1.04. Finally,\nwe provide a detailed analysis of different components of our system.\n","authors":["Shayekh Bin Islam","Ridwanul Hasan Tanvir","Sihat Afnan"],"pdf_url":"https://arxiv.org/pdf/2411.08344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03497v3","updated":"2024-11-13T04:41:31Z","published":"2024-08-07T01:37:10Z","title":"Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and\n  Tabnet with SMOTEENN","summary":"  Bank credit risk is a significant challenge in modern financial transactions,\nand the ability to identify qualified credit card holders among a large number\nof applicants is crucial for the profitability of a bank'sbank's credit card\nbusiness. In the past, screening applicants'applicants' conditions often\nrequired a significant amount of manual labor, which was time-consuming and\nlabor-intensive. Although the accuracy and reliability of previously used ML\nmodels have been continuously improving, the pursuit of more reliable and\npowerful AI intelligent models is undoubtedly the unremitting pursuit by major\nbanks in the financial industry. In this study, we used a dataset of over\n40,000 records provided by a commercial bank as the research object. We\ncompared various dimensionality reduction techniques such as PCA and T-SNE for\npreprocessing high-dimensional datasets and performed in-depth adaptation and\ntuning of distributed models such as LightGBM and XGBoost, as well as deep\nmodels like Tabnet. After a series of research and processing, we obtained\nexcellent research results by combining SMOTEENN with these techniques. The\nexperiments demonstrated that LightGBM combined with PCA and SMOTEENN\ntechniques can assist banks in accurately predicting potential high-quality\ncustomers, showing relatively outstanding performance compared to other models.\n","authors":["Chang Yu","Yixin Jin","Qianwen Xing","Ye Zhang","Shaobo Guo","Shuchen Meng"],"pdf_url":"https://arxiv.org/pdf/2408.03497v3.pdf","comment":"8 pagess on IEEE ICPICS"},{"id":"http://arxiv.org/abs/2411.08332v1","updated":"2024-11-13T04:27:25Z","published":"2024-11-13T04:27:25Z","title":"Learning-Augmented Algorithms for Online Concave Packing and Convex\n  Covering Problems","summary":"  Learning-augmented algorithms have been extensively studied across the\ncomputer science community in the recent years, driven by advances in machine\nlearning predictors, which can provide additional information to augment\nclassical algorithms. Such predictions are especially powerful in the context\nof online problems, where decisions have to be made without knowledge of the\nfuture, and which traditionally exhibits impossibility results bounding the\nperformance of any online algorithm. The study of learning-augmented algorithms\nthus aims to use external advice prudently, to overcome classical impossibility\nresults when the advice is accurate, and still perform comparably to the\nstate-of-the-art online algorithms even when the advice is inaccurate.\n  In this paper, we present learning-augmented algorithmic frameworks for two\nfundamental optimizations settings, extending and generalizing prior works. For\nonline packing with concave objectives, we present a simple but overarching\nstrategy that switches between the advice and the state-of-the-art online\nalgorithm. For online covering with convex objectives, we greatly extend\nprimal-dual methods for online convex covering programs by Azar et al. (FOCS\n2016) and previous learning-augmented framework for online covering linear\nprograms from the literature, to many new applications. We show that our\nalgorithms break impossibility results when the advice is accurate, while\nmaintaining comparable performance with state-of-the-art classical online\nalgorithms even when the advice is erroneous.\n","authors":["Elena Grigorescu","Young-San Lin","Maoyuan Song"],"pdf_url":"https://arxiv.org/pdf/2411.08332v1.pdf","comment":"38 pages. In submission"},{"id":"http://arxiv.org/abs/2411.08326v1","updated":"2024-11-13T04:20:29Z","published":"2024-11-13T04:20:29Z","title":"Neural Conjugate Flows: Physics-informed architectures with flow\n  structure","summary":"  We introduce Neural Conjugate Flows (NCF), a class of neural network\narchitectures equipped with exact flow structure. By leveraging topological\nconjugation, we prove that these networks are not only naturally isomorphic to\na continuous group, but are also universal approximators for flows of ordinary\ndifferential equation (ODEs). Furthermore, topological properties of these\nflows can be enforced by the architecture in an interpretable manner. We\ndemonstrate in numerical experiments how this topological group structure leads\nto concrete computational gains over other physics informed neural networks in\nestimating and extrapolating latent dynamics of ODEs, while training up to five\ntimes faster than other flow-based architectures.\n","authors":["Arthur Bizzi","Lucas Nissenbaum","Jo√£o M. Pereira"],"pdf_url":"https://arxiv.org/pdf/2411.08326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08324v1","updated":"2024-11-13T04:20:20Z","published":"2024-11-13T04:20:20Z","title":"Are LLMs Prescient? A Continuous Evaluation using Daily News as the\n  Oracle","summary":"  Many existing evaluation benchmarks for Large Language Models (LLMs) quickly\nbecome outdated due to the emergence of new models and training data. These\nbenchmarks also fall short in assessing how LLM performance changes over time,\nas they consist of static questions without a temporal dimension. To address\nthese limitations, we propose using future event prediction as a continuous\nevaluation method to assess LLMs' temporal generalization and forecasting\nabilities. Our benchmark, Daily Oracle, automatically generates question-answer\n(QA) pairs from daily news, challenging LLMs to predict \"future\" event\noutcomes. Our findings reveal that as pre-training data becomes outdated, LLM\nperformance degrades over time. While Retrieval Augmented Generation (RAG) has\nthe potential to enhance prediction accuracy, the performance degradation\npattern persists, highlighting the need for continuous model updates.\n","authors":["Hui Dai","Ryan Teehan","Mengye Ren"],"pdf_url":"https://arxiv.org/pdf/2411.08324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07207v2","updated":"2024-11-13T04:15:38Z","published":"2024-11-11T18:32:44Z","title":"General Geospatial Inference with a Population Dynamics Foundation Model","summary":"  Supporting the health and well-being of dynamic populations around the world\nrequires governmental agencies, organizations and researchers to understand and\nreason over complex relationships between human behavior and local contexts in\norder to identify high-risk groups and strategically allocate limited\nresources. Traditional approaches to these classes of problems often entail\ndeveloping manually curated, task-specific features and models to represent\nhuman behavior and the natural and built environment, which can be challenging\nto adapt to new, or even, related tasks. To address this, we introduce a\nPopulation Dynamics Foundation Model (PDFM) that aims to capture the\nrelationships between diverse data modalities and is applicable to a broad\nrange of geospatial tasks. We first construct a geo-indexed dataset for postal\ncodes and counties across the United States, capturing rich aggregated\ninformation on human behavior from maps, busyness, and aggregated search\ntrends, and environmental factors such as weather and air quality. We then\nmodel this data and the complex relationships between locations using a graph\nneural network, producing embeddings that can be adapted to a wide range of\ndownstream tasks using relatively simple models. We evaluate the effectiveness\nof our approach by benchmarking it on 27 downstream tasks spanning three\ndistinct domains: health indicators, socioeconomic factors, and environmental\nmeasurements. The approach achieves state-of-the-art performance on all 27\ngeospatial interpolation tasks, and on 25 out of the 27 extrapolation and\nsuper-resolution tasks. We combined the PDFM with a state-of-the-art\nforecasting foundation model, TimesFM, to predict unemployment and poverty,\nachieving performance that surpasses fully supervised forecasting. The full set\nof embeddings and sample code are publicly available for researchers.\n","authors":["Mohit Agarwal","Mimi Sun","Chaitanya Kamath","Arbaaz Muslim","Prithul Sarker","Joydeep Paul","Hector Yee","Marcin Sieniek","Kim Jablonski","Yael Mayer","David Fork","Sheila de Guia","Jamie McPike","Adam Boulanger","Tomer Shekel","David Schottlander","Yao Xiao","Manjit Chakravarthy Manukonda","Yun Liu","Neslihan Bulut","Sami Abu-el-haija","Arno Eigenwillig","Parth Kothari","Bryan Perozzi","Monica Bharel","Von Nguyen","Luke Barrington","Niv Efron","Yossi Matias","Greg Corrado","Krish Eswaran","Shruthi Prabhakara","Shravya Shetty","Gautam Prasad"],"pdf_url":"https://arxiv.org/pdf/2411.07207v2.pdf","comment":"28 pages, 16 figures, preprint; v2: updated github url"},{"id":"http://arxiv.org/abs/2411.08314v1","updated":"2024-11-13T03:42:55Z","published":"2024-11-13T03:42:55Z","title":"Conditional Variable Flow Matching: Transforming Conditional Densities\n  with Amortized Conditional Optimal Transport","summary":"  Forecasting stochastic nonlinear dynamical systems under the influence of\nconditioning variables is a fundamental challenge repeatedly encountered across\nthe biological and physical sciences. While flow-based models can impressively\npredict the temporal evolution of probability distributions representing\npossible outcomes of a specific process, existing frameworks cannot\nsatisfactorily account for the impact of conditioning variables on these\ndynamics. Amongst several limitations, existing methods require training data\nwith paired conditions and are developed for discrete conditioning variables.\nWe propose Conditional Variable Flow Matching (CVFM), a framework for learning\nflows transforming conditional distributions with amortization across\ncontinuous conditioning variables - permitting predictions across the\nconditional density manifold. This is accomplished through several novel\nadvances, in particular, simultaneous sample conditioned flows over the main\nand conditioning variables, alongside a conditional Wasserstein distance and\nkernel facilitating conditional optimal transport. Collectively, these advances\nallow for learning system dynamics provided measurement data whose states and\nconditioning variables are not in correspondence. We demonstrate CVFM on a\nsuite of increasingly challenging problems, including discrete and continuous\nconditional mapping benchmarks, image-to-image domain transfer, and modeling\nthe temporal evolution of materials internal structure during manufacturing\nprocesses. We observe that CVFM results in improved performance and convergence\ncharacteristics over alternative conditional variants.\n","authors":["Adam P. Generale","Andreas E. Robertson","Surya R. Kalidindi"],"pdf_url":"https://arxiv.org/pdf/2411.08314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08621v3","updated":"2024-11-13T03:24:24Z","published":"2024-02-13T17:42:27Z","title":"A Unified Framework for Analyzing Meta-algorithms in Online Convex\n  Optimization","summary":"  In this paper, we analyze the problem of online convex optimization in\ndifferent settings, including different feedback types\n(full-information/semi-bandit/bandit/etc) in either stochastic or\nnon-stochastic setting and different notions of regret (static adversarial\nregret/dynamic regret/adaptive regret). This is done through a framework which\nallows us to systematically propose and analyze meta-algorithms for the various\nsettings described above. We show that any algorithm for online linear\noptimization with fully adaptive adversaries is an algorithm for online convex\noptimization. We also show that any such algorithm that requires\nfull-information feedback may be transformed to an algorithm with semi-bandit\nfeedback with comparable regret bound. We further show that algorithms that are\ndesigned for fully adaptive adversaries using deterministic semi-bandit\nfeedback can obtain similar bounds using only stochastic semi-bandit feedback\nwhen facing oblivious adversaries. We use this to describe general\nmeta-algorithms to convert first order algorithms to zeroth order algorithms\nwith comparable regret bounds. Our framework allows us to analyze online\noptimization in various settings, recovers several results in the literature\nwith a simplified proof technique, and provides new results.\n","authors":["Mohammad Pedramfar","Vaneet Aggarwal"],"pdf_url":"https://arxiv.org/pdf/2402.08621v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08306v1","updated":"2024-11-13T03:08:33Z","published":"2024-11-13T03:08:33Z","title":"SDDBench: A Benchmark for Synthesizable Drug Design","summary":"  A significant challenge in wet lab experiments with current drug design\ngenerative models is the trade-off between pharmacological properties and\nsynthesizability. Molecules predicted to have highly desirable properties are\noften difficult to synthesize, while those that are easily synthesizable tend\nto exhibit less favorable properties. As a result, evaluating the\nsynthesizability of molecules in general drug design scenarios remains a\nsignificant challenge in the field of drug discovery. The commonly used\nsynthetic accessibility (SA) score aims to evaluate the ease of synthesizing\ngenerated molecules, but it falls short of guaranteeing that synthetic routes\ncan actually be found. Inspired by recent advances in top-down synthetic route\ngeneration, we propose a new, data-driven metric to evaluate molecule\nsynthesizability. Our approach directly assesses the feasibility of synthetic\nroutes for a given molecule through our proposed round-trip score. This novel\nmetric leverages the synergistic duality between retrosynthetic planners and\nreaction predictors, both of which are trained on extensive reaction datasets.\nTo demonstrate the efficacy of our method, we conduct a comprehensive\nevaluation of round-trip scores alongside search success rate across a range of\nrepresentative molecule generative models. Code is available at\nhttps://github.com/SongtaoLiu0823/SDDBench.\n","authors":["Songtao Liu","Zhengkai Tu","Hanjun Dai","Peng Liu"],"pdf_url":"https://arxiv.org/pdf/2411.08306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07468v2","updated":"2024-11-13T03:07:36Z","published":"2024-11-12T01:09:52Z","title":"Privacy-Preserving Verifiable Neural Network Inference Service","summary":"  Machine learning has revolutionized data analysis and pattern recognition,\nbut its resource-intensive training has limited accessibility. Machine Learning\nas a Service (MLaaS) simplifies this by enabling users to delegate their data\nsamples to an MLaaS provider and obtain the inference result using a\npre-trained model. Despite its convenience, leveraging MLaaS poses significant\nprivacy and reliability concerns to the client. Specifically, sensitive\ninformation from the client inquiry data can be leaked to an adversarial MLaaS\nprovider. Meanwhile, the lack of a verifiability guarantee can potentially\nresult in biased inference results or even unfair payment issues. While\nexisting trustworthy machine learning techniques, such as those relying on\nverifiable computation or secure computation, offer solutions to privacy and\nreliability concerns, they fall short of simultaneously protecting the privacy\nof client data and providing provable inference verifiability.\n  In this paper, we propose vPIN, a privacy-preserving and verifiable CNN\ninference scheme that preserves privacy for client data samples while ensuring\nverifiability for the inference. vPIN makes use of partial homomorphic\nencryption and commit-and-prove succinct non-interactive argument of knowledge\ntechniques to achieve desirable security properties. In vPIN, we develop\nvarious optimization techniques to minimize the proving circuit for homomorphic\ninference evaluation thereby, improving the efficiency and performance of our\ntechnique. We fully implemented and evaluated our vPIN scheme on standard\ndatasets (e.g., MNIST, CIFAR-10). Our experimental results show that vPIN\nachieves high efficiency in terms of proving time, verification time, and proof\nsize, while providing client data privacy guarantees and provable\nverifiability.\n","authors":["Arman Riasi","Jorge Guajardo","Thang Hoang"],"pdf_url":"https://arxiv.org/pdf/2411.07468v2.pdf","comment":"Accepted at the Annual Computer Security Applications Conference\n  (ACSAC) 2024. Source code: github.com/vt-asaplab/vPIN"},{"id":"http://arxiv.org/abs/2411.07954v2","updated":"2024-11-13T02:56:56Z","published":"2024-11-12T17:30:31Z","title":"Learning Memory Mechanisms for Decision Making through Demonstrations","summary":"  In Partially Observable Markov Decision Processes, integrating an agent's\nhistory into memory poses a significant challenge for decision-making.\nTraditional imitation learning, relying on observation-action pairs for expert\ndemonstrations, fails to capture the expert's memory mechanisms used in\ndecision-making. To capture memory processes as demonstrations, we introduce\nthe concept of memory dependency pairs $(p, q)$ indicating that events at time\n$p$ are recalled for decision-making at time $q$. We introduce AttentionTuner\nto leverage memory dependency pairs in Transformers and find significant\nimprovements across several tasks compared to standard Transformers when\nevaluated on Memory Gym and the Long-term Memory Benchmark. Code is available\nat https://github.com/WilliamYue37/AttentionTuner.\n","authors":["William Yue","Bo Liu","Peter Stone"],"pdf_url":"https://arxiv.org/pdf/2411.07954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07463v2","updated":"2024-11-13T02:39:12Z","published":"2024-11-12T00:54:26Z","title":"MSEG-VCUQ: Multimodal SEGmentation with Enhanced Vision Foundation\n  Models, Convolutional Neural Networks, and Uncertainty Quantification for\n  High-Speed Video Phase Detection Data","summary":"  Purpose: High-speed video (HSV) phase detection (PD) segmentation is vital in\nnuclear reactors, chemical processing, and electronics cooling for detecting\nvapor, liquid, and microlayer phases. Traditional segmentation models face\npixel-level accuracy and generalization issues in multimodal data. MSEG-VCUQ\nintroduces VideoSAM, a hybrid framework leveraging convolutional neural\nnetworks (CNNs) and transformer-based vision models to enhance segmentation\naccuracy and generalizability across complex multimodal PD tasks. Methods:\nVideoSAM combines U-Net CNN and the Segment Anything Model (SAM) for advanced\nfeature extraction and segmentation across diverse HSV PD modalities, spanning\nfluids like water, FC-72, nitrogen, and argon under varied heat flux\nconditions. The framework also incorporates uncertainty quantification (UQ) to\nassess pixel-based discretization errors, delivering reliable metrics such as\ncontact line density and dry area fraction under experimental conditions.\nResults: VideoSAM outperforms SAM and modality-specific CNN models in\nsegmentation accuracy, excelling in environments with complex phase boundaries,\noverlapping bubbles, and dynamic liquid-vapor interactions. Its hybrid\narchitecture supports cross-dataset generalization, adapting effectively to\nvarying modalities. The UQ module provides accurate error estimates, enhancing\nthe reliability of segmentation outputs for advanced HSV PD research.\nConclusion: MSEG-VCUQ, via VideoSAM, offers a robust solution for HSV PD\nsegmentation, addressing previous limitations with advanced deep learning and\nUQ techniques. The open-source datasets and tools introduced enable scalable,\nprecise, and adaptable segmentation for multimodal PD datasets, supporting\nadvancements in HSV analysis and autonomous experimentation. The codes and data\nused for this paper are publicly available at:\n\\url{https://github.com/chikap421/mseg_vcuq}\n","authors":["Chika Maduabuchi","Ericmoore Jossou","Matteo Bucci"],"pdf_url":"https://arxiv.org/pdf/2411.07463v2.pdf","comment":"Under Review in EAAI"},{"id":"http://arxiv.org/abs/2411.07249v2","updated":"2024-11-13T02:38:02Z","published":"2024-10-26T21:27:53Z","title":"SPDIM: Source-Free Unsupervised Conditional and Label Shift Adaptation\n  in EEG","summary":"  The non-stationary nature of electroencephalography (EEG) introduces\ndistribution shifts across domains (e.g., days and subjects), posing a\nsignificant challenge to EEG-based neurotechnology generalization. Without\nlabeled calibration data for target domains, the problem is a source-free\nunsupervised domain adaptation (SFUDA) problem. For scenarios with constant\nlabel distribution, Riemannian geometry-aware statistical alignment frameworks\non the symmetric positive definite (SPD) manifold are considered\nstate-of-the-art. However, many practical scenarios, including EEG-based sleep\nstaging, exhibit label shifts. Here, we propose a geometric deep learning\nframework for SFUDA problems under specific distribution shifts, including\nlabel shifts. We introduce a novel, realistic generative model and show that\nprior Riemannian statistical alignment methods on the SPD manifold can\ncompensate for specific marginal and conditional distribution shifts but hurt\ngeneralization under label shifts. As a remedy, we propose a\nparameter-efficient manifold optimization strategy termed SPDIM. SPDIM uses the\ninformation maximization principle to learn a single SPD-manifold-constrained\nparameter per target domain. In simulations, we demonstrate that SPDIM can\ncompensate for the shifts under our generative model. Moreover, using public\nEEG-based brain-computer interface and sleep staging datasets, we show that\nSPDIM outperforms prior approaches.\n","authors":["Shanglin Li","Motoaki Kawanabe","Reinmar J. Kobler"],"pdf_url":"https://arxiv.org/pdf/2411.07249v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08297v1","updated":"2024-11-13T02:32:38Z","published":"2024-11-13T02:32:38Z","title":"TowerDebias: A Novel Debiasing Method based on the Tower Property","summary":"  Decision-making processes have increasingly come to rely on sophisticated\nmachine learning tools, raising concerns about the fairness of their\npredictions with respect to any sensitive groups. The widespread use of\ncommercial black-box machine learning models necessitates careful consideration\nof their legal and ethical implications on consumers. In situations where users\nhave access to these \"black-box\" models, a key question emerges: how can we\nmitigate or eliminate the influence of sensitive attributes, such as race or\ngender? We propose towerDebias (tDB), a novel approach designed to reduce the\ninfluence of sensitive variables in predictions made by black-box models. Using\nthe Tower Property from probability theory, tDB aims to improve prediction\nfairness during the post-processing stage in a manner amenable to the\nFairness-Utility Tradeoff. This method is highly flexible, requiring no prior\nknowledge of the original model's internal structure, and can be extended to a\nrange of different applications. We provide a formal improvement theorem for\ntDB and demonstrate its effectiveness in both regression and classification\ntasks, underscoring its impact on the fairness-utility tradeoff.\n","authors":["Norman Matloff","Aditya Mittal"],"pdf_url":"https://arxiv.org/pdf/2411.08297v1.pdf","comment":"To be submitted to a journal soon"},{"id":"http://arxiv.org/abs/2411.08290v1","updated":"2024-11-13T02:17:03Z","published":"2024-11-13T02:17:03Z","title":"RESOLVE: Relational Reasoning with Symbolic and Object-Level Features\n  Using Vector Symbolic Processing","summary":"  Modern transformer-based encoder-decoder architectures struggle with\nreasoning tasks due to their inability to effectively extract relational\ninformation between input objects (data/tokens). Recent work introduced the\nAbstractor module, embedded between transformer layers, to address this gap.\nHowever, the Abstractor layer while excelling at capturing relational\ninformation (pure relational reasoning), faces challenges in tasks that require\nboth object and relational-level reasoning (partial relational reasoning). To\naddress this, we propose RESOLVE, a neuro-vector symbolic architecture that\ncombines object-level features with relational representations in\nhigh-dimensional spaces, using fast and efficient operations such as bundling\n(summation) and binding (Hadamard product) allowing both object-level features\nand relational representations to coexist within the same structure without\ninterfering with one another. RESOLVE is driven by a novel attention mechanism\nthat operates in a bipolar high dimensional space, allowing fast attention\nscore computation compared to the state-of-the-art. By leveraging this design,\nthe model achieves both low compute latency and memory efficiency. RESOLVE also\noffers better generalizability while achieving higher accuracy in purely\nrelational reasoning tasks such as sorting as well as partial relational\nreasoning tasks such as math problem-solving compared to state-of-the-art\nmethods.\n","authors":["Mohamed Mejri","Chandramouli Amarnath","Abhijit Chatterjee"],"pdf_url":"https://arxiv.org/pdf/2411.08290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02349v2","updated":"2024-11-13T02:03:01Z","published":"2023-11-04T08:28:33Z","title":"Sample Complexity of Opinion Formation on Networks with Linear\n  Regression Models","summary":"  Consider public health officials aiming to spread awareness about a new\nvaccine in a community interconnected by a social network. How can they\ndistribute information with minimal resources, so as to avoid polarization and\nensure community-wide convergence of opinion? To tackle such challenges, we\ninitiate the study of sample complexity of opinion convergence in networks. Our\nframework is built on the recognized opinion formation game, where we regard\nthe opinion of each agent as a data-derived model, unlike previous works that\ntreat opinions as data-independent scalars. The opinion model for every agent\nis initially learned from its local samples and evolves game-theoretically as\nall agents communicate with neighbors and revise their models towards an\nequilibrium. Our focus is on the sample complexity needed to ensure that the\nopinions converge to an equilibrium such that the final model of every agent\nhas low generalization error.\n  Our paper has two main technical results. First, we present a novel\npolynomial time optimization framework to quantify the total sample complexity\nfor arbitrary networks, when the underlying learning problem is (generalized)\nlinear regression. Second, we leverage this optimization to study the network\ngain which measures the improvement of sample complexity when learning over a\nnetwork compared to that in isolation. Towards this end, we derive network gain\nbounds for various network classes including cliques, star graphs, and random\nregular graphs. Additionally, our framework provides a method to study sample\ndistribution within the network, suggesting that it is sufficient to allocate\nsamples inversely to the degree. Empirical results on both synthetic and\nreal-world networks strongly support our theoretical findings.\n","authors":["Haolin Liu","Rajmohan Rajaraman","Ravi Sundaram","Anil Vullikanti","Omer Wasim","Haifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2311.02349v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08286v1","updated":"2024-11-13T02:02:52Z","published":"2024-11-13T02:02:52Z","title":"Hashing for Protein Structure Similarity Search","summary":"  Protein structure similarity search (PSSS), which tries to search proteins\nwith similar structures, plays a crucial role across diverse domains from drug\ndesign to protein function prediction and molecular evolution. Traditional\nalignment-based PSSS methods, which directly calculate alignment on the protein\nstructures, are highly time-consuming with high memory cost. Recently,\nalignment-free methods, which represent protein structures as fixed-length\nreal-valued vectors, are proposed for PSSS. Although these methods have lower\ntime and memory cost than alignment-based methods, their time and memory cost\nis still too high for large-scale PSSS, and their accuracy is unsatisfactory.\nIn this paper, we propose a novel method, called\n$\\underline{\\text{p}}$r$\\underline{\\text{o}}$tein\n$\\underline{\\text{s}}$tructure $\\underline{\\text{h}}$ashing (POSH), for PSSS.\nPOSH learns a binary vector representation for each protein structure, which\ncan dramatically reduce the time and memory cost for PSSS compared with\nreal-valued vector representation based methods. Furthermore, in POSH we also\npropose expressive hand-crafted features and a structure encoder to well model\nboth node and edge interactions in proteins. Experimental results on real\ndatasets show that POSH can outperform other methods to achieve\nstate-of-the-art accuracy. Furthermore, POSH achieves a memory saving of more\nthan six times and speed improvement of more than four times, compared with\nother methods.\n","authors":["Jin Han","Wu-Jun Li"],"pdf_url":"https://arxiv.org/pdf/2411.08286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12723v4","updated":"2024-11-13T01:45:11Z","published":"2024-06-18T15:45:21Z","title":"BIOSCAN-5M: A Multimodal Dataset for Insect Biodiversity","summary":"  As part of an ongoing worldwide effort to comprehend and monitor insect\nbiodiversity, this paper presents the BIOSCAN-5M Insect dataset to the machine\nlearning community and establish several benchmark tasks. BIOSCAN-5M is a\ncomprehensive dataset containing multi-modal information for over 5 million\ninsect specimens, and it significantly expands existing image-based biological\ndatasets by including taxonomic labels, raw nucleotide barcode sequences,\nassigned barcode index numbers, geographical, and size information. We propose\nthree benchmark experiments to demonstrate the impact of the multi-modal data\ntypes on the classification and clustering accuracy. First, we pretrain a\nmasked language model on the DNA barcode sequences of the BIOSCAN-5M dataset,\nand demonstrate the impact of using this large reference library on species-\nand genus-level classification performance. Second, we propose a zero-shot\ntransfer learning task applied to images and DNA barcodes to cluster feature\nembeddings obtained from self-supervised learning, to investigate whether\nmeaningful clusters can be derived from these representation embeddings. Third,\nwe benchmark multi-modality by performing contrastive learning on DNA barcodes,\nimage data, and taxonomic information. This yields a general shared embedding\nspace enabling taxonomic classification using multiple types of information and\nmodalities. The code repository of the BIOSCAN-5M Insect dataset is available\nat https://github.com/bioscan-ml/BIOSCAN-5M.\n","authors":["Zahra Gharaee","Scott C. Lowe","ZeMing Gong","Pablo Millan Arias","Nicholas Pellegrino","Austin T. Wang","Joakim Bruslund Haurum","Iuliia Zarubiieva","Lila Kari","Dirk Steinke","Graham W. Taylor","Paul Fieguth","Angel X. Chang"],"pdf_url":"https://arxiv.org/pdf/2406.12723v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.05386v2","updated":"2024-11-13T01:40:53Z","published":"2024-05-08T19:31:06Z","title":"Interpretability Needs a New Paradigm","summary":"  Interpretability is the study of explaining models in understandable terms to\nhumans. At present, interpretability is divided into two paradigms: the\nintrinsic paradigm, which believes that only models designed to be explained\ncan be explained, and the post-hoc paradigm, which believes that black-box\nmodels can be explained. At the core of this debate is how each paradigm\nensures its explanations are faithful, i.e., true to the model's behavior. This\nis important, as false but convincing explanations lead to unsupported\nconfidence in artificial intelligence (AI), which can be dangerous. This\npaper's position is that we should think about new paradigms while staying\nvigilant regarding faithfulness. First, by examining the history of paradigms\nin science, we see that paradigms are constantly evolving. Then, by examining\nthe current paradigms, we can understand their underlying beliefs, the value\nthey bring, and their limitations. Finally, this paper presents 3 emerging\nparadigms for interpretability. The first paradigm designs models such that\nfaithfulness can be easily measured. Another optimizes models such that\nexplanations become faithful. The last paradigm proposes to develop models that\nproduce both a prediction and an explanation.\n","authors":["Andreas Madsen","Himabindu Lakkaraju","Siva Reddy","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2405.05386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14798v2","updated":"2024-11-13T01:36:33Z","published":"2024-06-21T00:16:55Z","title":"Probabilistic Emulation of a Global Climate Model with Spherical\n  DYffusion","summary":"  Data-driven deep learning models are transforming global weather forecasting.\nIt is an open question if this success can extend to climate modeling, where\nthe complexity of the data and long inference rollouts pose significant\nchallenges. Here, we present the first conditional generative model that\nproduces accurate and physically consistent global climate ensemble simulations\nby emulating a coarse version of the United States' primary operational global\nforecast model, FV3GFS. Our model integrates the dynamics-informed diffusion\nframework (DYffusion) with the Spherical Fourier Neural Operator (SFNO)\narchitecture, enabling stable 100-year simulations at 6-hourly timesteps while\nmaintaining low computational overhead compared to single-step deterministic\nbaselines. The model achieves near gold-standard performance for climate model\nemulation, outperforming existing approaches and demonstrating promising\nensemble skill. This work represents a significant advance towards efficient,\ndata-driven climate simulations that can enhance our understanding of the\nclimate system and inform adaptation strategies.\n","authors":["Salva R√ºhling Cachay","Brian Henn","Oliver Watt-Meyer","Christopher S. Bretherton","Rose Yu"],"pdf_url":"https://arxiv.org/pdf/2406.14798v2.pdf","comment":"NeurIPS 2024; Code is available at\n  https://github.com/Rose-STL-Lab/spherical-dyffusion"},{"id":"http://arxiv.org/abs/2411.08267v1","updated":"2024-11-13T00:42:40Z","published":"2024-11-13T00:42:40Z","title":"Least Squares Training of Quadratic Convolutional Neural Networks with\n  Applications to System Theory","summary":"  This paper provides a least squares formulation for the training of a 2-layer\nconvolutional neural network using quadratic activation functions, a 2-norm\nloss function, and no regularization term. Using this method, an analytic\nexpression for the globally optimal weights is obtained alongside a quadratic\ninput-output equation for the network. These properties make the network a\nviable tool in system theory by enabling further analysis, such as the\nsensitivity of the output to perturbations in the input, which is crucial for\nsafety-critical systems such as aircraft or autonomous vehicles.The least\nsquares method is compared to previously proposed strategies for training\nquadratic networks and to a back-propagation-trained ReLU network. The proposed\nmethod is applied to a system identification problem and a GPS position\nestimation problem. The least squares network is shown to have a significantly\nreduced training time with minimal compromises on prediction accuracy alongside\nthe advantages of having an analytic input-output equation. Although these\nresults only apply to 2-layer networks, this paper motivates the exploration of\ndeeper quadratic networks in the context of system theory.\n","authors":["Zachary Yetman Van Egmond","Luis Rodrigues"],"pdf_url":"https://arxiv.org/pdf/2411.08267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.09995v2","updated":"2024-11-13T00:41:01Z","published":"2024-04-15T17:59:57Z","title":"Taming Latent Diffusion Model for Neural Radiance Field Inpainting","summary":"  Neural Radiance Field (NeRF) is a representation for 3D reconstruction from\nmulti-view images. Despite some recent work showing preliminary success in\nediting a reconstructed NeRF with diffusion prior, they remain struggling to\nsynthesize reasonable geometry in completely uncovered regions. One major\nreason is the high diversity of synthetic contents from the diffusion model,\nwhich hinders the radiance field from converging to a crisp and deterministic\ngeometry. Moreover, applying latent diffusion models on real data often yields\na textural shift incoherent to the image condition due to auto-encoding errors.\nThese two problems are further reinforced with the use of pixel-distance\nlosses. To address these issues, we propose tempering the diffusion model's\nstochasticity with per-scene customization and mitigating the textural shift\nwith masked adversarial training. During the analyses, we also found the\ncommonly used pixel and perceptual losses are harmful in the NeRF inpainting\ntask. Through rigorous experiments, our framework yields state-of-the-art NeRF\ninpainting results on various real-world scenes. Project page:\nhttps://hubert0527.github.io/MALD-NeRF\n","authors":["Chieh Hubert Lin","Changil Kim","Jia-Bin Huang","Qinbo Li","Chih-Yao Ma","Johannes Kopf","Ming-Hsuan Yang","Hung-Yu Tseng"],"pdf_url":"https://arxiv.org/pdf/2404.09995v2.pdf","comment":"Accepted to ECCV 2024. Project page:\n  https://hubert0527.github.io/MALD-NeRF"},{"id":"http://arxiv.org/abs/2402.17457v2","updated":"2024-11-13T00:38:48Z","published":"2024-02-27T12:28:01Z","title":"Super Consistency of Neural Network Landscapes and Learning Rate\n  Transfer","summary":"  Recently, there has been growing evidence that if the width and depth of a\nneural network are scaled toward the so-called rich feature learning limit\n(\\mup and its depth extension), then some hyperparameters -- such as the\nlearning rate -- exhibit transfer from small to very large models. From an\noptimization perspective, this phenomenon is puzzling, as it implies that the\nloss landscape is consistently similar across very different model sizes. In\nthis work, we study the landscape through the lens of the loss Hessian, with a\nfocus on its largest eigenvalue (i.e. the sharpness), and find that certain\nspectral properties under $\\mu$P are largely independent of the size of the\nnetwork, and remain consistent as training progresses. We name this property\nSuper Consistency of the landscape. On the other hand, we show that in the\nNeural Tangent Kernel (NTK) and other scaling regimes, the sharpness exhibits\nvery different dynamics at different scales. But what causes these differences\nin the sharpness dynamics? Through a connection between the Hessian's and the\nNTK's spectrum, we argue that the cause lies in the presence (for $\\mu$P) or\nprogressive absence (for the NTK scaling) of feature learning. We corroborate\nour claims with a substantial suite of experiments, covering a wide range of\ndatasets and architectures: from ResNets and Vision Transformers trained on\nbenchmark vision datasets to Transformers-based language models trained on\nWikiText.\n","authors":["Lorenzo Noci","Alexandru Meterez","Thomas Hofmann","Antonio Orvieto"],"pdf_url":"https://arxiv.org/pdf/2402.17457v2.pdf","comment":"The paper has been accepted at Neurips 2024. This is a revised\n  version of the paper previously titled \"Why do Learning Rates Transfer?\n  Reconciling Optimization and Scaling Limits for Deep Learning\""},{"id":"http://arxiv.org/abs/2410.01272v2","updated":"2024-11-13T00:19:34Z","published":"2024-10-02T06:30:49Z","title":"\"No Matter What You Do\": Purifying GNN Models via Backdoor Unlearning","summary":"  Recent studies have exposed that GNNs are vulnerable to several adversarial\nattacks, among which backdoor attack is one of the toughest. Similar to Deep\nNeural Networks (DNNs), backdoor attacks in GNNs lie in the fact that the\nattacker modifies a portion of graph data by embedding triggers and enforces\nthe model to learn the trigger feature during the model training process.\nDespite the massive prior backdoor defense works on DNNs, defending against\nbackdoor attacks in GNNs is largely unexplored, severely hindering the\nwidespread application of GNNs in real-world tasks. To bridge this gap, we\npresent GCleaner, the first backdoor mitigation method on GNNs. GCleaner can\nmitigate the presence of the backdoor logic within backdoored GNNs by reversing\nthe backdoor learning procedure, aiming to restore the model performance to a\nlevel similar to that is directly trained on the original clean dataset. To\nachieve this objective, we ask: How to recover universal and hard backdoor\ntriggers in GNNs? How to unlearn the backdoor trigger feature while maintaining\nthe model performance? We conduct the graph trigger recovery via the\nexplanation method to identify optimal trigger locations, facilitating the\nsearch of universal and hard backdoor triggers in the feature space of the\nbackdoored model through maximal similarity. Subsequently, we introduce the\nbackdoor unlearning mechanism, which combines knowledge distillation and\ngradient-based explainable knowledge for fine-grained backdoor erasure.\nExtensive experimental evaluations on four benchmark datasets demonstrate that\nGCleaner can reduce the backdoor attack success rate to 10% with only 1% of\nclean data, and has almost negligible degradation in model performance, which\nfar outperforms the state-of-the-art (SOTA) defense methods.\n","authors":["Jiale Zhang","Chengcheng Zhu","Bosen Rao","Hao Sui","Xiaobing Sun","Bing Chen","Chunyi Zhou","Shouling Ji"],"pdf_url":"https://arxiv.org/pdf/2410.01272v2.pdf","comment":"18 pages, 12 figures, 9 tables"},{"id":"http://arxiv.org/abs/2409.18164v2","updated":"2024-11-13T00:15:46Z","published":"2024-09-26T17:30:28Z","title":"Data-Prep-Kit: getting your data ready for LLM application development","summary":"  Data preparation is the first and a very important step towards any Large\nLanguage Model (LLM) development. This paper introduces an easy-to-use,\nextensible, and scale-flexible open-source data preparation toolkit called Data\nPrep Kit (DPK). DPK is architected and designed to enable users to scale their\ndata preparation to their needs. With DPK they can prepare data on a local\nmachine or effortlessly scale to run on a cluster with thousands of CPU Cores.\nDPK comes with a highly scalable, yet extensible set of modules that transform\nnatural language and code data. If the user needs additional transforms, they\ncan be easily developed using extensive DPK support for transform creation.\nThese modules can be used independently or pipelined to perform a series of\noperations. In this paper, we describe DPK architecture and show its\nperformance from a small scale to a very large number of CPUs. The modules from\nDPK have been used for the preparation of Granite Models [1] [2]. We believe\nDPK is a valuable contribution to the AI community to easily prepare data to\nenhance the performance of their LLM models or to fine-tune models with\nRetrieval-Augmented Generation (RAG).\n","authors":["David Wood","Boris Lublinsky","Alexy Roytman","Shivdeep Singh","Constantin Adam","Abdulhamid Adebayo","Sungeun An","Yuan Chi Chang","Xuan-Hong Dang","Nirmit Desai","Michele Dolfi","Hajar Emami-Gohari","Revital Eres","Takuya Goto","Dhiraj Joshi","Yan Koyfman","Mohammad Nassar","Hima Patel","Paramesvaran Selvam","Yousaf Shah","Saptha Surendran","Daiki Tsuzuku","Petros Zerfos","Shahrokh Daijavad"],"pdf_url":"https://arxiv.org/pdf/2409.18164v2.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.08257v1","updated":"2024-11-13T00:14:09Z","published":"2024-11-13T00:14:09Z","title":"GPTree: Towards Explainable Decision-Making via LLM-powered Decision\n  Trees","summary":"  Traditional decision tree algorithms are explainable but struggle with\nnon-linear, high-dimensional data, limiting its applicability in complex\ndecision-making. Neural networks excel at capturing complex patterns but\nsacrifice explainability in the process. In this work, we present GPTree, a\nnovel framework combining explainability of decision trees with the advanced\nreasoning capabilities of LLMs. GPTree eliminates the need for feature\nengineering and prompt chaining, requiring only a task-specific prompt and\nleveraging a tree-based structure to dynamically split samples. We also\nintroduce an expert-in-the-loop feedback mechanism to further enhance\nperformance by enabling human intervention to refine and rebuild decision\npaths, emphasizing the harmony between human expertise and machine\nintelligence. Our decision tree achieved a 7.8% precision rate for identifying\n\"unicorn\" startups at the inception stage of a startup, surpassing gpt-4o with\nfew-shot learning as well as the best human decision-makers (3.1% to 5.6%).\n","authors":["Sichao Xiong","Yigit Ihlamur","Fuat Alican","Aaron Ontoyin Yin"],"pdf_url":"https://arxiv.org/pdf/2411.08257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04883v6","updated":"2024-11-13T23:34:19Z","published":"2022-08-09T16:25:49Z","title":"Neural-Rendezvous: Provably Robust Guidance and Control to Encounter\n  Interstellar Objects","summary":"  Interstellar objects (ISOs) are likely representatives of primitive materials\ninvaluable in understanding exoplanetary star systems. Due to their poorly\nconstrained orbits with generally high inclinations and relative velocities,\nhowever, exploring ISOs with conventional human-in-the-loop approaches is\nsignificantly challenging. This paper presents Neural-Rendezvous -- a deep\nlearning-based guidance and control framework for encountering fast-moving\nobjects, including ISOs, robustly, accurately, and autonomously in real time.\nIt uses pointwise minimum norm tracking control on top of a guidance policy\nmodeled by a spectrally-normalized deep neural network, where its\nhyperparameters are tuned with a loss function directly penalizing the MPC\nstate trajectory tracking error. We show that Neural-Rendezvous provides a high\nprobability exponential bound on the expected spacecraft delivery error, the\nproof of which leverages stochastic incremental stability analysis. In\nparticular, it is used to construct a non-negative function with a\nsupermartingale property, explicitly accounting for the ISO state uncertainty\nand the local nature of nonlinear state estimation guarantees. In numerical\nsimulations, Neural-Rendezvous is demonstrated to satisfy the expected error\nbound for 100 ISO candidates. This performance is also empirically validated\nusing our spacecraft simulator and in high-conflict and distributed UAV swarm\nreconfiguration with up to 20 UAVs.\n","authors":["Hiroyasu Tsukamoto","Soon-Jo Chung","Yashwanth Kumar Nakka","Benjamin Donitz","Declan Mages","Michel Ingham"],"pdf_url":"https://arxiv.org/pdf/2208.04883v6.pdf","comment":"Preprint Version, Accepted: October, 2024 (One-minute YouTube\n  summary: https://youtu.be/q3e0LYS2IYQ, DOI:\n  https://doi.org/10.2514/1.G007671)"},{"id":"http://arxiv.org/abs/2411.09077v1","updated":"2024-11-13T23:09:53Z","published":"2024-11-13T23:09:53Z","title":"Drone Detection using Deep Neural Networks Trained on Pure Synthetic\n  Data","summary":"  Drone detection has benefited from improvements in deep neural networks, but\nlike many other applications, suffers from the availability of accurate data\nfor training. Synthetic data provides a potential for low-cost data generation\nand has been shown to improve data availability and quality. However, models\ntrained on synthetic datasets need to prove their ability to perform on\nreal-world data, known as the problem of sim-to-real transferability. Here, we\npresent a drone detection Faster-RCNN model trained on a purely synthetic\ndataset that transfers to real-world data. We found that it achieves an AP_50\nof 97.0% when evaluated on the MAV-Vid - a real dataset of flying drones -\ncompared with 97.8% for an equivalent model trained on real-world data. Our\nresults show that using synthetic data for drone detection has the potential to\nreduce data collection costs and improve labelling quality. These findings\ncould be a starting point for more elaborate synthetic drone datasets. For\nexample, realistic recreations of specific scenarios could de-risk the dataset\ngeneration of safety-critical applications such as the detection of drones at\nairports. Further, synthetic data may enable reliable drone detection systems,\nwhich could benefit other areas, such as unmanned traffic management systems.\nThe code is available\nhttps://github.com/mazqtpopx/cranfield-synthetic-drone-detection alongside the\ndatasets\nhttps://huggingface.co/datasets/mazqtpopx/cranfield-synthetic-drone-detection.\n","authors":["Mariusz Wisniewski","Zeeshan A. Rana","Ivan Petrunin","Alan Holt","Stephen Harman"],"pdf_url":"https://arxiv.org/pdf/2411.09077v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.07217v3","updated":"2024-11-13T23:09:38Z","published":"2024-11-11T18:38:22Z","title":"Feature Selection Based on Wasserstein Distance","summary":"  This paper presents a novel feature selection method leveraging the\nWasserstein distance to improve feature selection in machine learning. Unlike\ntraditional methods based on correlation or Kullback-Leibler (KL) divergence,\nour approach uses the Wasserstein distance to assess feature similarity,\ninherently capturing class relationships and making it robust to noisy labels.\nWe introduce a Markov blanket-based feature selection algorithm and demonstrate\nits effectiveness. Our analysis shows that the Wasserstein distance-based\nfeature selection method effectively reduces the impact of noisy labels without\nrelying on specific noise models. We provide a lower bound on its\neffectiveness, which remains meaningful even in the presence of noise.\nExperimental results across multiple datasets demonstrate that our approach\nconsistently outperforms traditional methods, particularly in noisy settings.\n","authors":["Fuwei Li"],"pdf_url":"https://arxiv.org/pdf/2411.07217v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14131v2","updated":"2024-11-13T23:07:44Z","published":"2024-05-23T03:11:07Z","title":"Statistical Advantages of Perturbing Cosine Router in Mixture of Experts","summary":"  The cosine router in Mixture of Experts (MoE) has recently emerged as an\nattractive alternative to the conventional linear router. Indeed, the cosine\nrouter demonstrates favorable performance in image and language tasks and\nexhibits better ability to mitigate the representation collapse issue, which\noften leads to parameter redundancy and limited representation potentials.\nDespite its empirical success, a comprehensive analysis of the cosine router in\nMoE has been lacking. Considering the least square estimation of the cosine\nrouting MoE, we demonstrate that due to the intrinsic interaction of the model\nparameters in the cosine router via some partial differential equations,\nregardless of the structures of the experts, the estimation rates of experts\nand model parameters can be as slow as $\\mathcal{O}(1/\\log^{\\tau}(n))$ where\n$\\tau > 0$ is some constant and $n$ is the sample size. Surprisingly, these\npessimistic non-polynomial convergence rates can be circumvented by the widely\nused technique in practice to stabilize the cosine router -- simply adding\nnoises to the $L^2$ norms in the cosine router, which we refer to as\n\\textit{perturbed cosine router}. Under the strongly identifiable settings of\nthe expert functions, we prove that the estimation rates for both the experts\nand model parameters under the perturbed cosine routing MoE are significantly\nimproved to polynomial rates. Finally, we conduct extensive simulation studies\nin both synthetic and real data settings to empirically validate our\ntheoretical results.\n","authors":["Huy Nguyen","Pedram Akbarian","Trang Pham","Trang Nguyen","Shujian Zhang","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2405.14131v2.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2411.09073v1","updated":"2024-11-13T22:56:00Z","published":"2024-11-13T22:56:00Z","title":"Code-mixed LLM: Improve Large Language Models' Capability to Handle\n  Code-Mixing through Reinforcement Learning from AI Feedback","summary":"  Code-mixing(CM) or code-switching(CSW) refers to the juxtaposition of\nlinguistic units from two or more languages during the conversation or\nsometimes even a single utterance. Code-mixing introduces unique challenges in\ndaily life, such as syntactic mismatches and semantic blending, that are rarely\nencountered in monolingual settings. Large language models (LLMs) have\nrevolutionized the field of natural language processing (NLP) by offering\nunprecedented capabilities in understanding human languages. However, the\neffectiveness of current state-of-the-art multilingual LLMs has not yet been\nfully explored in the CM scenario. To fill this gap, we first benchmark the\nperformance of multilingual LLMs on various code-mixing NLP tasks. Then we\npropose to improve the multilingual LLMs' ability to understand code-mixing\nthrough reinforcement learning from human feedback (RLHF) and code-mixed\nmachine translation tasks. Given the high-cost and time-consuming preference\nlabeling procedure, we improve this by utilizing LLMs as annotators to perform\nthe reinforcement learning from AI feedback (RLAIF). The experiments show the\neffectiveness of the proposed method.\n","authors":["Wenbo Zhang","Aditya Majumdar","Amulya Yadav"],"pdf_url":"https://arxiv.org/pdf/2411.09073v1.pdf","comment":"initial version: 5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.09072v1","updated":"2024-11-13T22:55:45Z","published":"2024-11-13T22:55:45Z","title":"Continuous GNN-based Anomaly Detection on Edge using Efficient Adaptive\n  Knowledge Graph Learning","summary":"  The increasing demand for robust security solutions across various industries\nhas made Video Anomaly Detection (VAD) a critical task in applications such as\nintelligent surveillance, evidence investigation, and violence detection.\nTraditional approaches to VAD often rely on finetuning large pre-trained\nmodels, which can be computationally expensive and impractical for real-time or\nresource-constrained environments. To address this, MissionGNN introduced a\nmore efficient method by training a graph neural network (GNN) using a fixed\nknowledge graph (KG) derived from large language models (LLMs) like GPT-4.\nWhile this approach demonstrated significant efficiency in computational power\nand memory, it faces limitations in dynamic environments where frequent updates\nto the KG are necessary due to evolving behavior trends and shifting data\npatterns. These updates typically require cloud-based computation, posing\nchallenges for edge computing applications. In this paper, we propose a novel\nframework that facilitates continuous KG adaptation directly on edge devices,\novercoming the limitations of cloud dependency. Our method dynamically modifies\nthe KG through a three-phase process: pruning, alternating, and creating nodes,\nenabling real-time adaptation to changing data trends. This continuous learning\napproach enhances the robustness of anomaly detection models, making them more\nsuitable for deployment in dynamic and resource-constrained environments.\n","authors":["Sanggeon Yun","Ryozo Masukawa","William Youngwoo Chung","Minhyoung Na","Nathaniel Bastian","Mohsen Imani"],"pdf_url":"https://arxiv.org/pdf/2411.09072v1.pdf","comment":"Accepted to DATE 2025"},{"id":"http://arxiv.org/abs/2405.20194v6","updated":"2024-11-13T22:51:10Z","published":"2024-05-30T15:58:22Z","title":"Occam Gradient Descent","summary":"  Deep learning neural network models must be large enough to adapt to their\nproblem domain, while small enough to avoid overfitting training data during\ngradient descent. To balance these competing demands, overprovisioned deep\nlearning models such as transformers are trained for a single epoch on large\ndata sets, and hence inefficient with both computing resources and training\ndata. In response to these inefficiencies, we exploit learning theory to derive\nOccam Gradient Descent, an algorithm that interleaves adaptive reduction of\nmodel size to minimize generalization error, with gradient descent on model\nweights to minimize fitting error. In contrast, traditional gradient descent\ngreedily minimizes fitting error without regard to generalization error. Our\nalgorithm simultaneously descends the space of weights and topological size of\nany neural network without modification. With respect to loss, compute and\nmodel size, our experiments show (a) on image classification benchmarks, linear\nand convolutional neural networks trained with Occam Gradient Descent\noutperform traditional gradient descent with or without post-train pruning; (b)\non a range of tabular data classification tasks, neural networks trained with\nOccam Gradient Descent outperform traditional gradient descent, as well as\nRandom Forests; (c) on natural language transformers, Occam Gradient Descent\noutperforms traditional gradient descent.\n","authors":["B. N. Kausik"],"pdf_url":"https://arxiv.org/pdf/2405.20194v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09065v1","updated":"2024-11-13T22:45:52Z","published":"2024-11-13T22:45:52Z","title":"Language-Model Prior Overcomes Cold-Start Items","summary":"  The growth of recommender systems (RecSys) is driven by digitization and the\nneed for personalized content in areas such as e-commerce and video streaming.\nThe content in these systems often changes rapidly and therefore they\nconstantly face the ongoing cold-start problem, where new items lack\ninteraction data and are hard to value. Existing solutions for the cold-start\nproblem, such as content-based recommenders and hybrid methods, leverage item\nmetadata to determine item similarities. The main challenge with these methods\nis their reliance on structured and informative metadata to capture detailed\nitem similarities, which may not always be available. This paper introduces a\nnovel approach for cold-start item recommendation that utilizes the language\nmodel (LM) to estimate item similarities, which are further integrated as a\nBayesian prior with classic recommender systems. This approach is generic and\nable to boost the performance of various recommenders. Specifically, our\nexperiments integrate it with both sequential and collaborative filtering-based\nrecommender and evaluate it on two real-world datasets, demonstrating the\nenhanced performance of the proposed approach.\n","authors":["Shiyu Wang","Hao Ding","Yupeng Gu","Sergul Aydore","Kousha Kalantari","Branislav Kveton"],"pdf_url":"https://arxiv.org/pdf/2411.09065v1.pdf","comment":"This paper is dedicated to cold-start item recommendation using\n  language-model priors"},{"id":"http://arxiv.org/abs/2411.09064v1","updated":"2024-11-13T22:44:25Z","published":"2024-11-13T22:44:25Z","title":"Minimax Optimal Two-Sample Testing under Local Differential Privacy","summary":"  We explore the trade-off between privacy and statistical utility in private\ntwo-sample testing under local differential privacy (LDP) for both multinomial\nand continuous data. We begin by addressing the multinomial case, where we\nintroduce private permutation tests using practical privacy mechanisms such as\nLaplace, discrete Laplace, and Google's RAPPOR. We then extend our multinomial\napproach to continuous data via binning and study its uniform separation rates\nunder LDP over H\\\"older and Besov smoothness classes. The proposed tests for\nboth discrete and continuous cases rigorously control the type I error for any\nfinite sample size, strictly adhere to LDP constraints, and achieve minimax\nseparation rates under LDP. The attained minimax rates reveal inherent\nprivacy-utility trade-offs that are unavoidable in private testing. To address\nscenarios with unknown smoothness parameters in density testing, we propose an\nadaptive test based on a Bonferroni-type approach that ensures robust\nperformance without prior knowledge of the smoothness parameters. We validate\nour theoretical findings with extensive numerical experiments and demonstrate\nthe practical relevance and effectiveness of our proposed methods.\n","authors":["Jongmin Mun","Seungwoo Kwak","Ilmun Kim"],"pdf_url":"https://arxiv.org/pdf/2411.09064v1.pdf","comment":"59 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.09056v1","updated":"2024-11-13T22:29:23Z","published":"2024-11-13T22:29:23Z","title":"Optimisation Strategies for Ensuring Fairness in Machine Learning: With\n  and Without Demographics","summary":"  Ensuring fairness has emerged as one of the primary concerns in AI and its\nrelated algorithms. Over time, the field of machine learning fairness has\nevolved to address these issues. This paper provides an extensive overview of\nthis field and introduces two formal frameworks to tackle open questions in\nmachine learning fairness.\n  In one framework, operator-valued optimisation and min-max objectives are\nemployed to address unfairness in time-series problems. This approach showcases\nstate-of-the-art performance on the notorious COMPAS benchmark dataset,\ndemonstrating its effectiveness in real-world scenarios.\n  In the second framework, the challenge of lacking sensitive attributes, such\nas gender and race, in commonly used datasets is addressed. This issue is\nparticularly pressing because existing algorithms in this field predominantly\nrely on the availability or estimations of such attributes to assess and\nmitigate unfairness. Here, a framework for a group-blind bias-repair is\nintroduced, aiming to mitigate bias without relying on sensitive attributes.\nThe efficacy of this approach is showcased through analyses conducted on the\nAdult Census Income dataset.\n  Additionally, detailed algorithmic analyses for both frameworks are provided,\naccompanied by convergence guarantees, ensuring the robustness and reliability\nof the proposed methodologies.\n","authors":["Quan Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.09056v1.pdf","comment":"PhD thesis. arXiv admin note: text overlap with arXiv:2310.11407"},{"id":"http://arxiv.org/abs/2411.09055v1","updated":"2024-11-13T22:28:05Z","published":"2024-11-13T22:28:05Z","title":"SAFELOC: Overcoming Data Poisoning Attacks in Heterogeneous Federated\n  Machine Learning for Indoor Localization","summary":"  Machine learning (ML) based indoor localization solutions are critical for\nmany emerging applications, yet their efficacy is often compromised by\nhardware/software variations across mobile devices (i.e., device heterogeneity)\nand the threat of ML data poisoning attacks. Conventional methods aimed at\ncountering these challenges show limited resilience to the uncertainties\ncreated by these phenomena. In response, in this paper, we introduce SAFELOC, a\nnovel framework that not only minimizes localization errors under these\nchallenging conditions but also ensures model compactness for efficient mobile\ndevice deployment. Our framework targets a distributed and co-operative\nlearning environment that uses federated learning (FL) to preserve user data\nprivacy and assumes heterogeneous mobile devices carried by users (just like in\nmost real-world scenarios). Within this heterogeneous FL context, SAFELOC\nintroduces a novel fused neural network architecture that performs data\npoisoning detection and localization, with a low model footprint. Additionally,\na dynamic saliency map-based aggregation strategy is designed to adapt based on\nthe severity of the detected data poisoning scenario. Experimental evaluations\ndemonstrate that SAFELOC achieves improvements of up to 5.9x in mean\nlocalization error, 7.8x in worst-case localization error, and a 2.1x reduction\nin model inference latency compared to state-of-the-art indoor localization\nframeworks, across diverse building floorplans, mobile devices, and ML data\npoisoning attack scenarios.\n","authors":["Akhil Singampalli","Danish Gufran","Sudeep Pasricha"],"pdf_url":"https://arxiv.org/pdf/2411.09055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09052v1","updated":"2024-11-13T22:15:31Z","published":"2024-11-13T22:15:31Z","title":"ClevrSkills: Compositional Language and Visual Reasoning in Robotics","summary":"  Robotics tasks are highly compositional by nature. For example, to perform a\nhigh-level task like cleaning the table a robot must employ low-level\ncapabilities of moving the effectors to the objects on the table, pick them up\nand then move them off the table one-by-one, while re-evaluating the\nconsequently dynamic scenario in the process. Given that large vision language\nmodels (VLMs) have shown progress on many tasks that require high level,\nhuman-like reasoning, we ask the question: if the models are taught the\nrequisite low-level capabilities, can they compose them in novel ways to\nachieve interesting high-level tasks like cleaning the table without having to\nbe explicitly taught so? To this end, we present ClevrSkills - a benchmark\nsuite for compositional reasoning in robotics. ClevrSkills is an environment\nsuite developed on top of the ManiSkill2 simulator and an accompanying dataset.\nThe dataset contains trajectories generated on a range of robotics tasks with\nlanguage and visual annotations as well as multi-modal prompts as task\nspecification. The suite includes a curriculum of tasks with three levels of\ncompositional understanding, starting with simple tasks requiring basic motor\nskills. We benchmark multiple different VLM baselines on ClevrSkills and show\nthat even after being pre-trained on large numbers of tasks, these models fail\non compositional reasoning in robotics tasks.\n","authors":["Sanjay Haresh","Daniel Dijkman","Apratim Bhattacharyya","Roland Memisevic"],"pdf_url":"https://arxiv.org/pdf/2411.09052v1.pdf","comment":"To appear at NeurIPS 2024 (D&B track)"},{"id":"http://arxiv.org/abs/2411.09047v1","updated":"2024-11-13T22:04:19Z","published":"2024-11-13T22:04:19Z","title":"Anomaly Detection in Large-Scale Cloud Systems: An Industry Case and\n  Dataset","summary":"  As Large-Scale Cloud Systems (LCS) become increasingly complex, effective\nanomaly detection is critical for ensuring system reliability and performance.\nHowever, there is a shortage of large-scale, real-world datasets available for\nbenchmarking anomaly detection methods.\n  To address this gap, we introduce a new high-dimensional dataset from IBM\nCloud, collected over 4.5 months from the IBM Cloud Console. This dataset\ncomprises 39,365 rows and 117,448 columns of telemetry data. Additionally, we\ndemonstrate the application of machine learning models for anomaly detection\nand discuss the key challenges faced in this process.\n  This study and the accompanying dataset provide a resource for researchers\nand practitioners in cloud system monitoring. It facilitates more efficient\ntesting of anomaly detection methods in real-world data, helping to advance the\ndevelopment of robust solutions to maintain the health and performance of\nlarge-scale cloud infrastructures.\n","authors":["Mohammad Saiful Islam","Mohamed Sami Rakha","William Pourmajidi","Janakan Sivaloganathan","John Steinbacher","Andriy Miranskyy"],"pdf_url":"https://arxiv.org/pdf/2411.09047v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06635v2","updated":"2024-11-13T21:20:06Z","published":"2024-11-11T00:10:48Z","title":"Mixed Effects Deep Learning for the interpretable analysis of single\n  cell RNA sequencing data by quantifying and visualizing batch effects","summary":"  Single-cell RNA sequencing (scRNA-seq) data are often confounded by technical\nor biological batch effects. Existing deep learning models mitigate these\neffects but often discard batch-specific information, potentially losing\nvaluable biological insights. We propose a Mixed Effects Deep Learning (MEDL)\nautoencoder framework that separately models batch-invariant (fixed effects)\nand batch-specific (random effects) components. By decoupling batch-invariant\nbiological states from batch variations, our framework integrates both into\npredictive models. Our approach also generates 2D visualizations of how the\nsame cell appears across batches, enhancing interpretability. Retaining both\nfixed and random effect latent spaces improves classification accuracy.\n  We applied our framework to three datasets spanning the cardiovascular system\n(Healthy Heart), Autism Spectrum Disorder (ASD), and Acute Myeloid Leukemia\n(AML). With 147 batches in the Healthy Heart dataset, far exceeding typical\nnumbers, we tested our framework's ability to handle many batches. In the ASD\ndataset, our approach captured donor heterogeneity between autistic and healthy\nindividuals. In the AML dataset, it distinguished donor heterogeneity despite\nmissing cell types and diseased donors exhibiting both healthy and malignant\ncells. These results highlight our framework's ability to characterize fixed\nand random effects, enhance batch effect visualization, and improve prediction\naccuracy across diverse datasets.\n","authors":["Aixa X. Andrade","Son Nguyen","Albert Montillo"],"pdf_url":"https://arxiv.org/pdf/2411.06635v2.pdf","comment":"Main manuscript: 29 pages, including 10 figures and 8 tables.\n  Supplemental material: 17 pages"},{"id":"http://arxiv.org/abs/2411.09027v1","updated":"2024-11-13T21:09:55Z","published":"2024-11-13T21:09:55Z","title":"Transformer-based Time-Series Biomarker Discovery for COPD Diagnosis","summary":"  Chronic Obstructive Pulmonary Disorder (COPD) is an irreversible and\nprogressive disease which is highly heritable. Clinically, COPD is defined\nusing the summary measures derived from a spirometry test but these are not\nalways adequate. Here we show that using the high-dimensional raw spirogram can\nprovide a richer signal compared to just using the summary measures. We design\na transformer-based deep learning technique to process the raw spirogram values\nalong with demographic information and predict clinically-relevant endpoints\nrelated to COPD. Our method is able to perform better than prior works while\nbeing more computationally efficient. Using the weights learned by the model,\nwe make the framework more interpretable by identifying parts of the spirogram\nthat are important for the model predictions. Pairing up with a board-certified\npulmonologist, we also provide clinical insights into the different aspects of\nthe spirogram and show that the explanations obtained from the model align with\nunderlying medical knowledge.\n","authors":["Soham Gadgil","Joshua Galanter","Mohammadreza Negahdar"],"pdf_url":"https://arxiv.org/pdf/2411.09027v1.pdf","comment":"Accepted as a workshop paper to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09018v1","updated":"2024-11-13T20:50:04Z","published":"2024-11-13T20:50:04Z","title":"Bridging the Visual Gap: Fine-Tuning Multimodal Models with\n  Knowledge-Adapted Captions","summary":"  Recent research increasingly focuses on training vision-language models\n(VLMs) with long, detailed image captions. However, small-scale VLMs often\nstruggle to balance the richness of these captions with the risk of\nhallucinating content during fine-tuning. In this paper, we explore how well\nVLMs adapt to such captions. To quantify caption quality, we propose Decomposed\nNLI (DNLI), an evaluation framework that breaks down generated captions into\nindividual propositions, assessing each in isolation. This fine-grained\nanalysis reveals a critical balance between capturing descriptive details and\npreventing hallucinations. Our findings show that simply reducing caption\ncomplexity or employing standard data curation techniques does not effectively\nresolve this issue. To tackle this challenge, we introduce Knowledge Adapted\n(KnowAda) fine-tuning, a data-centric approach that automatically adapts\ntraining data with the model's existing knowledge and visual understanding.\nKnowAda minimizes hallucinations while preserving high descriptiveness. We\nvalidate this approach across several small-scale VLMs (up to 7B parameters)\nand dense caption datasets, demonstrating that KnowAda effectively balances\nhallucination reduction and descriptiveness. Our results show that KnowAda\noutperforms various baselines in both automatic metrics and human evaluations.\nWe will release our code and models.\n","authors":["Moran Yanuka","Assaf Ben Kish","Yonatan Bitton","Idan Szpektor","Raja Giryes"],"pdf_url":"https://arxiv.org/pdf/2411.09018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00759v2","updated":"2024-11-13T20:48:26Z","published":"2024-11-01T17:35:09Z","title":"Minibatch Optimal Transport and Perplexity Bound Estimation in Discrete\n  Flow Matching","summary":"  Outperforming autoregressive models on categorical data distributions, such\nas textual data, remains challenging for continuous diffusion and flow models.\nDiscrete flow matching, a recent framework for modeling categorical data, has\nshown competitive performance with autoregressive models. Despite its\nsimilarities with continuous flow matching, the rectification strategy applied\nin the continuous version does not directly extend to the discrete one due to\nthe inherent stochasticity of discrete paths. This limitation necessitates\nexploring alternative methods to minimize state transitions during generation.\nTo address this, we propose a dynamic-optimal-transport-like minimization\nobjective for discrete flows with convex interpolants and derive its equivalent\nKantorovich formulation. The latter defines transport cost solely in terms of\ninter-state similarity and is optimized using a minibatch strategy. Another\nlimitation we address in the discrete flow framework is model evaluation.\nUnlike continuous flows, wherein the instantaneous change of variables enables\ndensity estimation, discrete models lack a similar mechanism due to the\ninherent non-determinism and discontinuity of their paths. To alleviate this\nissue, we propose an upper bound on the perplexity of discrete flow models,\nenabling performance evaluation and comparison with other methods.\n","authors":["Etrit Haxholli","Yeti Z. G√ºrb√ºz","Oƒüul Can","Eli Waxman"],"pdf_url":"https://arxiv.org/pdf/2411.00759v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09009v1","updated":"2024-11-13T20:30:15Z","published":"2024-11-13T20:30:15Z","title":"Cut Your Losses in Large-Vocabulary Language Models","summary":"  As language models grow ever larger, so do their vocabularies. This has\nshifted the memory footprint of LLMs during training disproportionately to one\nsingle layer: the cross-entropy in the loss computation. Cross-entropy builds\nup a logit matrix with entries for each pair of input tokens and vocabulary\nitems and, for small models, consumes an order of magnitude more memory than\nthe rest of the LLM combined. We propose Cut Cross-Entropy (CCE), a method that\ncomputes the cross-entropy loss without materializing the logits for all tokens\ninto global memory. Rather, CCE only computes the logit for the correct token\nand evaluates the log-sum-exp over all logits on the fly. We implement a custom\nkernel that performs the matrix multiplications and the log-sum-exp reduction\nover the vocabulary in flash memory, making global memory consumption for the\ncross-entropy computation negligible. This has a dramatic effect. Taking the\nGemma 2 (2B) model as an example, CCE reduces the memory footprint of the loss\ncomputation from 24 GB to 1 MB, and the total training-time memory consumption\nof the classifier head from 28 GB to 1 GB. To improve the throughput of CCE, we\nleverage the inherent sparsity of softmax and propose to skip elements of the\ngradient computation that have a negligible (i.e., below numerical precision)\ncontribution to the gradient. Experiments demonstrate that the dramatic\nreduction in memory consumption is accomplished without sacrificing training\nspeed or convergence.\n","authors":["Erik Wijmans","Brody Huval","Alexander Hertzberg","Vladlen Koltun","Philipp Kr√§henb√ºhl"],"pdf_url":"https://arxiv.org/pdf/2411.09009v1.pdf","comment":"Code is available at https://github.com/apple/ml-cross-entropy"},{"id":"http://arxiv.org/abs/2401.02501v3","updated":"2024-11-13T20:30:04Z","published":"2024-01-04T19:25:00Z","title":"A metric embedding kernel for live cell microscopy signaling patterns","summary":"  Live cell microscopy captures 5-D $(x,y,z,channel,time)$ movies that display\npatterns of cellular motion and signaling dynamics. We present here a metric\nkernel function for spatiotemporal patterns of cell signaling dynamics in 5-D\nlive cell microscopy movies unique in requiring no a priori knowledge of\nexpected pattern dynamics, and no training data. The approach uses Kolmogorov\ncomplexity theory to compute a metric distance between movies and to measure\nthe meaningful information among subsets of movies. Cell signaling kymographs\nstore at each spatiotemporal cell centroid the cell signaling state, or a\nfunctional output such as velocity. Patterns of similarity are identified via\nthe metric normalized compression distance (NCD). The NCD is a reproducing\nkernel for a Hilbert space that represents the input cell signaling kymographs\nas points in a low dimensional embedding that optimally captures the pattern\nsimilarity identified by the NCD throughout the space. The only parameter is\nthe expected cell radii ($\\mu m$). A new formulation of the cluster structure\nfunction optimally estimates the meaningful information captured by the\nembedding. Also presented is the cell signaling structure function (SSF), a\nKolmogorov structure function that optimally measures cell signaling state as\nnuclear intensity w.r.t. surrounding cytoplasm, a significant improvement\ncompared to the current state-of-the-art cytonuclear ratio. Results are\npresented quantifying the impact of ERK and AKT signaling between different\noncogenic mutations, and by the relation between ERK signaling and cellular\nvelocity patterns for movies of 2-D monolayers of human breast epithelial\n(MCF10A) cells, 3-D MCF10A spheroids under optogenetic manipulation of ERK, and\nhuman induced pluripotent stem cells.\n","authors":["Layton Aho","Mark Winter","Marc DeCarlo","Agne Frismantiene","Yannick Blum","Paolo Armando Gagliardi","Olivier Pertz","Andrew R. Cohen"],"pdf_url":"https://arxiv.org/pdf/2401.02501v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20367v2","updated":"2024-11-13T20:29:35Z","published":"2024-07-29T18:31:42Z","title":"Mixed Newton Method for Optimization in Complex Spaces","summary":"  In this paper, we modify and apply the recently introduced Mixed Newton\nMethod, which is originally designed for minimizing real-valued functions of\ncomplex variables, to the minimization of real-valued functions of real\nvariables by extending the functions to complex space. We show that arbitrary\nregularizations preserve the favorable local convergence properties of the\nmethod, and construct a special type of regularization used to prevent\nconvergence to complex minima. We compare several variants of the method\napplied to training neural networks with real and complex parameters.\n","authors":["Nikita Yudin","Roland Hildebrand","Sergey Bakhurin","Alexander Degtyarev","Anna Lisachenko","Ilya Kuruzov","Andrei Semenov","Mohammad Alkousa"],"pdf_url":"https://arxiv.org/pdf/2407.20367v2.pdf","comment":"16 pages, 7 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.14775v2","updated":"2024-11-13T20:28:24Z","published":"2024-06-20T22:57:38Z","title":"Machine Learning Global Simulation of Nonlocal Gravity Wave Propagation","summary":"  Global climate models typically operate at a grid resolution of hundreds of\nkilometers and fail to resolve atmospheric mesoscale processes, e.g., clouds,\nprecipitation, and gravity waves (GWs). Model representation of these processes\nand their sources is essential to the global circulation and planetary energy\nbudget, but subgrid scale contributions from these processes are often only\napproximately represented in models using parameterizations. These\nparameterizations are subject to approximations and idealizations, which limit\ntheir capability and accuracy. The most drastic of these approximations is the\n\"single-column approximation\" which completely neglects the horizontal\nevolution of these processes, resulting in key biases in current climate\nmodels. With a focus on atmospheric GWs, we present the first-ever global\nsimulation of atmospheric GW fluxes using machine learning (ML) models trained\non the WINDSET dataset to emulate global GW emulation in the atmosphere, as an\nalternative to traditional single-column parameterizations. Using an Attention\nU-Net-based architecture trained on globally resolved GW momentum fluxes, we\nillustrate the importance and effectiveness of global nonlocality, when\nsimulating GWs using data-driven schemes.\n","authors":["Aman Gupta","Aditi Sheshadri","Sujit Roy","Vishal Gaur","Manil Maskey","Rahul Ramachandran"],"pdf_url":"https://arxiv.org/pdf/2406.14775v2.pdf","comment":"International Conference on Machine Learning 2024"},{"id":"http://arxiv.org/abs/2406.03230v4","updated":"2024-11-13T20:18:19Z","published":"2024-06-05T13:06:33Z","title":"Defending Large Language Models Against Attacks With Residual Stream\n  Activation Analysis","summary":"  The widespread adoption of Large Language Models (LLMs), exemplified by\nOpenAI's ChatGPT, brings to the forefront the imperative to defend against\nadversarial threats on these models. These attacks, which manipulate an LLM's\noutput by introducing malicious inputs, undermine the model's integrity and the\ntrust users place in its outputs. In response to this challenge, our paper\npresents an innovative defensive strategy, given white box access to an LLM,\nthat harnesses residual activation analysis between transformer layers of the\nLLM. We apply a novel methodology for analyzing distinctive activation patterns\nin the residual streams for attack prompt classification. We curate multiple\ndatasets to demonstrate how this method of classification has high accuracy\nacross multiple types of attack scenarios, including our newly-created attack\ndataset. Furthermore, we enhance the model's resilience by integrating safety\nfine-tuning techniques for LLMs in order to measure its effect on our\ncapability to detect attacks. The results underscore the effectiveness of our\napproach in enhancing the detection and mitigation of adversarial inputs,\nadvancing the security framework within which LLMs operate.\n","authors":["Amelia Kawasaki","Andrew Davis","Houssam Abbas"],"pdf_url":"https://arxiv.org/pdf/2406.03230v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09003v1","updated":"2024-11-13T20:12:55Z","published":"2024-11-13T20:12:55Z","title":"Refusal in LLMs is an Affine Function","summary":"  We propose affine concept editing (ACE) as an approach for steering language\nmodels' behavior by intervening directly in activations. We begin with an\naffine decomposition of model activation vectors and show that prior methods\nfor steering model behavior correspond to subsets of terms of this\ndecomposition. We then provide a derivation of ACE and test it on refusal using\nLlama 3 8B and Hermes Eagle RWKV v5. ACE ultimately combines affine subspace\nprojection and activation addition to reliably control the model's refusal\nresponses across prompt types. We evaluate the results using LLM-based scoring\non a collection of harmful and harmless prompts. Our experiments demonstrate\nthat ACE consistently achieves more precise control over model behavior and\ngeneralizes to models where directional ablation via affine subspace projection\nalone produces incoherent outputs. Code for reproducing our results is\navailable at https://github.com/EleutherAI/steering-llama3 .\n","authors":["Thomas Marshall","Adam Scherlis","Nora Belrose"],"pdf_url":"https://arxiv.org/pdf/2411.09003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08998v1","updated":"2024-11-13T19:37:49Z","published":"2024-11-13T19:37:49Z","title":"Microfoundation Inference for Strategic Prediction","summary":"  Often in prediction tasks, the predictive model itself can influence the\ndistribution of the target variable, a phenomenon termed performative\nprediction. Generally, this influence stems from strategic actions taken by\nstakeholders with a vested interest in predictive models. A key challenge that\nhinders the widespread adaptation of performative prediction in machine\nlearning is that practitioners are generally unaware of the social impacts of\ntheir predictions. To address this gap, we propose a methodology for learning\nthe distribution map that encapsulates the long-term impacts of predictive\nmodels on the population. Specifically, we model agents' responses as a\ncost-adjusted utility maximization problem and propose estimates for said cost.\nOur approach leverages optimal transport to align pre-model exposure (ex ante)\nand post-model exposure (ex post) distributions. We provide a rate of\nconvergence for this proposed estimate and assess its quality through empirical\ndemonstrations on a credit-scoring dataset.\n","authors":["Daniele Bracale","Subha Maity","Felipe Maia Polo","Seamus Somerstep","Moulinath Banerjee","Yuekai Sun"],"pdf_url":"https://arxiv.org/pdf/2411.08998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23463v2","updated":"2024-11-13T19:34:22Z","published":"2024-10-30T21:08:07Z","title":"MDCure: A Scalable Pipeline for Multi-Document Instruction-Following","summary":"  Multi-document (MD) processing is crucial for LLMs to handle real-world tasks\nsuch as summarization and question-answering across large sets of documents.\nWhile LLMs have improved at processing long inputs, MD contexts still present\nchallenges, such as managing inter-document dependencies, redundancy, and\nincoherent structures. We introduce MDCure, a scalable and effective\nfine-tuning pipeline to enhance the MD capabilities of LLMs without the\ncomputational cost of pre-training or reliance on human annotated data. MDCure\nis based on generation of high-quality synthetic MD instruction data from sets\nof related articles via targeted prompts. We further introduce MDCureRM, a\nmulti-objective reward model which filters generated data based on their\ntraining utility for MD settings. With MDCure, we fine-tune a variety of LLMs,\nfrom the FlanT5, Qwen2, and LLAMA3.1 model families, up to 70B parameters in\nsize. Extensive evaluations on a wide range of MD and long-context benchmarks\nspanning various tasks show MDCure consistently improves performance over\npre-trained baselines and over corresponding base models by up to 75.5%. Our\ncode, datasets, and models are available at https://github.com/yale-nlp/MDCure.\n","authors":["Gabrielle Kaili-May Liu","Bowen Shi","Avi Caciularu","Idan Szpektor","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2410.23463v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08993v1","updated":"2024-11-13T19:33:47Z","published":"2024-11-13T19:33:47Z","title":"Parameter Inference via Differentiable Diffusion Bridge Importance\n  Sampling","summary":"  We introduce a methodology for performing parameter inference in\nhigh-dimensional, non-linear diffusion processes. We illustrate its\napplicability for obtaining insights into the evolution of and relationships\nbetween species, including ancestral state reconstruction. Estimation is\nperformed by utilising score matching to approximate diffusion bridges, which\nare subsequently used in an importance sampler to estimate log-likelihoods. The\nentire setup is differentiable, allowing gradient ascent on approximated\nlog-likelihoods. This allows both parameter inference and diffusion mean\nestimation. This novel, numerically stable, score matching-based parameter\ninference framework is presented and demonstrated on biological two- and\nthree-dimensional morphometry data.\n","authors":["Nicklas Boserup","Gefan Yang","Michael Lind Severinsen","Christy Anna Hipsley","Stefan Sommer"],"pdf_url":"https://arxiv.org/pdf/2411.08993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08987v1","updated":"2024-11-13T19:22:34Z","published":"2024-11-13T19:22:34Z","title":"Non-Euclidean High-Order Smooth Convex Optimization","summary":"  We develop algorithms for the optimization of convex objectives that have\nH\\\"older continuous $q$-th derivatives with respect to a $p$-norm by using a\n$q$-th order oracle, for $p, q \\geq 1$. We can also optimize other structured\nfunctions. We do this by developing a non-Euclidean inexact accelerated\nproximal point method that makes use of an inexact uniformly convex\nregularizer. We also provide nearly matching lower bounds for any deterministic\nalgorithm that interacts with the function via a local oracle.\n","authors":["Juan Pablo Contreras","Crist√≥bal Guzm√°n","David Mart√≠nez-Rubio"],"pdf_url":"https://arxiv.org/pdf/2411.08987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08982v1","updated":"2024-11-13T19:18:08Z","published":"2024-11-13T19:18:08Z","title":"Lynx: Enabling Efficient MoE Inference through Dynamic Batch-Aware\n  Expert Selection","summary":"  Mixture-of-Experts (MoE) architectures have recently gained popularity in\nenabling efficient scaling of large language models. However, we uncover a\nfundamental tension: while MoEs are designed for selective expert activation,\nproduction serving requires request batching, which forces the activation of\nall experts and negates MoE's efficiency benefits during the decode phase. We\npresent Lynx, a system that enables efficient MoE inference through dynamic,\nbatch-aware expert selection. Our key insight is that expert importance varies\nsignificantly across tokens and inference phases, creating opportunities for\nruntime optimization. Lynx leverages this insight through a lightweight\nframework that dynamically reduces active experts while preserving model\naccuracy. Our evaluations show that Lynx achieves up to 1.55x reduction in\ninference latency while maintaining negligible accuracy loss from baseline\nmodel across complex code generation and mathematical reasoning tasks.\n","authors":["Vima Gupta","Kartik Sinha","Ada Gavrilovska","Anand Padmanabha Iyer"],"pdf_url":"https://arxiv.org/pdf/2411.08982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08968v1","updated":"2024-11-13T19:02:36Z","published":"2024-11-13T19:02:36Z","title":"Sparse Upcycling: Inference Inefficient Finetuning","summary":"  Small, highly trained, open-source large language models are widely used due\nto their inference efficiency, but further improving their quality remains a\nchallenge. Sparse upcycling is a promising approach that transforms a\npretrained dense model into a Mixture-of-Experts (MoE) architecture, increasing\nthe model's parameter count and quality. In this work, we compare the\neffectiveness of sparse upcycling against continued pretraining (CPT) across\ndifferent model sizes, compute budgets, and pretraining durations. Our\nexperiments show that sparse upcycling can achieve better quality, with\nimprovements of over 20% relative to CPT in certain scenarios. However, this\ncomes with a significant inference cost, leading to 40% slowdowns in\nhigh-demand inference settings for larger models. Our findings highlight the\ntrade-off between model quality and inference efficiency, offering insights for\npractitioners seeking to balance model quality and deployment constraints.\n","authors":["Sasha Doubov","Nikhil Sardana","Vitaliy Chiley"],"pdf_url":"https://arxiv.org/pdf/2411.08968v1.pdf","comment":"12 pages, 4 figures, To appear in the 4th NeurIPS Workshop on\n  Efficient Natural Language and Speech Processing (ENLSP), 2024"},{"id":"http://arxiv.org/abs/2411.08954v1","updated":"2024-11-13T19:00:02Z","published":"2024-11-13T19:00:02Z","title":"Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply\n  Better Samples","summary":"  Although diffusion models can generate remarkably high-quality samples, they\nare intrinsically bottlenecked by their expensive iterative sampling procedure.\nConsistency models (CMs) have recently emerged as a promising diffusion model\ndistillation method, reducing the cost of sampling by generating high-fidelity\nsamples in just a few iterations. Consistency model distillation aims to solve\nthe probability flow ordinary differential equation (ODE) defined by an\nexisting diffusion model. CMs are not directly trained to minimize error\nagainst an ODE solver, rather they use a more computationally tractable\nobjective. As a way to study how effectively CMs solve the probability flow\nODE, and the effect that any induced error has on the quality of generated\nsamples, we introduce Direct CMs, which \\textit{directly} minimize this error.\nIntriguingly, we find that Direct CMs reduce the ODE solving error compared to\nCMs but also result in significantly worse sample quality, calling into\nquestion why exactly CMs work well in the first place. Full code is available\nat: https://github.com/layer6ai-labs/direct-cms.\n","authors":["No√´l Vouitsis","Rasa Hosseinzadeh","Brendan Leigh Ross","Valentin Villecroze","Satya Krishna Gorti","Jesse C. Cresswell","Gabriel Loaiza-Ganem"],"pdf_url":"https://arxiv.org/pdf/2411.08954v1.pdf","comment":"NeurIPS 2024 ATTRIB Workshop"},{"id":"http://arxiv.org/abs/2411.05196v2","updated":"2024-11-13T18:58:46Z","published":"2024-11-07T21:43:29Z","title":"Explainable AI through a Democratic Lens: DhondtXAI for Proportional\n  Feature Importance Using the D'Hondt Method","summary":"  In democratic societies, electoral systems play a crucial role in translating\npublic preferences into political representation. Among these, the D'Hondt\nmethod is widely used to ensure proportional representation, balancing fair\nrepresentation with governmental stability. Recently, there has been a growing\ninterest in applying similar principles of proportional representation to\nenhance interpretability in machine learning, specifically in Explainable AI\n(XAI). This study investigates the integration of D'Hondt-based voting\nprinciples in the DhondtXAI method, which leverages resource allocation\nconcepts to interpret feature importance within AI models. Through a comparison\nof SHAP (Shapley Additive Explanations) and DhondtXAI, we evaluate their\neffectiveness in feature attribution within CatBoost and XGBoost models for\nbreast cancer and diabetes prediction, respectively. The DhondtXAI approach\nallows for alliance formation and thresholding to enhance interpretability,\nrepresenting feature importance as seats in a parliamentary view. Statistical\ncorrelation analyses between SHAP values and DhondtXAI allocations support the\nconsistency of interpretations, demonstrating DhondtXAI's potential as a\ncomplementary tool for understanding feature importance in AI models. The\nresults highlight that integrating electoral principles, such as proportional\nrepresentation and alliances, into AI explainability can improve user\nunderstanding, especially in high-stakes fields like healthcare.\n","authors":["Turker Berk Donmez"],"pdf_url":"https://arxiv.org/pdf/2411.05196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1902.00615v6","updated":"2024-11-13T18:32:53Z","published":"2019-02-02T01:52:53Z","title":"Confidence Trigger Detection: Accelerating Real-time\n  Tracking-by-detection Systems","summary":"  Real-time object tracking necessitates a delicate balance between speed and\naccuracy, a challenge exacerbated by the computational demands of deep learning\nmethods. In this paper, we propose Confidence-Triggered Detection (CTD), an\ninnovative approach that strategically bypasses object detection for frames\nclosely resembling intermediate states, leveraging tracker confidence scores.\nCTD not only enhances tracking speed but also preserves accuracy, surpassing\nexisting tracking algorithms. Through extensive evaluation across various\ntracker confidence thresholds, we identify an optimal trade-off between\ntracking speed and accuracy, providing crucial insights for parameter\nfine-tuning and enhancing CTD's practicality in real-world scenarios. Our\nexperiments across diverse detection models underscore the robustness and\nversatility of the CTD framework, demonstrating its potential to enable\nreal-time tracking in resource-constrained environments.\n","authors":["Zhicheng Ding","Zhixin Lai","Siyang Li","Panfeng Li","Qikai Yang","Edward Wong"],"pdf_url":"https://arxiv.org/pdf/1902.00615v6.pdf","comment":"Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence"}]},"2024-11-14T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2411.09694v1","updated":"2024-11-14T18:58:23Z","published":"2024-11-14T18:58:23Z","title":"A Bayesian Optimization Approach to Machine Translation Reranking","summary":"  Reranking a list of candidates from a machine translation system with an\nexternal scoring model and returning the highest-scoring candidate remains a\nsimple and effective method for improving the overall output quality.\nTranslation scoring models continue to grow in size, with the best models being\ncomparable to generation models. Thus, reranking can add substantial\ncomputational cost to the translation pipeline. In this work, we pose reranking\nas a Bayesian optimization (BayesOpt) problem. By strategically selecting\ncandidates to score based on a balance of exploration and exploitation, we show\nthat it is possible to find top-scoring candidates when scoring only a fraction\nof the candidate list. For instance, our method achieves the same CometKiwi\nscore using only 70 scoring evaluations compared a baseline system using 180.\nWe present a multi-fidelity setting for BayesOpt, where the candidates are\nfirst scored with a cheaper but noisier proxy scoring model, which further\nimproves the cost-performance tradeoff when using smaller but well-trained\ndistilled proxy scorers.\n","authors":["Julius Cheng","Maike Z√ºfle","Vil√©m Zouhar","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2411.09694v1.pdf","comment":"v1: Preprint version"},{"id":"http://arxiv.org/abs/2411.09689v1","updated":"2024-11-14T18:55:26Z","published":"2024-11-14T18:55:26Z","title":"LLM Hallucination Reasoning with Zero-shot Knowledge Test","summary":"  LLM hallucination, where LLMs occasionally generate unfaithful text, poses\nsignificant challenges for their practical applications. Most existing\ndetection methods rely on external knowledge, LLM fine-tuning, or\nhallucination-labeled datasets, and they do not distinguish between different\ntypes of hallucinations, which are crucial for improving detection performance.\nWe introduce a new task, Hallucination Reasoning, which classifies\nLLM-generated text into one of three categories: aligned, misaligned, and\nfabricated. Our novel zero-shot method assesses whether LLM has enough\nknowledge about a given prompt and text. Our experiments conducted on new\ndatasets demonstrate the effectiveness of our method in hallucination reasoning\nand underscore its importance for enhancing detection performance.\n","authors":["Seongmin Lee","Hsiang Hsu","Chun-Fu Chen"],"pdf_url":"https://arxiv.org/pdf/2411.09689v1.pdf","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.09688v1","updated":"2024-11-14T18:54:19Z","published":"2024-11-14T18:54:19Z","title":"Squeezed Attention: Accelerating Long Context Length LLM Inference","summary":"  Emerging Large Language Model (LLM) applications require long input prompts\nto perform complex downstream tasks like document analysis and code generation.\nFor these long context length applications, the length of the input prompt\nposes a significant challenge in terms of inference efficiency since the\ninference costs increase linearly with sequence length. However, for many of\nthese applications, much of the context in the prompt is fixed across different\nuser inputs, thereby providing the opportunity to perform offline optimizations\nto process user inputs quickly, as they are received. In this work, we propose\nSqueezed Attention as a mechanism to accelerate LLM applications where a large\nportion of the input prompt is fixed. We first leverage K-means clustering\noffline to group the keys for the fixed context based on semantic similarity\nand represent each cluster with a single centroid value. During inference, we\ncompare query tokens from the user input with the centroids to predict which of\nthe keys from the fixed context are semantically relevant and need to be loaded\nduring inference. We then compute exact attention using only these important\nkeys from the fixed context, thereby reducing bandwidth and computational\ncosts. We also extend our method to use a hierarchical centroid lookup to\nidentify important keys, which can reduce the complexity of attention from\nlinear to logarithmic with respect to the context length. We implement\noptimized Triton kernels for centroid comparison and sparse FlashAttention with\nimportant keys, achieving more than 4x speedups during both the prefill and\ngeneration phases for long-context inference. Furthermore, we have extensively\nevaluated our method on various long-context benchmarks including LongBench,\nwhere it achieves a 3x reduction in KV cache budget without accuracy loss and\nup to an 8x reduction with <0.5 point accuracy gap for various models.\n","authors":["Coleman Hooper","Sehoon Kim","Hiva Mohammadzadeh","Monishwaran Maheswaran","June Paik","Michael W. Mahoney","Kurt Keutzer","Amir Gholami"],"pdf_url":"https://arxiv.org/pdf/2411.09688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05777v2","updated":"2024-11-14T18:35:19Z","published":"2024-11-08T18:43:15Z","title":"Quantitative Assessment of Intersectional Empathetic Bias and\n  Understanding","summary":"  A growing amount of literature critiques the current operationalizations of\nempathy based on loose definitions of the construct. Such definitions\nnegatively affect dataset quality, model robustness, and evaluation\nreliability. We propose an empathy evaluation framework that operationalizes\nempathy close to its psychological origins. The framework measures the variance\nin responses of LLMs to prompts using existing metrics for empathy and\nemotional valence. The variance is introduced through the controlled generation\nof the prompts by varying social biases affecting context understanding, thus\nimpacting empathetic understanding. The control over generation ensures high\ntheoretical validity of the constructs in the prompt dataset. Also, it makes\nhigh-quality translation, especially into languages that currently have\nlittle-to-no way of evaluating empathy or bias, such as the Slavonic family,\nmore manageable. Using chosen LLMs and various prompt types, we demonstrate the\nempathy evaluation with the framework, including multiple-choice answers and\nfree generation. The variance in our initial evaluation sample is small and we\nwere unable to measure convincing differences between the empathetic\nunderstanding in contexts given by different social groups. However, the\nresults are promising because the models showed significant alterations their\nreasoning chains needed to capture the relatively subtle changes in the\nprompts. This provides the basis for future research into the construction of\nthe evaluation sample and statistical methods for measuring the results.\n","authors":["Vojtech Formanek","Ondrej Sotolar"],"pdf_url":"https://arxiv.org/pdf/2411.05777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09661v1","updated":"2024-11-14T18:31:39Z","published":"2024-11-14T18:31:39Z","title":"Adaptive Decoding via Latent Preference Optimization","summary":"  During language model decoding, it is known that using higher temperature\nsampling gives more creative responses, while lower temperatures are more\nfactually accurate. However, such models are commonly applied to general\ninstruction following, which involves both creative and fact seeking tasks,\nusing a single fixed temperature across all examples and tokens. In this work,\nwe introduce Adaptive Decoding, a layer added to the model to select the\nsampling temperature dynamically at inference time, at either the token or\nexample level, in order to optimize performance. To learn its parameters we\nintroduce Latent Preference Optimization (LPO) a general approach to train\ndiscrete latent variables such as choices of temperature. Our method\noutperforms all fixed decoding temperatures across a range of tasks that\nrequire different temperatures, including UltraFeedback, Creative Story\nWriting, and GSM8K.\n","authors":["Shehzaad Dhuliawala","Ilia Kulikov","Ping Yu","Asli Celikyilmaz","Jason Weston","Sainbayar Sukhbaatar","Jack Lanchantin"],"pdf_url":"https://arxiv.org/pdf/2411.09661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03862v3","updated":"2024-11-14T18:27:39Z","published":"2024-04-05T02:27:09Z","title":"Verifiable by Design: Aligning Language Models to Quote from\n  Pre-Training Data","summary":"  To trust the fluent generations of large language models (LLMs), humans must\nbe able to verify their correctness against trusted, external sources. Recent\nefforts, such as providing citations via retrieved documents or post-hoc\nprovenance, enhance verifiability but provide no guarantees on their\ncorrectness. To address these limitations, we tackle the verifiability goal\nwith a different philosophy: trivializing the verification process by\ndeveloping models that quote verbatim statements from trusted sources in their\npre-training data. We propose Quote-Tuning, which demonstrates the feasibility\nof aligning models to quote. The core of Quote-Tuning is a fast membership\ninference function that efficiently verifies text against trusted corpora. We\nleverage this tool to design a reward function to quantify quotes in model\nresponses, and curate datasets for preference learning. Experiments show that\nQuote-Tuning significantly increases verbatim quotes from high-quality\ndocuments by up to 130% relative to base models while maintaining response\nquality. Quote-Tuning is applicable in different tasks, generalizes to\nout-of-domain data and diverse model families, and provides additional benefits\nto truthfulness. Our method not only serves as a hassle-free method to increase\nquoting but also opens up avenues for improving LLM trustworthiness through\nbetter verifiability.\n","authors":["Jingyu Zhang","Marc Marone","Tianjian Li","Benjamin Van Durme","Daniel Khashabi"],"pdf_url":"https://arxiv.org/pdf/2404.03862v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04783v2","updated":"2024-11-14T18:14:00Z","published":"2024-03-02T16:52:22Z","title":"AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks","summary":"  Despite extensive pre-training in moral alignment to prevent generating\nharmful information, large language models (LLMs) remain vulnerable to\njailbreak attacks. In this paper, we propose AutoDefense, a multi-agent defense\nframework that filters harmful responses from LLMs. With the response-filtering\nmechanism, our framework is robust against different jailbreak attack prompts,\nand can be used to defend different victim models. AutoDefense assigns\ndifferent roles to LLM agents and employs them to complete the defense task\ncollaboratively. The division in tasks enhances the overall\ninstruction-following of LLMs and enables the integration of other defense\ncomponents as tools. With AutoDefense, small open-source LMs can serve as\nagents and defend larger models against jailbreak attacks. Our experiments show\nthat AutoDefense can effectively defense against different jailbreak attacks,\nwhile maintaining the performance at normal user request. For example, we\nreduce the attack success rate on GPT-3.5 from 55.74% to 7.95% using\nLLaMA-2-13b with a 3-agent system. Our code and data are publicly available at\nhttps://github.com/XHMY/AutoDefense.\n","authors":["Yifan Zeng","Yiran Wu","Xiao Zhang","Huazheng Wang","Qingyun Wu"],"pdf_url":"https://arxiv.org/pdf/2403.04783v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09642v1","updated":"2024-11-14T18:06:55Z","published":"2024-11-14T18:06:55Z","title":"On the Limits of Language Generation: Trade-Offs Between Hallucination\n  and Mode Collapse","summary":"  Specifying all desirable properties of a language model is challenging, but\ncertain requirements seem essential. Given samples from an unknown language,\nthe trained model should produce valid strings not seen in training and be\nexpressive enough to capture the language's full richness. Otherwise,\noutputting invalid strings constitutes \"hallucination,\" and failing to capture\nthe full range leads to \"mode collapse.\" We ask if a language model can meet\nboth requirements.\n  We investigate this within a statistical language generation setting building\non Gold and Angluin. Here, the model receives random samples from a\ndistribution over an unknown language K, which belongs to a possibly infinite\ncollection of languages. The goal is to generate unseen strings from K. We say\nthe model generates from K with consistency and breadth if, as training size\nincreases, its output converges to all unseen strings in K.\n  Kleinberg and Mullainathan [KM24] asked if consistency and breadth in\nlanguage generation are possible. We answer this negatively: for a large class\nof language models, including next-token prediction models, this is impossible\nfor most collections of candidate languages. This contrasts with [KM24]'s\nresult, showing consistent generation without breadth is possible for any\ncountable collection of languages. Our finding highlights that generation with\nbreadth fundamentally differs from generation without breadth.\n  As a byproduct, we establish near-tight bounds on the number of samples\nneeded for generation with or without breadth.\n  Finally, our results offer hope: consistent generation with breadth is\nachievable for any countable collection of languages when negative examples\n(strings outside K) are available alongside positive ones. This suggests that\npost-training feedback, which encodes negative examples, can be crucial in\nreducing hallucinations while limiting mode collapse.\n","authors":["Alkis Kalavasis","Anay Mehrotra","Grigoris Velegkas"],"pdf_url":"https://arxiv.org/pdf/2411.09642v1.pdf","comment":"Abstract shortened to fit arXiv limit"},{"id":"http://arxiv.org/abs/2407.04573v2","updated":"2024-11-14T18:01:10Z","published":"2024-07-05T15:08:44Z","title":"VRSD: Rethinking Similarity and Diversity for Retrieval in Large\n  Language Models","summary":"  Vector retrieval algorithms are essential for semantic queries within the\nrapidly evolving landscape of Large Language Models (LLMs). The ability to\nretrieve vectors that satisfy both similarity and diversity criteria\nsubstantially enhances the performance of LLMs. Although Maximal Marginal\nRelevance (MMR) is widely employed in retrieval scenarios requiring relevance\nand diversity, variations in the parameter $\\lambda$ lead to fluctuations that\ncomplicate the optimization trajectory in vector spaces. This obscures the\ndirection of improvement and highlights the lack of a robust theoretical\nanalysis regarding similarity and diversity constraints in retrieval processes.\nTo address these challenges, this paper introduces a novel approach that\ncharacterizes both constraints through the relationship between the sum vector\nand the query vector. The proximity of these vectors ensures the similarity\nconstraint, while requiring individual vectors within the sum vector to diverge\nin their alignment with the query vector satisfies the diversity constraint. We\nfirst formulate a new combinatorial optimization problem, selecting k vectors\nfrom a candidate set such that their sum vector maximally aligns with the query\nvector, and demonstrate that this problem is NP-complete. This result\nunderscores the inherent difficulty of simultaneously achieving similarity and\ndiversity in vector retrieval, thereby providing a theoretical foundation for\nfuture research. Subsequently, we present the heuristic algorithm Vectors\nRetrieval with Similarity and Diversity, VRSD, which features a clear\noptimization objective and eliminates the need for preset parameters. VRSD also\nachieves a modest reduction in time complexity compared to MMR. Empirical\nvalidation confirms that VRSD significantly outperforms MMR across various\ndatasets.\n","authors":["Hang Gao","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.04573v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17897v2","updated":"2024-11-14T17:46:04Z","published":"2024-10-23T14:15:07Z","title":"Value Residual Learning For Alleviating Attention Concentration In\n  Transformers","summary":"  Transformers can capture long-range dependencies using self-attention,\nallowing tokens to attend to all others directly. However, stacking multiple\nattention layers leads to attention concentration. One natural way to address\nthis issue is to use cross-layer attention, allowing information from earlier\nlayers to be directly accessible to later layers. However, this approach is\ncomputationally expensive. To address this problem, we propose Transformer with\nresidual value (ResFormer) which approximates cross-layer attention through\nadding a residual connection from the values of the the first layer to all\nsubsequent layers. Based on this method, one variant is the Transformer with\nsingle layer value (SVFormer), where all layers share the same value embedding\nfrom first layer, reducing the $KV$ cache by nearly 50\\%. Comprehensive\nempirical evidence demonstrates that ResFormer mitigates attention\nconcentration problem in deeper layers and enhances representation across most\nlayers, outperforming the vanilla Transformer, DenseFormer, and NeuTRENO in\ntraining error as well as downstream tasks. Further visualization results\nsuggest that Resformer alleviates attention sinks through avoiding value-state\ndrains. SVFormer trains significantly faster than the vanilla Transformer and\nperforms better than other methods like GQA and CLA, with performance\ninfluenced by sequence length and cumulative learning rate.\n","authors":["Zhanchao Zhou","Tianyi Wu","Zhiyun Jiang","Zhenzhong Lan"],"pdf_url":"https://arxiv.org/pdf/2410.17897v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09613v1","updated":"2024-11-14T17:33:36Z","published":"2024-11-14T17:33:36Z","title":"PTR: Precision-Driven Tool Recommendation for Large Language Models","summary":"  By augmenting Large Language Models (LLMs) with external tools, their\ncapacity to solve complex problems has been significantly enhanced. However,\ndespite ongoing advancements in the parsing capabilities of LLMs, incorporating\nall available tools simultaneously in the prompt remains impractical due to the\nvast number of external tools. Consequently, it is essential to provide LLMs\nwith a precise set of tools tailored to the specific task, considering both\nquantity and quality. Current tool retrieval methods primarily focus on\nrefining the ranking list of tools and directly packaging a fixed number of\ntop-ranked tools as the tool set. However, these approaches often fail to equip\nLLMs with the optimal set of tools prior to execution, since the optimal number\nof tools for different tasks could be different, resulting in inefficiencies\nsuch as redundant or unsuitable tools, which impede immediate access to the\nmost relevant tools. This paper addresses the challenge of recommending precise\ntoolsets for LLMs. We introduce the problem of tool recommendation, define its\nscope, and propose a novel Precision-driven Tool Recommendation (PTR) approach.\nPTR captures an initial, concise set of tools by leveraging historical tool\nbundle usage and dynamically adjusts the tool set by performing tool matching,\nculminating in a multi-view-based tool addition. Additionally, we present a new\ndataset, RecTools, and a metric, TRACC, designed to evaluate the effectiveness\nof tool recommendation for LLMs. We further validate our design choices through\ncomprehensive experiments, demonstrating promising accuracy across two open\nbenchmarks and our RecTools dataset.\n","authors":["Hang Gao","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.09613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09612v1","updated":"2024-11-14T17:32:03Z","published":"2024-11-14T17:32:03Z","title":"The Moral Foundations Weibo Corpus","summary":"  Moral sentiments expressed in natural language significantly influence both\nonline and offline environments, shaping behavioral styles and interaction\npatterns, including social media selfpresentation, cyberbullying, adherence to\nsocial norms, and ethical decision-making. To effectively measure moral\nsentiments in natural language processing texts, it is crucial to utilize\nlarge, annotated datasets that provide nuanced understanding for accurate\nanalysis and modeltraining. However, existing corpora, while valuable, often\nface linguistic limitations. To address this gap in the Chinese language\ndomain,we introduce the Moral Foundation Weibo Corpus. This corpus consists of\n25,671 Chinese comments on Weibo, encompassing six diverse topic areas. Each\ncomment is manually annotated by at least three systematically trained\nannotators based on ten moral categories derived from a grounded theory of\nmorality. To assess annotator reliability, we present the kappa testresults, a\ngold standard for measuring consistency. Additionally, we apply several the\nlatest large language models to supplement the manual annotations, conducting\nanalytical experiments to compare their performance and report baseline results\nfor moral sentiment classification.\n","authors":["Renjie Cao","Miaoyan Hu","Jiahan Wei","Baha Ihnaini"],"pdf_url":"https://arxiv.org/pdf/2411.09612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09607v1","updated":"2024-11-14T17:25:43Z","published":"2024-11-14T17:25:43Z","title":"Initial Nugget Evaluation Results for the TREC 2024 RAG Track with the\n  AutoNuggetizer Framework","summary":"  This report provides an initial look at partial results from the TREC 2024\nRetrieval-Augmented Generation (RAG) Track. We have identified RAG evaluation\nas a barrier to continued progress in information access (and more broadly,\nnatural language processing and artificial intelligence), and it is our hope\nthat we can contribute to tackling the many challenges in this space. The\ncentral hypothesis we explore in this work is that the nugget evaluation\nmethodology, originally developed for the TREC Question Answering Track in\n2003, provides a solid foundation for evaluating RAG systems. As such, our\nefforts have focused on \"refactoring\" this methodology, specifically applying\nlarge language models to both automatically create nuggets and to automatically\nassign nuggets to system answers. We call this the AutoNuggetizer framework.\nWithin the TREC setup, we are able to calibrate our fully automatic process\nagainst a manual process whereby nuggets are created by human assessors\nsemi-manually and then assigned manually to system answers. Based on initial\nresults across 21 topics from 45 runs, we observe a strong correlation between\nscores derived from a fully automatic nugget evaluation and a (mostly) manual\nnugget evaluation by human assessors. This suggests that our fully automatic\nevaluation process can be used to guide future iterations of RAG systems.\n","authors":["Ronak Pradeep","Nandan Thakur","Shivani Upadhyay","Daniel Campos","Nick Craswell","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.09607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09595v1","updated":"2024-11-14T17:08:23Z","published":"2024-11-14T17:08:23Z","title":"LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models","summary":"  This work explores expanding the capabilities of large language models (LLMs)\npretrained on text to generate 3D meshes within a unified model. This offers\nkey advantages of (1) leveraging spatial knowledge already embedded in LLMs,\nderived from textual sources like 3D tutorials, and (2) enabling conversational\n3D generation and mesh understanding. A primary challenge is effectively\ntokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly.\nTo address this, we introduce LLaMA-Mesh, a novel approach that represents the\nvertex coordinates and face definitions of 3D meshes as plain text, allowing\ndirect integration with LLMs without expanding the vocabulary. We construct a\nsupervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate\n3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs\nas required, and (3) understand and interpret 3D meshes. Our work is the first\nto demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge\nfor 3D mesh generation in a text-based format, effectively unifying the 3D and\ntext modalities. LLaMA-Mesh achieves mesh generation quality on par with models\ntrained from scratch while maintaining strong text generation performance.\n","authors":["Zhengyi Wang","Jonathan Lorraine","Yikai Wang","Hang Su","Jun Zhu","Sanja Fidler","Xiaohui Zeng"],"pdf_url":"https://arxiv.org/pdf/2411.09595v1.pdf","comment":"See the project website at\n  https://research.nvidia.com/labs/toronto-ai/LLaMA-Mesh/"},{"id":"http://arxiv.org/abs/2411.09587v1","updated":"2024-11-14T16:57:46Z","published":"2024-11-14T16:57:46Z","title":"BabyLM Challenge: Exploring the Effect of Variation Sets on Language\n  Model Training Efficiency","summary":"  While current large language models have achieved a remarkable success, their\ndata efficiency remains a challenge to overcome. Recently it has been suggested\nthat child-directed speech (CDS) can improve training data efficiency of modern\nlanguage models based on Transformer neural networks. However, it is not yet\nunderstood which specific properties of CDS are effective for training these\nmodels. In the context of the BabyLM Challenge, we focus on Variation Sets\n(VSs), sets of consecutive utterances expressing a similar intent with slightly\ndifferent words and structures, which are ubiquitous in CDS. To assess the\nimpact of VSs on training data efficiency, we augment CDS data with different\nproportions of artificial VSs and use these datasets to train an\nauto-regressive model, GPT-2. We find that the best proportion of VSs depends\non the evaluation benchmark: BLiMP and GLUE scores benefit from the presence of\nVSs, but EWOK scores do not. Additionally, the results vary depending on\nmultiple factors such as the number of epochs and the order of utterance\npresentation. Taken together, these findings suggest that VSs can have a\nbeneficial influence on language models, while leaving room for further\ninvestigation.\n","authors":["Akari Haga","Akiyo Fukatsu","Miyu Oba","Arianna Bisazza","Yohei Oseki"],"pdf_url":"https://arxiv.org/pdf/2411.09587v1.pdf","comment":"This paper accepted BabyLM challenge 2024 at CONLL 2024"},{"id":"http://arxiv.org/abs/2411.09547v1","updated":"2024-11-14T16:01:33Z","published":"2024-11-14T16:01:33Z","title":"Piecing It All Together: Verifying Multi-Hop Multimodal Claims","summary":"  Existing claim verification datasets often do not require systems to perform\ncomplex reasoning or effectively interpret multimodal evidence. To address\nthis, we introduce a new task: multi-hop multimodal claim verification. This\ntask challenges models to reason over multiple pieces of evidence from diverse\nsources, including text, images, and tables, and determine whether the combined\nmultimodal evidence supports or refutes a given claim. To study this task, we\nconstruct MMCV, a large-scale dataset comprising 16k multi-hop claims paired\nwith multimodal evidence, generated and refined using large language models,\nwith additional input from human feedback. We show that MMCV is challenging\neven for the latest state-of-the-art multimodal large language models,\nespecially as the number of reasoning hops increases. Additionally, we\nestablish a human performance benchmark on a subset of MMCV. We hope this\ndataset and its evaluation task will encourage future research in multimodal\nmulti-hop claim verification.\n","authors":["Haoran Wang","Aman Rangapur","Xiongxiao Xu","Yueqing Liang","Haroon Gharwi","Carl Yang","Kai Shu"],"pdf_url":"https://arxiv.org/pdf/2411.09547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09539v1","updated":"2024-11-14T15:55:37Z","published":"2024-11-14T15:55:37Z","title":"A Practical Guide to Fine-tuning Language Models with Limited Data","summary":"  Employing pre-trained Large Language Models (LLMs) has become the de facto\nstandard in Natural Language Processing (NLP) despite their extensive data\nrequirements. Motivated by the recent surge in research focused on training\nLLMs with limited data, particularly in low-resource domains and languages,\nthis paper surveys recent transfer learning approaches to optimize model\nperformance in downstream tasks where data is scarce. We first address initial\nand continued pre-training strategies to better leverage prior knowledge in\nunseen domains and languages. We then examine how to maximize the utility of\nlimited data during fine-tuning and few-shot learning. The final section takes\na task-specific perspective, reviewing models and methods suited for different\nlevels of data scarcity. Our goal is to provide practitioners with practical\nguidelines for overcoming the challenges posed by constrained data while also\nhighlighting promising directions for future research.\n","authors":["M√°rton Sz√©p","Daniel Rueckert","R√ºdiger von Eisenhart-Rothe","Florian Hinterwimmer"],"pdf_url":"https://arxiv.org/pdf/2411.09539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08278v2","updated":"2024-11-14T15:49:46Z","published":"2024-11-13T01:33:05Z","title":"Knowledge Bases in Support of Large Language Models for Processing Web\n  News","summary":"  Large Language Models (LLMs) have received considerable interest in wide\napplications lately. During pre-training via massive datasets, such a model\nimplicitly memorizes the factual knowledge of trained datasets in its hidden\nparameters. However, knowledge held implicitly in parameters often makes its\nuse by downstream applications ineffective due to the lack of common-sense\nreasoning. In this article, we introduce a general framework that permits to\nbuild knowledge bases with an aid of LLMs, tailored for processing Web news.\nThe framework applies a rule-based News Information Extractor (NewsIE) to news\nitems for extracting their relational tuples, referred to as knowledge bases,\nwhich are then graph-convoluted with the implicit knowledge facts of news items\nobtained by LLMs, for their classification. It involves two lightweight\ncomponents: 1) NewsIE: for extracting the structural information of every news\nitem, in the form of relational tuples; 2) BERTGraph: for graph convoluting the\nimplicit knowledge facts with relational tuples extracted by NewsIE. We have\nevaluated our framework under different news-related datasets for news category\nclassification, with promising experimental results.\n","authors":["Yihe Zhang","Nabin Pakka","Nian-Feng Tzeng"],"pdf_url":"https://arxiv.org/pdf/2411.08278v2.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.09510v1","updated":"2024-11-14T15:19:01Z","published":"2024-11-14T15:19:01Z","title":"Communication Compression for Tensor Parallel LLM Inference","summary":"  Large Language Models (LLMs) have pushed the frontier of artificial\nintelligence but are comprised of hundreds of billions of parameters and\noperations. For faster inference latency, LLMs are deployed on multiple\nhardware accelerators through various Model Parallelism strategies. Our paper\nlooks into the details on one such strategy - Tensor Parallel - and proposes to\nreduce latency by compressing inter-accelerator communication. We leverage fine\ngrained quantization techniques to compress selected activations by 3.5 - 4.5x.\nOur proposed method leads up to 2x reduction of time-to-first-token (TTFT) with\nnegligible model performance degradation.\n","authors":["Jan Hansen-Palmus","Michael Truong-Le","Oliver Hausd√∂rfer","Alok Verma"],"pdf_url":"https://arxiv.org/pdf/2411.09510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09497v1","updated":"2024-11-14T15:04:17Z","published":"2024-11-14T15:04:17Z","title":"The Use of Readability Metrics in Legal Text: A Systematic Literature\n  Review","summary":"  Understanding the text in legal documents can be challenging due to their\ncomplex structure and the inclusion of domain-specific jargon. Laws and\nregulations are often crafted in such a manner that engagement with them\nrequires formal training, potentially leading to vastly different\ninterpretations of the same texts. Linguistic complexity is an important\ncontributor to the difficulties experienced by readers. Simplifying texts could\nenhance comprehension across a broader audience, not just among trained\nprofessionals. Various metrics have been developed to measure document\nreadability. Therefore, we adopted a systematic review approach to examine the\nlinguistic and readability metrics currently employed for legal and regulatory\ntexts. A total of 3566 initial papers were screened, with 34 relevant studies\nfound and further assessed. Our primary objective was to identify which current\nmetrics were applied for evaluating readability within the legal field. Sixteen\ndifferent metrics were identified, with the Flesch-Kincaid Grade Level being\nthe most frequently used method. The majority of studies (73.5%) were found in\nthe domain of \"informed consent forms\". From the analysis, it is clear that not\nall legal domains are well represented in terms of readability metrics and that\nthere is a further need to develop more consensus on which metrics should be\napplied for legal documents.\n","authors":["Yu Han","Aaron Ceross","Jeroen H. M. Bergmann"],"pdf_url":"https://arxiv.org/pdf/2411.09497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09492v1","updated":"2024-11-14T14:58:38Z","published":"2024-11-14T14:58:38Z","title":"MM-Eval: A Hierarchical Benchmark for Modern Mongolian Evaluation in\n  LLMs","summary":"  Large language models (LLMs) excel in high-resource languages but face\nnotable challenges in low-resource languages like Mongolian. This paper\naddresses these challenges by categorizing capabilities into language abilities\n(syntax and semantics) and cognitive abilities (knowledge and reasoning). To\nsystematically evaluate these areas, we developed MM-Eval, a specialized\ndataset based on Modern Mongolian Language Textbook I and enriched with WebQSP\nand MGSM datasets.\n  Preliminary experiments on models including Qwen2-7B-Instruct, GLM4-9b-chat,\nLlama3.1-8B-Instruct, GPT-4, and DeepseekV2.5 revealed that: 1) all models\nperformed better on syntactic tasks than semantic tasks, highlighting a gap in\ndeeper language understanding; and 2) knowledge tasks showed a moderate\ndecline, suggesting that models can transfer general knowledge from\nhigh-resource to low-resource contexts.\n  The release of MM-Eval, comprising 569 syntax, 677 semantics, 344 knowledge,\nand 250 reasoning tasks, offers valuable insights for advancing NLP and LLMs in\nlow-resource languages like Mongolian. The dataset is available at\nhttps://github.com/joenahm/MM-Eval.\n","authors":["Mengyuan Zhang","Ruihui Wang","Bo Xia","Yuan Sun","Xiaobing Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.09492v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03979v3","updated":"2024-11-14T14:34:13Z","published":"2024-10-04T23:37:21Z","title":"Improving Arabic Multi-Label Emotion Classification using Stacked\n  Embeddings and Hybrid Loss Function","summary":"  In multi-label emotion classification, particularly for low-resource\nlanguages like Arabic, the challenges of class imbalance and label correlation\nhinder model performance, especially in accurately predicting minority\nemotions. To address these issues, this study proposes a novel approach that\ncombines stacked embeddings, meta-learning, and a hybrid loss function to\nenhance multi-label emotion classification for the Arabic language. The study\nextracts contextual embeddings from three fine-tuned language\nmodels-ArabicBERT, MarBERT, and AraBERT-which are then stacked to form enriched\nembeddings. A meta-learner is trained on these stacked embeddings, and the\nresulting concatenated representations are provided as input to a Bi-LSTM\nmodel, followed by a fully connected neural network for multi-label\nclassification. To further improve performance, a hybrid loss function is\nintroduced, incorporating class weighting, label correlation matrix, and\ncontrastive learning, effectively addressing class imbalances and improving the\nhandling of label correlations. Extensive experiments validate the proposed\nmodel's performance across key metrics such as Precision, Recall, F1-Score,\nJaccard Accuracy, and Hamming Loss. The class-wise performance analysis\ndemonstrates the hybrid loss function's ability to significantly reduce\ndisparities between majority and minority classes, resulting in a more balanced\nemotion classification. An ablation study highlights the contribution of each\ncomponent, showing the superiority of the model compared to baseline approaches\nand other loss functions. This study not only advances multi-label emotion\nclassification for Arabic but also presents a generalizable framework that can\nbe adapted to other languages and domains, providing a significant step forward\nin addressing the challenges of low-resource emotion classification tasks.\n","authors":["Muhammad Azeem Aslam","Wang Jun","Nisar Ahmed","Muhammad Imran Zaman","Li Yanan","Hu Hongfei","Wang Shiyu","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2410.03979v3.pdf","comment":"The paper is submitted in Scientific Reports and is currently under\n  review"},{"id":"http://arxiv.org/abs/2402.06900v5","updated":"2024-11-14T14:28:58Z","published":"2024-02-10T07:55:27Z","title":"Can LLMs Recognize Toxicity? A Structured Investigation Framework and\n  Toxicity Metric","summary":"  In the pursuit of developing Large Language Models (LLMs) that adhere to\nsocietal standards, it is imperative to detect the toxicity in the generated\ntext. The majority of existing toxicity metrics rely on encoder models trained\non specific toxicity datasets, which are susceptible to out-of-distribution\n(OOD) problems and depend on the dataset's definition of toxicity. In this\npaper, we introduce a robust metric grounded on LLMs to flexibly measure\ntoxicity according to the given definition. We first analyze the toxicity\nfactors, followed by an examination of the intrinsic toxic attributes of LLMs\nto ascertain their suitability as evaluators. Finally, we evaluate the\nperformance of our metric with detailed analysis. Our empirical results\ndemonstrate outstanding performance in measuring toxicity within verified\nfactors, improving on conventional metrics by 12 points in the F1 score. Our\nfindings also indicate that upstream toxicity significantly influences\ndownstream metrics, suggesting that LLMs are unsuitable for toxicity\nevaluations within unverified factors.\n","authors":["Hyukhun Koh","Dohyung Kim","Minwoo Lee","Kyomin Jung"],"pdf_url":"https://arxiv.org/pdf/2402.06900v5.pdf","comment":"8 page long"},{"id":"http://arxiv.org/abs/2409.15933v2","updated":"2024-11-14T13:59:15Z","published":"2024-09-24T09:57:25Z","title":"SLIMER-IT: Zero-Shot NER on Italian Language","summary":"  Traditional approaches to Named Entity Recognition (NER) frame the task into\na BIO sequence labeling problem. Although these systems often excel in the\ndownstream task at hand, they require extensive annotated data and struggle to\ngeneralize to out-of-distribution input domains and unseen entity types. On the\ncontrary, Large Language Models (LLMs) have demonstrated strong zero-shot\ncapabilities. While several works address Zero-Shot NER in English, little has\nbeen done in other languages. In this paper, we define an evaluation framework\nfor Zero-Shot NER, applying it to the Italian language. Furthermore, we\nintroduce SLIMER-IT, the Italian version of SLIMER, an instruction-tuning\napproach for zero-shot NER leveraging prompts enriched with definition and\nguidelines. Comparisons with other state-of-the-art models, demonstrate the\nsuperiority of SLIMER-IT on never-seen-before entity tags.\n","authors":["Andrew Zamai","Leonardo Rigutini","Marco Maggini","Andrea Zugarini"],"pdf_url":"https://arxiv.org/pdf/2409.15933v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09436v1","updated":"2024-11-14T13:34:16Z","published":"2024-11-14T13:34:16Z","title":"Robot Tasks with Fuzzy Time Requirements from Natural Language\n  Instructions","summary":"  Natural language allows robot programming to be accessible to everyone.\nHowever, the inherent fuzziness in natural language poses challenges for\ninflexible, traditional robot systems. We focus on instructions with fuzzy time\nrequirements (e.g., \"start in a few minutes\"). Building on previous robotics\nresearch, we introduce fuzzy skills. These define an execution by the robot\nwith so-called satisfaction functions representing vague execution time\nrequirements. Such functions express a user's satisfaction over potential\nstarting times for skill execution. When the robot handles multiple fuzzy\nskills, the satisfaction function provides a temporal tolerance window for\nexecution, thus, enabling optimal scheduling based on satisfaction. We\ngeneralized such functions based on individual user expectations with a user\nstudy. The participants rated their satisfaction with an instruction's\nexecution at various times. Our investigations reveal that trapezoidal\nfunctions best approximate the users' satisfaction. Additionally, the results\nsuggest that users are more lenient if the execution is specified further into\nthe future.\n","authors":["Sascha Sucker","Michael Neubauer","Dominik Henrich"],"pdf_url":"https://arxiv.org/pdf/2411.09436v1.pdf","comment":"9 pages, 8 figures, to be published in 2024 IEEE International\n  Conference on Robotic Computing (IRC)"},{"id":"http://arxiv.org/abs/2411.09431v1","updated":"2024-11-14T13:29:09Z","published":"2024-11-14T13:29:09Z","title":"Everyone deserves their voice to be heard: Analyzing Predictive Gender\n  Bias in ASR Models Applied to Dutch Speech Data","summary":"  Recent research has shown that state-of-the-art (SotA) Automatic Speech\nRecognition (ASR) systems, such as Whisper, often exhibit predictive biases\nthat disproportionately affect various demographic groups. This study focuses\non identifying the performance disparities of Whisper models on Dutch speech\ndata from the Common Voice dataset and the Dutch National Public Broadcasting\norganisation. We analyzed the word error rate, character error rate and a\nBERT-based semantic similarity across gender groups. We used the moral\nframework of Weerts et al. (2022) to assess quality of service harms and\nfairness, and to provide a nuanced discussion on the implications of these\nbiases, particularly for automatic subtitling. Our findings reveal substantial\ndisparities in word error rate (WER) among gender groups across all model\nsizes, with bias identified through statistical testing.\n","authors":["Rik Raes","Saskia Lensink","Mykola Pechenizkiy"],"pdf_url":"https://arxiv.org/pdf/2411.09431v1.pdf","comment":"Accepted at ECML PKDD 2024, 4th Workshop on Bias and Fairness in AI\n  (BIAS)"},{"id":"http://arxiv.org/abs/2411.09389v1","updated":"2024-11-14T12:05:35Z","published":"2024-11-14T12:05:35Z","title":"Less is More: Unseen Domain Fake News Detection via Causal Propagation\n  Substructures","summary":"  The spread of fake news on social media poses significant threats to\nindividuals and society. Text-based and graph-based models have been employed\nfor fake news detection by analysing news content and propagation networks,\nshowing promising results in specific scenarios. However, these data-driven\nmodels heavily rely on pre-existing in-distribution data for training, limiting\ntheir performance when confronted with fake news from emerging or previously\nunseen domains, known as out-of-distribution (OOD) data. Tackling OOD fake news\nis a challenging yet critical task. In this paper, we introduce the Causal\nSubgraph-oriented Domain Adaptive Fake News Detection (CSDA) model, designed to\nenhance zero-shot fake news detection by extracting causal substructures from\npropagation graphs using in-distribution data and generalising this approach to\nOOD data. The model employs a graph neural network based mask generation\nprocess to identify dominant nodes and edges within the propagation graph,\nusing these substructures for fake news detection. Additionally, the\nperformance of CSDA is further improved through contrastive learning in\nfew-shot scenarios, where a limited amount of OOD data is available for\ntraining. Extensive experiments on public social media datasets demonstrate\nthat CSDA effectively handles OOD fake news detection, achieving a 7 to 16\npercents accuracy improvement over other state-of-the-art models.\n","authors":["Shuzhi Gong","Richard O. Sinnott","Jianzhong Qi","Cecile Paris"],"pdf_url":"https://arxiv.org/pdf/2411.09389v1.pdf","comment":"9 pages, 2 figures, 5 tables"},{"id":"http://arxiv.org/abs/2406.18406v2","updated":"2024-11-14T10:55:14Z","published":"2024-06-26T14:57:38Z","title":"IRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying\n  and Reweighting Context-Aware Neurons","summary":"  It is widely acknowledged that large language models (LLMs) encode a vast\nreservoir of knowledge after being trained on mass data. Recent studies\ndisclose knowledge conflicts in LLM generation, wherein outdated or incorrect\nparametric knowledge (i.e., encoded knowledge) contradicts new knowledge\nprovided in the context. To mitigate such knowledge conflicts, we propose a\nnovel framework, IRCAN (Identifying and Reweighting Context-Aware Neurons) to\ncapitalize on neurons that are crucial in processing contextual cues.\nSpecifically, IRCAN first identifies neurons that significantly contribute to\ncontext processing, utilizing a context-aware attribution score derived from\nintegrated gradients. Subsequently, the identified context-aware neurons are\nstrengthened via reweighting. In doing so, we steer LLMs to generate\ncontext-sensitive outputs with respect to the new knowledge provided in the\ncontext. Extensive experiments conducted across a variety of models and tasks\ndemonstrate that IRCAN not only achieves remarkable improvements in handling\nknowledge conflicts but also offers a scalable, plug-and-play solution that can\nbe integrated seamlessly with existing models. Our codes are released at\nhttps://github.com/danshi777/IRCAN.\n","authors":["Dan Shi","Renren Jin","Tianhao Shen","Weilong Dong","Xinwei Wu","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2406.18406v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09339v1","updated":"2024-11-14T10:36:19Z","published":"2024-11-14T10:36:19Z","title":"Re-Parameterization of Lightweight Transformer for On-Device Speech\n  Emotion Recognition","summary":"  With the increasing implementation of machine learning models on edge or\nInternet-of-Things (IoT) devices, deploying advanced models on\nresource-constrained IoT devices remains challenging. Transformer models, a\ncurrently dominant neural architecture, have achieved great success in broad\ndomains but their complexity hinders its deployment on IoT devices with limited\ncomputation capability and storage size. Although many model compression\napproaches have been explored, they often suffer from notorious performance\ndegradation. To address this issue, we introduce a new method, namely\nTransformer Re-parameterization, to boost the performance of lightweight\nTransformer models. It consists of two processes: the High-Rank Factorization\n(HRF) process in the training stage and the deHigh-Rank Factorization (deHRF)\nprocess in the inference stage. In the former process, we insert an additional\nlinear layer before the Feed-Forward Network (FFN) of the lightweight\nTransformer. It is supposed that the inserted HRF layers can enhance the model\nlearning capability. In the later process, the auxiliary HRF layer will be\nmerged together with the following FFN layer into one linear layer and thus\nrecover the original structure of the lightweight model. To examine the\neffectiveness of the proposed method, we evaluate it on three widely used\nTransformer variants, i.e., ConvTransformer, Conformer, and SpeechFormer\nnetworks, in the application of speech emotion recognition on the IEMOCAP, M3ED\nand DAIC-WOZ datasets. Experimental results show that our proposed method\nconsistently improves the performance of lightweight Transformers, even making\nthem comparable to large models. The proposed re-parameterization approach\nenables advanced Transformer models to be deployed on resource-constrained IoT\ndevices.\n","authors":["Zixing Zhang","Zhongren Dong","Weixiang Xu","Jing Han"],"pdf_url":"https://arxiv.org/pdf/2411.09339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09318v1","updated":"2024-11-14T10:00:33Z","published":"2024-11-14T10:00:33Z","title":"DriveThru: a Document Extraction Platform and Benchmark Datasets for\n  Indonesian Local Language Archives","summary":"  Indonesia is one of the most diverse countries linguistically. However,\ndespite this linguistic diversity, Indonesian languages remain underrepresented\nin Natural Language Processing (NLP) research and technologies. In the past two\nyears, several efforts have been conducted to construct NLP resources for\nIndonesian languages. However, most of these efforts have been focused on\ncreating manual resources thus difficult to scale to more languages. Although\nmany Indonesian languages do not have a web presence, locally there are\nresources that document these languages well in printed forms such as books,\nmagazines, and newspapers. Digitizing these existing resources will enable\nscaling of Indonesian language resource construction to many more languages. In\nthis paper, we propose an alternative method of creating datasets by digitizing\ndocuments, which have not previously been used to build digital language\nresources in Indonesia. DriveThru is a platform for extracting document content\nutilizing Optical Character Recognition (OCR) techniques in its system to\nprovide language resource building with less manual effort and cost. This paper\nalso studies the utility of current state-of-the-art LLM for post-OCR\ncorrection to show the capability of increasing the character accuracy rate\n(CAR) and word accuracy rate (WAR) compared to off-the-shelf OCR.\n","authors":["MohammadRifqi Farhansyah","Muhammad Zuhdi Fikri Johari","Afinzaki Amiral","Ayu Purwarianti","Kumara Ari Yuana","Derry Tanti Wijaya"],"pdf_url":"https://arxiv.org/pdf/2411.09318v1.pdf","comment":"12 pages, 3 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.14979v4","updated":"2024-11-14T09:17:48Z","published":"2024-10-19T05:01:56Z","title":"Do Large Language Models Truly Grasp Mathematics? An Empirical\n  Exploration From Cognitive Psychology","summary":"  The cognitive mechanism by which Large Language Models (LLMs) solve\nmathematical problems remains a widely debated and unresolved issue. Currently,\nthere is little interpretable experimental evidence that connects LLMs'\nproblem-solving with human cognitive psychology.To determine if LLMs possess\nhuman-like mathematical reasoning, we modified the problems used in the human\nCognitive Reflection Test (CRT). Our results show that, even with the use of\nChains of Thought (CoT) prompts, mainstream LLMs, including the latest o1 model\n(noted for its reasoning capabilities), have a high error rate when solving\nthese modified CRT problems. Specifically, the average accuracy rate dropped by\nup to 50% compared to the original questions.Further analysis of LLMs'\nincorrect answers suggests that they primarily rely on pattern matching from\ntheir training data, which aligns more with human intuition (System 1 thinking)\nrather than with human-like reasoning (System 2 thinking). This finding\nchallenges the belief that LLMs have genuine mathematical reasoning abilities\ncomparable to humans. As a result, this work may adjust overly optimistic views\non LLMs' progress towards artificial general intelligence.\n","authors":["Wei Xie","Shuoyoucheng Ma","Zhenhua Wang","Enze Wang","Kai Chen","Xiaobing Sun","Baosheng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14979v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09297v1","updated":"2024-11-14T09:16:48Z","published":"2024-11-14T09:16:48Z","title":"DTELS: Towards Dynamic Granularity of Timeline Summarization","summary":"  The rapid proliferation of online news has posed significant challenges in\ntracking the continuous development of news topics. Traditional timeline\nsummarization constructs a chronological summary of the events but often lacks\nthe flexibility to meet the diverse granularity needs. To overcome this\nlimitation, we introduce a new paradigm, Dynamic-granularity TimELine\nSummarization, (DTELS), which aims to construct adaptive timelines based on\nuser instructions or requirements. This paper establishes a comprehensive\nbenchmark for DTLES that includes: (1) an evaluation framework grounded in\njournalistic standards to assess the timeline quality across four dimensions:\nInformativeness, Granular Consistency, Factuality, and Coherence; (2) a\nlarge-scale, multi-source dataset with multiple granularity timeline\nannotations based on a consensus process to facilitate authority; (3) extensive\nexperiments and analysis with two proposed solutions based on Large Language\nModels (LLMs) and existing state-of-the-art TLS methods. The experimental\nresults demonstrate the effectiveness of LLM-based solutions. However, even the\nmost advanced LLMs struggle to consistently generate timelines that are both\ninformative and granularly consistent, highlighting the challenges of the DTELS\ntask.\n","authors":["Chenlong Zhang","Tong Zhou","Pengfei Cao","Zhuoran Jin","Yubo Chen","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.09297v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2411.09289v1","updated":"2024-11-14T09:03:54Z","published":"2024-11-14T09:03:54Z","title":"StreamAdapter: Efficient Test Time Adaptation from Contextual Streams","summary":"  In-context learning (ICL) allows large language models (LLMs) to adapt to new\ntasks directly from the given demonstrations without requiring gradient\nupdates. While recent advances have expanded context windows to accommodate\nmore demonstrations, this approach increases inference costs without\nnecessarily improving performance. To mitigate these issues, We propose\nStreamAdapter, a novel approach that directly updates model parameters from\ncontext at test time, eliminating the need for explicit in-context\ndemonstrations. StreamAdapter employs context mapping and weight absorption\nmechanisms to dynamically transform ICL demonstrations into parameter updates\nwith minimal additional parameters. By reducing reliance on numerous in-context\nexamples, StreamAdapter significantly reduce inference costs and allows for\nefficient inference with constant time complexity, regardless of demonstration\ncount. Extensive experiments across diverse tasks and model architectures\ndemonstrate that StreamAdapter achieves comparable or superior adaptation\ncapability to ICL while requiring significantly fewer demonstrations. The\nsuperior task adaptation and context encoding capabilities of StreamAdapter on\nboth language understanding and generation tasks provides a new perspective for\nadapting LLMs at test time using context, allowing for more efficient\nadaptation across scenarios and more cost-effective inference\n","authors":["Dilxat Muhtar","Yelong Shen","Yaming Yang","Xiaodong Liu","Yadong Lu","Jianfeng Liu","Yuefeng Zhan","Hao Sun","Weiwei Deng","Feng Sun","Xueliang Zhang","Jianfeng Gao","Weizhu Chen","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.09289v1.pdf","comment":"22 Pages, 9 Figures"},{"id":"http://arxiv.org/abs/2411.09273v1","updated":"2024-11-14T08:22:42Z","published":"2024-11-14T08:22:42Z","title":"Cross-Modal Consistency in Multimodal Large Language Models","summary":"  Recent developments in multimodal methodologies have marked the beginning of\nan exciting era for models adept at processing diverse data types, encompassing\ntext, audio, and visual content. Models like GPT-4V, which merge computer\nvision with advanced language processing, exhibit extraordinary proficiency in\nhandling intricate tasks that require a simultaneous understanding of both\ntextual and visual information. Prior research efforts have meticulously\nevaluated the efficacy of these Vision Large Language Models (VLLMs) in various\ndomains, including object detection, image captioning, and other related\nfields. However, existing analyses have often suffered from limitations,\nprimarily centering on the isolated evaluation of each modality's performance\nwhile neglecting to explore their intricate cross-modal interactions.\nSpecifically, the question of whether these models achieve the same level of\naccuracy when confronted with identical task instances across different\nmodalities remains unanswered. In this study, we take the initiative to delve\ninto the interaction and comparison among these modalities of interest by\nintroducing a novel concept termed cross-modal consistency. Furthermore, we\npropose a quantitative evaluation framework founded on this concept. Our\nexperimental findings, drawn from a curated collection of parallel\nvision-language datasets developed by us, unveil a pronounced inconsistency\nbetween the vision and language modalities within GPT-4V, despite its portrayal\nas a unified multimodal model. Our research yields insights into the\nappropriate utilization of such models and hints at potential avenues for\nenhancing their design.\n","authors":["Xiang Zhang","Senyu Li","Ning Shi","Bradley Hauer","Zijun Wu","Grzegorz Kondrak","Muhammad Abdul-Mageed","Laks V. S. Lakshmanan"],"pdf_url":"https://arxiv.org/pdf/2411.09273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07176v2","updated":"2024-11-14T08:20:22Z","published":"2024-11-11T17:56:28Z","title":"More Expressive Attention with Negative Weights","summary":"  We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention can shift the token deletion and copying\nfunction from a static OV matrix to dynamic QK inner products, with the OV\nmatrix now focusing more on refinement or modification. The attention head can\nsimultaneously delete, copy, or retain tokens by assigning them negative,\npositive, or minimal attention weights, respectively. As a result, a single\nattention head becomes more flexible and expressive. (2) Cog Attention improves\nthe model's robustness against representational collapse, which can occur when\nearlier tokens are over-squashed into later positions, leading to homogeneous\nrepresentations. Negative weights reduce effective information paths from\nearlier to later tokens, helping to mitigate this issue. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models for language modeling and U-ViT diffusion models for image\ngeneration. Experiments show that models using Cog Attention exhibit superior\nperformance compared to those employing traditional softmax attention modules.\nOur approach suggests a promising research direction for rethinking and\nbreaking the entrenched constraints of traditional softmax attention, such as\nthe requirement for non-negative weights.\n","authors":["Ang Lv","Ruobing Xie","Shuaipeng Li","Jiayi Liao","Xingwu Sun","Zhanhui Kang","Di Wang","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2411.07176v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09259v1","updated":"2024-11-14T07:51:51Z","published":"2024-11-14T07:51:51Z","title":"Jailbreak Attacks and Defenses against Multimodal Generative Models: A\n  Survey","summary":"  The rapid evolution of multimodal foundation models has led to significant\nadvancements in cross-modal understanding and generation across diverse\nmodalities, including text, images, audio, and video. However, these models\nremain susceptible to jailbreak attacks, which can bypass built-in safety\nmechanisms and induce the production of potentially harmful content.\nConsequently, understanding the methods of jailbreak attacks and existing\ndefense mechanisms is essential to ensure the safe deployment of multimodal\ngenerative models in real-world scenarios, particularly in security-sensitive\napplications. To provide comprehensive insight into this topic, this survey\nreviews jailbreak and defense in multimodal generative models. First, given the\ngeneralized lifecycle of multimodal jailbreak, we systematically explore\nattacks and corresponding defense strategies across four levels: input,\nencoder, generator, and output. Based on this analysis, we present a detailed\ntaxonomy of attack methods, defense mechanisms, and evaluation frameworks\nspecific to multimodal generative models. Additionally, we cover a wide range\nof input-output configurations, including modalities such as Any-to-Text,\nAny-to-Vision, and Any-to-Any within generative systems. Finally, we highlight\ncurrent research challenges and propose potential directions for future\nresearch.The open-source repository corresponding to this work can be found at\nhttps://github.com/liuxuannan/Awesome-Multimodal-Jailbreak.\n","authors":["Xuannan Liu","Xing Cui","Peipei Li","Zekun Li","Huaibo Huang","Shuhan Xia","Miaoxuan Zhang","Yueying Zou","Ran He"],"pdf_url":"https://arxiv.org/pdf/2411.09259v1.pdf","comment":"ongoing work"},{"id":"http://arxiv.org/abs/2411.09255v1","updated":"2024-11-14T07:41:34Z","published":"2024-11-14T07:41:34Z","title":"DAHL: Domain-specific Automated Hallucination Evaluation of Long-Form\n  Text through a Benchmark Dataset in Biomedicine","summary":"  We introduce DAHL, a benchmark dataset and automated evaluation system\ndesigned to assess hallucination in long-form text generation, specifically\nwithin the biomedical domain. Our benchmark dataset, meticulously curated from\nbiomedical research papers, consists of 8,573 questions across 29 categories.\nDAHL evaluates fact-conflicting hallucinations in Large Language Models (LLMs)\nby deconstructing responses into atomic units, each representing a single piece\nof information. The accuracy of these responses is averaged to produce the DAHL\nScore, offering a more in-depth evaluation of hallucinations compared to\nprevious methods that rely on multiple-choice tasks. We conduct experiments\nwith 8 different models, finding that larger models tend to hallucinate less;\nhowever, beyond a model size of 7 to 8 billion parameters, further scaling does\nnot significantly improve factual accuracy. The DAHL Score holds potential as\nan efficient alternative to human-annotated preference labels, being able to be\nexpanded to other specialized domains. We release the dataset and code in\npublic.\n","authors":["Jean Seo","Jongwon Lim","Dongjun Jang","Hyopil Shin"],"pdf_url":"https://arxiv.org/pdf/2411.09255v1.pdf","comment":"EMNLP2024/FEVER"},{"id":"http://arxiv.org/abs/2411.09249v1","updated":"2024-11-14T07:28:09Z","published":"2024-11-14T07:28:09Z","title":"Enhancing Financial Domain Adaptation of Language Models via Model\n  Augmentation","summary":"  The domain adaptation of language models, including large language models\n(LLMs), has become increasingly important as the use of such models continues\nto expand. This study demonstrates the effectiveness of Composition to Augment\nLanguage Models (CALM) in adapting to the financial domain. CALM is a model to\nextend the capabilities of existing models by introducing cross-attention\nbetween two LLMs with different functions. In our experiments, we developed a\nCALM to enhance the financial performance of an LLM with strong response\ncapabilities by leveraging a financial-specialized LLM. Notably, the CALM was\ntrained using a financial dataset different from the one used to train the\nfinancial-specialized LLM, confirming CALM's ability to adapt to various\ndatasets. The models were evaluated through quantitative Japanese financial\nbenchmarks and qualitative response comparisons, demonstrating that CALM\nenables superior responses with higher scores than the original models and\nbaselines. Additionally, comparative experiments on connection points revealed\nthat connecting the middle layers of the models is most effective in\nfacilitating adaptation to the financial domain. These findings confirm that\nCALM is a practical approach for adapting LLMs to the financial domain.\n","authors":["Kota Tanabe","Masanori Hirano","Kazuki Matoya","Kentaro Imajo","Hiroki Sakaji","Itsuki Noda"],"pdf_url":"https://arxiv.org/pdf/2411.09249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10880v2","updated":"2024-11-14T07:01:07Z","published":"2024-06-16T10:04:19Z","title":"Exploring the Potential of Multimodal LLM with Knowledge-Intensive\n  Multimodal ASR","summary":"  Recent advancements in multimodal large language models (MLLMs) have made\nsignificant progress in integrating information across various modalities, yet\nreal-world applications in educational and scientific domains remain\nchallenging. This paper introduces the Multimodal Scientific ASR (MS-ASR) task,\nwhich focuses on transcribing scientific conference videos by leveraging visual\ninformation from slides to enhance the accuracy of technical terminologies.\nRealized that traditional metrics like WER fall short in assessing performance\naccurately, prompting the proposal of severity-aware WER (SWER) that considers\nthe content type and severity of ASR errors. We propose the Scientific Vision\nAugmented ASR (SciVASR) framework as a baseline method, enabling MLLMs to\nimprove transcript quality through post-editing. Evaluations of\nstate-of-the-art MLLMs, including GPT-4o, show a 45% improvement over\nspeech-only baselines, highlighting the importance of multimodal information\nintegration.\n","authors":["Minghan Wang","Yuxia Wang","Thuy-Trang Vu","Ehsan Shareghi","Gholamreza Haffari"],"pdf_url":"https://arxiv.org/pdf/2406.10880v2.pdf","comment":"Accepted to EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2407.00996v2","updated":"2024-11-14T06:55:27Z","published":"2024-07-01T06:22:38Z","title":"Can Small Language Models Learn, Unlearn, and Retain Noise Patterns?","summary":"  Small Language Models (SLMs) are generally considered more compact versions\nof large language models (LLMs). This study investigates the ability of SLMs\nwith parameters between 1 and 3 billion to learn, retain, and subsequently\neliminate different types of noise present in the data. Four pre-trained SLMs\nwere utilized for this: Olmo 1B, Qwen1.5 1.8B, Gemma 2B, and Phi2 2.7B. The\nmodels were instruction-tuned on noise-free data and tested using in-context\nexamples to determine if they could learn noise through examples. Subsequently,\nnoise patterns were introduced in instruction tuning to evaluate the noise\nlearning, unlearning, and retention capabilities of the models. Olmo, the\nsmallest model, was highly sensitive to noise, quickly adapting to noisy\npatterns. Phi2 resisted learning character-level and transliteration noise,\nlikely due to its carefully curated, structured, and high-quality pretraining\ndata. Gemma excelled with transliteration noise, likely benefiting from its\nmultilingual pretraining. The findings can be used to develop robust training\nstrategies for SLMs.\n","authors":["Nicy Scaria","Silvester John Joseph Kennedy","Deepak Subramani"],"pdf_url":"https://arxiv.org/pdf/2407.00996v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.03735v4","updated":"2024-11-14T06:42:51Z","published":"2024-01-08T08:54:22Z","title":"Language Models Encode the Value of Numbers Linearly","summary":"  Large language models (LLMs) have exhibited impressive competence in various\ntasks, but their internal mechanisms on mathematical problems are still\nunder-explored. In this paper, we study a fundamental question: how language\nmodels encode the value of numbers, a basic element in math. To study the\nquestion, we construct a synthetic dataset comprising addition problems and\nutilize linear probes to read out input numbers from the hidden states.\nExperimental results support the existence of encoded number values in LLMs on\ndifferent layers, and these values can be extracted via linear probes. Further\nexperiments show that LLMs store their calculation results in a similar manner,\nand we can intervene the output via simple vector additions, proving the causal\nconnection between encoded numbers and language model outputs. Our research\nprovides evidence that LLMs encode the value of numbers linearly, offering\ninsights for better exploring, designing, and utilizing numeric information in\nLLMs.\n","authors":["Fangwei Zhu","Damai Dai","Zhifang Sui"],"pdf_url":"https://arxiv.org/pdf/2401.03735v4.pdf","comment":"The code and data are available at\n  https://github.com/solitaryzero/NumProbe"},{"id":"http://arxiv.org/abs/2411.09214v1","updated":"2024-11-14T06:20:21Z","published":"2024-11-14T06:20:21Z","title":"HateGPT: Unleashing GPT-3.5 Turbo to Combat Hate Speech on X","summary":"  The widespread use of social media platforms like Twitter and Facebook has\nenabled people of all ages to share their thoughts and experiences, leading to\nan immense accumulation of user-generated content. However, alongside the\nbenefits, these platforms also face the challenge of managing hate speech and\noffensive content, which can undermine rational discourse and threaten\ndemocratic values. As a result, there is a growing need for automated methods\nto detect and mitigate such content, especially given the complexity of\nconversations that may require contextual analysis across multiple languages,\nincluding code-mixed languages like Hinglish, German-English, and Bangla. We\nparticipated in the English task where we have to classify English tweets into\ntwo categories namely Hate and Offensive and Non Hate-Offensive. In this work,\nwe experiment with state-of-the-art large language models like GPT-3.5 Turbo\nvia prompting to classify tweets into Hate and Offensive or Non Hate-Offensive.\nIn this study, we evaluate the performance of a classification model using\nMacro-F1 scores across three distinct runs. The Macro-F1 score, which balances\nprecision and recall across all classes, is used as the primary metric for\nmodel evaluation. The scores obtained are 0.756 for run 1, 0.751 for run 2, and\n0.754 for run 3, indicating a high level of performance with minimal variance\namong the runs. The results suggest that the model consistently performs well\nin terms of precision and recall, with run 1 showing the highest performance.\nThese findings highlight the robustness and reliability of the model across\ndifferent runs.\n","authors":["Aniket Deroy","Subhankar Maity"],"pdf_url":"https://arxiv.org/pdf/2411.09214v1.pdf","comment":"Accepted at FIRE 2024 (Track: Hate Speech and Offensive Content\n  Identification in English and Indo-Aryan Languages (HASOC)). arXiv admin\n  note: text overlap with arXiv:2411.05039, arXiv:2411.06946"},{"id":"http://arxiv.org/abs/2411.09213v1","updated":"2024-11-14T06:19:18Z","published":"2024-11-14T06:19:18Z","title":"Comprehensive and Practical Evaluation of Retrieval-Augmented Generation\n  Systems for Medical Question Answering","summary":"  Retrieval-augmented generation (RAG) has emerged as a promising approach to\nenhance the performance of large language models (LLMs) in knowledge-intensive\ntasks such as those from medical domain. However, the sensitive nature of the\nmedical domain necessitates a completely accurate and trustworthy system. While\nexisting RAG benchmarks primarily focus on the standard retrieve-answer\nsetting, they overlook many practical scenarios that measure crucial aspects of\na reliable medical system. This paper addresses this gap by providing a\ncomprehensive evaluation framework for medical question-answering (QA) systems\nin a RAG setting for these situations, including sufficiency, integration, and\nrobustness. We introduce Medical Retrieval-Augmented Generation Benchmark\n(MedRGB) that provides various supplementary elements to four medical QA\ndatasets for testing LLMs' ability to handle these specific scenarios.\nUtilizing MedRGB, we conduct extensive evaluations of both state-of-the-art\ncommercial LLMs and open-source models across multiple retrieval conditions.\nOur experimental results reveals current models' limited ability to handle\nnoise and misinformation in the retrieved documents. We further analyze the\nLLMs' reasoning processes to provides valuable insights and future directions\nfor developing RAG systems in this critical medical domain.\n","authors":["Nghia Trung Ngo","Chien Van Nguyen","Franck Dernoncourt","Thien Huu Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.09213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10570v6","updated":"2024-11-14T06:09:47Z","published":"2023-10-16T16:45:12Z","title":"On Context Utilization in Summarization with Large Language Models","summary":"  Large language models (LLMs) excel in abstractive summarization tasks,\ndelivering fluent and pertinent summaries. Recent advancements have extended\ntheir capabilities to handle long-input contexts, exceeding 100k tokens.\nHowever, in question answering, language models exhibit uneven utilization of\ntheir input context. They tend to favor the initial and final segments,\nresulting in a U-shaped performance pattern concerning where the answer is\nlocated within the input. This bias raises concerns, particularly in\nsummarization where crucial content may be dispersed throughout the source\ndocument(s). Besides, in summarization, mapping facts from the source to the\nsummary is not trivial as salient content is usually re-phrased. In this paper,\nwe conduct the first comprehensive study on context utilization and position\nbias in summarization. Our analysis encompasses 6 LLMs, 10 datasets, and 5\nevaluation metrics. We introduce a new evaluation benchmark called MiddleSum on\nthe which we benchmark two alternative inference methods to alleviate position\nbias: hierarchical summarization and incremental summarization. Our code and\ndata can be found here: https://github.com/ntunlp/MiddleSum.\n","authors":["Mathieu Ravaut","Aixin Sun","Nancy F. Chen","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2310.10570v6.pdf","comment":"ACL 2024. 9 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2407.00476v3","updated":"2024-11-14T06:06:09Z","published":"2024-06-29T15:47:28Z","title":"Large Language Models for Power Scheduling: A User-Centric Approach","summary":"  While traditional optimization and scheduling schemes are designed to meet\nfixed, predefined system requirements, future systems are moving toward\nuser-driven approaches and personalized services, aiming to achieve high\nquality-of-experience (QoE) and flexibility. This challenge is particularly\npronounced in wireless and digitalized energy networks, where users'\nrequirements have largely not been taken into consideration due to the lack of\na common language between users and machines. The emergence of powerful large\nlanguage models (LLMs) marks a radical departure from traditional\nsystem-centric methods into more advanced user-centric approaches by providing\na natural communication interface between users and devices. In this paper, for\nthe first time, we introduce a novel architecture for resource scheduling\nproblems by constructing three LLM agents to convert an arbitrary user's voice\nrequest (VRQ) into a resource allocation vector. Specifically, we design an LLM\nintent recognition agent to translate the request into an optimization problem\n(OP), an LLM OP parameter identification agent, and an LLM OP solving agent. To\nevaluate system performance, we construct a database of typical VRQs in the\ncontext of electric vehicle (EV) charging. As a proof of concept, we primarily\nuse Llama 3 8B. Through testing with different prompt engineering scenarios,\nthe obtained results demonstrate the efficiency of the proposed architecture.\nThe conducted performance analysis allows key insights to be extracted. For\ninstance, having a larger set of candidate OPs to model the real-world problem\nmight degrade the final performance because of a higher recognition/OP\nclassification noise level. All results and codes are open source.\n","authors":["Thomas Mongaillard","Samson Lasaulce","Othman Hicheur","Chao Zhang","Lina Bariah","Vineeth S. Varma","Hang Zou","Qiyang Zhao","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2407.00476v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09593v4","updated":"2024-11-14T06:00:39Z","published":"2022-12-19T16:29:26Z","title":"Unsupervised Summarization Re-ranking","summary":"  With the rise of task-specific pre-training objectives, abstractive\nsummarization models like PEGASUS offer appealing zero-shot performance on\ndownstream summarization tasks. However, the performance of such unsupervised\nmodels still lags significantly behind their supervised counterparts. Similarly\nto the supervised setup, we notice a very high variance in quality among\nsummary candidates from these models while only one candidate is kept as the\nsummary output. In this paper, we propose to re-rank summary candidates in an\nunsupervised manner, aiming to close the performance gap between unsupervised\nand supervised models. Our approach improves the unsupervised PEGASUS by up to\n7.27% and ChatGPT by up to 6.86% relative mean ROUGE across four widely-adopted\nsummarization benchmarks ; and achieves relative gains of 7.51% (up to 23.73%\nfrom XSum to WikiHow) averaged over 30 zero-shot transfer setups (finetuning on\na dataset, evaluating on another).\n","authors":["Mathieu Ravaut","Shafiq Joty","Nancy Chen"],"pdf_url":"https://arxiv.org/pdf/2212.09593v4.pdf","comment":"9 pages, 1 figure, 10 tables, 23 appendix pages, ACL Findings 2023"},{"id":"http://arxiv.org/abs/2411.08504v2","updated":"2024-11-14T05:51:26Z","published":"2024-11-13T10:42:11Z","title":"Towards Objective and Unbiased Decision Assessments with LLM-Enhanced\n  Hierarchical Attention Networks","summary":"  How objective and unbiased are we while making decisions? This work\ninvestigates cognitive bias identification in high-stake decision making\nprocess by human experts, questioning its effectiveness in real-world settings,\nsuch as candidates assessments for university admission. We begin with a\nstatistical analysis assessing correlations among different decision points\namong in the current process, which discovers discrepancies that imply\ncognitive bias and inconsistency in decisions. This motivates our exploration\nof bias-aware AI-augmented workflow that surpass human judgment. We propose\nBGM-HAN, an enhanced Hierarchical Attention Network with Byte-Pair Encoding,\nGated Residual Connections and Multi-Head Attention. Using it as a backbone\nmodel, we further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow,\nwhich simulate real-world decision-making. In our experiments, both the\nproposed model and the agentic workflow significantly improves on both human\njudgment and alternative models, validated with real-world data.\n","authors":["Junhua Liu","Kwan Hui Lim","Roy Ka-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2411.08504v2.pdf","comment":"Source code is available at: https://github.com/junhua/bgm-han"},{"id":"http://arxiv.org/abs/2407.12471v2","updated":"2024-11-14T05:49:31Z","published":"2024-07-17T10:49:47Z","title":"Characterization of Political Polarized Users Attacked by Language\n  Toxicity on Twitter","summary":"  Understanding the dynamics of language toxicity on social media is important\nfor us to investigate the propagation of misinformation and the development of\necho chambers for political scenarios such as U.S. presidential elections.\nRecent research has used large-scale data to investigate the dynamics across\nsocial media platforms. However, research on the toxicity dynamics is not\nenough. This study aims to provide a first exploration of the potential\nlanguage toxicity flow among Left, Right and Center users. Specifically, we aim\nto examine whether Left users were easier to be attacked by language toxicity.\nIn this study, more than 500M Twitter posts were examined. It was discovered\nthat Left users received much more toxic replies than Right and Center users.\n","authors":["Wentao Xu"],"pdf_url":"https://arxiv.org/pdf/2407.12471v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09166v1","updated":"2024-11-14T03:54:42Z","published":"2024-11-14T03:54:42Z","title":"Unstructured Text Enhanced Open-domain Dialogue System: A Systematic\n  Survey","summary":"  Incorporating external knowledge into dialogue generation has been proven to\nbenefit the performance of an open-domain Dialogue System (DS), such as\ngenerating informative or stylized responses, controlling conversation topics.\nIn this article, we study the open-domain DS that uses unstructured text as\nexternal knowledge sources (\\textbf{U}nstructured \\textbf{T}ext\n\\textbf{E}nhanced \\textbf{D}ialogue \\textbf{S}ystem, \\textbf{UTEDS}). The\nexistence of unstructured text entails distinctions between UTEDS and\ntraditional data-driven DS and we aim to analyze these differences. We first\ngive the definition of the UTEDS related concepts, then summarize the recently\nreleased datasets and models. We categorize UTEDS into Retrieval and Generative\nmodels and introduce them from the perspective of model components. The\nretrieval models consist of Fusion, Matching, and Ranking modules, while the\ngenerative models comprise Dialogue and Knowledge Encoding, Knowledge\nSelection, and Response Generation modules. We further summarize the evaluation\nmethods utilized in UTEDS and analyze the current models' performance. At last,\nwe discuss the future development trends of UTEDS, hoping to inspire new\nresearch in this field.\n","authors":["Longxuan Ma","Mingda Li","Weinan Zhang","Jiapeng Li","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2411.09166v1.pdf","comment":"45 pages, 3 Figures, 11 Tables"},{"id":"http://arxiv.org/abs/2406.11214v3","updated":"2024-11-14T03:53:56Z","published":"2024-06-17T05:13:25Z","title":"Problematic Tokens: Tokenizer Bias in Large Language Models","summary":"  Recent advancements in large language models(LLMs), such as GPT-4 and GPT-4o,\nhave shown exceptional performance, especially in languages with abundant\nresources like English, thanks to extensive datasets that ensure robust\ntraining. Conversely, these models exhibit limitations when processing\nunder-resourced languages such as Chinese and Korean, where issues including\nhallucinatory responses remain prevalent. This paper traces the roots of these\ndisparities to the tokenization process inherent to these models. Specifically,\nit explores how the tokenizers vocabulary, often used to speed up the\ntokenization process and reduce tokens but constructed independently of the\nactual model training data, inadequately represents non-English languages. This\nmisrepresentation results in the propagation of under-trained or untrained\ntokens, which perpetuate biases and pose serious concerns related to data\nsecurity and ethical standards. We aim to dissect the tokenization mechanics of\nGPT-4o, illustrating how its simplified token-handling methods amplify these\nrisks and offer strategic solutions to mitigate associated security and ethical\nissues. Through this study, we emphasize the critical need to rethink\ntokenization frameworks to foster more equitable and secure AI technologies.\nThe code and data are available at https://github.com/yeyimilk/LLMGPT4o\n","authors":["Jin Yang","Zhiqiang Wang","Yanbin Lin","Zunduo Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.11214v3.pdf","comment":"11th IEEE Special session on Privacy and Security of Big Data (PSBD\n  2024)"},{"id":"http://arxiv.org/abs/2406.12382v3","updated":"2024-11-14T03:10:45Z","published":"2024-06-18T08:14:28Z","title":"From Instance Training to Instruction Learning: Task Adapters Generation\n  from Instructions","summary":"  Large language models (LLMs) have acquired the ability to solve general tasks\nby utilizing instruction finetuning (IFT). However, IFT still relies heavily on\ninstance training of extensive task data, which greatly limits the adaptability\nof LLMs to real-world scenarios where labeled task instances are scarce and\nbroader task generalization becomes paramount. Contrary to LLMs, humans acquire\nskills and complete tasks not merely through repeated practice but also by\nunderstanding and following instructional guidelines. This paper is dedicated\nto simulating human learning to address the shortcomings of instance training,\nfocusing on instruction learning to enhance cross-task generalization. Within\nthis context, we introduce Task Adapters Generation from Instructions (TAGI),\nwhich automatically constructs the task-specific model in a parameter\ngeneration manner based on the given task instructions without retraining for\nunseen tasks. Specifically, we utilize knowledge distillation to enhance the\nconsistency between TAGI developed through Learning with Instruction and\ntask-specific models developed through Training with Instance, by aligning the\nlabels, output logits, and adapter parameters between them. TAGI is endowed\nwith cross-task generalization capabilities through a two-stage training\nprocess that includes hypernetwork pretraining and finetuning. We evaluate TAGI\non the Super-Natural Instructions and P3 datasets. The experimental results\ndemonstrate that TAGI can match or even outperform traditional meta-trained\nmodels and other hypernetwork models, while significantly reducing\ncomputational requirements.\n","authors":["Huanxuan Liao","Shizhu He","Yao Xu","Yuanzhe Zhang","Yanchao Hao","Shengping Liu","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.12382v3.pdf","comment":"accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.08733v2","updated":"2024-11-14T02:36:58Z","published":"2024-11-13T16:15:38Z","title":"Dynamic Rewarding with Prompt Optimization Enables Tuning-free\n  Self-Alignment of Language Models","summary":"  Aligning Large Language Models (LLMs) traditionally relies on costly training\nand human preference annotations. Self-alignment seeks to reduce these expenses\nby enabling models to align themselves. To further lower costs and achieve\nalignment without any expensive tuning or annotations, we introduce a new\ntuning-free approach for self-alignment, Dynamic Rewarding with Prompt\nOptimization (DRPO). Our approach leverages a search-based optimization\nframework that allows LLMs to iteratively self-improve and craft the optimal\nalignment instructions, all without additional training or human intervention.\nThe core of DRPO is a dynamic rewarding mechanism, which identifies and\nrectifies model-specific alignment weaknesses, allowing LLMs to adapt\nefficiently to diverse alignment challenges. Empirical evaluations on eight\nrecent LLMs, both open- and closed-sourced, demonstrate that DRPO significantly\nenhances alignment performance, with base models outperforming their\nSFT/RLHF-tuned counterparts. Moreover, the prompts automatically optimized by\nDRPO surpass those curated by human experts, further validating the\neffectiveness of our approach. Our findings highlight the great potential of\ncurrent LLMs to achieve adaptive self-alignment through inference-time\noptimization, complementing tuning-based alignment methods.\n","authors":["Somanshu Singla","Zhen Wang","Tianyang Liu","Abdullah Ashfaq","Zhiting Hu","Eric P. Xing"],"pdf_url":"https://arxiv.org/pdf/2411.08733v2.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.19258v3","updated":"2024-11-14T01:56:11Z","published":"2024-10-25T02:22:00Z","title":"Not All Heads Matter: A Head-Level KV Cache Compression Method with\n  Integrated Retrieval and Reasoning","summary":"  Key-Value (KV) caching is a common technique to enhance the computational\nefficiency of Large Language Models (LLMs), but its memory overhead grows\nrapidly with input length. Prior work has shown that not all tokens are equally\nimportant for text generation, proposing layer-level KV cache compression to\nselectively retain key information. Recognizing the distinct roles of attention\nheads in generation, we propose HeadKV, a head-level KV cache compression\nmethod, and HeadKV-R2, which leverages a novel contextual reasoning ability\nestimation for compression. Our approach operates at the level of individual\nheads, estimating their importance for contextual QA tasks that require both\nretrieval and reasoning capabilities. Extensive experiments across diverse\nbenchmarks (LongBench, LooGLE), model architectures (e.g., Llama-3-8B-Instruct,\nMistral-7B-Instruct), and long-context abilities tests demonstrate that our\nhead-level KV cache compression significantly outperforms strong baselines,\nparticularly in low-resource settings (KV size = 64 & 128). Notably, our method\nretains just 1.5% of the KV cache while achieving 97% of the performance of the\nfull KV cache on the contextual question answering benchmark.Codes are\navailable at https://github.com/FYYFU/HeadKV\n","authors":["Yu Fu","Zefan Cai","Abedelkadir Asi","Wayne Xiong","Yue Dong","Wen Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.19258v3.pdf","comment":"18pages"},{"id":"http://arxiv.org/abs/2411.09125v1","updated":"2024-11-14T01:48:08Z","published":"2024-11-14T01:48:08Z","title":"DROJ: A Prompt-Driven Attack against Large Language Models","summary":"  Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross various natural language processing tasks. Due to their training on\ninternet-sourced datasets, LLMs can sometimes generate objectionable content,\nnecessitating extensive alignment with human feedback to avoid such outputs.\nDespite massive alignment efforts, LLMs remain susceptible to adversarial\njailbreak attacks, which usually are manipulated prompts designed to circumvent\nsafety mechanisms and elicit harmful responses. Here, we introduce a novel\napproach, Directed Rrepresentation Optimization Jailbreak (DROJ), which\noptimizes jailbreak prompts at the embedding level to shift the hidden\nrepresentations of harmful queries towards directions that are more likely to\nelicit affirmative responses from the model. Our evaluations on LLaMA-2-7b-chat\nmodel show that DROJ achieves a 100\\% keyword-based Attack Success Rate (ASR),\neffectively preventing direct refusals. However, the model occasionally\nproduces repetitive and non-informative responses. To mitigate this, we\nintroduce a helpfulness system prompt that enhances the utility of the model's\nresponses. Our code is available at\nhttps://github.com/Leon-Leyang/LLM-Safeguard.\n","authors":["Leyang Hu","Boran Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04997v2","updated":"2024-11-14T01:36:12Z","published":"2024-11-07T18:59:16Z","title":"LLM2CLIP: Powerful Language Model Unlocks Richer Visual Representation","summary":"  CLIP is one of the most important multimodal foundational models today. What\npowers CLIP's capabilities? The rich supervision signals provided by natural\nlanguage, the carrier of human knowledge, shape a powerful cross-modal\nrepresentation space. However, with the rapid advancements in large language\nmodels LLMs like GPT-4 and LLaMA, the boundaries of language comprehension and\ngeneration are continually being pushed. This raises an intriguing question:\ncan the capabilities of LLMs be harnessed to further improve multimodal\nrepresentation learning? The potential benefits of incorporating LLMs into CLIP\nare clear. LLMs' strong textual understanding can fundamentally improve CLIP's\nability to handle image captions, drastically enhancing its ability to process\nlong and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMs\nare trained on a vast corpus of text, possessing open-world knowledge. This\nallows them to expand on caption information during training, increasing the\nefficiency of the learning process. In this paper, we propose LLM2CLIP, a novel\napproach that embraces the power of LLMs to unlock CLIP's potential. By\nfine-tuning the LLM in the caption space with contrastive learning, we extract\nits textual capabilities into the output embeddings, significantly improving\nthe output layer's textual discriminability. We then design an efficient\ntraining process where the fine-tuned LLM acts as a powerful teacher for CLIP's\nvisual encoder. Thanks to the LLM's presence, we can now incorporate longer and\nmore complex captions without being restricted by vanilla CLIP's text encoder's\ncontext window and ability limitations. Our experiments demonstrate that this\napproach brings substantial improvements in cross-modal tasks.\n","authors":["Weiquan Huang","Aoqi Wu","Yifan Yang","Xufang Luo","Yuqing Yang","Liang Hu","Qi Dai","Xiyang Dai","Dongdong Chen","Chong Luo","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2411.04997v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09116v1","updated":"2024-11-14T01:29:36Z","published":"2024-11-14T01:29:36Z","title":"P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent\n  Evaluation of LLMs","summary":"  Recent advancements in large language models (LLMs) showcase varied\nmultilingual capabilities across tasks like translation, code generation, and\nreasoning. Previous assessments often limited their scope to fundamental\nnatural language processing (NLP) or isolated capability-specific tasks. To\nalleviate this drawback, we aim to present a comprehensive multilingual\nmultitask benchmark. First, we present a pipeline for selecting available and\nreasonable benchmarks from massive ones, addressing the oversight in previous\nwork regarding the utility of these benchmarks, i.e., their ability to\ndifferentiate between models being evaluated. Leveraging this pipeline, we\nintroduce P-MMEval, a large-scale benchmark covering effective fundamental and\ncapability-specialized datasets. Furthermore, P-MMEval delivers consistent\nlanguage coverage across various datasets and provides parallel samples.\nFinally, we conduct extensive experiments on representative multilingual model\nseries to compare performances across models, analyze dataset effectiveness,\nexamine prompt impacts on model performances, and explore the relationship\nbetween multilingual performances and factors such as tasks, model sizes, and\nlanguages. These insights offer valuable guidance for future research. The\ndataset is available at https://huggingface.co/datasets/Qwen/P-MMEval.\n","authors":["Yidan Zhang","Boyi Deng","Yu Wan","Baosong Yang","Haoran Wei","Fei Huang","Bowen Yu","Junyang Lin","Fei Huang","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.09116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09109v1","updated":"2024-11-14T00:52:45Z","published":"2024-11-14T00:52:45Z","title":"Personalized Help for Optimizing Low-Skilled Users' Strategy","summary":"  AIs can beat humans in game environments; however, how helpful those agents\nare to human remains understudied. We augment CICERO, a natural language agent\nthat demonstrates superhuman performance in Diplomacy, to generate both move\nand message advice based on player intentions. A dozen Diplomacy games with\nnovice and experienced players, with varying advice settings, show that some of\nthe generated advice is beneficial. It helps novices compete with experienced\nplayers and in some instances even surpass them. The mere presence of advice\ncan be advantageous, even if players do not follow it.\n","authors":["Feng Gu","Wichayaporn Wongkamjan","Jordan Lee Boyd-Graber","Jonathan K. Kummerfeld","Denis Peskoff","Jonathan May"],"pdf_url":"https://arxiv.org/pdf/2411.09109v1.pdf","comment":"9 pages, 3 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2407.04573v2","updated":"2024-11-14T18:01:10Z","published":"2024-07-05T15:08:44Z","title":"VRSD: Rethinking Similarity and Diversity for Retrieval in Large\n  Language Models","summary":"  Vector retrieval algorithms are essential for semantic queries within the\nrapidly evolving landscape of Large Language Models (LLMs). The ability to\nretrieve vectors that satisfy both similarity and diversity criteria\nsubstantially enhances the performance of LLMs. Although Maximal Marginal\nRelevance (MMR) is widely employed in retrieval scenarios requiring relevance\nand diversity, variations in the parameter $\\lambda$ lead to fluctuations that\ncomplicate the optimization trajectory in vector spaces. This obscures the\ndirection of improvement and highlights the lack of a robust theoretical\nanalysis regarding similarity and diversity constraints in retrieval processes.\nTo address these challenges, this paper introduces a novel approach that\ncharacterizes both constraints through the relationship between the sum vector\nand the query vector. The proximity of these vectors ensures the similarity\nconstraint, while requiring individual vectors within the sum vector to diverge\nin their alignment with the query vector satisfies the diversity constraint. We\nfirst formulate a new combinatorial optimization problem, selecting k vectors\nfrom a candidate set such that their sum vector maximally aligns with the query\nvector, and demonstrate that this problem is NP-complete. This result\nunderscores the inherent difficulty of simultaneously achieving similarity and\ndiversity in vector retrieval, thereby providing a theoretical foundation for\nfuture research. Subsequently, we present the heuristic algorithm Vectors\nRetrieval with Similarity and Diversity, VRSD, which features a clear\noptimization objective and eliminates the need for preset parameters. VRSD also\nachieves a modest reduction in time complexity compared to MMR. Empirical\nvalidation confirms that VRSD significantly outperforms MMR across various\ndatasets.\n","authors":["Hang Gao","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.04573v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09607v1","updated":"2024-11-14T17:25:43Z","published":"2024-11-14T17:25:43Z","title":"Initial Nugget Evaluation Results for the TREC 2024 RAG Track with the\n  AutoNuggetizer Framework","summary":"  This report provides an initial look at partial results from the TREC 2024\nRetrieval-Augmented Generation (RAG) Track. We have identified RAG evaluation\nas a barrier to continued progress in information access (and more broadly,\nnatural language processing and artificial intelligence), and it is our hope\nthat we can contribute to tackling the many challenges in this space. The\ncentral hypothesis we explore in this work is that the nugget evaluation\nmethodology, originally developed for the TREC Question Answering Track in\n2003, provides a solid foundation for evaluating RAG systems. As such, our\nefforts have focused on \"refactoring\" this methodology, specifically applying\nlarge language models to both automatically create nuggets and to automatically\nassign nuggets to system answers. We call this the AutoNuggetizer framework.\nWithin the TREC setup, we are able to calibrate our fully automatic process\nagainst a manual process whereby nuggets are created by human assessors\nsemi-manually and then assigned manually to system answers. Based on initial\nresults across 21 topics from 45 runs, we observe a strong correlation between\nscores derived from a fully automatic nugget evaluation and a (mostly) manual\nnugget evaluation by human assessors. This suggests that our fully automatic\nevaluation process can be used to guide future iterations of RAG systems.\n","authors":["Ronak Pradeep","Nandan Thakur","Shivani Upadhyay","Daniel Campos","Nick Craswell","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.09607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15933v2","updated":"2024-11-14T13:59:15Z","published":"2024-09-24T09:57:25Z","title":"SLIMER-IT: Zero-Shot NER on Italian Language","summary":"  Traditional approaches to Named Entity Recognition (NER) frame the task into\na BIO sequence labeling problem. Although these systems often excel in the\ndownstream task at hand, they require extensive annotated data and struggle to\ngeneralize to out-of-distribution input domains and unseen entity types. On the\ncontrary, Large Language Models (LLMs) have demonstrated strong zero-shot\ncapabilities. While several works address Zero-Shot NER in English, little has\nbeen done in other languages. In this paper, we define an evaluation framework\nfor Zero-Shot NER, applying it to the Italian language. Furthermore, we\nintroduce SLIMER-IT, the Italian version of SLIMER, an instruction-tuning\napproach for zero-shot NER leveraging prompts enriched with definition and\nguidelines. Comparisons with other state-of-the-art models, demonstrate the\nsuperiority of SLIMER-IT on never-seen-before entity tags.\n","authors":["Andrew Zamai","Leonardo Rigutini","Marco Maggini","Andrea Zugarini"],"pdf_url":"https://arxiv.org/pdf/2409.15933v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09425v1","updated":"2024-11-14T13:22:41Z","published":"2024-11-14T13:22:41Z","title":"MARM: Unlocking the Future of Recommendation Systems through Memory\n  Augmentation and Scalable Complexity","summary":"  Scaling-law has guided the language model designing for past years, however,\nit is worth noting that the scaling laws of NLP cannot be directly applied to\nRecSys due to the following reasons: (1) The amount of training samples and\nmodel parameters is typically not the bottleneck for the model. Our\nrecommendation system can generate over 50 billion user samples daily, and such\na massive amount of training data can easily allow our model parameters to\nexceed 200 billion, surpassing many LLMs (about 100B). (2) To ensure the\nstability and robustness of the recommendation system, it is essential to\ncontrol computational complexity FLOPs carefully. Considering the above\ndifferences with LLM, we can draw a conclusion that: for a RecSys model,\ncompared to model parameters, the computational complexity FLOPs is a more\nexpensive factor that requires careful control. In this paper, we propose our\nmilestone work, MARM (Memory Augmented Recommendation Model), which explores a\nnew cache scaling-laws successfully.\n","authors":["Xiao Lv","Jiangxia Cao","Shijie Guan","Xiaoyou Zhou","Zhiguang Qi","Yaqiang Zang","Ming Li","Ben Wang","Kun Gai","Guorui Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.09425v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2403.07331v3","updated":"2024-11-14T13:04:41Z","published":"2024-03-12T05:32:33Z","title":"LIST: Learning to Index Spatio-Textual Data for Embedding based Spatial\n  Keyword Queries","summary":"  With the proliferation of spatio-textual data, Top-k KNN spatial keyword\nqueries (TkQs), which return a list of objects based on a ranking function that\nconsiders both spatial and textual relevance, have found many real-life\napplications. To efficiently handle TkQs, many indexes have been developed, but\nthe effectiveness of TkQ is limited. To improve effectiveness, several deep\nlearning models have recently been proposed, but they suffer severe efficiency\nissues and there are no efficient indexes specifically designed to accelerate\nthe top-k search process for these deep learning models. To tackle these\nissues, we consider embedding based spatial keyword queries, which capture the\nsemantic meaning of query keywords and object descriptions in two separate\nembeddings to evaluate textual relevance. Although various models can be used\nto generate these embeddings, no indexes have been specifically designed for\nsuch queries. To fill this gap, we propose LIST, a novel machine learning based\nApproximate Nearest Neighbor Search index that Learns to Index the\nSpatio-Textual data. LIST utilizes a new learning-to-cluster technique to group\nrelevant queries and objects together while separating irrelevant queries and\nobjects. There are two key challenges in building an effective and efficient\nindex, i.e., the absence of high-quality labels and the unbalanced clustering\nresults. We develop a novel pseudo-label generation technique to address the\ntwo challenges. Additionally, we introduce a learning based spatial relevance\nmodel that can integrates with various text relevance models to form a\nlightweight yet effective relevance for reranking objects retrieved by LIST.\n","authors":["Ziqi Yin","Shanshan Feng","Shang Liu","Gao Cong","Yew Soon Ong","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2403.07331v3.pdf","comment":"Accepted by VLDB Journal"},{"id":"http://arxiv.org/abs/2411.09410v1","updated":"2024-11-14T13:00:23Z","published":"2024-11-14T13:00:23Z","title":"LLM-assisted Explicit and Implicit Multi-interest Learning Framework for\n  Sequential Recommendation","summary":"  Multi-interest modeling in current recommender systems (RS) is mainly based\non user behavioral data, capturing user interest preferences from multiple\ndimensions. However, since behavioral data is implicit and often highly sparse,\nit is challenging to understand users' complex and diverse interests. Recent\nstudies have shown that the rich semantic information in the text can\neffectively supplement the deficiencies of behavioral data. Despite this, it is\nstill difficult for small models to directly extract semantic features\nassociated with users' deep interests. That is, how to effectively align\nsemantics with behavioral information to form a more comprehensive and accurate\nunderstanding of user interests has become a critical research problem.To\naddress this, we propose an LLM-assisted explicit and implicit multi-interest\nlearning framework (named EIMF) to model user interests on two levels: behavior\nand semantics. The framework consists of two parts: Implicit Behavioral\nInterest Module (IBIM) and Explicit Semantic Interest Module (ESIM). The\ntraditional multi-interest RS model in IBIM can learn users' implicit\nbehavioral interests from interactions with items. In ESIM, we first adopt a\nclustering algorithm to select typical samples and design a prompting strategy\non LLM to obtain explicit semantic interests. Furthermore, in the training\nphase, the semantic interests of typical samples can enhance the representation\nlearning of behavioral interests based on the multi-task learning on semantic\nprediction and modality alignment. Therefore, in the inference stage, accurate\nrecommendations can be achieved with only the user's behavioral data. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of the\nproposed EIMF framework, which effectively and efficiently combines small\nmodels with LLM to improve the accuracy of multi-interest modeling.\n","authors":["Shutong Qiao","Chen Gao","Yong Li","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2411.09410v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2312.10947v2","updated":"2024-11-14T13:00:05Z","published":"2023-12-18T05:53:44Z","title":"LabelCraft: Empowering Short Video Recommendations with Automated Label\n  Crafting","summary":"  Short video recommendations often face limitations due to the quality of user\nfeedback, which may not accurately depict user interests. To tackle this\nchallenge, a new task has emerged: generating more dependable labels from\noriginal feedback. Existing label generation methods rely on manual rules,\ndemanding substantial human effort and potentially misaligning with the desired\nobjectives of the platform. To transcend these constraints, we introduce\nLabelCraft, a novel automated label generation method explicitly optimizing\npivotal operational metrics for platform success. By formulating label\ngeneration as a higher-level optimization problem above recommender model\noptimization, LabelCraft introduces a trainable labeling model for automatic\nlabel mechanism modeling. Through meta-learning techniques, LabelCraft\neffectively addresses the bi-level optimization hurdle posed by the recommender\nand labeling models, enabling the automatic acquisition of intricate label\ngeneration mechanisms. Extensive experiments on real-world datasets corroborate\nLabelCraft's excellence across varied operational metrics, encompassing usage\ntime, user engagement, and retention. Codes are available at\nhttps://github.com/baiyimeng/LabelCraft.\n","authors":["Yimeng Bai","Yang Zhang","Jing Lu","Jianxin Chang","Xiaoxue Zang","Yanan Niu","Yang Song","Fuli Feng"],"pdf_url":"https://arxiv.org/pdf/2312.10947v2.pdf","comment":"Accepted by WSDM'24"},{"id":"http://arxiv.org/abs/2411.09269v1","updated":"2024-11-14T08:12:36Z","published":"2024-11-14T08:12:36Z","title":"Harnessing multiple LLMs for Information Retrieval: A case study on Deep\n  Learning methodologies in Biodiversity publications","summary":"  Deep Learning (DL) techniques are increasingly applied in scientific studies\nacross various domains to address complex research questions. However, the\nmethodological details of these DL models are often hidden in the unstructured\ntext. As a result, critical information about how these models are designed,\ntrained, and evaluated is challenging to access and comprehend. To address this\nissue, in this work, we use five different open-source Large Language Models\n(LLMs): Llama-3 70B, Llama-3.1 70B, Mixtral-8x22B-Instruct-v0.1, Mixtral 8x7B,\nand Gemma 2 9B in combination with Retrieval-Augmented Generation (RAG)\napproach to extract and process DL methodological details from scientific\npublications automatically. We built a voting classifier from the outputs of\nfive LLMs to accurately report DL methodological information. We tested our\napproach using biodiversity publications, building upon our previous research.\nTo validate our pipeline, we employed two datasets of DL-related biodiversity\npublications: a curated set of 100 publications from our prior work and a set\nof 364 publications from the Ecological Informatics journal. Our results\ndemonstrate that the multi-LLM, RAG-assisted pipeline enhances the retrieval of\nDL methodological information, achieving an accuracy of 69.5% (417 out of 600\ncomparisons) based solely on textual content from publications. This\nperformance was assessed against human annotators who had access to code,\nfigures, tables, and other supplementary information. Although demonstrated in\nbiodiversity, our methodology is not limited to this field; it can be applied\nacross other scientific domains where detailed methodological reporting is\nessential for advancing knowledge and ensuring reproducibility. This study\npresents a scalable and reliable approach for automating information\nextraction, facilitating better reproducibility and knowledge transfer across\nstudies.\n","authors":["Vamsi Krishna Kommineni","Birgitta K√∂nig-Ries","Sheeba Samuel"],"pdf_url":"https://arxiv.org/pdf/2411.09269v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09213v1","updated":"2024-11-14T06:19:18Z","published":"2024-11-14T06:19:18Z","title":"Comprehensive and Practical Evaluation of Retrieval-Augmented Generation\n  Systems for Medical Question Answering","summary":"  Retrieval-augmented generation (RAG) has emerged as a promising approach to\nenhance the performance of large language models (LLMs) in knowledge-intensive\ntasks such as those from medical domain. However, the sensitive nature of the\nmedical domain necessitates a completely accurate and trustworthy system. While\nexisting RAG benchmarks primarily focus on the standard retrieve-answer\nsetting, they overlook many practical scenarios that measure crucial aspects of\na reliable medical system. This paper addresses this gap by providing a\ncomprehensive evaluation framework for medical question-answering (QA) systems\nin a RAG setting for these situations, including sufficiency, integration, and\nrobustness. We introduce Medical Retrieval-Augmented Generation Benchmark\n(MedRGB) that provides various supplementary elements to four medical QA\ndatasets for testing LLMs' ability to handle these specific scenarios.\nUtilizing MedRGB, we conduct extensive evaluations of both state-of-the-art\ncommercial LLMs and open-source models across multiple retrieval conditions.\nOur experimental results reveals current models' limited ability to handle\nnoise and misinformation in the retrieved documents. We further analyze the\nLLMs' reasoning processes to provides valuable insights and future directions\nfor developing RAG systems in this critical medical domain.\n","authors":["Nghia Trung Ngo","Chien Van Nguyen","Franck Dernoncourt","Thien Huu Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.09213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09181v1","updated":"2024-11-14T04:39:30Z","published":"2024-11-14T04:39:30Z","title":"DeBaTeR: Denoising Bipartite Temporal Graph for Recommendation","summary":"  Due to the difficulty of acquiring large-scale explicit user feedback,\nimplicit feedback (e.g., clicks or other interactions) is widely applied as an\nalternative source of data, where user-item interactions can be modeled as a\nbipartite graph. Due to the noisy and biased nature of implicit real-world\nuser-item interactions, identifying and rectifying noisy interactions are vital\nto enhance model performance and robustness. Previous works on purifying\nuser-item interactions in collaborative filtering mainly focus on mining the\ncorrelation between user/item embeddings and noisy interactions, neglecting the\nbenefit of temporal patterns in determining noisy interactions. Time\ninformation, while enhancing the model utility, also bears its natural\nadvantage in helping to determine noisy edges, e.g., if someone usually watches\nhorror movies at night and talk shows in the morning, a record of watching a\nhorror movie in the morning is more likely to be noisy interaction. Armed with\nthis observation, we introduce a simple yet effective mechanism for generating\ntime-aware user/item embeddings and propose two strategies for denoising\nbipartite temporal graph in recommender systems (DeBaTeR): the first is through\nreweighting the adjacency matrix (DeBaTeR-A), where a reliability score is\ndefined to reweight the edges through both soft assignment and hard assignment;\nthe second is through reweighting the loss function (DeBaTeR-L), where weights\nare generated to reweight user-item samples in the losses. Extensive\nexperiments have been conducted to demonstrate the efficacy of our methods and\nillustrate how time information indeed helps identifying noisy edges.\n","authors":["Xinyu He","Jose Sepulveda","Mostafa Rahmani","Alyssa Woo","Fei Wang","Hanghang Tong"],"pdf_url":"https://arxiv.org/pdf/2411.09181v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.09702v1","updated":"2024-11-14T18:59:40Z","published":"2024-11-14T18:59:40Z","title":"On the Surprising Effectiveness of Attention Transfer for Vision\n  Transformers","summary":"  Conventional wisdom suggests that pre-training Vision Transformers (ViT)\nimproves downstream performance by learning useful representations. Is this\nactually true? We investigate this question and find that the features and\nrepresentations learned during pre-training are not essential. Surprisingly,\nusing only the attention patterns from pre-training (i.e., guiding how\ninformation flows between tokens) is sufficient for models to learn high\nquality features from scratch and achieve comparable downstream performance. We\nshow this by introducing a simple method called attention transfer, where only\nthe attention patterns from a pre-trained teacher ViT are transferred to a\nstudent, either by copying or distilling the attention maps. Since attention\ntransfer lets the student learn its own features, ensembling it with a\nfine-tuned teacher also further improves accuracy on ImageNet. We\nsystematically study various aspects of our findings on the sufficiency of\nattention maps, including distribution shift settings where they underperform\nfine-tuning. We hope our exploration provides a better understanding of what\npre-training accomplishes and leads to a useful alternative to the standard\npractice of fine-tuning\n","authors":["Alexander C. Li","Yuandong Tian","Beidi Chen","Deepak Pathak","Xinlei Chen"],"pdf_url":"https://arxiv.org/pdf/2411.09702v1.pdf","comment":"NeurIPS 2024. Code:\n  https://github.com/alexlioralexli/attention-transfer"},{"id":"http://arxiv.org/abs/2405.09596v2","updated":"2024-11-14T18:57:09Z","published":"2024-05-15T13:43:07Z","title":"Enhancing Maritime Trajectory Forecasting via H3 Index and Causal\n  Language Modelling (CLM)","summary":"  The prediction of ship trajectories is a growing field of study in artificial\nintelligence. Traditional methods rely on the use of LSTM, GRU networks, and\neven Transformer architectures for the prediction of spatio-temporal series.\nThis study proposes a viable alternative for predicting these trajectories\nusing only GNSS positions. It considers this spatio-temporal problem as a\nnatural language processing problem. The latitude/longitude coordinates of AIS\nmessages are transformed into cell identifiers using the H3 index. Thanks to\nthe pseudo-octal representation, it becomes easier for language models to learn\nthe spatial hierarchy of the H3 index. The method is compared with a classical\nKalman filter, widely used in the maritime domain, and introduces the Fr\\'echet\ndistance as the main evaluation metric. We show that it is possible to predict\nship trajectories quite precisely up to 8 hours ahead with 30 minutes of\ncontext, using solely GNSS positions, without relying on any additional\ninformation such as speed, course, or external conditions - unlike many\ntraditional methods. We demonstrate that this alternative works well enough to\npredict trajectories worldwide.\n","authors":["Nicolas Drapier","Aladine Chetouani","Aur√©lien Chateigner"],"pdf_url":"https://arxiv.org/pdf/2405.09596v2.pdf","comment":"28 pages, 18 figures"},{"id":"http://arxiv.org/abs/2411.09686v1","updated":"2024-11-14T18:53:51Z","published":"2024-11-14T18:53:51Z","title":"Conditional regression for the Nonlinear Single-Variable Model","summary":"  Several statistical models for regression of a function $F$ on $\\mathbb{R}^d$\nwithout the statistical and computational curse of dimensionality exist, for\nexample by imposing and exploiting geometric assumptions on the distribution of\nthe data (e.g. that its support is low-dimensional), or strong smoothness\nassumptions on $F$, or a special structure $F$. Among the latter, compositional\nmodels assume $F=f\\circ g$ with $g$ mapping to $\\mathbb{R}^r$ with $r\\ll d$,\nhave been studied, and include classical single- and multi-index models and\nrecent works on neural networks. While the case where $g$ is linear is rather\nwell-understood, much less is known when $g$ is nonlinear, and in particular\nfor which $g$'s the curse of dimensionality in estimating $F$, or both $f$ and\n$g$, may be circumvented. In this paper, we consider a model\n$F(X):=f(\\Pi_\\gamma X) $ where $\\Pi_\\gamma:\\mathbb{R}^d\\to[0,\\rm{len}_\\gamma]$\nis the closest-point projection onto the parameter of a regular curve $\\gamma:\n[0,\\rm{len}_\\gamma]\\to\\mathbb{R}^d$ and $f:[0,\\rm{len}_\\gamma]\\to\\mathbb{R}^1$.\nThe input data $X$ is not low-dimensional, far from $\\gamma$, conditioned on\n$\\Pi_\\gamma(X)$ being well-defined. The distribution of the data, $\\gamma$ and\n$f$ are unknown. This model is a natural nonlinear generalization of the\nsingle-index model, which corresponds to $\\gamma$ being a line. We propose a\nnonparametric estimator, based on conditional regression, and show that under\nsuitable assumptions, the strongest of which being that $f$ is coarsely\nmonotone, it can achieve the $one$-$dimensional$ optimal min-max rate for\nnon-parametric regression, up to the level of noise in the observations, and be\nconstructed in time $\\mathcal{O}(d^2n\\log n)$. All the constants in the\nlearning bounds, in the minimal number of samples required for our bounds to\nhold, and in the computational complexity are at most low-order polynomials in\n$d$.\n","authors":["Yantao Wu","Mauro Maggioni"],"pdf_url":"https://arxiv.org/pdf/2411.09686v1.pdf","comment":"55 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.09683v1","updated":"2024-11-14T18:52:05Z","published":"2024-11-14T18:52:05Z","title":"Towards a Classification of Open-Source ML Models and Datasets for\n  Software Engineering","summary":"  Background: Open-Source Pre-Trained Models (PTMs) and datasets provide\nextensive resources for various Machine Learning (ML) tasks, yet these\nresources lack a classification tailored to Software Engineering (SE) needs.\nAims: We apply an SE-oriented classification to PTMs and datasets on a popular\nopen-source ML repository, Hugging Face (HF), and analyze the evolution of PTMs\nover time. Method: We conducted a repository mining study. We started with a\nsystematically gathered database of PTMs and datasets from the HF API. Our\nselection was refined by analyzing model and dataset cards and metadata, such\nas tags, and confirming SE relevance using Gemini 1.5 Pro. All analyses are\nreplicable, with a publicly accessible replication package. Results: The most\ncommon SE task among PTMs and datasets is code generation, with a primary focus\non software development and limited attention to software management. Popular\nPTMs and datasets mainly target software development. Among ML tasks, text\ngeneration is the most common in SE PTMs and datasets. There has been a marked\nincrease in PTMs for SE since 2023 Q2. Conclusions: This study underscores the\nneed for broader task coverage to enhance the integration of ML within SE\npractices.\n","authors":["Alexandra Gonz√°lez","Xavier Franch","David Lo","Silverio Mart√≠nez-Fern√°ndez"],"pdf_url":"https://arxiv.org/pdf/2411.09683v1.pdf","comment":"5 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.09678v1","updated":"2024-11-14T18:44:31Z","published":"2024-11-14T18:44:31Z","title":"NeuralDEM - Real-time Simulation of Industrial Particulate Flows","summary":"  Advancements in computing power have made it possible to numerically simulate\nlarge-scale fluid-mechanical and/or particulate systems, many of which are\nintegral to core industrial processes. Among the different numerical methods\navailable, the discrete element method (DEM) provides one of the most accurate\nrepresentations of a wide range of physical systems involving granular and\ndiscontinuous materials. Consequently, DEM has become a widely accepted\napproach for tackling engineering problems connected to granular flows and\npowder mechanics. Additionally, DEM can be integrated with grid-based\ncomputational fluid dynamics (CFD) methods, enabling the simulation of chemical\nprocesses taking place, e.g., in fluidized beds. However, DEM is\ncomputationally intensive because of the intrinsic multiscale nature of\nparticulate systems, restricting simulation duration or number of particles.\nTowards this end, NeuralDEM presents an end-to-end approach to replace slow\nnumerical DEM routines with fast, adaptable deep learning surrogates. NeuralDEM\nis capable of picturing long-term transport processes across different regimes\nusing macroscopic observables without any reference to microscopic model\nparameters. First, NeuralDEM treats the Lagrangian discretization of DEM as an\nunderlying continuous field, while simultaneously modeling macroscopic behavior\ndirectly as additional auxiliary fields. Second, NeuralDEM introduces\nmulti-branch neural operators scalable to real-time modeling of\nindustrially-sized scenarios - from slow and pseudo-steady to fast and\ntransient. Such scenarios have previously posed insurmountable challenges for\ndeep learning models. Notably, NeuralDEM faithfully models coupled CFD-DEM\nfluidized bed reactors of 160k CFD cells and 500k DEM particles for\ntrajectories of 28s. NeuralDEM will open many new doors to advanced engineering\nand much faster process cycles.\n","authors":["Benedikt Alkin","Tobias Kronlachner","Samuele Papa","Stefan Pirker","Thomas Lichtenegger","Johannes Brandstetter"],"pdf_url":"https://arxiv.org/pdf/2411.09678v1.pdf","comment":"Project page: https://nx-ai.github.io/NeuralDEM/"},{"id":"http://arxiv.org/abs/2411.09648v1","updated":"2024-11-14T18:17:30Z","published":"2024-11-14T18:17:30Z","title":"Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable\n  Medical Information","summary":"  This paper introduces Med-Bot, an AI-powered chatbot designed to provide\nusers with accurate and reliable medical information. Utilizing advanced\nlibraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq,\nMed-Bot is built to handle the complexities of natural language understanding\nin a healthcare context. The integration of llamaassisted data processing and\nAutoGPT-Q provides enhanced performance in processing and responding to queries\nbased on PDFs of medical literature, ensuring that users receive precise and\ntrustworthy information. This research details the methodologies employed in\ndeveloping Med-Bot and evaluates its effectiveness in disseminating healthcare\ninformation.\n","authors":["Ahan Bhatt","Nandan Vaghela"],"pdf_url":"https://arxiv.org/pdf/2411.09648v1.pdf","comment":"3 figures, 5 pages Keywords-LLM, AI-powered healthcare, Medical\n  chatbot, Context-based interaction, Llama-assisted data processing,\n  AutoGPT-Q, PyTorch, TensorFlow, Reliable medical information, Machine\n  learning in healthcare, Conversational AI"},{"id":"http://arxiv.org/abs/2411.09645v1","updated":"2024-11-14T18:14:32Z","published":"2024-11-14T18:14:32Z","title":"How do Machine Learning Models Change?","summary":"  The proliferation of Machine Learning (ML) models and their open-source\nimplementations has transformed Artificial Intelligence research and\napplications. Platforms like Hugging Face (HF) enable the development, sharing,\nand deployment of these models, fostering an evolving ecosystem. While previous\nstudies have examined aspects of models hosted on platforms like HF, a\ncomprehensive longitudinal study of how these models change remains\nunderexplored. This study addresses this gap by utilizing both repository\nmining and longitudinal analysis methods to examine over 200,000 commits and\n1,200 releases from over 50,000 models on HF. We replicate and extend an ML\nchange taxonomy for classifying commits and utilize Bayesian networks to\nuncover patterns in commit and release activities over time. Our findings\nindicate that commit activities align with established data science\nmethodologies, such as CRISP-DM, emphasizing iterative refinement and\ncontinuous improvement. Additionally, release patterns tend to consolidate\nsignificant updates, particularly in documentation, distinguishing between\ngranular changes and milestone-based releases. Furthermore, projects with\nhigher popularity prioritize infrastructure enhancements early in their\nlifecycle, and those with intensive collaboration practices exhibit improved\ndocumentation standards. These and other insights enhance the understanding of\nmodel changes on community platforms and provide valuable guidance for best\npractices in model maintenance.\n","authors":["Joel Casta√±o","Rafael Caba√±as","Antonio Salmer√≥n","David Lo","Silverio Mart√≠nez-Fern√°ndez"],"pdf_url":"https://arxiv.org/pdf/2411.09645v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04783v2","updated":"2024-11-14T18:14:00Z","published":"2024-03-02T16:52:22Z","title":"AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks","summary":"  Despite extensive pre-training in moral alignment to prevent generating\nharmful information, large language models (LLMs) remain vulnerable to\njailbreak attacks. In this paper, we propose AutoDefense, a multi-agent defense\nframework that filters harmful responses from LLMs. With the response-filtering\nmechanism, our framework is robust against different jailbreak attack prompts,\nand can be used to defend different victim models. AutoDefense assigns\ndifferent roles to LLM agents and employs them to complete the defense task\ncollaboratively. The division in tasks enhances the overall\ninstruction-following of LLMs and enables the integration of other defense\ncomponents as tools. With AutoDefense, small open-source LMs can serve as\nagents and defend larger models against jailbreak attacks. Our experiments show\nthat AutoDefense can effectively defense against different jailbreak attacks,\nwhile maintaining the performance at normal user request. For example, we\nreduce the attack success rate on GPT-3.5 from 55.74% to 7.95% using\nLLaMA-2-13b with a 3-agent system. Our code and data are publicly available at\nhttps://github.com/XHMY/AutoDefense.\n","authors":["Yifan Zeng","Yiran Wu","Xiao Zhang","Huazheng Wang","Qingyun Wu"],"pdf_url":"https://arxiv.org/pdf/2403.04783v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09644v1","updated":"2024-11-14T18:12:06Z","published":"2024-11-14T18:12:06Z","title":"Neural Operators Can Play Dynamic Stackelberg Games","summary":"  Dynamic Stackelberg games are a broad class of two-player games in which the\nleader acts first, and the follower chooses a response strategy to the leader's\nstrategy. Unfortunately, only stylized Stackelberg games are explicitly\nsolvable since the follower's best-response operator (as a function of the\ncontrol of the leader) is typically analytically intractable. This paper\naddresses this issue by showing that the \\textit{follower's best-response\noperator} can be approximately implemented by an \\textit{attention-based neural\noperator}, uniformly on compact subsets of adapted open-loop controls for the\nleader. We further show that the value of the Stackelberg game where the\nfollower uses the approximate best-response operator approximates the value of\nthe original Stackelberg game. Our main result is obtained using our universal\napproximation theorem for attention-based neural operators between spaces of\nsquare-integrable adapted stochastic processes, as well as stability results\nfor a general class of Stackelberg games.\n","authors":["Guillermo Alvarez","Ibrahim Ekren","Anastasis Kratsios","Xuwei Yang"],"pdf_url":"https://arxiv.org/pdf/2411.09644v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09642v1","updated":"2024-11-14T18:06:55Z","published":"2024-11-14T18:06:55Z","title":"On the Limits of Language Generation: Trade-Offs Between Hallucination\n  and Mode Collapse","summary":"  Specifying all desirable properties of a language model is challenging, but\ncertain requirements seem essential. Given samples from an unknown language,\nthe trained model should produce valid strings not seen in training and be\nexpressive enough to capture the language's full richness. Otherwise,\noutputting invalid strings constitutes \"hallucination,\" and failing to capture\nthe full range leads to \"mode collapse.\" We ask if a language model can meet\nboth requirements.\n  We investigate this within a statistical language generation setting building\non Gold and Angluin. Here, the model receives random samples from a\ndistribution over an unknown language K, which belongs to a possibly infinite\ncollection of languages. The goal is to generate unseen strings from K. We say\nthe model generates from K with consistency and breadth if, as training size\nincreases, its output converges to all unseen strings in K.\n  Kleinberg and Mullainathan [KM24] asked if consistency and breadth in\nlanguage generation are possible. We answer this negatively: for a large class\nof language models, including next-token prediction models, this is impossible\nfor most collections of candidate languages. This contrasts with [KM24]'s\nresult, showing consistent generation without breadth is possible for any\ncountable collection of languages. Our finding highlights that generation with\nbreadth fundamentally differs from generation without breadth.\n  As a byproduct, we establish near-tight bounds on the number of samples\nneeded for generation with or without breadth.\n  Finally, our results offer hope: consistent generation with breadth is\nachievable for any countable collection of languages when negative examples\n(strings outside K) are available alongside positive ones. This suggests that\npost-training feedback, which encodes negative examples, can be crucial in\nreducing hallucinations while limiting mode collapse.\n","authors":["Alkis Kalavasis","Anay Mehrotra","Grigoris Velegkas"],"pdf_url":"https://arxiv.org/pdf/2411.09642v1.pdf","comment":"Abstract shortened to fit arXiv limit"},{"id":"http://arxiv.org/abs/2411.09639v1","updated":"2024-11-14T18:03:44Z","published":"2024-11-14T18:03:44Z","title":"MCCE: Missingness-aware Causal Concept Explainer","summary":"  Causal concept effect estimation is gaining increasing interest in the field\nof interpretable machine learning. This general approach explains the behaviors\nof machine learning models by estimating the causal effect of\nhuman-understandable concepts, which represent high-level knowledge more\ncomprehensibly than raw inputs like tokens. However, existing causal concept\neffect explanation methods assume complete observation of all concepts involved\nwithin the dataset, which can fail in practice due to incomplete annotations or\nmissing concept data. We theoretically demonstrate that unobserved concepts can\nbias the estimation of the causal effects of observed concepts. To address this\nlimitation, we introduce the Missingness-aware Causal Concept Explainer (MCCE),\na novel framework specifically designed to estimate causal concept effects when\nnot all concepts are observable. Our framework learns to account for residual\nbias resulting from missing concepts and utilizes a linear predictor to model\nthe relationships between these concepts and the outputs of black-box machine\nlearning models. It can offer explanations on both local and global levels. We\nconduct validations using a real-world dataset, demonstrating that MCCE\nachieves promising performance compared to state-of-the-art explanation methods\nin causal concept effect estimation.\n","authors":["Jifan Gao","Guanhua Chen"],"pdf_url":"https://arxiv.org/pdf/2411.09639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09635v1","updated":"2024-11-14T18:01:02Z","published":"2024-11-14T18:01:02Z","title":"Counterfactual Uncertainty Quantification of Factual Estimand of\n  Efficacy from Before-and-After Treatment Repeated Measures Randomized\n  Controlled Trials","summary":"  The ideal estimand for comparing a new treatment $Rx$ with a control $C$ is\nthe $\\textit{counterfactual}$ efficacy $Rx:C$, the expected differential\noutcome between $Rx$ and $C$ if each patient were given $\\textit{both}$. While\ncounterfactual $\\textit{point estimation}$ from $\\textit{factual}$ Randomized\nControlled Trials (RCTs) has been available, this article shows\n$\\textit{counterfactual}$ uncertainty quantification (CUQ), quantifying\nuncertainty for factual point estimates but in a counterfactual setting, is\nsurprisingly achievable. We achieve CUQ whose variability is typically smaller\nthan factual UQ, by creating a new statistical modeling principle called ETZ\nwhich is applicable to RCTs with $\\textit{Before-and-After}$ treatment Repeated\nMeasures, common in many therapeutic areas.\n  We urge caution when estimate of the unobservable true condition of a patient\nbefore treatment has measurement error, because that violation of standard\nregression assumption can cause attenuation in estimating treatment effects.\nFortunately, we prove that, for traditional medicine in general, and for\ntargeted therapy with efficacy defined as averaged over the population,\ncounterfactual point estimation is unbiased. However, for targeted therapy,\nboth Real Human and Digital Twins approaches should respect this limitation,\nlest predicted treatment effect in $\\textit{subgroups}$ will have bias.\n","authors":["Xingya Wang","Yang Han","Yushi Liu","Szu-Yu Tang","Jason C. Hsu"],"pdf_url":"https://arxiv.org/pdf/2411.09635v1.pdf","comment":"39 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.09625v1","updated":"2024-11-14T17:49:27Z","published":"2024-11-14T17:49:27Z","title":"Local deployment of large-scale music AI models on commodity hardware","summary":"  We present the MIDInfinite, a web application capable of generating symbolic\nmusic using a large-scale generative AI model locally on commodity hardware.\nCreating this demo involved porting the Anticipatory Music Transformer, a large\nlanguage model (LLM) pre-trained on the Lakh MIDI dataset, to the Machine\nLearning Compilation (MLC) framework. Once the model is ported, MLC facilitates\ninference on a variety of runtimes including C++, mobile, and the browser. We\nenvision that MLC has the potential to bridge the gap between the landscape of\nincreasingly capable music AI models and technology more familiar to music\nsoftware developers. As a proof of concept, we build a web application that\nallows users to generate endless streams of multi-instrumental MIDI in the\nbrowser, either from scratch or conditioned on a prompt. On commodity hardware\n(an M3 Macbook Pro), our demo can generate 51 notes per second, which is faster\nthan real-time playback for 72.9% of generations, and increases to 86.3% with 2\nseconds of upfront buffering.\n","authors":["Xun Zhou","Charlie Ruan","Zihe Zhao","Tianqi Chen","Chris Donahue"],"pdf_url":"https://arxiv.org/pdf/2411.09625v1.pdf","comment":"2 pages"},{"id":"http://arxiv.org/abs/2411.09618v1","updated":"2024-11-14T17:37:19Z","published":"2024-11-14T17:37:19Z","title":"MICCAI-CDMRI 2023 QuantConn Challenge Findings on Achieving Robust\n  Quantitative Connectivity through Harmonized Preprocessing of Diffusion MRI","summary":"  White matter alterations are increasingly implicated in neurological diseases\nand their progression. International-scale studies use diffusion-weighted\nmagnetic resonance imaging (DW-MRI) to qualitatively identify changes in white\nmatter microstructure and connectivity. Yet, quantitative analysis of DW-MRI\ndata is hindered by inconsistencies stemming from varying acquisition\nprotocols. There is a pressing need to harmonize the preprocessing of DW-MRI\ndatasets to ensure the derivation of robust quantitative diffusion metrics\nacross acquisitions. In the MICCAI-CDMRI 2023 QuantConn challenge, participants\nwere provided raw data from the same individuals collected on the same scanner\nbut with two different acquisitions and tasked with preprocessing the DW-MRI to\nminimize acquisition differences while retaining biological variation.\nSubmissions are evaluated on the reproducibility and comparability of\ncross-acquisition bundle-wise microstructure measures, bundle shape features,\nand connectomics. The key innovations of the QuantConn challenge are that (1)\nwe assess bundles and tractography in the context of harmonization for the\nfirst time, (2) we assess connectomics in the context of harmonization for the\nfirst time, and (3) we have 10x additional subjects over prior harmonization\nchallenge, MUSHAC and 100x over SuperMUDI. We find that bundle surface area,\nfractional anisotropy, connectome assortativity, betweenness centrality, edge\ncount, modularity, nodal strength, and participation coefficient measures are\nmost biased by acquisition and that machine learning voxel-wise correction,\nRISH mapping, and NeSH methods effectively reduce these biases. In addition,\nmicrostructure measures AD, MD, RD, bundle length, connectome density,\nefficiency, and path length are least biased by these acquisition differences.\n","authors":["Nancy R. Newlin","Kurt Schilling","Serge Koudoro","Bramsh Qamar Chandio","Praitayini Kanakaraj","Daniel Moyer","Claire E. Kelly","Sila Genc","Jian Chen","Joseph Yuan-Mou Yang","Ye Wu","Yifei He","Jiawei Zhang","Qingrun Zeng","Fan Zhang","Nagesh Adluru","Vishwesh Nath","Sudhir Pathak","Walter Schneider","Anurag Gade","Yogesh Rathi","Tom Hendriks","Anna Vilanova","Maxime Chamberland","Tomasz Pieciak","Dominika Ciupek","Antonio Trist√°n Vega","Santiago Aja-Fern√°ndez","Maciej Malawski","Gani Ouedraogo","Julia Machnio","Christian Ewert","Paul M. Thompson","Neda Jahanshad","Eleftherios Garyfallidis","Bennett A. Landman"],"pdf_url":"https://arxiv.org/pdf/2411.09618v1.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024/019"},{"id":"http://arxiv.org/abs/2411.09612v1","updated":"2024-11-14T17:32:03Z","published":"2024-11-14T17:32:03Z","title":"The Moral Foundations Weibo Corpus","summary":"  Moral sentiments expressed in natural language significantly influence both\nonline and offline environments, shaping behavioral styles and interaction\npatterns, including social media selfpresentation, cyberbullying, adherence to\nsocial norms, and ethical decision-making. To effectively measure moral\nsentiments in natural language processing texts, it is crucial to utilize\nlarge, annotated datasets that provide nuanced understanding for accurate\nanalysis and modeltraining. However, existing corpora, while valuable, often\nface linguistic limitations. To address this gap in the Chinese language\ndomain,we introduce the Moral Foundation Weibo Corpus. This corpus consists of\n25,671 Chinese comments on Weibo, encompassing six diverse topic areas. Each\ncomment is manually annotated by at least three systematically trained\nannotators based on ten moral categories derived from a grounded theory of\nmorality. To assess annotator reliability, we present the kappa testresults, a\ngold standard for measuring consistency. Additionally, we apply several the\nlatest large language models to supplement the manual annotations, conducting\nanalytical experiments to compare their performance and report baseline results\nfor moral sentiment classification.\n","authors":["Renjie Cao","Miaoyan Hu","Jiahan Wei","Baha Ihnaini"],"pdf_url":"https://arxiv.org/pdf/2411.09612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07104v2","updated":"2024-11-14T17:28:37Z","published":"2024-11-11T16:27:25Z","title":"Learning Multi-Agent Loco-Manipulation for Long-Horizon Quadrupedal\n  Pushing","summary":"  Recently, quadrupedal locomotion has achieved significant success, but their\nmanipulation capabilities, particularly in handling large objects, remain\nlimited, restricting their usefulness in demanding real-world applications such\nas search and rescue, construction, industrial automation, and room\norganization. This paper tackles the task of obstacle-aware, long-horizon\npushing by multiple quadrupedal robots. We propose a hierarchical multi-agent\nreinforcement learning framework with three levels of control. The high-level\ncontroller integrates an RRT planner and a centralized adaptive policy to\ngenerate subgoals, while the mid-level controller uses a decentralized\ngoal-conditioned policy to guide the robots toward these sub-goals. A\npre-trained low-level locomotion policy executes the movement commands. We\nevaluate our method against several baselines in simulation, demonstrating\nsignificant improvements over baseline approaches, with 36.0% higher success\nrates and 24.5% reduction in completion time than the best baseline. Our\nframework successfully enables long-horizon, obstacle-aware manipulation tasks\nlike Push-Cuboid and Push-T on Go1 robots in the real world.\n","authors":["Yuming Feng","Chuye Hong","Yaru Niu","Shiqi Liu","Yuxiang Yang","Wenhao Yu","Tingnan Zhang","Jie Tan","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.07104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09600v1","updated":"2024-11-14T17:18:24Z","published":"2024-11-14T17:18:24Z","title":"Latency Optimization in LEO Satellite Communications with Hybrid Beam\n  Pattern and Interference Control","summary":"  The rapid advancement of low Earth orbit (LEO) satellite communication\nsystems has significantly enhanced global connectivity, offering high-capacity,\nlow-latency services crucial for next-generation applications. However, the\ndense configuration of LEO constellations poses challenges in resource\nallocation optimization and interference management, complicating coexistence\nwith other communication systems. To address these limitations, this paper\nproposes a novel framework for optimizing the beam scheduling and resource\nallocation in multi-beam LEO systems. To satisfy the uneven terrestrial traffic\ndemand, a hybrid beam pattern is employed to enhance the downlink quality of\nservice and minimize the transmission latency from LEO satellites to ground\nuser terminals. Additionally, a dynamic co-channel interference (CCI) control\nmechanism is developed to mitigate inter-beam interference within the LEO\nconstellation and limit cross-system interference affecting protected users\nfrom other networks. The problem of user-beam-frequency allocation with power\noptimization is formulated as a mixed-integer dynamic programming model and\nsolved using a low-complexity neural network-based graph generation algorithm.\nSimulation results show that the proposed approach outperforms the baseline\nmethods of full frequency reuse and single-channel transmission, and highlights\nthe potential for further performance improvement with multi-user\ntransmissions.\n","authors":["Qianqian Zhang","Ye Hu","Minchae Jung"],"pdf_url":"https://arxiv.org/pdf/2411.09600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09595v1","updated":"2024-11-14T17:08:23Z","published":"2024-11-14T17:08:23Z","title":"LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models","summary":"  This work explores expanding the capabilities of large language models (LLMs)\npretrained on text to generate 3D meshes within a unified model. This offers\nkey advantages of (1) leveraging spatial knowledge already embedded in LLMs,\nderived from textual sources like 3D tutorials, and (2) enabling conversational\n3D generation and mesh understanding. A primary challenge is effectively\ntokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly.\nTo address this, we introduce LLaMA-Mesh, a novel approach that represents the\nvertex coordinates and face definitions of 3D meshes as plain text, allowing\ndirect integration with LLMs without expanding the vocabulary. We construct a\nsupervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate\n3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs\nas required, and (3) understand and interpret 3D meshes. Our work is the first\nto demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge\nfor 3D mesh generation in a text-based format, effectively unifying the 3D and\ntext modalities. LLaMA-Mesh achieves mesh generation quality on par with models\ntrained from scratch while maintaining strong text generation performance.\n","authors":["Zhengyi Wang","Jonathan Lorraine","Yikai Wang","Hang Su","Jun Zhu","Sanja Fidler","Xiaohui Zeng"],"pdf_url":"https://arxiv.org/pdf/2411.09595v1.pdf","comment":"See the project website at\n  https://research.nvidia.com/labs/toronto-ai/LLaMA-Mesh/"},{"id":"http://arxiv.org/abs/2410.18958v2","updated":"2024-11-14T17:06:55Z","published":"2024-10-24T17:55:52Z","title":"Stable Consistency Tuning: Understanding and Improving Consistency\n  Models","summary":"  Diffusion models achieve superior generation quality but suffer from slow\ngeneration speed due to the iterative nature of denoising. In contrast,\nconsistency models, a new generative family, achieve competitive performance\nwith significantly faster sampling. These models are trained either through\nconsistency distillation, which leverages pretrained diffusion models, or\nconsistency training/tuning directly from raw data. In this work, we propose a\nnovel framework for understanding consistency models by modeling the denoising\nprocess of the diffusion model as a Markov Decision Process (MDP) and framing\nconsistency model training as the value estimation through Temporal\nDifference~(TD) Learning. More importantly, this framework allows us to analyze\nthe limitations of current consistency training/tuning strategies. Built upon\nEasy Consistency Tuning (ECT), we propose Stable Consistency Tuning (SCT),\nwhich incorporates variance-reduced learning using the score identity. SCT\nleads to significant performance improvements on benchmarks such as CIFAR-10\nand ImageNet-64. On ImageNet-64, SCT achieves 1-step FID 2.42 and 2-step FID\n1.55, a new SoTA for consistency models.\n","authors":["Fu-Yun Wang","Zhengyang Geng","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2410.18958v2.pdf","comment":"Code is available at\n  https://github.com/G-U-N/Stable-Consistency-Tuning"},{"id":"http://arxiv.org/abs/2411.09591v1","updated":"2024-11-14T17:02:41Z","published":"2024-11-14T17:02:41Z","title":"Expert Study on Interpretable Machine Learning Models with Missing Data","summary":"  Inherently interpretable machine learning (IML) models provide valuable\ninsights for clinical decision-making but face challenges when features have\nmissing values. Classical solutions like imputation or excluding incomplete\nrecords are often unsuitable in applications where values are missing at test\ntime. In this work, we conducted a survey with 71 clinicians from 29 trauma\ncenters across France, including 20 complete responses to study the interaction\nbetween medical professionals and IML applied to data with missing values. This\nprovided valuable insights into how missing data is interpreted in clinical\nmachine learning. We used the prediction of hemorrhagic shock as a concrete\nexample to gauge the willingness and readiness of the participants to adopt IML\nmodels from three classes of methods. Our findings show that, while clinicians\nvalue interpretability and are familiar with common IML methods, classical\nimputation techniques often misalign with their intuition, and that models that\nnatively handle missing values are preferred. These results emphasize the need\nto integrate clinical intuition into future IML models for better\nhuman-computer interaction.\n","authors":["Lena Stempfle","Arthur James","Julie Josse","Tobias Gauss","Fredrik D. Johansson"],"pdf_url":"https://arxiv.org/pdf/2411.09591v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 13 pages"},{"id":"http://arxiv.org/abs/2407.16677v3","updated":"2024-11-14T16:54:02Z","published":"2024-07-23T17:44:54Z","title":"From Imitation to Refinement -- Residual RL for Precise Assembly","summary":"  Advances in behavior cloning (BC), like action-chunking and diffusion, have\nenabled impressive capabilities. Still, imitation alone remains insufficient\nfor learning reliable policies for tasks requiring precise aligning and\ninserting of objects, like assembly. Our key insight is that chunked BC\npolicies effectively function as trajectory planners, enabling long-horizon\ntasks. Conversely, as they execute action chunks open-loop, they lack the\nfine-grained reactivity necessary for reliable execution. Further, we find that\nthe performance of BC policies saturates despite increasing data. Reinforcement\nlearning (RL) is a natural way to overcome BC's limitations, but it is not\nstraightforward to apply directly to action-chunked models like diffusion\npolicies. We present a simple yet effective method, ResiP (Residual for Precise\nManipulation), that sidesteps these challenges by augmenting a frozen, chunked\nBC model with a fully closed-loop residual policy trained with RL. The residual\npolicy is trained via on-policy RL, addressing distribution shifts and\nintroducing reactive control without altering the BC trajectory planner.\nEvaluation on high-precision manipulation tasks demonstrates strong performance\nof ResiP over BC methods and direct RL fine-tuning. Videos, code, and data are\navailable at https://residual-assembly.github.io.\n","authors":["Lars Ankile","Anthony Simeonov","Idan Shenfeld","Marcel Torne","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2407.16677v3.pdf","comment":"Project website: https://residual-assembly.github.io"},{"id":"http://arxiv.org/abs/2402.02681v3","updated":"2024-11-14T16:30:13Z","published":"2024-02-05T02:35:11Z","title":"Equivariant Symmetry Breaking Sets","summary":"  Equivariant neural networks (ENNs) have been shown to be extremely effective\nin applications involving underlying symmetries. By construction ENNs cannot\nproduce lower symmetry outputs given a higher symmetry input. However, symmetry\nbreaking occurs in many physical systems and we may obtain a less symmetric\nstable state from an initial highly symmetric one. Hence, it is imperative that\nwe understand how to systematically break symmetry in ENNs. In this work, we\npropose a novel symmetry breaking framework that is fully equivariant and is\nthe first which fully addresses spontaneous symmetry breaking. We emphasize\nthat our approach is general and applicable to equivariance under any group. To\nachieve this, we introduce the idea of symmetry breaking sets (SBS). Rather\nthan redesign existing networks, we design sets of symmetry breaking objects\nwhich we feed into our network based on the symmetry of our inputs and outputs.\nWe show there is a natural way to define equivariance on these sets, which\ngives an additional constraint. Minimizing the size of these sets equates to\ndata efficiency. We prove that minimizing these sets translates to a well\nstudied group theory problem, and tabulate solutions to this problem for the\npoint groups. Finally, we provide some examples of symmetry breaking to\ndemonstrate how our approach works in practice. The code for these examples is\navailable at \\url{https://github.com/atomicarchitects/equivariant-SBS}.\n","authors":["YuQing Xie","Tess Smidt"],"pdf_url":"https://arxiv.org/pdf/2402.02681v3.pdf","comment":"50 pages, 19 figures Published in Transactions on Machine Learning\n  Research, October 2024"},{"id":"http://arxiv.org/abs/2411.01881v2","updated":"2024-11-14T16:17:40Z","published":"2024-11-04T08:24:56Z","title":"Causal Discovery and Classification Using Lempel-Ziv Complexity","summary":"  Inferring causal relationships in the decision-making processes of machine\nlearning algorithms is a crucial step toward achieving explainable Artificial\nIntelligence (AI). In this research, we introduce a novel causality measure and\na distance metric derived from Lempel-Ziv (LZ) complexity. We explore how the\nproposed causality measure can be used in decision trees by enabling splits\nbased on features that most strongly \\textit{cause} the outcome. We further\nevaluate the effectiveness of the causality-based decision tree and the\ndistance-based decision tree in comparison to a traditional decision tree using\nGini impurity. While the proposed methods demonstrate comparable classification\nperformance overall, the causality-based decision tree significantly\noutperforms both the distance-based decision tree and the Gini-based decision\ntree on datasets generated from causal models. This result indicates that the\nproposed approach can capture insights beyond those of classical decision\ntrees, especially in causally structured data. Based on the features used in\nthe LZ causal measure based decision tree, we introduce a causal strength for\neach features in the dataset so as to infer the predominant causal variables\nfor the occurrence of the outcome.\n","authors":[" Dhruthi","Nithin Nagaraj","Harikrishnan N B"],"pdf_url":"https://arxiv.org/pdf/2411.01881v2.pdf","comment":"17 pages, 8 figures, 5 tables"},{"id":"http://arxiv.org/abs/2411.06503v2","updated":"2024-11-14T16:15:20Z","published":"2024-11-10T15:57:53Z","title":"Diffusion Sampling Correction via Approximately 10 Parameters","summary":"  Diffusion Probabilistic Models (DPMs) have demonstrated exceptional\nperformance in generative tasks, but this comes at the expense of sampling\nefficiency. To enhance sampling speed without sacrificing quality, various\ndistillation-based accelerated sampling algorithms have been recently proposed.\nHowever, they typically require significant additional training costs and model\nparameter storage, which limit their practical application. In this work, we\npropose PCA-based Adaptive Search (PAS), which optimizes existing solvers for\nDPMs with minimal learnable parameters and training costs. Specifically, we\nfirst employ PCA to obtain a few orthogonal unit basis vectors to span the\nhigh-dimensional sampling space, which enables us to learn just a set of\ncoordinates to correct the sampling direction; furthermore, based on the\nobservation that the cumulative truncation error exhibits an ``S''-shape, we\ndesign an adaptive search strategy that further enhances the sampling\nefficiency and reduces the number of stored parameters to approximately 10.\nExtensive experiments demonstrate that PAS can significantly enhance existing\nfast solvers in a plug-and-play manner with negligible costs. For instance, on\nCIFAR10, PAS requires only 12 parameters and less than 1 minute of training on\na single NVIDIA A100 GPU to optimize the DDIM from 15.69 FID (NFE=10) to 4.37.\n","authors":["Guangyi Wang","Wei Peng","Lijiang Li","Wenyu Chen","Yuren Cai","Songzhi Su"],"pdf_url":"https://arxiv.org/pdf/2411.06503v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09558v1","updated":"2024-11-14T16:10:15Z","published":"2024-11-14T16:10:15Z","title":"Adaptive Deviation Learning for Visual Anomaly Detection with Data\n  Contamination","summary":"  Visual anomaly detection targets to detect images that notably differ from\nnormal pattern, and it has found extensive application in identifying defective\nparts within the manufacturing industry. These anomaly detection paradigms\npredominantly focus on training detection models using only clean, unlabeled\nnormal samples, assuming an absence of contamination; a condition often unmet\nin real-world scenarios. The performance of these methods significantly depends\non the quality of the data and usually decreases when exposed to noise. We\nintroduce a systematic adaptive method that employs deviation learning to\ncompute anomaly scores end-to-end while addressing data contamination by\nassigning relative importance to the weights of individual instances. In this\napproach, the anomaly scores for normal instances are designed to approximate\nscalar scores obtained from the known prior distribution. Meanwhile, anomaly\nscores for anomaly examples are adjusted to exhibit statistically significant\ndeviations from these reference scores. Our approach incorporates a constrained\noptimization problem within the deviation learning framework to update instance\nweights, resolving this problem for each mini-batch. Comprehensive experiments\non the MVTec and VisA benchmark datasets indicate that our proposed method\nsurpasses competing techniques and exhibits both stability and robustness in\nthe presence of data contamination.\n","authors":["Anindya Sundar Das","Guansong Pang","Monowar Bhuyan"],"pdf_url":"https://arxiv.org/pdf/2411.09558v1.pdf","comment":"Accepted to IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV 2025)"},{"id":"http://arxiv.org/abs/2411.09545v1","updated":"2024-11-14T15:59:41Z","published":"2024-11-14T15:59:41Z","title":"Equation-informed data-driven identification of flow budgets and\n  dynamics","summary":"  Computational Fluid Dynamics (CFD) is an indispensable method of fluid\nmodelling in engineering applications, reducing the need for physical\nprototypes and testing for tasks such as design optimisation and performance\nanalysis. Depending on the complexity of the system under consideration, models\nranging from low to high fidelity can be used for prediction, allowing\nsignificant speed-up. However, the choice of model requires information about\nthe actual dynamics of the flow regime. Correctly identifying the\nregions/clusters of flow that share the same dynamics has been a challenging\nresearch topic to date. In this study, we propose a novel hybrid approach to\nflow clustering. It consists of characterising each sample point of the system\nwith equation-based features, i.e. features are budgets that represent the\ncontribution of each term from the original governing equation to the local\ndynamics at each sample point. This was achieved by applying the Sparse\nIdentification of Nonlinear Dynamical systems (SINDy) method pointwise to time\nevolution data. The method proceeds with equation-based clustering using the\nGirvan-Newman algorithm. This allows the detection of communities that share\nthe same physical dynamics. The algorithm is implemented in both Eulerian and\nLagrangian frameworks. In the Lagrangian, i.e. dynamic approach, the clustering\nis performed on the trajectory of each point, allowing the change of clusters\nto be represented also in time. The performance of the algorithm is first\ntested on a flow around a cylinder. The construction of the dynamic clusters in\nthis test case clearly shows the evolution of the wake from the steady state\nsolution through the transient to the oscillatory solution. Dynamic clustering\nwas then successfully tested on turbulent flow data. Two distinct and\nwell-defined clusters were identified and their temporal evolution was\nreconstructed.\n","authors":["Nataliya Sevryugina","Serena Costanzo","Steve de Bruyn Kops","Colm-cille Caulfield","Iraj Mortazavi","Taraneh Sayadi"],"pdf_url":"https://arxiv.org/pdf/2411.09545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09540v1","updated":"2024-11-14T15:56:11Z","published":"2024-11-14T15:56:11Z","title":"Prompting the Unseen: Detecting Hidden Backdoors in Black-Box Models","summary":"  Visual prompting (VP) is a new technique that adapts well-trained frozen\nmodels for source domain tasks to target domain tasks. This study examines VP's\nbenefits for black-box model-level backdoor detection. The visual prompt in VP\nmaps class subspaces between source and target domains. We identify a\nmisalignment, termed class subspace inconsistency, between clean and poisoned\ndatasets. Based on this, we introduce \\textsc{BProm}, a black-box model-level\ndetection method to identify backdoors in suspicious models, if any.\n\\textsc{BProm} leverages the low classification accuracy of prompted models\nwhen backdoors are present. Extensive experiments confirm \\textsc{BProm}'s\neffectiveness.\n","authors":["Zi-Xuan Huang","Jia-Wei Chen","Zhi-Peng Zhang","Chia-Mu Yu"],"pdf_url":"https://arxiv.org/pdf/2411.09540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09539v1","updated":"2024-11-14T15:55:37Z","published":"2024-11-14T15:55:37Z","title":"A Practical Guide to Fine-tuning Language Models with Limited Data","summary":"  Employing pre-trained Large Language Models (LLMs) has become the de facto\nstandard in Natural Language Processing (NLP) despite their extensive data\nrequirements. Motivated by the recent surge in research focused on training\nLLMs with limited data, particularly in low-resource domains and languages,\nthis paper surveys recent transfer learning approaches to optimize model\nperformance in downstream tasks where data is scarce. We first address initial\nand continued pre-training strategies to better leverage prior knowledge in\nunseen domains and languages. We then examine how to maximize the utility of\nlimited data during fine-tuning and few-shot learning. The final section takes\na task-specific perspective, reviewing models and methods suited for different\nlevels of data scarcity. Our goal is to provide practitioners with practical\nguidelines for overcoming the challenges posed by constrained data while also\nhighlighting promising directions for future research.\n","authors":["M√°rton Sz√©p","Daniel Rueckert","R√ºdiger von Eisenhart-Rothe","Florian Hinterwimmer"],"pdf_url":"https://arxiv.org/pdf/2411.09539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09517v1","updated":"2024-11-14T15:28:40Z","published":"2024-11-14T15:28:40Z","title":"Randomized Truthful Auctions with Learning Agents","summary":"  We study a setting where agents use no-regret learning algorithms to\nparticipate in repeated auctions. \\citet{kolumbus2022auctions} showed, rather\nsurprisingly, that when bidders participate in second-price auctions using\nno-regret bidding algorithms, no matter how large the number of interactions\n$T$ is, the runner-up bidder may not converge to bidding truthfully. Our first\nresult shows that this holds for \\emph{general deterministic} truthful\nauctions. We also show that the ratio of the learning rates of the bidders can\n\\emph{qualitatively} affect the convergence of the bidders. Next, we consider\nthe problem of revenue maximization in this environment. In the setting with\nfully rational bidders, \\citet{myerson1981optimal} showed that revenue can be\nmaximized by using a second-price auction with reserves.We show that, in stark\ncontrast, in our setting with learning bidders, \\emph{randomized} auctions can\nhave strictly better revenue guarantees than second-price auctions with\nreserves, when $T$ is large enough. Finally, we study revenue maximization in\nthe non-asymptotic regime. We define a notion of {\\em auctioneer regret}\ncomparing the revenue generated to the revenue of a second price auction with\ntruthful bids. When the auctioneer has to use the same auction throughout the\ninteraction, we show an (almost) tight regret bound of $\\smash{\\widetilde\n\\Theta(T^{3/4})}.$ If the auctioneer can change auctions during the\ninteraction, but in a way that is oblivious to the bids, we show an (almost)\ntight bound of $\\smash{\\widetilde \\Theta(\\sqrt{T})}.$\n","authors":["Gagan Aggarwal","Anupam Gupta","Andres Perlroth","Grigoris Velegkas"],"pdf_url":"https://arxiv.org/pdf/2411.09517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09512v1","updated":"2024-11-14T15:26:10Z","published":"2024-11-14T15:26:10Z","title":"GAN-Based Architecture for Low-dose Computed Tomography Imaging\n  Denoising","summary":"  Generative Adversarial Networks (GANs) have surfaced as a revolutionary\nelement within the domain of low-dose computed tomography (LDCT) imaging,\nproviding an advanced resolution to the enduring issue of reconciling radiation\nexposure with image quality. This comprehensive review synthesizes the rapid\nadvancements in GAN-based LDCT denoising techniques, examining the evolution\nfrom foundational architectures to state-of-the-art models incorporating\nadvanced features such as anatomical priors, perceptual loss functions, and\ninnovative regularization strategies. We critically analyze various GAN\narchitectures, including conditional GANs (cGANs), CycleGANs, and\nSuper-Resolution GANs (SRGANs), elucidating their unique strengths and\nlimitations in the context of LDCT denoising. The evaluation provides both\nqualitative and quantitative results related to the improvements in performance\nin benchmark and clinical datasets with metrics such as PSNR, SSIM, and LPIPS.\nAfter highlighting the positive results, we discuss some of the challenges\npreventing a wider clinical use, including the interpretability of the images\ngenerated by GANs, synthetic artifacts, and the need for clinically relevant\nmetrics. The review concludes by highlighting the essential significance of\nGAN-based methodologies in the progression of precision medicine via tailored\nLDCT denoising models, underlining the transformative possibilities presented\nby artificial intelligence within contemporary radiological practice.\n","authors":["Yunuo Wang","Ningning Yang","Jialin Li"],"pdf_url":"https://arxiv.org/pdf/2411.09512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09510v1","updated":"2024-11-14T15:19:01Z","published":"2024-11-14T15:19:01Z","title":"Communication Compression for Tensor Parallel LLM Inference","summary":"  Large Language Models (LLMs) have pushed the frontier of artificial\nintelligence but are comprised of hundreds of billions of parameters and\noperations. For faster inference latency, LLMs are deployed on multiple\nhardware accelerators through various Model Parallelism strategies. Our paper\nlooks into the details on one such strategy - Tensor Parallel - and proposes to\nreduce latency by compressing inter-accelerator communication. We leverage fine\ngrained quantization techniques to compress selected activations by 3.5 - 4.5x.\nOur proposed method leads up to 2x reduction of time-to-first-token (TTFT) with\nnegligible model performance degradation.\n","authors":["Jan Hansen-Palmus","Michael Truong-Le","Oliver Hausd√∂rfer","Alok Verma"],"pdf_url":"https://arxiv.org/pdf/2411.09510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09502v1","updated":"2024-11-14T15:13:13Z","published":"2024-11-14T15:13:13Z","title":"Golden Noise for Diffusion Models: A Learning Framework","summary":"  Text-to-image diffusion model is a popular paradigm that synthesizes\npersonalized images by providing a text prompt and a random Gaussian noise.\nWhile people observe that some noises are ``golden noises'' that can achieve\nbetter text-image alignment and higher human preference than others, we still\nlack a machine learning framework to obtain those golden noises. To learn\ngolden noises for diffusion sampling, we mainly make three contributions in\nthis paper. First, we identify a new concept termed the \\textit{noise prompt},\nwhich aims at turning a random Gaussian noise into a golden noise by adding a\nsmall desirable perturbation derived from the text prompt. Following the\nconcept, we first formulate the \\textit{noise prompt learning} framework that\nsystematically learns ``prompted'' golden noise associated with a text prompt\nfor diffusion models. Second, we design a noise prompt data collection pipeline\nand collect a large-scale \\textit{noise prompt dataset}~(NPD) that contains\n100k pairs of random noises and golden noises with the associated text prompts.\nWith the prepared NPD as the training dataset, we trained a small \\textit{noise\nprompt network}~(NPNet) that can directly learn to transform a random noise\ninto a golden noise. The learned golden noise perturbation can be considered as\na kind of prompt for noise, as it is rich in semantic information and tailored\nto the given text prompt. Third, our extensive experiments demonstrate the\nimpressive effectiveness and generalization of NPNet on improving the quality\nof synthesized images across various diffusion models, including SDXL,\nDreamShaper-xl-v2-turbo, and Hunyuan-DiT. Moreover, NPNet is a small and\nefficient controller that acts as a plug-and-play module with very limited\nadditional inference and computational costs, as it just provides a golden\nnoise instead of a random noise without accessing the original pipeline.\n","authors":["Zikai Zhou","Shitong Shao","Lichen Bai","Zhiqiang Xu","Bo Han","Zeke Xie"],"pdf_url":"https://arxiv.org/pdf/2411.09502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09499v1","updated":"2024-11-14T15:06:50Z","published":"2024-11-14T15:06:50Z","title":"Developement of Reinforcement Learning based Optimisation Method for\n  Side-Sill Design","summary":"  Optimisation for crashworthiness is a critical part of the vehicle\ndevelopment process. Due to stringent regulations and increasing market\ndemands, multiple factors must be considered within a limited timeframe.\nHowever, for optimal crashworthiness design, multiobjective optimisation is\nnecessary, and for complex parts, multiple design parameters must be evaluated.\nThis crashworthiness analysis requires computationally intensive finite element\nsimulations. This challenge leads to the need for inverse multi-parameter\nmulti-objective optimisation. This challenge leads to the need for\nmulti-parameter, multi-objective inverse optimisation. This article\ninvestigates a machine learning-based method for this type of optimisation,\nfocusing on the design optimisation of a multi-cell side sill to improve\ncrashworthiness results. Furthermore, the optimiser is coupled with an FE\nsolver to achieve improved results.\n","authors":["Aditya Borse","Rutwik Gulakala","Marcus Stoffel"],"pdf_url":"https://arxiv.org/pdf/2411.09499v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.03648v3","updated":"2024-11-14T15:06:12Z","published":"2023-08-07T14:58:53Z","title":"Generative Forests","summary":"  We focus on generative AI for a type of data that still represent one of the\nmost prevalent form of data: tabular data. Our paper introduces two key\ncontributions: a new powerful class of forest-based models fit for such tasks\nand a simple training algorithm with strong convergence guarantees in a\nboosting model that parallels that of the original weak / strong supervised\nlearning setting. This algorithm can be implemented by a few tweaks to the most\npopular induction scheme for decision tree induction (i.e. supervised learning)\nwith two classes. Experiments on the quality of generated data display\nsubstantial improvements compared to the state of the art. The losses our\nalgorithm minimize and the structure of our models make them practical for\nrelated tasks that require fast estimation of a density given a generative\nmodel and an observation (even partially specified): such tasks include missing\ndata imputation and density estimation. Additional experiments on these tasks\nreveal that our models can be notably good contenders to diverse state of the\nart methods, relying on models as diverse as (or mixing elements of) trees,\nneural nets, kernels or graphical models.\n","authors":["Richard Nock","Mathieu Guillame-Bert"],"pdf_url":"https://arxiv.org/pdf/2308.03648v3.pdf","comment":"NeurIPS'24"},{"id":"http://arxiv.org/abs/2410.01440v3","updated":"2024-11-14T15:04:33Z","published":"2024-10-02T11:42:49Z","title":"Closed-Loop Long-Horizon Robotic Planning via Equilibrium Sequence\n  Modeling","summary":"  In the endeavor to make autonomous robots take actions, task planning is a\nmajor challenge that requires translating high-level task descriptions into\nlong-horizon action sequences. Despite recent advances in language model\nagents, they remain prone to planning errors and limited in their ability to\nplan ahead. To address these limitations in robotic planning, we advocate a\nself-refining scheme that iteratively refines a draft plan until an equilibrium\nis reached. Remarkably, this process can be optimized end-to-end from an\nanalytical perspective without the need to curate additional verifiers or\nreward models, allowing us to train self-refining planners in a simple\nsupervised learning fashion. Meanwhile, a nested equilibrium sequence modeling\nprocedure is devised for efficient closed-loop planning that incorporates\nuseful feedback from the environment (or an internal world model). Our method\nis evaluated on the VirtualHome-Env benchmark, showing advanced performance\nwith better scaling for inference computation. Code is available at\nhttps://github.com/Singularity0104/equilibrium-planner.\n","authors":["Jinghan Li","Zhicheng Sun","Fei Li","Cao Sheng","Jiazhong Yu","Yadong Mu"],"pdf_url":"https://arxiv.org/pdf/2410.01440v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.24006v2","updated":"2024-11-14T14:58:26Z","published":"2024-10-31T15:09:36Z","title":"DiffPAD: Denoising Diffusion-based Adversarial Patch Decontamination","summary":"  In the ever-evolving adversarial machine learning landscape, developing\neffective defenses against patch attacks has become a critical challenge,\nnecessitating reliable solutions to safeguard real-world AI systems. Although\ndiffusion models have shown remarkable capacity in image synthesis and have\nbeen recently utilized to counter $\\ell_p$-norm bounded attacks, their\npotential in mitigating localized patch attacks remains largely underexplored.\nIn this work, we propose DiffPAD, a novel framework that harnesses the power of\ndiffusion models for adversarial patch decontamination. DiffPAD first performs\nsuper-resolution restoration on downsampled input images, then adopts\nbinarization, dynamic thresholding scheme and sliding window for effective\nlocalization of adversarial patches. Such a design is inspired by the\ntheoretically derived correlation between patch size and diffusion restoration\nerror that is generalized across diverse patch attack scenarios. Finally,\nDiffPAD applies inpainting techniques to the original input images with the\nestimated patch region being masked. By integrating closed-form solutions for\nsuper-resolution restoration and image inpainting into the conditional reverse\nsampling process of a pre-trained diffusion model, DiffPAD obviates the need\nfor text guidance or fine-tuning. Through comprehensive experiments, we\ndemonstrate that DiffPAD not only achieves state-of-the-art adversarial\nrobustness against patch attacks but also excels in recovering naturalistic\nimages without patch remnants. The source code is available at\nhttps://github.com/JasonFu1998/DiffPAD.\n","authors":["Jia Fu","Xiao Zhang","Sepideh Pashami","Fatemeh Rahimian","Anders Holst"],"pdf_url":"https://arxiv.org/pdf/2410.24006v2.pdf","comment":"Accepted to 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV)"},{"id":"http://arxiv.org/abs/2411.09483v1","updated":"2024-11-14T14:37:47Z","published":"2024-11-14T14:37:47Z","title":"Sparse Bayesian Generative Modeling for Compressive Sensing","summary":"  This work addresses the fundamental linear inverse problem in compressive\nsensing (CS) by introducing a new type of regularizing generative prior. Our\nproposed method utilizes ideas from classical dictionary-based CS and, in\nparticular, sparse Bayesian learning (SBL), to integrate a strong\nregularization towards sparse solutions. At the same time, by leveraging the\nnotion of conditional Gaussianity, it also incorporates the adaptability from\ngenerative models to training data. However, unlike most state-of-the-art\ngenerative models, it is able to learn from a few compressed and noisy data\nsamples and requires no optimization algorithm for solving the inverse problem.\nAdditionally, similar to Dirichlet prior networks, our model parameterizes a\nconjugate prior enabling its application for uncertainty quantification. We\nsupport our approach theoretically through the concept of variational inference\nand validate it empirically using different types of compressible signals.\n","authors":["Benedikt B√∂ck","Sadaf Syed","Wolfgang Utschick"],"pdf_url":"https://arxiv.org/pdf/2411.09483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09481v1","updated":"2024-11-14T14:37:15Z","published":"2024-11-14T14:37:15Z","title":"What makes a good BIM design: quantitative linking between design\n  behavior and quality","summary":"  In the Architecture Engineering & Construction (AEC) industry, how design\nbehaviors impact design quality remains unclear. This study proposes a novel\napproach, which, for the first time, identifies and quantitatively describes\nthe relationship between design behaviors and quality of design based on\nBuilding Information Modeling (BIM). Real-time collection and log mining are\nintegrated to collect raw data of design behaviors. Feature engineering and\nvarious machine learning models are then utilized for quantitative modeling and\ninterpretation. Results confirm an existing quantifiable relationship which can\nbe learned by various models. The best-performing model using Extremely Random\nTrees achieved an R2 value of 0.88 on the test set. Behavioral features related\nto designer's skill level and changes of design intentions are identified to\nhave significant impacts on design quality. These findings deepen our\nunderstanding of the design process and help forming BIM designs with better\nquality.\n","authors":["Xiang-Rui Ni","Peng Pan","Jia-Rui Lin"],"pdf_url":"https://arxiv.org/pdf/2411.09481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09476v1","updated":"2024-11-14T14:31:52Z","published":"2024-11-14T14:31:52Z","title":"Graph Neural Networks and Differential Equations: A hybrid approach for\n  data assimilation of fluid flows","summary":"  This study presents a novel hybrid approach that combines Graph Neural\nNetworks (GNNs) with Reynolds-Averaged Navier Stokes (RANS) equations to\nenhance the accuracy of mean flow reconstruction across a range of fluid\ndynamics applications. Traditional purely data-driven Neural Networks (NNs)\nmodels, often struggle maintaining physical consistency. Moreover, they\ntypically require large datasets to achieve reliable performances. The GNN\nframework, which naturally handles unstructured data such as complex geometries\nin Computational Fluid Dynamics (CFD), is here integrated with RANS equations\nas a physical baseline model. The methodology leverages the adjoint method,\nenabling the use of RANS-derived gradients as optimization terms in the GNN\ntraining process. This ensures that the learned model adheres to the governing\nphysics, maintaining physical consistency while improving the prediction\naccuracy. We test our approach on multiple CFD scenarios, including cases\ninvolving generalization with respect to the Reynolds number, sparse\nmeasurements, denoising and inpainting of missing portions of the mean flow.\nThe results demonstrate significant improvements in the accuracy of the\nreconstructed mean flow compared to purely data-driven models, using limited\namounts of data in the training dataset. The key strengths of this study are\nthe integration of physical laws into the training process of the GNN, and the\nability to achieve high-accuracy predictions with a limited amount of data,\nmaking this approach particularly valuable for applications in fluid dynamics\nwhere data is often scarce.\n","authors":["M. Quattromini","M. A. Bucci","S. Cherubini","O. Semeraro"],"pdf_url":"https://arxiv.org/pdf/2411.09476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09475v1","updated":"2024-11-14T14:31:30Z","published":"2024-11-14T14:31:30Z","title":"ResidualDroppath: Enhancing Feature Reuse over Residual Connections","summary":"  Residual connections are one of the most important components in neural\nnetwork architectures for mitigating the vanishing gradient problem and\nfacilitating the training of much deeper networks. One possible explanation for\nhow residual connections aid deeper network training is by promoting feature\nreuse. However, we identify and analyze the limitations of feature reuse with\nvanilla residual connections. To address these limitations, we propose\nmodifications in training methods. Specifically, we provide an additional\nopportunity for the model to learn feature reuse with residual connections\nthrough two types of iterations during training. The first type of iteration\ninvolves using droppath, which enforces feature reuse by randomly dropping a\nsubset of layers. The second type of iteration focuses on training the dropped\nparts of the model while freezing the undropped parts. As a result, the dropped\nparts learn in a way that encourages feature reuse, as the model relies on the\nundropped parts with feature reuse in mind. Overall, we demonstrated\nperformance improvements in models with residual connections for image\nclassification in certain cases.\n","authors":["Sejik Park"],"pdf_url":"https://arxiv.org/pdf/2411.09475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02407v3","updated":"2024-11-14T14:26:42Z","published":"2024-08-05T12:01:42Z","title":"Terracorder: Sense Long and Prosper","summary":"  In-situ sensing devices need to be deployed in remote environments for long\nperiods of time; minimizing their power consumption is vital for maximising\nboth their operational lifetime and coverage. We introduce Terracorder -- a\nversatile multi-sensor device -- and showcase its exceptionally low power\nconsumption using an on-device reinforcement learning scheduler. We prototype a\nunique device setup for biodiversity monitoring and compare its battery life\nusing our scheduler against a number of fixed schedules; the scheduler captures\nmore than 80% of events at less than 50% of the number of activations of the\nbest-performing fixed schedule. We then explore how a collaborative scheduler\ncan maximise the useful operation of a network of devices, improving overall\nnetwork power consumption and robustness.\n","authors":["Josh Millar","Sarab Sethi","Hamed Haddadi","Anil Madhavapeddy"],"pdf_url":"https://arxiv.org/pdf/2408.02407v3.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.01013v2","updated":"2024-11-14T14:23:29Z","published":"2024-11-01T20:33:49Z","title":"A Similarity-Based Oversampling Method for Multi-label Imbalanced Text\n  Data","summary":"  In real-world applications, as data availability increases, obtaining labeled\ndata for machine learning (ML) projects remains challenging due to the high\ncosts and intensive efforts required for data annotation. Many ML projects,\nparticularly those focused on multi-label classification, also grapple with\ndata imbalance issues, where certain classes may lack sufficient data to train\neffective classifiers. This study introduces and examines a novel oversampling\nmethod for multi-label text classification, designed to address performance\nchallenges associated with data imbalance. The proposed method identifies\npotential new samples from unlabeled data by leveraging similarity measures\nbetween instances. By iteratively searching the unlabeled dataset, the method\nlocates instances similar to those in underrepresented classes and evaluates\ntheir contribution to classifier performance enhancement. Instances that\ndemonstrate performance improvement are then added to the labeled dataset.\nExperimental results indicate that the proposed approach effectively enhances\nclassifier performance post-oversampling.\n","authors":["Ismail Hakki Karaman","Gulser Koksal","Levent Eriskin","Salih Salihoglu"],"pdf_url":"https://arxiv.org/pdf/2411.01013v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09471v1","updated":"2024-11-14T14:21:49Z","published":"2024-11-14T14:21:49Z","title":"Renal Cell Carcinoma subtyping: learning from multi-resolution\n  localization","summary":"  Renal Cell Carcinoma is typically asymptomatic at the early stages for many\npatients. This leads to a late diagnosis of the tumor, where the curability\nlikelihood is lower, and makes the mortality rate of Renal Cell Carcinoma high,\nwith respect to its incidence rate. To increase the survival chance, a fast and\ncorrect categorization of the tumor subtype is paramount. Nowadays,\ncomputerized methods, based on artificial intelligence, represent an\ninteresting opportunity to improve the productivity and the objectivity of the\nmicroscopy-based Renal Cell Carcinoma diagnosis. Nonetheless, much of their\nexploitation is hampered by the paucity of annotated dataset, essential for a\nproficient training of supervised machine learning technologies. This study\nsets out to investigate a novel self supervised training strategy for machine\nlearning diagnostic tools, based on the multi-resolution nature of the\nhistological samples. We aim at reducing the need of annotated dataset, without\nsignificantly reducing the accuracy of the tool. We demonstrate the\nclassification capability of our tool on a whole slide imaging dataset for\nRenal Cancer subtyping, and we compare our solution with several\nstate-of-the-art classification counterparts.\n","authors":["Mohamad Mohamad","Francesco Ponzio","Santa Di Cataldo","Damien Ambrosetti","Xavier Descombes"],"pdf_url":"https://arxiv.org/pdf/2411.09471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09468v1","updated":"2024-11-14T14:16:50Z","published":"2024-11-14T14:16:50Z","title":"Harnessing Machine Learning for Single-Shot Measurement of Free Electron\n  Laser Pulse Power","summary":"  Electron beam accelerators are essential in many scientific and technological\nfields. Their operation relies heavily on the stability and precision of the\nelectron beam. Traditional diagnostic techniques encounter difficulties in\naddressing the complex and dynamic nature of electron beams. Particularly in\nthe context of free-electron lasers (FELs), it is fundamentally impossible to\nmeasure the lasing-on and lasingoff electron power profiles for a single\nelectron bunch. This is a crucial hurdle in the exact reconstruction of the\nphoton pulse profile. To overcome this hurdle, we developed a machine learning\nmodel that predicts the temporal power profile of the electron bunch in the\nlasing-off regime using machine parameters that can be obtained when lasing is\non. The model was statistically validated and showed superior predictions\ncompared to the state-of-the-art batch calibrations. The work we present here\nis a critical element for a virtual pulse reconstruction diagnostic (VPRD) tool\ndesigned to reconstruct the power profile of individual photon pulses without\nrequiring repeated measurements in the lasing-off regime. This promises to\nsignificantly enhance the diagnostic capabilities in FELs at large.\n","authors":["Till Korten","Vladimir Rybnikov","Mathias Vogt","Juliane Roensch-Schulenburg","Peter Steinbach","Najmeh Mirian"],"pdf_url":"https://arxiv.org/pdf/2411.09468v1.pdf","comment":"10 pages, 4 figures, Machine Learning and the Physical Sciences\n  Workshop, NeurIPS 2024 https://neurips.cc/virtual/2024/100009"},{"id":"http://arxiv.org/abs/2402.03227v4","updated":"2024-11-14T14:11:57Z","published":"2024-02-05T17:38:49Z","title":"IGUANe: a 3D generalizable CycleGAN for multicenter harmonization of\n  brain MR images","summary":"  In MRI studies, the aggregation of imaging data from multiple acquisition\nsites enhances sample size but may introduce site-related variabilities that\nhinder consistency in subsequent analyses. Deep learning methods for image\ntranslation have emerged as a solution for harmonizing MR images across sites.\nIn this study, we introduce IGUANe (Image Generation with Unified Adversarial\nNetworks), an original 3D model that leverages the strengths of domain\ntranslation and straightforward application of style transfer methods for\nmulticenter brain MR image harmonization. IGUANe extends CycleGAN by\nintegrating an arbitrary number of domains for training through a many-to-one\narchitecture. The framework based on domain pairs enables the implementation of\nsampling strategies that prevent confusion between site-related and biological\nvariabilities. During inference, the model can be applied to any image, even\nfrom an unknown acquisition site, making it a universal generator for\nharmonization. Trained on a dataset comprising T1-weighted images from 11\ndifferent scanners, IGUANe was evaluated on data from unseen sites. The\nassessments included the transformation of MR images with traveling subjects,\nthe preservation of pairwise distances between MR images within domains, the\nevolution of volumetric patterns related to age and Alzheimer$'$s disease (AD),\nand the performance in age regression and patient classification tasks.\nComparisons with other harmonization and normalization methods suggest that\nIGUANe better preserves individual information in MR images and is more\nsuitable for maintaining and reinforcing variabilities related to age and AD.\nFuture studies may further assess IGUANe in other multicenter contexts, either\nusing the same model or retraining it for applications to different image\nmodalities. IGUANe is available at\nhttps://github.com/RocaVincent/iguane_harmonization.git.\n","authors":["Vincent Roca","Gr√©gory Kuchcinski","Jean-Pierre Pruvo","Dorian Manouvriez","Renaud Lopes"],"pdf_url":"https://arxiv.org/pdf/2402.03227v4.pdf","comment":"29 pages, 14 figures"},{"id":"http://arxiv.org/abs/2411.09459v1","updated":"2024-11-14T14:10:31Z","published":"2024-11-14T14:10:31Z","title":"Caravan MultiMet: Extending Caravan with Multiple Weather Nowcasts and\n  Forecasts","summary":"  The Caravan large-sample hydrology dataset (Kratzert et al., 2023) was\ncreated to standardize and harmonize streamflow data from various regional\ndatasets, combined with globally available meteorological forcing and catchment\nattributes. This community-driven project also allows researchers to\nconveniently extend the dataset for additional basins, as done 6 times to date\n(see https://github.com/kratzert/Caravan/discussions/10). We present a novel\nextension to Caravan, focusing on enriching the meteorological forcing data.\nOur extension adds three precipitation nowcast products (CPC, IMERG v07 Early,\nand CHIRPS) and three weather forecast products (ECMWF IFS HRES, GraphCast, and\nCHIRPS-GEFS) to the existing ERA5-Land reanalysis data. The inclusion of\ndiverse data sources, particularly weather forecasts, enables more robust\nevaluation and benchmarking of hydrological models, especially for real-time\nforecasting scenarios. To the best of our knowledge, this extension makes\nCaravan the first large-sample hydrology dataset to incorporate weather\nforecast data, significantly enhancing its capabilities and fostering\nadvancements in hydrological research, benchmarking, and real-time hydrologic\nforecasting. The data is publicly available under a CC-BY-4.0 license on Zenodo\nin two parts (https://zenodo.org/records/14161235,\nhttps://zenodo.org/records/14161281) and on Google Cloud Platform (GCP) - see\nmore under the Data Availability chapter.\n","authors":["Guy Shalev","Frederik Kratzert"],"pdf_url":"https://arxiv.org/pdf/2411.09459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09453v1","updated":"2024-11-14T13:59:01Z","published":"2024-11-14T13:59:01Z","title":"Long-Tailed Object Detection Pre-training: Dynamic Rebalancing\n  Contrastive Learning with Dual Reconstruction","summary":"  Pre-training plays a vital role in various vision tasks, such as object\nrecognition and detection. Commonly used pre-training methods, which typically\nrely on randomized approaches like uniform or Gaussian distributions to\ninitialize model parameters, often fall short when confronted with long-tailed\ndistributions, especially in detection tasks. This is largely due to extreme\ndata imbalance and the issue of simplicity bias. In this paper, we introduce a\nnovel pre-training framework for object detection, called Dynamic Rebalancing\nContrastive Learning with Dual Reconstruction (2DRCL). Our method builds on a\nHolistic-Local Contrastive Learning mechanism, which aligns pre-training with\nobject detection by capturing both global contextual semantics and detailed\nlocal patterns. To tackle the imbalance inherent in long-tailed data, we design\na dynamic rebalancing strategy that adjusts the sampling of underrepresented\ninstances throughout the pre-training process, ensuring better representation\nof tail classes. Moreover, Dual Reconstruction addresses simplicity bias by\nenforcing a reconstruction task aligned with the self-consistency principle,\nspecifically benefiting underrepresented tail classes. Experiments on COCO and\nLVIS v1.0 datasets demonstrate the effectiveness of our method, particularly in\nimproving the mAP/AP scores for tail classes.\n","authors":["Chen-Long Duan","Yong Li","Xiu-Shen Wei","Lin Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.09453v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09451v1","updated":"2024-11-14T13:56:02Z","published":"2024-11-14T13:56:02Z","title":"DiffRoad: Realistic and Diverse Road Scenario Generation for Autonomous\n  Vehicle Testing","summary":"  Generating realistic and diverse road scenarios is essential for autonomous\nvehicle testing and validation. Nevertheless, owing to the complexity and\nvariability of real-world road environments, creating authentic and varied\nscenarios for intelligent driving testing is challenging. In this paper, we\npropose DiffRoad, a novel diffusion model designed to produce controllable and\nhigh-fidelity 3D road scenarios. DiffRoad leverages the generative capabilities\nof diffusion models to synthesize road layouts from white noise through an\ninverse denoising process, preserving real-world spatial features. To enhance\nthe quality of generated scenarios, we design the Road-UNet architecture,\noptimizing the balance between backbone and skip connections for high-realism\nscenario generation. Furthermore, we introduce a road scenario evaluation\nmodule that screens adequate and reasonable scenarios for intelligent driving\ntesting using two critical metrics: road continuity and road reasonableness.\nExperimental results on multiple real-world datasets demonstrate DiffRoad's\nability to generate realistic and smooth road structures while maintaining the\noriginal distribution. Additionally, the generated scenarios can be fully\nautomated into the OpenDRIVE format, facilitating generalized autonomous\nvehicle simulation testing. DiffRoad provides a rich and diverse scenario\nlibrary for large-scale autonomous vehicle testing and offers valuable insights\nfor future infrastructure designs that are better suited for autonomous\nvehicles.\n","authors":["Junjie Zhou","Lin Wang","Qiang Meng","Xiaofan Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09451v1.pdf","comment":"14 pages, 9 figures"},{"id":"http://arxiv.org/abs/2312.11166v4","updated":"2024-11-14T13:54:32Z","published":"2023-12-18T13:09:55Z","title":"Volume-Preserving Transformers for Learning Time Series Data with\n  Structure","summary":"  Two of the many trends in neural network research of the past few years have\nbeen (i) the learning of dynamical systems, especially with recurrent neural\nnetworks such as long short-term memory networks (LSTMs) and (ii) the\nintroduction of transformer neural networks for natural language processing\n(NLP) tasks.\n  While some work has been performed on the intersection of these two trends,\nthose efforts were largely limited to using the vanilla transformer directly\nwithout adjusting its architecture for the setting of a physical system.\n  In this work we develop a transformer-inspired neural network and use it to\nlearn a dynamical system. We (for the first time) change the activation\nfunction of the attention layer to imbue the transformer with\nstructure-preserving properties to improve long-term stability. This is shown\nto be of great advantage when applying the neural network to learning the\ntrajectory of a rigid body.\n","authors":["Benedikt Brantner","Guillaume de Romemont","Michael Kraus","Zeyuan Li"],"pdf_url":"https://arxiv.org/pdf/2312.11166v4.pdf","comment":"Will be published as part of \"Cemracs Proceedings 2023\" (status:\n  accepted)"},{"id":"http://arxiv.org/abs/2411.09444v1","updated":"2024-11-14T13:45:22Z","published":"2024-11-14T13:45:22Z","title":"Learning efficient and provably convergent splitting methods","summary":"  Splitting methods are widely used for solving initial value problems (IVPs)\ndue to their ability to simplify complicated evolutions into more manageable\nsubproblems which can be solved efficiently and accurately. Traditionally,\nthese methods are derived using analytic and algebraic techniques from\nnumerical analysis, including truncated Taylor series and their Lie algebraic\nanalogue, the Baker--Campbell--Hausdorff formula. These tools enable the\ndevelopment of high-order numerical methods that provide exceptional accuracy\nfor small timesteps. Moreover, these methods often (nearly) conserve important\nphysical invariants, such as mass, unitarity, and energy. However, in many\npractical applications the computational resources are limited. Thus, it is\ncrucial to identify methods that achieve the best accuracy within a fixed\ncomputational budget, which might require taking relatively large timesteps. In\nthis regime, high-order methods derived with traditional methods often exhibit\nlarge errors since they are only designed to be asymptotically optimal. Machine\nLearning techniques offer a potential solution since they can be trained to\nefficiently solve a given IVP with less computational resources. However, they\nare often purely data-driven, come with limited convergence guarantees in the\nsmall-timestep regime and do not necessarily conserve physical invariants. In\nthis work, we propose a framework for finding machine learned splitting methods\nthat are computationally efficient for large timesteps and have provable\nconvergence and conservation guarantees in the small-timestep limit. We\ndemonstrate numerically that the learned methods, which by construction\nconverge quadratically in the timestep size, can be significantly more\nefficient than established methods for the Schr\\\"{o}dinger equation if the\ncomputational budget is limited.\n","authors":["L. M. Kreusser","H. E. Lockyer","E. H. M√ºller","P. Singh"],"pdf_url":"https://arxiv.org/pdf/2411.09444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06651v2","updated":"2024-11-14T13:26:35Z","published":"2024-11-11T01:36:48Z","title":"Machine learning-enabled velocity model building with uncertainty\n  quantification","summary":"  Accurately characterizing migration velocity models is crucial for a wide\nrange of geophysical applications, from hydrocarbon exploration to monitoring\nof CO2 sequestration projects. Traditional velocity model building methods such\nas Full-Waveform Inversion (FWI) are powerful but often struggle with the\ninherent complexities of the inverse problem, including noise, limited\nbandwidth, receiver aperture and computational constraints. To address these\nchallenges, we propose a scalable methodology that integrates generative\nmodeling, in the form of Diffusion networks, with physics-informed summary\nstatistics, making it suitable for complicated imaging problems including field\ndatasets. By defining these summary statistics in terms of subsurface-offset\nimage volumes for poor initial velocity models, our approach allows for\ncomputationally efficient generation of Bayesian posterior samples for\nmigration velocity models that offer a useful assessment of uncertainty. To\nvalidate our approach, we introduce a battery of tests that measure the quality\nof the inferred velocity models, as well as the quality of the inferred\nuncertainties. With modern synthetic datasets, we reconfirm gains from using\nsubsurface-image gathers as the conditioning observable. For complex velocity\nmodel building involving salt, we propose a new iterative workflow that refines\namortized posterior approximations with salt flooding and demonstrate how the\nuncertainty in the velocity model can be propagated to the final product\nreverse time migrated images. Finally, we present a proof of concept on field\ndatasets to show that our method can scale to industry-sized problems.\n","authors":["Rafael Orozco","Huseyin Tuna Erdinc","Yunlin Zeng","Mathias Louboutin","Felix J. Herrmann"],"pdf_url":"https://arxiv.org/pdf/2411.06651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09420v1","updated":"2024-11-14T13:15:27Z","published":"2024-11-14T13:15:27Z","title":"SAG-ViT: A Scale-Aware, High-Fidelity Patching Approach with Graph\n  Attention for Vision Transformers","summary":"  Image classification is a computer vision task where a model analyzes an\nimage to categorize it into a specific label. Vision Transformers (ViT) improve\nthis task by leveraging self-attention to capture complex patterns and long\nrange relationships between image patches. However, a key challenge for ViTs is\nefficiently incorporating multiscale feature representations, which is inherent\nin CNNs through their hierarchical structure. In this paper, we introduce the\nScale-Aware Graph Attention Vision Transformer (SAG-ViT), a novel framework\nthat addresses this challenge by integrating multi-scale features. Using\nEfficientNet as a backbone, the model extracts multi-scale feature maps, which\nare divided into patches to preserve semantic information. These patches are\norganized into a graph based on spatial and feature similarities, with a Graph\nAttention Network (GAT) refining the node embeddings. Finally, a Transformer\nencoder captures long-range dependencies and complex interactions. The SAG-ViT\nis evaluated on benchmark datasets, demonstrating its effectiveness in\nenhancing image classification performance.\n","authors":["Shravan Venkatraman","Jaskaran Singh Walia","Joe Dhanith P R"],"pdf_url":"https://arxiv.org/pdf/2411.09420v1.pdf","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.07974v3","updated":"2024-11-14T12:51:52Z","published":"2024-10-10T14:32:16Z","title":"Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition\n  Path Sampling","summary":"  Rare event sampling in dynamical systems is a fundamental problem arising in\nthe natural sciences, which poses significant computational challenges due to\nan exponentially large space of trajectories. For settings where the dynamical\nsystem of interest follows a Brownian motion with known drift, the question of\nconditioning the process to reach a given endpoint or desired rare event is\ndefinitively answered by Doob's h-transform. However, the naive estimation of\nthis transform is infeasible, as it requires simulating sufficiently many\nforward trajectories to estimate rare event probabilities. In this work, we\npropose a variational formulation of Doob's h-transform as an optimization\nproblem over trajectories between a given initial point and the desired ending\npoint. To solve this optimization, we propose a simulation-free training\nobjective with a model parameterization that imposes the desired boundary\nconditions by design. Our approach significantly reduces the search space over\ntrajectories and avoids expensive trajectory simulation and inefficient\nimportance sampling estimators which are required in existing methods. We\ndemonstrate the ability of our method to find feasible transition paths on\nreal-world molecular simulation and protein folding tasks.\n","authors":["Yuanqi Du","Michael Plainer","Rob Brekelmans","Chenru Duan","Frank No√©","Carla P. Gomes","Al√°n Aspuru-Guzik","Kirill Neklyudov"],"pdf_url":"https://arxiv.org/pdf/2410.07974v3.pdf","comment":"Accepted as Spotlight at Conference on Neural Information Processing\n  Systems (NeurIPS 2024); Alanine dipeptide results updated after fixing\n  unphysical parameterization"},{"id":"http://arxiv.org/abs/2411.05757v2","updated":"2024-11-14T12:12:15Z","published":"2024-11-08T18:18:18Z","title":"Tract-RLFormer: A Tract-Specific RL policy based Decoder-only\n  Transformer Network","summary":"  Fiber tractography is a cornerstone of neuroimaging, enabling the detailed\nmapping of the brain's white matter pathways through diffusion MRI. This is\ncrucial for understanding brain connectivity and function, making it a valuable\ntool in neurological applications. Despite its importance, tractography faces\nchallenges due to its complexity and susceptibility to false positives,\nmisrepresenting vital pathways. To address these issues, recent strategies have\nshifted towards deep learning, utilizing supervised learning, which depends on\nprecise ground truth, or reinforcement learning, which operates without it. In\nthis work, we propose Tract-RLFormer, a network utilizing both supervised and\nreinforcement learning, in a two-stage policy refinement process that markedly\nimproves the accuracy and generalizability across various data-sets. By\nemploying a tract-specific approach, our network directly delineates the tracts\nof interest, bypassing the traditional segmentation process. Through rigorous\nvalidation on datasets such as TractoInferno, HCP, and ISMRM-2015, our\nmethodology demonstrates a leap forward in tractography, showcasing its ability\nto accurately map the brain's white matter tracts.\n","authors":["Ankita Joshi","Ashutosh Sharma","Anoushkrit Goel","Ranjeet Ranjan Jha","Chirag Ahuja","Arnav Bhavsar","Aditya Nigam"],"pdf_url":"https://arxiv.org/pdf/2411.05757v2.pdf","comment":"Accepted at 27th International Conference on Pattern Recognition\n  (ICPR), 2024"},{"id":"http://arxiv.org/abs/2411.09393v1","updated":"2024-11-14T12:11:08Z","published":"2024-11-14T12:11:08Z","title":"Inherently Interpretable and Uncertainty-Aware Models for Online\n  Learning in Cyber-Security Problems","summary":"  In this paper, we address the critical need for interpretable and\nuncertainty-aware machine learning models in the context of online learning for\nhigh-risk industries, particularly cyber-security. While deep learning and\nother complex models have demonstrated impressive predictive capabilities,\ntheir opacity and lack of uncertainty quantification present significant\nquestions about their trustworthiness. We propose a novel pipeline for online\nsupervised learning problems in cyber-security, that harnesses the inherent\ninterpretability and uncertainty awareness of Additive Gaussian Processes\n(AGPs) models. Our approach aims to balance predictive performance with\ntransparency while improving the scalability of AGPs, which represents their\nmain drawback, potentially enabling security analysts to better validate threat\ndetection, troubleshoot and reduce false positives, and generally make\ntrustworthy, informed decisions. This work contributes to the growing field of\ninterpretable AI by proposing a class of models that can be significantly\nbeneficial for high-stake decision problems such as the ones typical of the\ncyber-security domain. The source code is available.\n","authors":["Benjamin Kolicic","Alberto Caron","Chris Hicks","Vasilios Mavroudis"],"pdf_url":"https://arxiv.org/pdf/2411.09393v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09389v1","updated":"2024-11-14T12:05:35Z","published":"2024-11-14T12:05:35Z","title":"Less is More: Unseen Domain Fake News Detection via Causal Propagation\n  Substructures","summary":"  The spread of fake news on social media poses significant threats to\nindividuals and society. Text-based and graph-based models have been employed\nfor fake news detection by analysing news content and propagation networks,\nshowing promising results in specific scenarios. However, these data-driven\nmodels heavily rely on pre-existing in-distribution data for training, limiting\ntheir performance when confronted with fake news from emerging or previously\nunseen domains, known as out-of-distribution (OOD) data. Tackling OOD fake news\nis a challenging yet critical task. In this paper, we introduce the Causal\nSubgraph-oriented Domain Adaptive Fake News Detection (CSDA) model, designed to\nenhance zero-shot fake news detection by extracting causal substructures from\npropagation graphs using in-distribution data and generalising this approach to\nOOD data. The model employs a graph neural network based mask generation\nprocess to identify dominant nodes and edges within the propagation graph,\nusing these substructures for fake news detection. Additionally, the\nperformance of CSDA is further improved through contrastive learning in\nfew-shot scenarios, where a limited amount of OOD data is available for\ntraining. Extensive experiments on public social media datasets demonstrate\nthat CSDA effectively handles OOD fake news detection, achieving a 7 to 16\npercents accuracy improvement over other state-of-the-art models.\n","authors":["Shuzhi Gong","Richard O. Sinnott","Jianzhong Qi","Cecile Paris"],"pdf_url":"https://arxiv.org/pdf/2411.09389v1.pdf","comment":"9 pages, 2 figures, 5 tables"},{"id":"http://arxiv.org/abs/2411.09388v1","updated":"2024-11-14T12:05:08Z","published":"2024-11-14T12:05:08Z","title":"A survey of probabilistic generative frameworks for molecular\n  simulations","summary":"  Generative artificial intelligence is now a widely used tool in molecular\nscience. Despite the popularity of probabilistic generative models, numerical\nexperiments benchmarking their performance on molecular data are lacking. In\nthis work, we introduce and explain several classes of generative models,\nbroadly sorted into two categories: flow-based models and diffusion models. We\nselect three representative models: Neural Spline Flows, Conditional Flow\nMatching, and Denoising Diffusion Probabilistic Models, and examine their\naccuracy, computational cost, and generation speed across datasets with tunable\ndimensionality, complexity, and modal asymmetry. Our findings are varied, with\nno one framework being the best for all purposes. In a nutshell, (i) Neural\nSpline Flows do best at capturing mode asymmetry present in low-dimensional\ndata, (ii) Conditional Flow Matching outperforms other models for\nhigh-dimensional data with low complexity, and (iii) Denoising Diffusion\nProbabilistic Models appears the best for low-dimensional data with high\ncomplexity. Our datasets include a Gaussian mixture model and the dihedral\ntorsion angle distribution of the Aib\\textsubscript{9} peptide, generated via a\nmolecular dynamics simulation. We hope our taxonomy of probabilistic generative\nframeworks and numerical results may guide model selection for a wide range of\nmolecular tasks.\n","authors":["Richard John","Lukas Herron","Pratyush Tiwary"],"pdf_url":"https://arxiv.org/pdf/2411.09388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07506v2","updated":"2024-11-14T12:02:01Z","published":"2024-01-15T07:13:43Z","title":"SeMaScore : a new evaluation metric for automatic speech recognition\n  tasks","summary":"  In this study, we present SeMaScore, generated using a segment-wise mapping\nand scoring algorithm that serves as an evaluation metric for automatic speech\nrecognition tasks. SeMaScore leverages both the error rate and a more robust\nsimilarity score. We show that our algorithm's score generation improves upon\nthe state-of-the-art BERTScore. Our experimental results show that SeMaScore\ncorresponds well with expert human assessments, signal-to-noise ratio levels,\nand other natural language metrics. We outperform BERTScore by 41x in metric\ncomputation speed. Overall, we demonstrate that SeMaScore serves as a more\ndependable evaluation metric, particularly in real-world situations involving\natypical speech patterns.\n","authors":["Zitha Sasindran","Harsha Yelchuri","T. V. Prabhakar"],"pdf_url":"https://arxiv.org/pdf/2401.07506v2.pdf","comment":"Accepted at Interspeech 2024"},{"id":"http://arxiv.org/abs/2404.07940v3","updated":"2024-11-14T11:51:00Z","published":"2024-03-11T02:06:30Z","title":"InfiBench: Evaluating the Question-Answering Capabilities of Code Large\n  Language Models","summary":"  Large Language Models for code (code LLMs) have witnessed tremendous progress\nin recent years. With the rapid development of code LLMs, many popular\nevaluation benchmarks, such as HumanEval, DS-1000, and MBPP, have emerged to\nmeasure the performance of code LLMs with a particular focus on code generation\ntasks. However, they are insufficient to cover the full range of expected\ncapabilities of code LLMs, which span beyond code generation to answering\ndiverse coding-related questions. To fill this gap, we propose InfiBench, the\nfirst large-scale freeform question-answering (QA) benchmark for code to our\nknowledge, comprising 234 carefully selected high-quality Stack Overflow\nquestions that span across 15 programming languages. InfiBench uses four types\nof model-free automatic metrics to evaluate response correctness where domain\nexperts carefully concretize the criterion for each question. We conduct a\nsystematic evaluation for over 100 latest code LLMs on InfiBench, leading to a\nseries of novel and insightful findings. Our detailed analyses showcase\npotential directions for further advancement of code LLMs. InfiBench is fully\nopen source at https://infi-coder.github.io/infibench and continuously\nexpanding to foster more scientific and systematic practices for code LLM\nevaluation.\n","authors":["Linyi Li","Shijie Geng","Zhenwen Li","Yibo He","Hao Yu","Ziyue Hua","Guanghan Ning","Siwei Wang","Tao Xie","Hongxia Yang"],"pdf_url":"https://arxiv.org/pdf/2404.07940v3.pdf","comment":"31 pages. Appear at NeurIPS 2024 Datasets and Benchmarks track.\n  Project website: https://infi-coder.github.io/infibench"},{"id":"http://arxiv.org/abs/2411.09373v1","updated":"2024-11-14T11:27:15Z","published":"2024-11-14T11:27:15Z","title":"Are nuclear masks all you need for improved out-of-domain\n  generalisation? A closer look at cancer classification in histopathology","summary":"  Domain generalisation in computational histopathology is challenging because\nthe images are substantially affected by differences among hospitals due to\nfactors like fixation and staining of tissue and imaging equipment. We\nhypothesise that focusing on nuclei can improve the out-of-domain (OOD)\ngeneralisation in cancer detection. We propose a simple approach to improve OOD\ngeneralisation for cancer detection by focusing on nuclear morphology and\norganisation, as these are domain-invariant features critical in cancer\ndetection. Our approach integrates original images with nuclear segmentation\nmasks during training, encouraging the model to prioritise nuclei and their\nspatial arrangement. Going beyond mere data augmentation, we introduce a\nregularisation technique that aligns the representations of masks and original\nimages. We show, using multiple datasets, that our method improves OOD\ngeneralisation and also leads to increased robustness to image corruptions and\nadversarial attacks. The source code is available at\nhttps://github.com/undercutspiky/SFL/\n","authors":["Dhananjay Tomar","Alexander Binder","Andreas Kleppe"],"pdf_url":"https://arxiv.org/pdf/2411.09373v1.pdf","comment":"Poster at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09365v1","updated":"2024-11-14T11:16:32Z","published":"2024-11-14T11:16:32Z","title":"Stability and Generalization for Distributed SGDA","summary":"  Minimax optimization is gaining increasing attention in modern machine\nlearning applications. Driven by large-scale models and massive volumes of data\ncollected from edge devices, as well as the concern to preserve client privacy,\ncommunication-efficient distributed minimax optimization algorithms become\npopular, such as Local Stochastic Gradient Descent Ascent (Local-SGDA), and\nLocal Decentralized SGDA (Local-DSGDA). While most existing research on\ndistributed minimax algorithms focuses on convergence rates, computation\ncomplexity, and communication efficiency, the generalization performance\nremains underdeveloped, whereas generalization ability is a pivotal indicator\nfor evaluating the holistic performance of a model when fed with unknown data.\nIn this paper, we propose the stability-based generalization analytical\nframework for Distributed-SGDA, which unifies two popular distributed minimax\nalgorithms including Local-SGDA and Local-DSGDA, and conduct a comprehensive\nanalysis of stability error, generalization gap, and population risk across\ndifferent metrics under various settings, e.g., (S)C-(S)C, PL-SC, and NC-NC\ncases. Our theoretical results reveal the trade-off between the generalization\ngap and optimization error and suggest hyperparameters choice to obtain the\noptimal population risk. Numerical experiments for Local-SGDA and Local-DSGDA\nvalidate the theoretical results.\n","authors":["Miaoxi Zhu","Yan Sun","Li Shen","Bo Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2411.09365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09361v1","updated":"2024-11-14T11:08:54Z","published":"2024-11-14T11:08:54Z","title":"Time-to-Event Pretraining for 3D Medical Imaging","summary":"  With the rise of medical foundation models and the growing availability of\nimaging data, scalable pretraining techniques offer a promising way to identify\nimaging biomarkers predictive of future disease risk. While current\nself-supervised methods for 3D medical imaging models capture local structural\nfeatures like organ morphology, they fail to link pixel biomarkers with\nlong-term health outcomes due to a missing context problem. Current approaches\nlack the temporal context necessary to identify biomarkers correlated with\ndisease progression, as they rely on supervision derived only from images and\nconcurrent text descriptions. To address this, we introduce time-to-event\npretraining, a pretraining framework for 3D medical imaging models that\nleverages large-scale temporal supervision from paired, longitudinal electronic\nhealth records (EHRs). Using a dataset of 18,945 CT scans (4.2 million 2D\nimages) and time-to-event distributions across thousands of EHR-derived tasks,\nour method improves outcome prediction, achieving an average AUROC increase of\n23.7% and a 29.4% gain in Harrell's C-index across 8 benchmark tasks.\nImportantly, these gains are achieved without sacrificing diagnostic\nclassification performance. This study lays the foundation for integrating\nlongitudinal EHR and 3D imaging data to advance clinical risk prediction.\n","authors":["Zepeng Huo","Jason Alan Fries","Alejandro Lozano","Jeya Maria Jose Valanarasu","Ethan Steinberg","Louis Blankemeier","Akshay S. Chaudhari","Curtis Langlotz","Nigam H. Shah"],"pdf_url":"https://arxiv.org/pdf/2411.09361v1.pdf","comment":"34 pages, 19 figures"},{"id":"http://arxiv.org/abs/2410.21858v3","updated":"2024-11-14T10:54:53Z","published":"2024-10-29T08:42:22Z","title":"Joint Estimation of Conditional Mean and Covariance for Unbalanced\n  Panels","summary":"  We propose a nonparametric, kernel-based joint estimator for conditional mean\nand covariance matrices in large unbalanced panels. Our estimator, with proven\nconsistency and finite-sample guarantees, is applied to a comprehensive panel\nof monthly US stock excess returns from 1962 to 2021, conditioned on\nmacroeconomic and firm-specific covariates. The estimator captures time-varying\ncross-sectional dependencies effectively, demonstrating robust statistical\nperformance. In asset pricing, it generates conditional mean-variance efficient\nportfolios with out-of-sample Sharpe ratios that substantially exceed those of\nequal-weighted benchmarks.\n","authors":["Damir Filipovic","Paul Schneider"],"pdf_url":"https://arxiv.org/pdf/2410.21858v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09341v1","updated":"2024-11-14T10:37:34Z","published":"2024-11-14T10:37:34Z","title":"Approximated Variational Bayesian Inverse Reinforcement Learning for\n  Large Language Model Alignment","summary":"  The alignment of large language models (LLMs) is crucial for generating\nhelpful and harmless content. Existing approaches leverage preference-based\nhuman feedback data to learn the reward function and align the LLM with the\nfeedback data. However, these approaches focus on modeling the reward\ndifference between the chosen and rejected demonstrations, rather than directly\nmodeling the true reward from each demonstration. Moreover, these approaches\nassume that the reward is only obtained at the end of the sentence, which\noverlooks the modeling of intermediate rewards. These issues lead to\ninsufficient use of training signals in the feedback data, limiting the\nrepresentation and generalization ability of the reward and potentially\nresulting in reward hacking. In this paper, we formulate LLM alignment as a\nBayesian Inverse Reinforcement Learning (BIRL) problem and propose a novel\ntraining objective, Approximated Variational Alignment (AVA), to perform LLM\nalignment through Approximated Variational Reward Imitation Learning (AVRIL).\nThe BIRL formulation facilitates intermediate reward modeling and direct reward\nmodeling on each single demonstration, which enhances the utilization of\ntraining signals in the feedback data. Experiments show that AVA outperforms\nexisting LLM alignment approaches in reward modeling, RL fine-tuning, and\ndirect optimization.\n","authors":["Yuang Cai","Yuyu Yuan","Jinsheng Shi","Qinhong Lin"],"pdf_url":"https://arxiv.org/pdf/2411.09341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02930v2","updated":"2024-11-14T10:24:06Z","published":"2024-02-05T11:52:23Z","title":"Embedding Hardware Approximations in Discrete Genetic-based Training for\n  Printed MLPs","summary":"  Printed Electronics (PE) stands out as a promisingtechnology for widespread\ncomputing due to its distinct attributes, such as low costs and flexible\nmanufacturing. Unlike traditional silicon-based technologies, PE enables\nstretchable, conformal,and non-toxic hardware. However, PE are constrained by\nlarger feature sizes, making it challenging to implement complex circuits such\nas machine learning (ML) classifiers. Approximate computing has been proven to\nreduce the hardware cost of ML circuits such as Multilayer Perceptrons (MLPs).\nIn this paper, we maximize the benefits of approximate computing by integrating\nhardware approximation into the MLP training process. Due to the discrete\nnature of hardware approximation, we propose and implement a genetic-based,\napproximate, hardware-aware training approach specifically designed for printed\nMLPs. For a 5% accuracy loss, our MLPs achieve over 5x area and power reduction\ncompared to the baseline while outperforming state of-the-art approximate and\nstochastic printed MLPs.\n","authors":["Florentia Afentaki","Michael Hefenbrock","Georgios Zervakis","Mehdi B. Tahoori"],"pdf_url":"https://arxiv.org/pdf/2402.02930v2.pdf","comment":"Accepted for publication at the 27th Design, Automation and Test in\n  Europe Conference (DATE'24), Mar 25-27 2024, Valencia, Spain"},{"id":"http://arxiv.org/abs/2312.17612v3","updated":"2024-11-14T10:22:05Z","published":"2023-12-29T14:16:11Z","title":"Bespoke Approximation of Multiplication-Accumulation and Activation\n  Targeting Printed Multilayer Perceptrons","summary":"  Printed Electronics (PE) feature distinct and remarkable characteristics that\nmake them a prominent technology for achieving true ubiquitous computing. This\nis particularly relevant in application domains that require conformal and\nultra-low cost solutions, which have experienced limited penetration of\ncomputing until now. Unlike silicon-based technologies, PE offer unparalleled\nfeatures such as non-recurring engineering costs, ultra-low manufacturing cost,\nand on-demand fabrication of conformal, flexible, non-toxic, and stretchable\nhardware. However, PE face certain limitations due to their large feature\nsizes, that impede the realization of complex circuits, such as machine\nlearning classifiers. In this work, we address these limitations by leveraging\nthe principles of Approximate Computing and Bespoke (fully-customized) design.\nWe propose an automated framework for designing ultra-low power Multilayer\nPerceptron (MLP) classifiers which employs, for the first time, a holistic\napproach to approximate all functions of the MLP's neurons: multiplication,\naccumulation, and activation. Through comprehensive evaluation across various\nMLPs of varying size, our framework demonstrates the ability to enable\nbattery-powered operation of even the most intricate MLP architecture examined,\nsignificantly surpassing the current state of the art.\n","authors":["Florentia Afentaki","Gurol Saglam","Argyris Kokkinis","Kostas Siozios","Georgios Zervakis","Mehdi B Tahoori"],"pdf_url":"https://arxiv.org/pdf/2312.17612v3.pdf","comment":"Accepted for publication at the 42th IEEE/ACM International\n  Conference on Computer Aided Design (ICCAD) 2023, San Francisco, USA"},{"id":"http://arxiv.org/abs/2411.09329v1","updated":"2024-11-14T10:21:41Z","published":"2024-11-14T10:21:41Z","title":"Improving hp-Variational Physics-Informed Neural Networks for\n  Steady-State Convection-Dominated Problems","summary":"  This paper proposes and studies two extensions of applying hp-variational\nphysics-informed neural networks, more precisely the FastVPINNs framework, to\nconvection-dominated convection-diffusion-reaction problems. First, a term in\nthe spirit of a SUPG stabilization is included in the loss functional and a\nnetwork architecture is proposed that predicts spatially varying stabilization\nparameters. Having observed that the selection of the indicator function in\nhard-constrained Dirichlet boundary conditions has a big impact on the accuracy\nof the computed solutions, the second novelty is the proposal of a network\narchitecture that learns good parameters for a class of indicator functions.\nNumerical studies show that both proposals lead to noticeably more accurate\nresults than approaches that can be found in the literature.\n","authors":["Thivin Anandh","Divij Ghose","Himanshu Jain","Pratham Sunkad","Sashikumaar Ganesan","Volker John"],"pdf_url":"https://arxiv.org/pdf/2411.09329v1.pdf","comment":"25 pages, 11 figures, 8 tables"},{"id":"http://arxiv.org/abs/2309.17196v4","updated":"2024-11-14T10:16:35Z","published":"2023-09-29T12:45:39Z","title":"ResBit: Residual Bit Vector for Categorical Values","summary":"  One-hot vectors, a common method for representing discrete/categorical data,\nin machine learning are widely used because of their simplicity and\nintuitiveness. However, one-hot vectors suffer from a linear increase in\ndimensionality, posing computational and memory challenges, especially when\ndealing with datasets containing numerous categories. In this paper, we focus\non tabular data generation, and reveal the multinomial diffusion faces the mode\ncollapse phenomenon when the cardinality is high. Moreover, due to the\nlimitations of one-hot vectors, the training phase takes time longer in such a\nsituation. To address these issues, we propose Residual Bit Vectors (ResBit), a\ntechnique for densely representing categorical data. ResBit is an extension of\nanalog bits and overcomes limitations of analog bits when applied to tabular\ndata generation. Our experiments demonstrate that ResBit not only accelerates\ntraining but also maintains performance when compared with the situations\nbefore applying ResBit. Furthermore, our results indicate that many existing\nmethods struggle with high-cardinality data, underscoring the need for\nlower-dimensional representations, such as ResBit and latent vectors.\n","authors":["Masane Fuchi","Amar Zanashir","Hiroto Minami","Tomohiro Takagi"],"pdf_url":"https://arxiv.org/pdf/2309.17196v4.pdf","comment":"25 pages, 29 tables, and 10 figures"},{"id":"http://arxiv.org/abs/2407.02279v2","updated":"2024-11-14T10:15:35Z","published":"2024-07-02T14:08:23Z","title":"How to Boost Any Loss Function","summary":"  Boosting is a highly successful ML-born optimization setting in which one is\nrequired to computationally efficiently learn arbitrarily good models based on\nthe access to a weak learner oracle, providing classifiers performing at least\nslightly differently from random guessing. A key difference with gradient-based\noptimization is that boosting's original model does not requires access to\nfirst order information about a loss, yet the decades long history of boosting\nhas quickly evolved it into a first order optimization setting -- sometimes\neven wrongfully defining it as such. Owing to recent progress extending\ngradient-based optimization to use only a loss' zeroth ($0^{th}$) order\ninformation to learn, this begs the question: what loss functions can be\nefficiently optimized with boosting and what is the information really needed\nfor boosting to meet the original boosting blueprint's requirements?\n  We provide a constructive formal answer essentially showing that any loss\nfunction can be optimized with boosting and thus boosting can achieve a feat\nnot yet known to be possible in the classical $0^{th}$ order setting, since\nloss functions are not required to be be convex, nor differentiable or\nLipschitz -- and in fact not required to be continuous either. Some tools we\nuse are rooted in quantum calculus, the mathematical field -- not to be\nconfounded with quantum computation -- that studies calculus without passing to\nthe limit, and thus without using first order information.\n","authors":["Richard Nock","Yishay Mansour"],"pdf_url":"https://arxiv.org/pdf/2407.02279v2.pdf","comment":"NeurIPS'24"},{"id":"http://arxiv.org/abs/2411.09317v1","updated":"2024-11-14T09:50:41Z","published":"2024-11-14T09:50:41Z","title":"Pie: Pooling CPU Memory for LLM Inference","summary":"  The rapid growth of LLMs has revolutionized natural language processing and\nAI analysis, but their increasing size and memory demands present significant\nchallenges. A common solution is to spill over to CPU memory; however,\ntraditional GPU-CPU memory swapping often results in higher latency and lower\nthroughput.\n  This paper introduces Pie, an LLM inference framework that addresses these\nchallenges with performance-transparent swapping and adaptive expansion. By\nleveraging predictable memory access patterns and the high bandwidth of modern\nhardware like the NVIDIA GH200 Grace Hopper Superchip, Pie enables concurrent\ndata swapping without affecting foreground computation, expanding effective\nmemory without added latency. Adaptive expansion dynamically adjusts CPU memory\nallocation based on real-time information, optimizing memory usage and\nperformance under varying conditions.\n  Pie maintains low computation latency, high throughput, and high elasticity.\nOur experimental evaluation demonstrates that Pie achieves optimal swapping\npolicy during cache warmup and effectively balances increased memory capacity\nwith negligible impact on computation. With its extended capacity, Pie\noutperforms vLLM by up to 1.9X in throughput and 2X in latency. Additionally,\nPie can reduce GPU memory usage by up to 1.67X while maintaining the same\nperformance. Compared to FlexGen, an offline profiling-based swapping solution,\nPie achieves magnitudes lower latency and 9.4X higher throughput.\n","authors":["Yi Xu","Ziming Mao","Xiangxi Mo","Shu Liu","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2411.09317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09312v1","updated":"2024-11-14T09:38:58Z","published":"2024-11-14T09:38:58Z","title":"Approximate Probabilistic Inference forTime-Series Data A Robust Latent\n  Gaussian Model With Temporal Awareness","summary":"  The development of robust generative models for highly varied non-stationary\ntime series data is a complex yet important problem. Traditional models for\ntime series data prediction, such as Long Short-Term Memory (LSTM), are\ninefficient and generalize poorly as they cannot capture complex temporal\nrelationships. In this paper, we present a probabilistic generative model that\ncan be trained to capture temporal information, and that is robust to data\nerrors. We call it Time Deep Latent Gaussian Model (tDLGM). Its novel\narchitecture is inspired by Deep Latent Gaussian Model (DLGM). Our model is\ntrained to minimize a loss function based on the negative log loss. One\ncontributing factor to Time Deep Latent Gaussian Model (tDLGM) robustness is\nour regularizer, which accounts for data trends. Experiments conducted show\nthat tDLGM is able to reconstruct and generate complex time series data, and\nthat it is robust against to noise and faulty data.\n","authors":["Anton Johansson","Arunselvan Ramaswamy"],"pdf_url":"https://arxiv.org/pdf/2411.09312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09311v1","updated":"2024-11-14T09:38:41Z","published":"2024-11-14T09:38:41Z","title":"Compression Method for Solar Polarization Spectra Collected from Hinode\n  SOT/SP Observations","summary":"  The complex structure and extensive details of solar spectral data, combined\nwith a recent surge in volume, present significant processing challenges. To\naddress this, we propose a deep learning-based compression technique using deep\nautoencoder (DAE) and 1D-convolutional autoencoder (CAE) models developed with\nHinode SOT/SP data. We focused on compressing Stokes I and V polarization\nspectra from the quiet Sun, as well as from active regions, providing a novel\ninsight into comprehensive spectral analysis by incorporating spectra from\nextreme magnetic fields. The results indicate that the CAE model outperforms\nthe DAE model in reconstructing Stokes profiles, demonstrating greater\nrobustness and achieving reconstruction errors around the observational noise\nlevel. The proposed method has proven effective in compressing Stokes I and V\nspectra from both the quiet Sun and active regions, highlighting its potential\nfor impactful applications in solar spectral analysis, such as detection of\nunusual spectral signals.\n","authors":["Jargalmaa Batmunkh","Yusuke Iida","Takayoshi Oba","Haruhisa Iijima"],"pdf_url":"https://arxiv.org/pdf/2411.09311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03017v2","updated":"2024-11-14T09:19:43Z","published":"2024-02-05T13:55:54Z","title":"Toward Green and Human-Like Artificial Intelligence: A Complete Survey\n  on Contemporary Few-Shot Learning Approaches","summary":"  Despite deep learning's widespread success, its data-hungry and\ncomputationally expensive nature makes it impractical for many data-constrained\nreal-world applications. Few-Shot Learning (FSL) aims to address these\nlimitations by enabling rapid adaptation to novel learning tasks, seeing\nsignificant growth in recent years. This survey provides a comprehensive\noverview of the field's latest advancements. Initially, FSL is formally\ndefined, and its relationship with different learning fields is presented. A\nnovel taxonomy is introduced, extending previously proposed ones, and\nreal-world applications in classic and novel fields are described. Finally,\nrecent trends shaping the field, outstanding challenges, and promising future\nresearch directions are discussed.\n","authors":["Georgios Tsoumplekas","Vladislav Li","Panagiotis Sarigiannidis","Vasileios Argyriou"],"pdf_url":"https://arxiv.org/pdf/2402.03017v2.pdf","comment":"35 pages, 9 figures. Submitted to ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2410.14979v4","updated":"2024-11-14T09:17:48Z","published":"2024-10-19T05:01:56Z","title":"Do Large Language Models Truly Grasp Mathematics? An Empirical\n  Exploration From Cognitive Psychology","summary":"  The cognitive mechanism by which Large Language Models (LLMs) solve\nmathematical problems remains a widely debated and unresolved issue. Currently,\nthere is little interpretable experimental evidence that connects LLMs'\nproblem-solving with human cognitive psychology.To determine if LLMs possess\nhuman-like mathematical reasoning, we modified the problems used in the human\nCognitive Reflection Test (CRT). Our results show that, even with the use of\nChains of Thought (CoT) prompts, mainstream LLMs, including the latest o1 model\n(noted for its reasoning capabilities), have a high error rate when solving\nthese modified CRT problems. Specifically, the average accuracy rate dropped by\nup to 50% compared to the original questions.Further analysis of LLMs'\nincorrect answers suggests that they primarily rely on pattern matching from\ntheir training data, which aligns more with human intuition (System 1 thinking)\nrather than with human-like reasoning (System 2 thinking). This finding\nchallenges the belief that LLMs have genuine mathematical reasoning abilities\ncomparable to humans. As a result, this work may adjust overly optimistic views\non LLMs' progress towards artificial general intelligence.\n","authors":["Wei Xie","Shuoyoucheng Ma","Zhenhua Wang","Enze Wang","Kai Chen","Xiaobing Sun","Baosheng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14979v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21862v2","updated":"2024-11-14T09:17:31Z","published":"2024-10-29T08:56:29Z","title":"Hierarchical mixtures of Unigram models for short text clustering: the\n  role of Beta-Liouville priors","summary":"  This paper presents a variant of the Multinomial mixture model tailored for\nthe unsupervised classification of short text data. Traditionally, the\nMultinomial probability vector in this hierarchical model is assigned a\nDirichlet prior distribution. Here, however, we explore an alternative\nprior--the Beta-Liouville distribution--which offers a more flexible\ncorrelation structure than the Dirichlet. We examine the theoretical properties\nof the Beta-Liouville distribution, focusing on its conjugacy with the\nMultinomial likelihood. This property enables the derivation of update\nequations for a CAVI (Coordinate Ascent Variational Inference) variational\nalgorithm, facilitating the approximate posterior estimation of model\nparameters. Additionally, we propose a stochastic variant of the CAVI algorithm\nthat enhances scalability. The paper concludes with data examples that\ndemonstrate effective strategies for setting the Beta-Liouville\nhyperparameters.\n","authors":["Massimo Bilancia","Samuele Magro"],"pdf_url":"https://arxiv.org/pdf/2410.21862v2.pdf","comment":"32 pages, 4 figures. Submitted"},{"id":"http://arxiv.org/abs/2411.09296v1","updated":"2024-11-14T09:15:28Z","published":"2024-11-14T09:15:28Z","title":"Enhancing generalization in high energy physics using white-box\n  adversarial attacks","summary":"  Machine learning is becoming increasingly popular in the context of particle\nphysics. Supervised learning, which uses labeled Monte Carlo (MC) simulations,\nremains one of the most widely used methods for discriminating signals beyond\nthe Standard Model. However, this paper suggests that supervised models may\ndepend excessively on artifacts and approximations from Monte Carlo\nsimulations, potentially limiting their ability to generalize well to real\ndata. This study aims to enhance the generalization properties of supervised\nmodels by reducing the sharpness of local minima. It reviews the application of\nfour distinct white-box adversarial attacks in the context of classifying Higgs\nboson decay signals. The attacks are divided into weight space attacks, and\nfeature space attacks. To study and quantify the sharpness of different local\nminima this paper presents two analysis methods: gradient ascent and reduced\nHessian eigenvalue analysis. The results show that white-box adversarial\nattacks significantly improve generalization performance, albeit with increased\ncomputational complexity.\n","authors":["Franck Rothen","Samuel Klein","Matthew Leigh","Tobias Golling"],"pdf_url":"https://arxiv.org/pdf/2411.09296v1.pdf","comment":"10 pages, 4 figures, 8 tables, 3 algorithms, to be published in\n  Physical Review D (PRD), presented at the ML4Jets 2024 conference"},{"id":"http://arxiv.org/abs/2404.08434v2","updated":"2024-11-14T09:11:26Z","published":"2024-04-12T12:31:06Z","title":"An improved tabular data generator with VAE-GMM integration","summary":"  The rising use of machine learning in various fields requires robust methods\nto create synthetic tabular data. Data should preserve key characteristics\nwhile addressing data scarcity challenges. Current approaches based on\nGenerative Adversarial Networks, such as the state-of-the-art CTGAN model,\nstruggle with the complex structures inherent in tabular data. These data often\ncontain both continuous and discrete features with non-Gaussian distributions.\nTherefore, we propose a novel Variational Autoencoder (VAE)-based model that\naddresses these limitations. Inspired by the TVAE model, our approach\nincorporates a Bayesian Gaussian Mixture model (BGM) within the VAE\narchitecture. This avoids the limitations imposed by assuming a strictly\nGaussian latent space, allowing for a more accurate representation of the\nunderlying data distribution during data generation. Furthermore, our model\noffers enhanced flexibility by allowing the use of various differentiable\ndistributions for individual features, making it possible to handle both\ncontinuous and discrete data types. We thoroughly validate our model on three\nreal-world datasets with mixed data types, including two medically relevant\nones, based on their resemblance and utility. This evaluation demonstrates\nsignificant outperformance against CTGAN and TVAE, establishing its potential\nas a valuable tool for generating synthetic tabular data in various domains,\nparticularly in healthcare.\n","authors":["Patricia A. Apell√°niz","Juan Parras","Santiago Zazo"],"pdf_url":"https://arxiv.org/pdf/2404.08434v2.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.09286v1","updated":"2024-11-14T08:53:23Z","published":"2024-11-14T08:53:23Z","title":"A Centralized-Distributed Transfer Model for Cross-Domain Recommendation\n  Based on Multi-Source Heterogeneous Transfer Learning","summary":"  Cross-domain recommendation (CDR) methods are proposed to tackle the sparsity\nproblem in click through rate (CTR) estimation. Existing CDR methods directly\ntransfer knowledge from the source domains to the target domain and ignore the\nheterogeneities among domains, including feature dimensional heterogeneity and\nlatent space heterogeneity, which may lead to negative transfer. Besides, most\nof the existing methods are based on single-source transfer, which cannot\nsimultaneously utilize knowledge from multiple source domains to further\nimprove the model performance in the target domain. In this paper, we propose a\ncentralized-distributed transfer model (CDTM) for CDR based on multi-source\nheterogeneous transfer learning. To address the issue of feature dimension\nheterogeneity, we build a dual embedding structure: domain specific embedding\n(DSE) and global shared embedding (GSE) to model the feature representation in\nthe single domain and the commonalities in the global space,separately. To\nsolve the latent space heterogeneity, the transfer matrix and attention\nmechanism are used to map and combine DSE and GSE adaptively. Extensive offline\nand online experiments demonstrate the effectiveness of our model.\n","authors":["Ke Xu","Ziliang Wang","Wei Zheng","Yuhao Ma","Chenglin Wang","Nengxue Jiang","Cai Cao"],"pdf_url":"https://arxiv.org/pdf/2411.09286v1.pdf","comment":"Published in: 2022 IEEE International Conference on Data Mining\n  (ICDM) (The authors were affiliated Hangzhou NetEase Cloud Music Technology\n  Co., Ltd.)"},{"id":"http://arxiv.org/abs/2410.02367v2","updated":"2024-11-14T08:39:54Z","published":"2024-10-03T10:25:23Z","title":"SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference\n  Acceleration","summary":"  The transformer architecture predominates across various models. As the heart\nof the transformer, attention has a computational complexity of O(N^2),\ncompared to O(N) for linear transformations. When handling large sequence\nlengths, attention becomes the primary time-consuming component. Although\nquantization has proven to be an effective method for accelerating model\ninference, existing quantization methods primarily focus on optimizing the\nlinear layer. In response, we first analyze the feasibility of quantization in\nattention detailedly. Following that, we propose SageAttention, a highly\nefficient and accurate quantization method for attention. The OPS (operations\nper second) of our approach outperforms FlashAttention2 and xformers by about\n2.1 times and 2.7 times, respectively. SageAttention also achieves superior\naccuracy performance over FlashAttention3. Comprehensive experiments confirm\nthat our approach incurs almost no end-to-end metrics loss across diverse\nmodels, including those for large language processing, image generation, and\nvideo generation. The codes are available at\nhttps://github.com/thu-ml/SageAttention.\n","authors":["Jintao Zhang","Jia wei","Haofeng Huang","Pengle Zhang","Jun Zhu","Jianfei Chen"],"pdf_url":"https://arxiv.org/pdf/2410.02367v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14212v2","updated":"2024-11-14T08:31:10Z","published":"2024-10-18T07:01:56Z","title":"Comparative Evaluation of Clustered Federated Learning Methods","summary":"  Over recent years, Federated Learning (FL) has proven to be one of the most\npromising methods of distributed learning which preserves data privacy. As the\nmethod evolved and was confronted to various real-world scenarios, new\nchallenges have emerged. One such challenge is the presence of highly\nheterogeneous (often referred as non-IID) data distributions among participants\nof the FL protocol. A popular solution to this hurdle is Clustered Federated\nLearning (CFL), which aims to partition clients into groups where the\ndistribution are homogeneous. In the literature, state-of-the-art CFL\nalgorithms are often tested using a few cases of data heterogeneities, without\nsystematically justifying the choices. Further, the taxonomy used for\ndifferentiating the different heterogeneity scenarios is not always\nstraightforward. In this paper, we explore the performance of two\nstate-of-theart CFL algorithms with respect to a proposed taxonomy of data\nheterogeneities in federated learning (FL). We work with three image\nclassification datasets and analyze the resulting clusters against the\nheterogeneity classes using extrinsic clustering metrics. Our objective is to\nprovide a clearer understanding of the relationship between CFL performances\nand data heterogeneity scenarios.\n","authors":["Michael Ben Ali","Omar El-Rifai","Imen Megdiche","Andr√© Peninou","Olivier Teste"],"pdf_url":"https://arxiv.org/pdf/2410.14212v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07176v2","updated":"2024-11-14T08:20:22Z","published":"2024-11-11T17:56:28Z","title":"More Expressive Attention with Negative Weights","summary":"  We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention can shift the token deletion and copying\nfunction from a static OV matrix to dynamic QK inner products, with the OV\nmatrix now focusing more on refinement or modification. The attention head can\nsimultaneously delete, copy, or retain tokens by assigning them negative,\npositive, or minimal attention weights, respectively. As a result, a single\nattention head becomes more flexible and expressive. (2) Cog Attention improves\nthe model's robustness against representational collapse, which can occur when\nearlier tokens are over-squashed into later positions, leading to homogeneous\nrepresentations. Negative weights reduce effective information paths from\nearlier to later tokens, helping to mitigate this issue. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models for language modeling and U-ViT diffusion models for image\ngeneration. Experiments show that models using Cog Attention exhibit superior\nperformance compared to those employing traditional softmax attention modules.\nOur approach suggests a promising research direction for rethinking and\nbreaking the entrenched constraints of traditional softmax attention, such as\nthe requirement for non-negative weights.\n","authors":["Ang Lv","Ruobing Xie","Shuaipeng Li","Jiayi Liao","Xingwu Sun","Zhanhui Kang","Di Wang","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2411.07176v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09267v1","updated":"2024-11-14T08:08:25Z","published":"2024-11-14T08:08:25Z","title":"Towards efficient compression and communication for prototype-based\n  decentralized learning","summary":"  In prototype-based federated learning, the exchange of model parameters\nbetween clients and the master server is replaced by transmission of prototypes\nor quantized versions of the data samples to the aggregation server. A fully\ndecentralized deployment of prototype- based learning, without a central\nagregartor of prototypes, is more robust upon network failures and reacts\nfaster to changes in the statistical distribution of the data, suggesting\npotential advantages and quick adaptation in dynamic learning tasks, e.g., when\nthe data sources are IoT devices or when data is non-iid. In this paper, we\nconsider the problem of designing a communication-efficient decentralized\nlearning system based on prototypes. We address the challenge of prototype\nredundancy by leveraging on a twofold data compression technique, i.e., sending\nonly update messages if the prototypes are informationtheoretically useful (via\nthe Jensen-Shannon distance), and using clustering on the prototypes to\ncompress the update messages used in the gossip protocol. We also use parallel\ninstead of sequential gossiping, and present an analysis of its\nage-of-information (AoI). Our experimental results show that, with these\nimprovements, the communications load can be substantially reduced without\ndecreasing the convergence rate of the learning algorithm.\n","authors":["Pablo Fern√°ndez-Pi√±eiro","Manuel Fer√°ndez-Veiga","Rebeca P. D√≠az-Redondo","Ana Fern√°ndez-Vilas","Mart√≠n Gonz√°lez-Soto"],"pdf_url":"https://arxiv.org/pdf/2411.09267v1.pdf","comment":"15 pages, 2 tables, 7 figures, 6 algorithms"},{"id":"http://arxiv.org/abs/2411.09266v1","updated":"2024-11-14T08:07:02Z","published":"2024-11-14T08:07:02Z","title":"How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative\n  Study of ChatGPT, AI Models and Human Perception","summary":"  Multimodal deepfakes involving audiovisual manipulations are a growing threat\nbecause they are difficult to detect with the naked eye or using unimodal deep\nlearningbased forgery detection methods. Audiovisual forensic models, while\nmore capable than unimodal models, require large training datasets and are\ncomputationally expensive for training and inference. Furthermore, these models\nlack interpretability and often do not generalize well to unseen manipulations.\nIn this study, we examine the detection capabilities of a large language model\n(LLM) (i.e., ChatGPT) to identify and account for any possible visual and\nauditory artifacts and manipulations in audiovisual deepfake content. Extensive\nexperiments are conducted on videos from a benchmark multimodal deepfake\ndataset to evaluate the detection performance of ChatGPT and compare it with\nthe detection capabilities of state-of-the-art multimodal forensic models and\nhumans. Experimental results demonstrate the importance of domain knowledge and\nprompt engineering for video forgery detection tasks using LLMs. Unlike\napproaches based on end-to-end learning, ChatGPT can account for spatial and\nspatiotemporal artifacts and inconsistencies that may exist within or across\nmodalities. Additionally, we discuss the limitations of ChatGPT for multimedia\nforensic tasks.\n","authors":["Sahibzada Adil Shahzad","Ammarah Hashmi","Yan-Tsung Peng","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09276v2","updated":"2024-11-14T08:06:46Z","published":"2024-05-15T11:46:47Z","title":"Dual-Segment Clustering Strategy for Hierarchical Federated Learning in\n  Heterogeneous Wireless Environments","summary":"  Non-independent and identically distributed (Non- IID) data adversely affects\nfederated learning (FL) while heterogeneity in communication quality can\nundermine the reliability of model parameter transmission, potentially\ndegrading wireless FL convergence. This paper proposes a novel dual-segment\nclustering (DSC) strategy that jointly addresses communication and data\nheterogeneity in FL. This is achieved by defining a new signal-to-noise ratio\n(SNR) matrix and information quantity matrix to capture the communication and\ndata heterogeneity, respectively. The celebrated affinity propagation algorithm\nis leveraged to iteratively refine the clustering of clients based on the newly\ndefined matrices effectively enhancing model aggregation in heterogeneous\nenvironments. The convergence analysis and experimental results show that the\nDSC strategy can improve the convergence rate of wireless FL and demonstrate\nsuperior accuracy in heterogeneous environments compared to classical\nclustering methods.\n","authors":["Pengcheng Sun","Erwu Liu","Wei Ni","Kanglei Yu","Xinyu Qu","Rui Wang","Yanlong Bi","Chuanchun Zhang","Abbas Jamalipour"],"pdf_url":"https://arxiv.org/pdf/2405.09276v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09263v1","updated":"2024-11-14T08:02:14Z","published":"2024-11-14T08:02:14Z","title":"Rethinking Weight-Averaged Model-merging","summary":"  Weight-averaged model-merging has emerged as a powerful approach in deep\nlearning, capable of enhancing model performance without fine-tuning or\nretraining. However, the underlying mechanisms that explain its effectiveness\nremain largely unexplored. In this paper, we investigate this technique from\nthree novel perspectives to provide deeper insights into how and why\nweight-averaged model-merging works: (1) we examine the intrinsic patterns\ncaptured by the learning of the model weights, through the visualizations of\ntheir patterns on several datasets, showing that these weights often encode\nstructured and interpretable patterns; (2) we investigate model ensemble\nmerging strategies based on averaging on weights versus averaging on features,\nproviding detailed analyses across diverse architectures and datasets; and (3)\nwe explore the impact on model-merging prediction stability in terms of\nchanging the parameter magnitude, revealing insights into the way of weight\naveraging works as regularization by showing the robustness across different\nparameter scales. Our findings shed light on the \"black box\" of weight-averaged\nmodel-merging, offering valuable insights and practical recommendations that\nadvance the model-merging process.\n","authors":["Hu Wang","Congbo Ma","Ibrahim Almakky","Ian Reid","Gustavo Carneiro","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2411.09263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14193v2","updated":"2024-11-14T07:58:03Z","published":"2024-10-18T06:07:22Z","title":"xPerT: Extended Persistence Transformer","summary":"  A persistence diagram provides a compact summary of persistent homology,\nwhich captures the topological features of a space at different scales.\nHowever, due to its nature as a set, incorporating it as a feature into a\nmachine learning framework is challenging. Several methods have been proposed\nto use persistence diagrams as input for machine learning models, but they\noften require complex preprocessing steps and extensive hyperparameter tuning.\nIn this paper, we propose a novel transformer architecture called the\n\\textit{Extended Persistence Transformer (xPerT)}, which is highly scalable\nthan the compared to Persformer, an existing transformer for persistence\ndiagrams. xPerT reduces GPU memory usage by over 90\\% and improves accuracy on\nmultiple datasets. Additionally, xPerT does not require complex preprocessing\nsteps or extensive hyperparameter tuning, making it easy to use in practice.\nOur code is available at https://github.com/sehunfromdaegu/xpert.\n","authors":["Sehun Kim"],"pdf_url":"https://arxiv.org/pdf/2410.14193v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09242v1","updated":"2024-11-14T07:16:23Z","published":"2024-11-14T07:16:23Z","title":"FluidML: Fast and Memory Efficient Inference Optimization","summary":"  Machine learning models deployed on edge devices have enabled numerous\nexciting new applications, such as humanoid robots, AR glasses, and autonomous\nvehicles. However, the computing resources available on these edge devices are\nnot catching up with the ever-growing number of parameters in these models. As\nthe models become bigger and more complicated, the novel yet sophisticated\nstructure challenges the inference runtime optimization. We present FluidML, a\ngeneric runtime memory management and optimization framework that can flexibly\ntransform the model execution blueprint to achieve faster and more\nmemory-efficient inference. Evaluations across different platforms show that\nFluidML can consistently reduce the end-to-end inference latency by up to\n25.38% for popular language models and reduce peak memory usage by up to\n41.47%, compared to state-of-the-art approaches. FluidML is of ~30K line of\ncodes, built for general-purpose usage, and will be released as an open-source\ninference runtime optimization framework to the community.\n","authors":["Jinjie Liu","Hang Qiu"],"pdf_url":"https://arxiv.org/pdf/2411.09242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09238v1","updated":"2024-11-14T07:13:08Z","published":"2024-11-14T07:13:08Z","title":"Rethinking the \"Heatmap + Monte Carlo Tree Search\" Paradigm for Solving\n  Large Scale TSP","summary":"  The Travelling Salesman Problem (TSP) remains a fundamental challenge in\ncombinatorial optimization, inspiring diverse algorithmic strategies. This\npaper revisits the \"heatmap + Monte Carlo Tree Search (MCTS)\" paradigm that has\nrecently gained traction for learning-based TSP solutions. Within this\nframework, heatmaps encode the likelihood of edges forming part of the optimal\ntour, and MCTS refines this probabilistic guidance to discover optimal\nsolutions. Contemporary approaches have predominantly emphasized the refinement\nof heatmap generation through sophisticated learning models, inadvertently\nsidelining the critical role of MCTS. Our extensive empirical analysis reveals\ntwo pivotal insights: 1) The configuration of MCTS strategies profoundly\ninfluences the solution quality, demanding meticulous tuning to leverage their\nfull potential; 2) Our findings demonstrate that a rudimentary and\nparameter-free heatmap, derived from the intrinsic $k$-nearest nature of TSP,\ncan rival or even surpass the performance of complicated heatmaps, with strong\ngeneralizability across various scales. Empirical evaluations across various\nTSP scales underscore the efficacy of our approach, achieving competitive\nresults. These observations challenge the prevailing focus on heatmap\nsophistication, advocating a reevaluation of the paradigm to harness both\ncomponents synergistically. Our code is available at:\nhttps://github.com/LOGO-CUHKSZ/rethink_mcts_tsp.\n","authors":["Xuanhao Pan","Chenguang Wang","Chaolong Ying","Ye Xue","Tianshu Yu"],"pdf_url":"https://arxiv.org/pdf/2411.09238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00996v2","updated":"2024-11-14T06:55:27Z","published":"2024-07-01T06:22:38Z","title":"Can Small Language Models Learn, Unlearn, and Retain Noise Patterns?","summary":"  Small Language Models (SLMs) are generally considered more compact versions\nof large language models (LLMs). This study investigates the ability of SLMs\nwith parameters between 1 and 3 billion to learn, retain, and subsequently\neliminate different types of noise present in the data. Four pre-trained SLMs\nwere utilized for this: Olmo 1B, Qwen1.5 1.8B, Gemma 2B, and Phi2 2.7B. The\nmodels were instruction-tuned on noise-free data and tested using in-context\nexamples to determine if they could learn noise through examples. Subsequently,\nnoise patterns were introduced in instruction tuning to evaluate the noise\nlearning, unlearning, and retention capabilities of the models. Olmo, the\nsmallest model, was highly sensitive to noise, quickly adapting to noisy\npatterns. Phi2 resisted learning character-level and transliteration noise,\nlikely due to its carefully curated, structured, and high-quality pretraining\ndata. Gemma excelled with transliteration noise, likely benefiting from its\nmultilingual pretraining. The findings can be used to develop robust training\nstrategies for SLMs.\n","authors":["Nicy Scaria","Silvester John Joseph Kennedy","Deepak Subramani"],"pdf_url":"https://arxiv.org/pdf/2407.00996v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15750v3","updated":"2024-11-14T06:33:26Z","published":"2024-09-24T05:12:10Z","title":"The Roles of Generative Artificial Intelligence in Internet of Electric\n  Vehicles","summary":"  With the advancements of generative artificial intelligence (GenAI) models,\ntheir capabilities are expanding significantly beyond content generation and\nthe models are increasingly being used across diverse applications.\nParticularly, GenAI shows great potential in addressing challenges in the\nelectric vehicle (EV) ecosystem ranging from charging management to\ncyber-attack prevention. In this paper, we specifically consider Internet of\nelectric vehicles (IoEV) and we categorize GenAI for IoEV into four different\nlayers namely, EV's battery layer, individual EV layer, smart grid layer, and\nsecurity layer. We introduce various GenAI techniques used in each layer of\nIoEV applications. Subsequently, public datasets available for training the\nGenAI models are summarized. Finally, we provide recommendations for future\ndirections. This survey not only categorizes the applications of GenAI in IoEV\nacross different layers but also serves as a valuable resource for researchers\nand practitioners by highlighting the design and implementation challenges\nwithin each layer. Furthermore, it provides a roadmap for future research\ndirections, enabling the development of more robust and efficient IoEV systems\nthrough the integration of advanced GenAI techniques.\n","authors":["Hanwen Zhang","Dusit Niyato","Wei Zhang","Changyuan Zhao","Hongyang Du","Abbas Jamalipour","Sumei Sun","Yiyang Pei"],"pdf_url":"https://arxiv.org/pdf/2409.15750v3.pdf","comment":"25 Pages"},{"id":"http://arxiv.org/abs/2411.09210v1","updated":"2024-11-14T06:14:39Z","published":"2024-11-14T06:14:39Z","title":"Classical Verification of Quantum Learning Advantages with Noises","summary":"  Classical verification of quantum learning allows classical clients to\nreliably leverage quantum computing advantages by interacting with untrusted\nquantum servers. Yet, current quantum devices available in practice suffers\nfrom a variety of noises and whether existed classical verification protocols\ncarry over to noisy scenarios remains unclear. Here, we propose an efficient\nclassical error rectification algorithm to reconstruct the noise-free results\ngiven by the quantum Fourier sampling circuit with practical constant-level\nnoises. In particular, we prove that the error rectification algorithm can\nrestore the heavy Fourier coefficients by using a small number of noisy samples\nthat scales logarithmically with the problem size. We apply this algorithm to\nthe agnostic parity learning task with uniform input marginal and prove that\nthis task can be accomplished in an efficient way on noisy quantum devices with\nour algorithm. In addition, we prove that a classical client with access to the\nrandom example oracle can verify the agnostic parity learning results from the\nnoisy quantum prover in an efficient way, under the condition that the Fourier\ncoefficients are sparse. Our results demonstrate the feasibility of classical\nverification of quantum learning advantages with noises, which provide a\nvaluable guide for both theoretical studies and practical applications with\ncurrent noisy intermediate scale quantum devices.\n","authors":["Yinghao Ma","Jiaxi Su","Dong-Ling Deng"],"pdf_url":"https://arxiv.org/pdf/2411.09210v1.pdf","comment":"13 pages 1 figure"},{"id":"http://arxiv.org/abs/2411.09199v1","updated":"2024-11-14T05:43:42Z","published":"2024-11-14T05:43:42Z","title":"Ghost-Connect Net: A Generalization-Enhanced Guidance For Sparse Deep\n  Networks Under Distribution Shifts","summary":"  Sparse deep neural networks (DNNs) excel in real-world applications like\nrobotics and computer vision, by reducing computational demands that hinder\nusability. However, recent studies aim to boost DNN efficiency by trimming\nredundant neurons or filters based on task relevance, but neglect their\nadaptability to distribution shifts. We aim to enhance these existing\ntechniques by introducing a companion network, Ghost Connect-Net (GC-Net), to\nmonitor the connections in the original network with distribution\ngeneralization advantage. GC-Net's weights represent connectivity measurements\nbetween consecutive layers of the original network. After pruning GC-Net, the\npruned locations are mapped back to the original network as pruned connections,\nallowing for the combination of magnitude and connectivity-based pruning\nmethods. Experimental results using common DNN benchmarks, such as CIFAR-10,\nFashion MNIST, and Tiny ImageNet show promising results for hybridizing the\nmethod, and using GC-Net guidance for later layers of a network and direct\npruning on earlier layers. We provide theoretical foundations for GC-Net's\napproach to improving generalization under distribution shifts.\n","authors":["Mary Isabelle Wisell","Salimeh Yasaei Sekeh"],"pdf_url":"https://arxiv.org/pdf/2411.09199v1.pdf","comment":"21 pages, 4 figures, 3 subfigures, 42 tables"},{"id":"http://arxiv.org/abs/2406.05964v2","updated":"2024-11-14T05:00:13Z","published":"2024-06-10T01:46:42Z","title":"Distributionally Robust Safe Sample Elimination under Covariate Shift","summary":"  We consider a machine learning setup where one training dataset is used to\ntrain multiple models across slightly different data distributions. This occurs\nwhen customized models are needed for various deployment environments. To\nreduce storage and training costs, we propose the DRSSS method, which combines\ndistributionally robust (DR) optimization and safe sample screening (SSS). The\nkey benefit of this method is that models trained on the reduced dataset will\nperform the same as those trained on the full dataset for all possible\ndifferent environments. In this paper, we focus on covariate shift as a type of\ndata distribution change and demonstrate the effectiveness of our method\nthrough experiments.\n","authors":["Hiroyuki Hanada","Tatsuya Aoyama","Satoshi Akahane","Tomonari Tanaka","Yoshito Okura","Yu Inatsu","Noriaki Hashimoto","Shion Takeno","Taro Murayama","Hanju Lee","Shinya Kojima","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/2406.05964v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.08318v2","updated":"2024-11-14T04:52:16Z","published":"2024-05-14T04:58:23Z","title":"No-Regret Learning of Nash Equilibrium for Black-Box Games via Gaussian\n  Processes","summary":"  This paper investigates the challenge of learning in black-box games, where\nthe underlying utility function is unknown to any of the agents. While there is\nan extensive body of literature on the theoretical analysis of algorithms for\ncomputing the Nash equilibrium with complete information about the game,\nstudies on Nash equilibrium in black-box games are less common. In this paper,\nwe focus on learning the Nash equilibrium when the only available information\nabout an agent's payoff comes in the form of empirical queries. We provide a\nno-regret learning algorithm that utilizes Gaussian processes to identify the\nequilibrium in such games. Our approach not only ensures a theoretical\nconvergence rate but also demonstrates effectiveness across a variety\ncollection of games through experimental validation.\n","authors":["Minbiao Han","Fengxue Zhang","Yuxin Chen"],"pdf_url":"https://arxiv.org/pdf/2405.08318v2.pdf","comment":"40th Conference on Uncertainty in Artificial Intelligence (UAI 2024)"},{"id":"http://arxiv.org/abs/2411.09184v1","updated":"2024-11-14T04:46:08Z","published":"2024-11-14T04:46:08Z","title":"Dynamic technology impact analysis: A multi-task learning approach to\n  patent citation prediction","summary":"  Machine learning (ML) models are valuable tools for analyzing the impact of\ntechnology using patent citation information. However, existing ML-based\nmethods often struggle to account for the dynamic nature of the technology\nimpact over time and the interdependencies of these impacts across different\nperiods. This study proposes a multi-task learning (MTL) approach to enhance\nthe prediction of technology impact across various time frames by leveraging\nknowledge sharing and simultaneously monitoring the evolution of technology\nimpact. First, we quantify the technology impacts and identify patterns through\ncitation analysis over distinct time periods. Next, we develop MTL models to\npredict citation counts using multiple patent indicators over time. Finally, we\nexamine the changes in key input indicators and their patterns over different\nperiods using the SHapley Additive exPlanation method. We also offer guidelines\nfor validating and interpreting the results by employing statistical methods\nand natural language processing techniques. A case study on battery\ntechnologies demonstrates that our approach not only deepens the understanding\nof technology impact, but also improves prediction accuracy, yielding valuable\ninsights for both academia and industry.\n","authors":["Youngjin Seol","Jaewoong Choi","Seunghyun Lee","Janghyeok Yoon"],"pdf_url":"https://arxiv.org/pdf/2411.09184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09181v1","updated":"2024-11-14T04:39:30Z","published":"2024-11-14T04:39:30Z","title":"DeBaTeR: Denoising Bipartite Temporal Graph for Recommendation","summary":"  Due to the difficulty of acquiring large-scale explicit user feedback,\nimplicit feedback (e.g., clicks or other interactions) is widely applied as an\nalternative source of data, where user-item interactions can be modeled as a\nbipartite graph. Due to the noisy and biased nature of implicit real-world\nuser-item interactions, identifying and rectifying noisy interactions are vital\nto enhance model performance and robustness. Previous works on purifying\nuser-item interactions in collaborative filtering mainly focus on mining the\ncorrelation between user/item embeddings and noisy interactions, neglecting the\nbenefit of temporal patterns in determining noisy interactions. Time\ninformation, while enhancing the model utility, also bears its natural\nadvantage in helping to determine noisy edges, e.g., if someone usually watches\nhorror movies at night and talk shows in the morning, a record of watching a\nhorror movie in the morning is more likely to be noisy interaction. Armed with\nthis observation, we introduce a simple yet effective mechanism for generating\ntime-aware user/item embeddings and propose two strategies for denoising\nbipartite temporal graph in recommender systems (DeBaTeR): the first is through\nreweighting the adjacency matrix (DeBaTeR-A), where a reliability score is\ndefined to reweight the edges through both soft assignment and hard assignment;\nthe second is through reweighting the loss function (DeBaTeR-L), where weights\nare generated to reweight user-item samples in the losses. Extensive\nexperiments have been conducted to demonstrate the efficacy of our methods and\nillustrate how time information indeed helps identifying noisy edges.\n","authors":["Xinyu He","Jose Sepulveda","Mostafa Rahmani","Alyssa Woo","Fei Wang","Hanghang Tong"],"pdf_url":"https://arxiv.org/pdf/2411.09181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09178v1","updated":"2024-11-14T04:36:12Z","published":"2024-11-14T04:36:12Z","title":"SAFES: Sequential Privacy and Fairness Enhancing Data Synthesis for\n  Responsible AI","summary":"  As data-driven and AI-based decision making gains widespread adoption in most\ndisciplines, it is crucial that both data privacy and decision fairness are\nappropriately addressed. While differential privacy (DP) provides a robust\nframework for guaranteeing privacy and several widely accepted methods have\nbeen proposed for improving fairness, the vast majority of existing literature\ntreats the two concerns independently. For methods that do consider privacy and\nfairness simultaneously, they often only apply to a specific machine learning\ntask, limiting their generalizability. In response, we introduce SAFES, a\nSequential PrivAcy and Fairness Enhancing data Synthesis procedure that\nsequentially combines DP data synthesis with a fairness-aware data\ntransformation. SAFES allows full control over the privacy-fairness-utility\ntrade-off via tunable privacy and fairness parameters. We illustrate SAFES by\ncombining AIM, a graphical model-based DP data synthesizer, with a popular\nfairness-aware data pre-processing transformation. Empirical evaluations on the\nAdult and COMPAS datasets demonstrate that for reasonable privacy loss,\nSAFES-generated synthetic data achieve significantly improved fairness metrics\nwith relatively low utility loss.\n","authors":["Spencer Giddens","Fang Liu"],"pdf_url":"https://arxiv.org/pdf/2411.09178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09175v1","updated":"2024-11-14T04:26:47Z","published":"2024-11-14T04:26:47Z","title":"Hybrid deep additive neural networks","summary":"  Traditional neural networks (multi-layer perceptrons) have become an\nimportant tool in data science due to their success across a wide range of\ntasks. However, their performance is sometimes unsatisfactory, and they often\nrequire a large number of parameters, primarily due to their reliance on the\nlinear combination structure. Meanwhile, additive regression has been a popular\nalternative to linear regression in statistics. In this work, we introduce\nnovel deep neural networks that incorporate the idea of additive regression.\nOur neural networks share architectural similarities with Kolmogorov-Arnold\nnetworks but are based on simpler yet flexible activation and basis functions.\nAdditionally, we introduce several hybrid neural networks that combine this\narchitecture with that of traditional neural networks. We derive their\nuniversal approximation properties and demonstrate their effectiveness through\nsimulation studies and a real-data application. The numerical results indicate\nthat our neural networks generally achieve better performance than traditional\nneural networks while using fewer parameters.\n","authors":["Gyu Min Kim","Jeong Min Jeon"],"pdf_url":"https://arxiv.org/pdf/2411.09175v1.pdf","comment":"29 pages, 13 figures"},{"id":"http://arxiv.org/abs/2411.09174v1","updated":"2024-11-14T04:23:28Z","published":"2024-11-14T04:23:28Z","title":"Advancing Diffusion Models: Alias-Free Resampling and Enhanced\n  Rotational Equivariance","summary":"  Recent advances in image generation, particularly via diffusion models, have\nled to impressive improvements in image synthesis quality. Despite this,\ndiffusion models are still challenged by model-induced artifacts and limited\nstability in image fidelity. In this work, we hypothesize that the primary\ncause of this issue is the improper resampling operation that introduces\naliasing in the diffusion model and a careful alias-free resampling dictated by\nimage processing theory can improve the model's performance in image synthesis.\nWe propose the integration of alias-free resampling layers into the UNet\narchitecture of diffusion models without adding extra trainable parameters,\nthereby maintaining computational efficiency. We then assess whether these\ntheory-driven modifications enhance image quality and rotational equivariance.\nOur experimental results on benchmark datasets, including CIFAR-10, MNIST, and\nMNIST-M, reveal consistent gains in image quality, particularly in terms of FID\nand KID scores. Furthermore, we propose a modified diffusion process that\nenables user-controlled rotation of generated images without requiring\nadditional training. Our findings highlight the potential of theory-driven\nenhancements such as alias-free resampling in generative models to improve\nimage quality while maintaining model efficiency and pioneer future research\ndirections to incorporate them into video-generating diffusion models, enabling\ndeeper exploration of the applications of alias-free resampling in generative\nmodeling.\n","authors":["Md Fahim Anjum"],"pdf_url":"https://arxiv.org/pdf/2411.09174v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.04204v2","updated":"2024-11-14T04:14:55Z","published":"2024-11-06T19:02:42Z","title":"Online Budgeted Matching with General Bids","summary":"  Online Budgeted Matching (OBM) is a classic problem with important\napplications in online advertising, online service matching, revenue\nmanagement, and beyond. Traditional online algorithms typically assume a small\nbid setting, where the maximum bid-to-budget ratio (\\kappa) is infinitesimally\nsmall. While recent algorithms have tried to address scenarios with non-small\nor general bids, they often rely on the Fractional Last Matching (FLM)\nassumption, which allows for accepting partial bids when the remaining budget\nis insufficient. This assumption, however, does not hold for many applications\nwith indivisible bids. In this paper, we remove the FLM assumption and tackle\nthe open problem of OBM with general bids. We first establish an upper bound of\n1-\\kappa on the competitive ratio for any deterministic online algorithm. We\nthen propose a novel meta algorithm, called MetaAd, which reduces to different\nalgorithms with first known provable competitive ratios parameterized by the\nmaximum bid-to-budget ratio \\kappa \\in [0, 1]. As a by-product, we extend\nMetaAd to the FLM setting and get provable competitive algorithms. Finally, we\napply our competitive analysis to the design learning-augmented algorithms.\n","authors":["Jianyi Yang","Pengfei Li","Adam Wierman","Shaolei Ren"],"pdf_url":"https://arxiv.org/pdf/2411.04204v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09170v1","updated":"2024-11-14T04:12:47Z","published":"2024-11-14T04:12:47Z","title":"Towards Scalable Handwriting Communication via EEG Decoding and Latent\n  Embedding Integration","summary":"  In recent years, brain-computer interfaces have made advances in decoding\nvarious motor-related tasks, including gesture recognition and movement\nclassification, utilizing electroencephalogram (EEG) data. These developments\nare fundamental in exploring how neural signals can be interpreted to recognize\nspecific physical actions. This study centers on a written alphabet\nclassification task, where we aim to decode EEG signals associated with\nhandwriting. To achieve this, we incorporate hand kinematics to guide the\nextraction of the consistent embeddings from high-dimensional neural recordings\nusing auxiliary variables (CEBRA). These CEBRA embeddings, along with the EEG,\nare processed by a parallel convolutional neural network model that extracts\nfeatures from both data sources simultaneously. The model classifies nine\ndifferent handwritten characters, including symbols such as exclamation marks\nand commas, within the alphabet. We evaluate the model using a quantitative\nfive-fold cross-validation approach and explore the structure of the embedding\nspace through visualizations. Our approach achieves a classification accuracy\nof 91 % for the nine-class task, demonstrating the feasibility of fine-grained\nhandwriting decoding from EEG.\n","authors":["Jun-Young Kim","Deok-Seon Kim","Seo-Hyun Lee"],"pdf_url":"https://arxiv.org/pdf/2411.09170v1.pdf","comment":"4 pages, 2 figures, 1 table, Name of Conference: International\n  Conference on Brain-Computer Interface"},{"id":"http://arxiv.org/abs/2411.09160v1","updated":"2024-11-14T03:28:02Z","published":"2024-11-14T03:28:02Z","title":"Rationality based Innate-Values-driven Reinforcement Learning","summary":"  Innate values describe agents' intrinsic motivations, which reflect their\ninherent interests and preferences to pursue goals and drive them to develop\ndiverse skills satisfying their various needs. The essence of reinforcement\nlearning (RL) is learning from interaction based on reward-driven behaviors,\nmuch like natural agents. It is an excellent model to describe the\ninnate-values-driven (IV) behaviors of AI agents. Especially developing the\nawareness of the AI agent through balancing internal and external utilities\nbased on its needs in different tasks is a crucial problem for individuals\nlearning to support AI agents integrating human society with safety and harmony\nin the long term. This paper proposes a hierarchical compound intrinsic value\nreinforcement learning model -- innate-values-driven reinforcement learning\ntermed IVRL to describe the complex behaviors of AI agents' interaction. We\nformulated the IVRL model and proposed two IVRL models: DQN and A2C. By\ncomparing them with benchmark algorithms such as DQN, DDQN, A2C, and PPO in the\nRole-Playing Game (RPG) reinforcement learning test platform VIZDoom, we\ndemonstrated that rationally organizing various individual needs can\neffectively achieve better performance.\n","authors":["Qin Yang"],"pdf_url":"https://arxiv.org/pdf/2411.09160v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2401.05572"},{"id":"http://arxiv.org/abs/2411.09152v1","updated":"2024-11-14T03:07:57Z","published":"2024-11-14T03:07:57Z","title":"GRAINRec: Graph and Attention Integrated Approach for Real-Time\n  Session-Based Item Recommendations","summary":"  Recent advancements in session-based recommendation models using deep\nlearning techniques have demonstrated significant performance improvements.\nWhile they can enhance model sophistication and improve the relevance of\nrecommendations, they also make it challenging to implement a scalable\nreal-time solution. To addressing this challenge, we propose GRAINRec- a Graph\nand Attention Integrated session-based recommendation model that generates\nrecommendations in real-time. Our scope of work is item recommendations in\nonline retail where a session is defined as an ordered sequence of digital\nguest actions, such as page views or adds to cart. The proposed model generates\nrecommendations by considering the importance of all items in the session\ntogether, letting us predict relevant recommendations dynamically as the\nsession evolves. We also propose a heuristic approach to implement real-time\ninferencing that meets Target platform's service level agreement (SLA). The\nproposed architecture lets us predict relevant recommendations dynamically as\nthe session evolves, rather than relying on pre-computed recommendations for\neach item. Evaluation results of the proposed model show an average improvement\nof 1.5% across all offline evaluation metrics. A/B tests done over a 2 week\nduration showed an increase of 10% in click through rate and 9% increase in\nattributable demand. Extensive ablation studies are also done to understand our\nmodel performance for different parameters.\n","authors":["Bhavtosh Rath","Pushkar Chennu","David Relyea","Prathyusha Kanmanth Reddy","Amit Pande"],"pdf_url":"https://arxiv.org/pdf/2411.09152v1.pdf","comment":"Accepted to the 2024 IEEE International Conference on Big Data (IEEE\n  BigData 2024)"},{"id":"http://arxiv.org/abs/2411.09142v1","updated":"2024-11-14T02:52:47Z","published":"2024-11-14T02:52:47Z","title":"Laplace Transform Interpretation of Differential Privacy","summary":"  We introduce a set of useful expressions of Differential Privacy (DP) notions\nin terms of the Laplace transform of the privacy loss distribution. Its bare\nform expression appears in several related works on analyzing DP, either as an\nintegral or an expectation. We show that recognizing the expression as a\nLaplace transform unlocks a new way to reason about DP properties by exploiting\nthe duality between time and frequency domains. Leveraging our interpretation,\nwe connect the $(q, \\rho(q))$-R\\'enyi DP curve and the $(\\epsilon,\n\\delta(\\epsilon))$-DP curve as being the Laplace and inverse-Laplace transforms\nof one another. This connection shows that the R\\'enyi divergence is\nwell-defined for complex orders $q = \\gamma + i \\omega$. Using our Laplace\ntransform-based analysis, we also prove an adaptive composition theorem for\n$(\\epsilon, \\delta)$-DP guarantees that is exactly tight (i.e., matches even in\nconstants) for all values of $\\epsilon$. Additionally, we resolve an issue\nregarding symmetry of $f$-DP on subsampling that prevented equivalence across\nall functional DP notions.\n","authors":["Rishav Chourasia","Uzair Javaid","Biplap Sikdar"],"pdf_url":"https://arxiv.org/pdf/2411.09142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09417v3","updated":"2024-11-14T02:00:33Z","published":"2024-01-17T18:56:18Z","title":"Vision Mamba: Efficient Visual Representation Learning with\n  Bidirectional State Space Model","summary":"  Recently the state space models (SSMs) with efficient hardware-aware designs,\ni.e., the Mamba deep learning model, have shown great potential for long\nsequence modeling. Meanwhile building efficient and generic vision backbones\npurely upon SSMs is an appealing direction. However, representing visual data\nis challenging for SSMs due to the position-sensitivity of visual data and the\nrequirement of global context for visual understanding. In this paper, we show\nthat the reliance on self-attention for visual representation learning is not\nnecessary and propose a new generic vision backbone with bidirectional Mamba\nblocks (Vim), which marks the image sequences with position embeddings and\ncompresses the visual representation with bidirectional state space models. On\nImageNet classification, COCO object detection, and ADE20k semantic\nsegmentation tasks, Vim achieves higher performance compared to\nwell-established vision transformers like DeiT, while also demonstrating\nsignificantly improved computation & memory efficiency. For example, Vim is\n2.8$\\times$ faster than DeiT and saves 86.8% GPU memory when performing batch\ninference to extract features on images with a resolution of 1248$\\times$1248.\nThe results demonstrate that Vim is capable of overcoming the computation &\nmemory constraints on performing Transformer-style understanding for\nhigh-resolution images and it has great potential to be the next-generation\nbackbone for vision foundation models. Code is available at\nhttps://github.com/hustvl/Vim.\n","authors":["Lianghui Zhu","Bencheng Liao","Qian Zhang","Xinlong Wang","Wenyu Liu","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2401.09417v3.pdf","comment":"Vision Mamba (Vim) is accepted by ICML 2024. Code is available at\n  https://github.com/hustvl/Vim"},{"id":"http://arxiv.org/abs/2411.09127v1","updated":"2024-11-14T02:00:22Z","published":"2024-11-14T02:00:22Z","title":"Complexity-Aware Training of Deep Neural Networks for Optimal Structure\n  Discovery","summary":"  We propose a novel algorithm for combined unit/filter and layer pruning of\ndeep neural networks that functions during training and without requiring a\npre-trained network to apply. Our algorithm optimally trades-off learning\naccuracy and pruning levels while balancing layer vs. unit/filter pruning and\ncomputational vs. parameter complexity using only three user-defined\nparameters, which are easy to interpret and tune. The optimal network structure\nis found as the solution of a stochastic optimization problem over the network\nweights and the parameters of variational Bernoulli distributions for 0/1\nRandom Variables scaling the units and layers of the network. Pruning occurs\nwhen a variational parameter converges to 0 rendering the corresponding\nstructure permanently inactive, thus saving computations during training and\nprediction. A key contribution of our approach is to define a cost function\nthat combines the objectives of prediction accuracy and network pruning in a\ncomputational/parameter complexity-aware manner and the automatic selection of\nthe many regularization parameters. We show that the solutions of the\noptimization problem to which the algorithm converges are deterministic\nnetworks. We analyze the ODE system that underlies our stochastic optimization\nalgorithm and establish domains of attraction around zero for the dynamics of\nthe network parameters. These results provide theoretical support for safely\npruning units/filters and/or layers during training and lead to practical\npruning conditions. We evaluate our method on the CIFAR-10/100 and ImageNet\ndatasets using ResNet architectures and demonstrate that our method improves\nupon layer only or unit only pruning and favorably competes with combined\nunit/filter and layer pruning algorithms requiring pre-trained networks with\nrespect to pruning ratios and test accuracy.\n","authors":["Valentin Frank Ingmar Guenter","Athanasios Sideris"],"pdf_url":"https://arxiv.org/pdf/2411.09127v1.pdf","comment":"28 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2411.09120v1","updated":"2024-11-14T01:41:00Z","published":"2024-11-14T01:41:00Z","title":"Neural Graph Simulator for Complex Systems","summary":"  Numerical simulation is a predominant tool for studying the dynamics in\ncomplex systems, but large-scale simulations are often intractable due to\ncomputational limitations. Here, we introduce the Neural Graph Simulator (NGS)\nfor simulating time-invariant autonomous systems on graphs. Utilizing a graph\nneural network, the NGS provides a unified framework to simulate diverse\ndynamical systems with varying topologies and sizes without constraints on\nevaluation times through its non-uniform time step and autoregressive approach.\nThe NGS offers significant advantages over numerical solvers by not requiring\nprior knowledge of governing equations and effectively handling noisy or\nmissing data with a robust training scheme. It demonstrates superior\ncomputational efficiency over conventional methods, improving performance by\nover $10^5$ times in stiff problems. Furthermore, it is applied to real traffic\ndata, forecasting traffic flow with state-of-the-art accuracy. The versatility\nof the NGS extends beyond the presented cases, offering numerous potential\navenues for enhancement.\n","authors":["Hoyun Choi","Sungyeop Lee","B. Kahng","Junghyo Jo"],"pdf_url":"https://arxiv.org/pdf/2411.09120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09118v1","updated":"2024-11-14T01:37:24Z","published":"2024-11-14T01:37:24Z","title":"FxTS-Net: Fixed-Time Stable Learning Framework for Neural ODEs","summary":"  Neural Ordinary Differential Equations (Neural ODEs), as a novel category of\nmodeling big data methods, cleverly link traditional neural networks and\ndynamical systems. However, it is challenging to ensure the dynamics system\nreaches a correctly predicted state within a user-defined fixed time. To\naddress this problem, we propose a new method for training Neural ODEs using\nfixed-time stability (FxTS) Lyapunov conditions. Our framework, called\nFxTS-Net, is based on the novel FxTS loss (FxTS-Loss) designed on Lyapunov\nfunctions, which aims to encourage convergence to accurate predictions in a\nuser-defined fixed time. We also provide an innovative approach for\nconstructing Lyapunov functions to meet various tasks and network architecture\nrequirements, achieved by leveraging supervised information during training. By\ndeveloping a more precise time upper bound estimation for bounded\nnon-vanishingly perturbed systems, we demonstrate that minimizing FxTS-Loss not\nonly guarantees FxTS behavior of the dynamics but also input perturbation\nrobustness. For optimising FxTS-Loss, we also propose a learning algorithm, in\nwhich the simulated perturbation sampling method can capture sample points in\ncritical regions to approximate FxTS-Loss. Experimentally, we find that\nFxTS-Net provides better prediction performance and better robustness under\ninput perturbation.\n","authors":["Chaoyang Luo","Yan Zou","Wanying Li","Nanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2411.09118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09117v1","updated":"2024-11-14T01:37:02Z","published":"2024-11-14T01:37:02Z","title":"Efficiently learning and sampling multimodal distributions with\n  data-based initialization","summary":"  We consider the problem of sampling a multimodal distribution with a Markov\nchain given a small number of samples from the stationary measure. Although\nmixing can be arbitrarily slow, we show that if the Markov chain has a $k$th\norder spectral gap, initialization from a set of $\\tilde O(k/\\varepsilon^2)$\nsamples from the stationary distribution will, with high probability over the\nsamples, efficiently generate a sample whose conditional law is\n$\\varepsilon$-close in TV distance to the stationary measure. In particular,\nthis applies to mixtures of $k$ distributions satisfying a Poincar\\'e\ninequality, with faster convergence when they satisfy a log-Sobolev inequality.\nOur bounds are stable to perturbations to the Markov chain, and in particular\nwork for Langevin diffusion over $\\mathbb R^d$ with score estimation error, as\nwell as Glauber dynamics combined with approximation error from\npseudolikelihood estimation. This justifies the success of data-based\ninitialization for score matching methods despite slow mixing for the data\ndistribution, and improves and generalizes the results of Koehler and Vuong\n(2023) to have linear, rather than exponential, dependence on $k$ and apply to\narbitrary semigroups. As a consequence of our results, we show for the first\ntime that a natural class of low-complexity Ising measures can be efficiently\nlearned from samples.\n","authors":["Frederic Koehler","Holden Lee","Thuy-Duong Vuong"],"pdf_url":"https://arxiv.org/pdf/2411.09117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13306v4","updated":"2024-11-14T01:18:01Z","published":"2023-01-30T21:59:30Z","title":"Autobidders with Budget and ROI Constraints: Efficiency, Regret, and\n  Pacing Dynamics","summary":"  We study a game between autobidding algorithms that compete in an online\nadvertising platform. Each autobidder is tasked with maximizing its\nadvertiser's total value over multiple rounds of a repeated auction, subject to\nbudget and return-on-investment constraints. We propose a gradient-based\nlearning algorithm that is guaranteed to satisfy all constraints and achieves\nvanishing individual regret. Our algorithm uses only bandit feedback and can be\nused with the first- or second-price auction, as well as with any\n\"intermediate\" auction format. Our main result is that when these autobidders\nplay against each other, the resulting expected liquid welfare over all rounds\nis at least half of the expected optimal liquid welfare achieved by any\nallocation. This holds whether or not the bidding dynamics converges to an\nequilibrium.\n","authors":["Brendan Lucier","Sarath Pattathil","Aleksandrs Slivkins","Mengxiao Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.13306v4.pdf","comment":"Appeared at COLT 2024. Numerical experiments added since Jun'24\n  version"},{"id":"http://arxiv.org/abs/2411.09111v1","updated":"2024-11-14T00:59:13Z","published":"2024-11-14T00:59:13Z","title":"Reducing Reasoning Costs - The Path of Optimization for Chain of Thought\n  via Sparse Attention Mechanism","summary":"  In order to address the chain of thought in the large language model\ninference cost surge, this research proposes to use a sparse attention\nmechanism that only focuses on a few relevant tokens. The researcher\nconstructed a new attention mechanism and used GiantRabbit trained with custom\nGPTs as an experimental tool. The experiment tested and compared the reasoning\ntime, correctness score and chain of thought length of this model and o1\nPreview in solving the linear algebra test questions of MIT OpenCourseWare. The\nresults show that GiantRabbit's reasoning time and chain of thought length are\nsignificantly lower than o1 Preview, confirming the feasibility of the sparse\nattention mechanism in reducing chain of thought reasoning. Detailed\narchitectural details and experimental process have been uploaded to Github,\nthe link is:https://github.com/brucewang123456789/GeniusTrail.git.\n","authors":["Libo Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09111v1.pdf","comment":"The main text is 9 pages, totaling 13 pages; 5 figures, 3 tables;\n  preprints have been submitted to NeurIPS 2024 Workshop MusIML and OpenReview"},{"id":"http://arxiv.org/abs/2410.13986v2","updated":"2024-11-14T00:09:09Z","published":"2024-10-17T19:32:25Z","title":"Recurrent Neural Goodness-of-Fit Test for Time Series","summary":"  Time series data are crucial across diverse domains such as finance and\nhealthcare, where accurate forecasting and decision-making rely on advanced\nmodeling techniques. While generative models have shown great promise in\ncapturing the intricate dynamics inherent in time series, evaluating their\nperformance remains a major challenge. Traditional evaluation metrics fall\nshort due to the temporal dependencies and potential high dimensionality of the\nfeatures. In this paper, we propose the REcurrent NeurAL (RENAL)\nGoodness-of-Fit test, a novel and statistically rigorous framework for\nevaluating generative time series models. By leveraging recurrent neural\nnetworks, we transform the time series into conditionally independent data\npairs, enabling the application of a chi-square-based goodness-of-fit test to\nthe temporal dependencies within the data. This approach offers a robust,\ntheoretically grounded solution for assessing the quality of generative models,\nparticularly in settings with limited time sequences. We demonstrate the\nefficacy of our method across both synthetic and real-world datasets,\noutperforming existing methods in terms of reliability and accuracy. Our method\nfills a critical gap in the evaluation of time series generative models,\noffering a tool that is both practical and adaptable to high-stakes\napplications.\n","authors":["Aoran Zhang","Wenbin Zhou","Liyan Xie","Shixiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.13986v2.pdf","comment":"27 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.09678v1","updated":"2024-11-14T18:44:31Z","published":"2024-11-14T18:44:31Z","title":"NeuralDEM -- Real-time Simulation of Industrial Particulate Flows","summary":"  Advancements in computing power have made it possible to numerically simulate\nlarge-scale fluid-mechanical and/or particulate systems, many of which are\nintegral to core industrial processes. Among the different numerical methods\navailable, the discrete element method (DEM) provides one of the most accurate\nrepresentations of a wide range of physical systems involving granular and\ndiscontinuous materials. Consequently, DEM has become a widely accepted\napproach for tackling engineering problems connected to granular flows and\npowder mechanics. Additionally, DEM can be integrated with grid-based\ncomputational fluid dynamics (CFD) methods, enabling the simulation of chemical\nprocesses taking place, e.g., in fluidized beds. However, DEM is\ncomputationally intensive because of the intrinsic multiscale nature of\nparticulate systems, restricting simulation duration or number of particles.\nTowards this end, NeuralDEM presents an end-to-end approach to replace slow\nnumerical DEM routines with fast, adaptable deep learning surrogates. NeuralDEM\nis capable of picturing long-term transport processes across different regimes\nusing macroscopic observables without any reference to microscopic model\nparameters. First, NeuralDEM treats the Lagrangian discretization of DEM as an\nunderlying continuous field, while simultaneously modeling macroscopic behavior\ndirectly as additional auxiliary fields. Second, NeuralDEM introduces\nmulti-branch neural operators scalable to real-time modeling of\nindustrially-sized scenarios - from slow and pseudo-steady to fast and\ntransient. Such scenarios have previously posed insurmountable challenges for\ndeep learning models. Notably, NeuralDEM faithfully models coupled CFD-DEM\nfluidized bed reactors of 160k CFD cells and 500k DEM particles for\ntrajectories of 28s. NeuralDEM will open many new doors to advanced engineering\nand much faster process cycles.\n","authors":["Benedikt Alkin","Tobias Kronlachner","Samuele Papa","Stefan Pirker","Thomas Lichtenegger","Johannes Brandstetter"],"pdf_url":"https://arxiv.org/pdf/2411.09678v1.pdf","comment":"Project page: https://nx-ai.github.io/NeuralDEM/"},{"id":"http://arxiv.org/abs/2411.09267v1","updated":"2024-11-14T08:08:25Z","published":"2024-11-14T08:08:25Z","title":"Towards efficient compression and communication for prototype-based\n  decentralized learning","summary":"  In prototype-based federated learning, the exchange of model parameters\nbetween clients and the master server is replaced by transmission of prototypes\nor quantized versions of the data samples to the aggregation server. A fully\ndecentralized deployment of prototype-based learning, without a central\nagregartor of prototypes, is more robust upon network failures and reacts\nfaster to changes in the statistical distribution of the data, suggesting\npotential advantages and quick adaptation in dynamic learning tasks, e.g., when\nthe data sources are IoT devices or when data is non-iid. In this paper, we\nconsider the problem of designing a communication-efficient decentralized\nlearning system based on prototypes. We address the challenge of prototype\nredundancy by leveraging on a twofold data compression technique, i.e., sending\nonly update messages if the prototypes are informationtheoretically useful (via\nthe Jensen-Shannon distance), and using clustering on the prototypes to\ncompress the update messages used in the gossip protocol. We also use parallel\ninstead of sequential gossiping, and present an analysis of its\nage-of-information (AoI). Our experimental results show that, with these\nimprovements, the communications load can be substantially reduced without\ndecreasing the convergence rate of the learning algorithm.\n","authors":["Pablo Fern√°ndez-Pi√±eiro","Manuel Fer√°ndez-Veiga","Rebeca P. D√≠az-Redondo","Ana Fern√°ndez-Vilas","Mart√≠n Gonz√°lez-Soto"],"pdf_url":"https://arxiv.org/pdf/2411.09267v1.pdf","comment":"15 pages, 2 tables, 7 figures, 6 algorithms"},{"id":"http://arxiv.org/abs/2411.09152v1","updated":"2024-11-14T03:07:57Z","published":"2024-11-14T03:07:57Z","title":"GRAINRec: Graph and Attention Integrated Approach for Real-Time\n  Session-Based Item Recommendations","summary":"  Recent advancements in session-based recommendation models using deep\nlearning techniques have demonstrated significant performance improvements.\nWhile they can enhance model sophistication and improve the relevance of\nrecommendations, they also make it challenging to implement a scalable\nreal-time solution. To addressing this challenge, we propose GRAINRec: a Graph\nand Attention Integrated session-based recommendation model that generates\nrecommendations in real-time. Our scope of work is item recommendations in\nonline retail where a session is defined as an ordered sequence of digital\nguest actions, such as page views or adds to cart. The proposed model generates\nrecommendations by considering the importance of all items in the session\ntogether, letting us predict relevant recommendations dynamically as the\nsession evolves. We also propose a heuristic approach to implement real-time\ninferencing that meets Target platform's service level agreement (SLA). The\nproposed architecture lets us predict relevant recommendations dynamically as\nthe session evolves, rather than relying on pre-computed recommendations for\neach item. Evaluation results of the proposed model show an average improvement\nof 1.5% across all offline evaluation metrics. A/B tests done over a 2 week\nduration showed an increase of 10% in click through rate and 9% increase in\nattributable demand. Extensive ablation studies are also done to understand our\nmodel performance for different parameters.\n","authors":["Bhavtosh Rath","Pushkar Chennu","David Relyea","Prathyusha Kanmanth Reddy","Amit Pande"],"pdf_url":"https://arxiv.org/pdf/2411.09152v1.pdf","comment":"Accepted to the 2024 IEEE International Conference on Big Data (IEEE\n  BigData 2024)"},{"id":"http://arxiv.org/abs/2411.09111v1","updated":"2024-11-14T00:59:13Z","published":"2024-11-14T00:59:13Z","title":"Reducing Reasoning Costs -- The Path of Optimization for Chain of\n  Thought via Sparse Attention Mechanism","summary":"  In order to address the chain of thought in the large language model\ninference cost surge, this research proposes to use a sparse attention\nmechanism that only focuses on a few relevant tokens. The researcher\nconstructed a new attention mechanism and used GiantRabbit trained with custom\nGPTs as an experimental tool. The experiment tested and compared the reasoning\ntime, correctness score and chain of thought length of this model and o1\nPreview in solving the linear algebra test questions of MIT OpenCourseWare. The\nresults show that GiantRabbit's reasoning time and chain of thought length are\nsignificantly lower than o1 Preview, confirming the feasibility of the sparse\nattention mechanism in reducing chain of thought reasoning. Detailed\narchitectural details and experimental process have been uploaded to Github,\nthe link is:https://github.com/brucewang123456789/GeniusTrail.git.\n","authors":["Libo Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09111v1.pdf","comment":"The main text is 9 pages, totaling 13 pages; 5 figures, 3 tables;\n  preprints have been submitted to NeurIPS 2024 Workshop MusIML and OpenReview"}]}}